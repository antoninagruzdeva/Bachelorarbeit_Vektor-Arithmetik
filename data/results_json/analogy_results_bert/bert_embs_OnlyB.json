[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.8644824624061584,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.7352026700973511,
            "answer": "soundtrack",
            "hit": false
          },
          {
            "score": 0.7295689582824707,
            "answer": "recording",
            "hit": false
          },
          {
            "score": 0.7289184927940369,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.7241525650024414,
            "answer": "recordings",
            "hit": false
          },
          {
            "score": 0.7237745523452759,
            "answer": "compilation",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8644824922084808,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.9009242653846741,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.8155382871627808,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8056777119636536,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8047682046890259,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7863502502441406,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7809638977050781,
            "answer": "applicant",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9009242653846741,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.8565005660057068,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.8103245496749878,
            "answer": "region",
            "hit": false
          },
          {
            "score": 0.7307422161102295,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7225697040557861,
            "answer": "local",
            "hit": false
          },
          {
            "score": 0.7192504405975342,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.7185463905334473,
            "answer": "vicinity",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8565005660057068,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.81975919008255,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.7956697940826416,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.7778321504592896,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7739416360855103,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7534350752830505,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.7375367879867554,
            "answer": "automobiles",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8197591304779053,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.8267761468887329,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.8113839626312256,
            "answer": "university",
            "hit": false
          },
          {
            "score": 0.7907925844192505,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7326310276985168,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.7291486263275146,
            "answer": "academy",
            "hit": false
          },
          {
            "score": 0.7259975671768188,
            "answer": "campus",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8267762064933777,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8414276242256165,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7532263994216919,
            "answer": "committee",
            "hit": false
          },
          {
            "score": 0.7240277528762817,
            "answer": "assembly",
            "hit": false
          },
          {
            "score": 0.7198300957679749,
            "answer": "commission",
            "hit": false
          },
          {
            "score": 0.7144585847854614,
            "answer": "board",
            "hit": false
          },
          {
            "score": 0.713279128074646,
            "answer": "corporation",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8414276242256165,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.9011974334716797,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.806989312171936,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.8059214949607849,
            "answer": "clients",
            "hit": false
          },
          {
            "score": 0.803330659866333,
            "answer": "client",
            "hit": false
          },
          {
            "score": 0.7968368530273438,
            "answer": "buyer",
            "hit": false
          },
          {
            "score": 0.7952539920806885,
            "answer": "vendor",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9011974930763245,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7994188070297241,
            "answer": "night",
            "hit": false
          },
          {
            "score": 0.7698453068733215,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.759762167930603,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7572205066680908,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.74506676197052,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.7424029111862183,
            "answer": "evening",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7698453068733215,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.8017896413803101,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7606333494186401,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.7518199682235718,
            "answer": "murder",
            "hit": false
          },
          {
            "score": 0.7507700324058533,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.743732750415802,
            "answer": "suicide",
            "hit": false
          },
          {
            "score": 0.740431010723114,
            "answer": "killing",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8017896115779877,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.871290922164917,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.7889171242713928,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.7252346277236938,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.7104392051696777,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7069371938705444,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.706177830696106,
            "answer": "office",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.871290922164917,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.820833146572113,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8068602681159973,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8064819574356079,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.7974133491516113,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7781939506530762,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7709943056106567,
            "answer": "developer",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8064819276332855,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.8425065875053406,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7713639736175537,
            "answer": "differential",
            "hit": false
          },
          {
            "score": 0.7691789269447327,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7604545950889587,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7564893960952759,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.7546565532684326,
            "answer": "distinguishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8425065875053406,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8690990805625916,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7811530828475952,
            "answer": "directing",
            "hit": false
          },
          {
            "score": 0.7694095373153687,
            "answer": "directs",
            "hit": false
          },
          {
            "score": 0.7664947509765625,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7622211575508118,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7566249966621399,
            "answer": "chairman",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8690990805625916,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.859031081199646,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.7271926403045654,
            "answer": "incident",
            "hit": false
          },
          {
            "score": 0.7260274887084961,
            "answer": "tournament",
            "hit": false
          },
          {
            "score": 0.7258241176605225,
            "answer": "festival",
            "hit": false
          },
          {
            "score": 0.7243248820304871,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.7237482070922852,
            "answer": "venue",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8590310215950012,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.874977707862854,
            "answer": "instance",
            "hit": false
          },
          {
            "score": 0.8687595129013062,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.7416287660598755,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.7388077974319458,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.7329233884811401,
            "answer": "exception",
            "hit": false
          },
          {
            "score": 0.7252377867698669,
            "answer": "illustration",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8687595129013062,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7798193693161011,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.738646924495697,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.731156587600708,
            "answer": "reality",
            "hit": false
          },
          {
            "score": 0.7276492714881897,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.7161043286323547,
            "answer": "assertion",
            "hit": false
          },
          {
            "score": 0.7133613228797913,
            "answer": "truths",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7798193991184235,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.8484916090965271,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.7765336632728577,
            "answer": "colleague",
            "hit": false
          },
          {
            "score": 0.7610671520233154,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7593350410461426,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.7585520148277283,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7575234174728394,
            "answer": "neighbour",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8484916090965271,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7899547219276428,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.778424859046936,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7676933407783508,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.7529815435409546,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.7487075328826904,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7361624240875244,
            "answer": "heaven",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7899547219276428,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8139969110488892,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.8006747961044312,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.7317718863487244,
            "answer": "authorities",
            "hit": false
          },
          {
            "score": 0.7307775020599365,
            "answer": "administration",
            "hit": false
          },
          {
            "score": 0.7291184663772583,
            "answer": "state",
            "hit": false
          },
          {
            "score": 0.7276989221572876,
            "answer": "military",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8139969706535339,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.8318973183631897,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.7510126829147339,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.7446164488792419,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.7397217154502869,
            "answer": "minutes",
            "hit": false
          },
          {
            "score": 0.7382346391677856,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7376064658164978,
            "answer": "afternoon",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8318973183631897,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.8307483196258545,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.8165513277053833,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.79961758852005,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7580933570861816,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.7543278336524963,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.7490841150283813,
            "answer": "notions",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8307483494281769,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.8385054469108582,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.7654755115509033,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7564325332641602,
            "answer": "dialect",
            "hit": false
          },
          {
            "score": 0.7362682223320007,
            "answer": "interpreter",
            "hit": false
          },
          {
            "score": 0.7274118661880493,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.7173192501068115,
            "answer": "syntax",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8385054767131805,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.8111249208450317,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7359194159507751,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.725117564201355,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.7182949781417847,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.7098134756088257,
            "answer": "ordinance",
            "hit": false
          },
          {
            "score": 0.7035226821899414,
            "answer": "statutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.811124861240387,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.8885610103607178,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7599232196807861,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7521191835403442,
            "answer": "participant",
            "hit": false
          },
          {
            "score": 0.7346371412277222,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7248547077178955,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7241908311843872,
            "answer": "supporter",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8885610699653625,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8555895090103149,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.835185170173645,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.8170998096466064,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.793064296245575,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.7700594067573547,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.7608919739723206,
            "answer": "decade",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.835185170173645,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.8302822709083557,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.7994188070297241,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.7884368300437927,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.770266056060791,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7622989416122437,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7401750087738037,
            "answer": "evenings",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7884368896484375,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.8481666445732117,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7316462993621826,
            "answer": "apartment",
            "hit": false
          },
          {
            "score": 0.7175436019897461,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.7120763063430786,
            "answer": "headquarters",
            "hit": false
          },
          {
            "score": 0.708694338798523,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.706177830696106,
            "answer": "department",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8481666445732117,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.843325674533844,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7731773853302002,
            "answer": "era",
            "hit": false
          },
          {
            "score": 0.7262874245643616,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.7246601581573486,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.7194925546646118,
            "answer": "phase",
            "hit": false
          },
          {
            "score": 0.7118967771530151,
            "answer": "eras",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.843325674533844,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.8820763826370239,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7600159645080566,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7438198328018188,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.7406581044197083,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7386939525604248,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7346110343933105,
            "answer": "athlete",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8820763826370239,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.857046365737915,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.7698667049407959,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.7638323903083801,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.7593204975128174,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.7498102784156799,
            "answer": "residents",
            "hit": false
          },
          {
            "score": 0.7398080825805664,
            "answer": "populated",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8570464253425598,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.8689195513725281,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.791073739528656,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.7708796262741089,
            "answer": "issue",
            "hit": false
          },
          {
            "score": 0.7676928043365479,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.7640476226806641,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7639373540878296,
            "answer": "trouble",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8689195513725281,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.8913757801055908,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.7437615394592285,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.7315893173217773,
            "answer": "merchandise",
            "hit": false
          },
          {
            "score": 0.7290970087051392,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7287144064903259,
            "answer": "invention",
            "hit": false
          },
          {
            "score": 0.7272711396217346,
            "answer": "derivative",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8913758397102356,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.8797117471694946,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.7811137437820435,
            "answer": "asset",
            "hit": false
          },
          {
            "score": 0.7697100043296814,
            "answer": "nutrient",
            "hit": false
          },
          {
            "score": 0.7643053531646729,
            "answer": "firearm",
            "hit": false
          },
          {
            "score": 0.7633303999900818,
            "answer": "repository",
            "hit": false
          },
          {
            "score": 0.762759268283844,
            "answer": "fuels",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8797117471694946,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7951056957244873,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.7767574787139893,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7694068551063538,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7406179904937744,
            "answer": "stream",
            "hit": false
          },
          {
            "score": 0.729520320892334,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.7276856899261475,
            "answer": "valley",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7951056957244873,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8028563261032104,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7806305885314941,
            "answer": "street",
            "hit": false
          },
          {
            "score": 0.7724869251251221,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.7569975256919861,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7377707362174988,
            "answer": "lane",
            "hit": false
          },
          {
            "score": 0.7300031185150146,
            "answer": "route",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8028563857078552,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.8738459348678589,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7457602024078369,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.738553524017334,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.7265105247497559,
            "answer": "position",
            "hit": false
          },
          {
            "score": 0.7238976955413818,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.7238750457763672,
            "answer": "involvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8738459050655365,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8156399726867676,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.8046100735664368,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.7965739965438843,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.7908280491828918,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.7566766738891602,
            "answer": "biology",
            "hit": false
          },
          {
            "score": 0.7522562742233276,
            "answer": "physics",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8046101331710815,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.9041209816932678,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7920689582824707,
            "answer": "remedy",
            "hit": false
          },
          {
            "score": 0.786177933216095,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.7712699174880981,
            "answer": "resolving",
            "hit": false
          },
          {
            "score": 0.7690297365188599,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.7651865482330322,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.904120922088623,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8471250534057617,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7488545179367065,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.7421640753746033,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7419005632400513,
            "answer": "tune",
            "hit": false
          },
          {
            "score": 0.7359930276870728,
            "answer": "poem",
            "hit": false
          },
          {
            "score": 0.7316223978996277,
            "answer": "track",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8471250236034393,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.805750846862793,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.7806305885314941,
            "answer": "road",
            "hit": false
          },
          {
            "score": 0.7728825807571411,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.7303848266601562,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.7234740257263184,
            "answer": "alley",
            "hit": false
          },
          {
            "score": 0.7148681879043579,
            "answer": "sidewalk",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8057508766651154,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8731222748756409,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7913932204246521,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7583470940589905,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7543283700942993,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7522435188293457,
            "answer": "pupils",
            "hit": false
          },
          {
            "score": 0.7518979907035828,
            "answer": "undergraduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8731223046779633,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.8661997318267822,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.7519052028656006,
            "answer": "network",
            "hit": false
          },
          {
            "score": 0.7224140763282776,
            "answer": "setup",
            "hit": false
          },
          {
            "score": 0.7147729396820068,
            "answer": "structure",
            "hit": false
          },
          {
            "score": 0.7122206091880798,
            "answer": "program",
            "hit": false
          },
          {
            "score": 0.7116101980209351,
            "answer": "method",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8661996722221375,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.798719048500061,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.7362068891525269,
            "answer": "stuff",
            "hit": false
          },
          {
            "score": 0.7289633750915527,
            "answer": "creature",
            "hit": false
          },
          {
            "score": 0.6980082988739014,
            "answer": "entity",
            "hit": false
          },
          {
            "score": 0.6963534355163574,
            "answer": "astonishing",
            "hit": false
          },
          {
            "score": 0.696049690246582,
            "answer": "person",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7987189888954163,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8373545408248901,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.8183847665786743,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.8107476830482483,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.7294437289237976,
            "answer": "community",
            "hit": false
          },
          {
            "score": 0.714566171169281,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.7129496932029724,
            "answer": "district",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8107477128505707,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.8980226516723633,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.7842469811439514,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.7720174193382263,
            "answer": "listener",
            "hit": false
          },
          {
            "score": 0.7685433626174927,
            "answer": "programmer",
            "hit": false
          },
          {
            "score": 0.7652671337127686,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.7629048824310303,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8980226218700409,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.895764172077179,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.799042820930481,
            "answer": "variant",
            "hit": false
          },
          {
            "score": 0.7766610383987427,
            "answer": "edition",
            "hit": false
          },
          {
            "score": 0.7741076946258545,
            "answer": "rendition",
            "hit": false
          },
          {
            "score": 0.764585554599762,
            "answer": "counterpart",
            "hit": false
          },
          {
            "score": 0.7555413246154785,
            "answer": "variants",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.895764172077179,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.8284754753112793,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8183847665786743,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7886946797370911,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.7676321268081665,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7511031031608582,
            "answer": "community",
            "hit": false
          },
          {
            "score": 0.736613929271698,
            "answer": "settlement",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8284754455089569,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.8944810628890991,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.827055811882019,
            "answer": "blog",
            "hit": false
          },
          {
            "score": 0.7837082147598267,
            "answer": "blogger",
            "hit": false
          },
          {
            "score": 0.7832363247871399,
            "answer": "blogs",
            "hit": false
          },
          {
            "score": 0.7813265323638916,
            "answer": "online",
            "hit": false
          },
          {
            "score": 0.7757949829101562,
            "answer": "podcast",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8944810032844543,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.8555895090103149,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.8291501998901367,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.8037397861480713,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7938202619552612,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.762424886226654,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.760002613067627,
            "answer": "thursday",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8291502296924591,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.8170998096466064,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.8110271096229553,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.793820321559906,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7887669801712036,
            "answer": "season",
            "hit": false
          },
          {
            "score": 0.7811722755432129,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.74506676197052,
            "answer": "day",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8110271096229553,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 41,
      "cnt_questions_total": 50,
      "accuracy": 0.82
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "aa499ecd-26c4-433f-92c4-7a030d5d5cde",
      "timestamp": "2025-05-18T12:23:18.898825"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.8869143128395081,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.8346363306045532,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.8077893257141113,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7953668832778931,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.7863197326660156,
            "answer": "willingness",
            "hit": false
          },
          {
            "score": 0.7849581241607666,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8869143128395081,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8688060641288757,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.7726728320121765,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.764654815196991,
            "answer": "active",
            "hit": false
          },
          {
            "score": 0.7545899152755737,
            "answer": "behavior",
            "hit": false
          },
          {
            "score": 0.7524405121803284,
            "answer": "exercising",
            "hit": false
          },
          {
            "score": 0.7509532570838928,
            "answer": "energetic",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8688060641288757,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.8723375797271729,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7648329734802246,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.7562031149864197,
            "answer": "agent",
            "hit": false
          },
          {
            "score": 0.7361007928848267,
            "answer": "organization",
            "hit": false
          },
          {
            "score": 0.7309286594390869,
            "answer": "entities",
            "hit": false
          },
          {
            "score": 0.727654755115509,
            "answer": "contractors",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8723375797271729,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.8922757506370544,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.8550774455070496,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.8482692241668701,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.8460749387741089,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.8239923715591431,
            "answer": "analysts",
            "hit": false
          },
          {
            "score": 0.8224866390228271,
            "answer": "analytical",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8922758102416992,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8167074918746948,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.793438196182251,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7891421318054199,
            "answer": "navy",
            "hit": false
          },
          {
            "score": 0.7787108421325684,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7548291087150574,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7439376711845398,
            "answer": "forces",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8167075514793396,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.800561785697937,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.7790018320083618,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7372533679008484,
            "answer": "legitimacy",
            "hit": false
          },
          {
            "score": 0.736846923828125,
            "answer": "jurisdiction",
            "hit": false
          },
          {
            "score": 0.7348488569259644,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7315928936004639,
            "answer": "empowered",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8005618155002594,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7572040557861328,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.7430668473243713,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.7388567924499512,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.7333294153213501,
            "answer": "footing",
            "hit": false
          },
          {
            "score": 0.7296767830848694,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.7290297746658325,
            "answer": "outset",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7388567477464676,
        "b in neighbourhood of b_prime": 473,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.7658736109733582,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7236138582229614,
            "answer": "company",
            "hit": false
          },
          {
            "score": 0.7103995680809021,
            "answer": "trade",
            "hit": false
          },
          {
            "score": 0.7088195085525513,
            "answer": "enterprise",
            "hit": false
          },
          {
            "score": 0.7085803747177124,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.7071633338928223,
            "answer": "commercial",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7658736109733582,
        "b in neighbourhood of b_prime": 280,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.8757023215293884,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7834962606430054,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.7620560526847839,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.7493565082550049,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.7482093572616577,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.7413643598556519,
            "answer": "classification",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8757023215293884,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.8365888595581055,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.7887378931045532,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7804059982299805,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.7760962247848511,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.7268667221069336,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.7182385921478271,
            "answer": "era",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8365888595581055,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.8179024457931519,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.780210018157959,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7487035989761353,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7470058798789978,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7431133985519409,
            "answer": "son",
            "hit": false
          },
          {
            "score": 0.7418811917304993,
            "answer": "kid",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8179024457931519,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8373546004295349,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7947366237640381,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7676321268081665,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7410731911659241,
            "answer": "state",
            "hit": false
          },
          {
            "score": 0.7399407625198364,
            "answer": "country",
            "hit": false
          },
          {
            "score": 0.7303814888000488,
            "answer": "county",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7947366237640381,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.8569783568382263,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7511031031608582,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7459967732429504,
            "answer": "neighborhood",
            "hit": false
          },
          {
            "score": 0.7356355786323547,
            "answer": "communal",
            "hit": false
          },
          {
            "score": 0.7313491106033325,
            "answer": "population",
            "hit": false
          },
          {
            "score": 0.7294437289237976,
            "answer": "town",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8569783866405487,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.7667356729507446,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.7399407625198364,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7320194244384766,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.7145379781723022,
            "answer": "region",
            "hit": false
          },
          {
            "score": 0.7102839350700378,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7084628343582153,
            "answer": "world",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.732019454240799,
        "b in neighbourhood of b_prime": 190,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8307289481163025,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7546263337135315,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7455023527145386,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7340063452720642,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7332342863082886,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.7303814888000488,
            "answer": "city",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8307289481163025,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.8249965906143188,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7714501023292542,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7573217749595642,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7530065178871155,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.740713357925415,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.7353664636611938,
            "answer": "assignment",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8249966502189636,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.854987382888794,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.8036140203475952,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7989457845687866,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7867914438247681,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.7780627608299255,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.7637021541595459,
            "answer": "economists",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.854987382888794,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8325443863868713,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7745412588119507,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.7511928081512451,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.7355453968048096,
            "answer": "power",
            "hit": false
          },
          {
            "score": 0.7317395210266113,
            "answer": "infused",
            "hit": false
          },
          {
            "score": 0.724358320236206,
            "answer": "intensity",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8325443863868713,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.8564363121986389,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.8245590925216675,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.7661768198013306,
            "answer": "entering",
            "hit": false
          },
          {
            "score": 0.7627091407775879,
            "answer": "enter",
            "hit": false
          },
          {
            "score": 0.7568832635879517,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.7515515089035034,
            "answer": "enters",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8564363718032837,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.8782715797424316,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.7726469039916992,
            "answer": "venue",
            "hit": false
          },
          {
            "score": 0.7668320536613464,
            "answer": "accommodations",
            "hit": false
          },
          {
            "score": 0.7660156488418579,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7642583847045898,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7625444531440735,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8782715797424316,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.7864689826965332,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7225582599639893,
            "answer": "group",
            "hit": false
          },
          {
            "score": 0.7172368168830872,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7167023420333862,
            "answer": "community",
            "hit": false
          },
          {
            "score": 0.7138643264770508,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7122005224227905,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7864690124988556,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.798130214214325,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7846118211746216,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.7468132972717285,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7276344895362854,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7182533144950867,
            "answer": "geography",
            "hit": false
          },
          {
            "score": 0.7070249319076538,
            "answer": "heritage",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7981302440166473,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.8263266682624817,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.7482348084449768,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.7388166189193726,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7381240725517273,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.7357394099235535,
            "answer": "factories",
            "hit": false
          },
          {
            "score": 0.734587550163269,
            "answer": "businesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8263267278671265,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.8701762557029724,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7672860622406006,
            "answer": "archives",
            "hit": false
          },
          {
            "score": 0.763396143913269,
            "answer": "archive",
            "hit": false
          },
          {
            "score": 0.7404251098632812,
            "answer": "stacks",
            "hit": false
          },
          {
            "score": 0.7398531436920166,
            "answer": "museum",
            "hit": false
          },
          {
            "score": 0.7337455749511719,
            "answer": "museums",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8701763153076172,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7706395387649536,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.7273810505867004,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7055041193962097,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.7047205567359924,
            "answer": "career",
            "hit": false
          },
          {
            "score": 0.7026125192642212,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.6925244331359863,
            "answer": "live",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7706395387649536,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8367204070091248,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7924119234085083,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7893664836883545,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7837561964988708,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7661536931991577,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7403942346572876,
            "answer": "defeat",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8367203772068024,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.8447285890579224,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.7645311951637268,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7612528800964355,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7411755919456482,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.7394182085990906,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.7286440134048462,
            "answer": "remember",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8447285592556,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8703550100326538,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.7943353652954102,
            "answer": "chance",
            "hit": false
          },
          {
            "score": 0.7535496354103088,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.7508811354637146,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.7440277338027954,
            "answer": "option",
            "hit": false
          },
          {
            "score": 0.743391215801239,
            "answer": "initiatives",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8703549802303314,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8870156407356262,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7776840925216675,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.7540470361709595,
            "answer": "ideology",
            "hit": false
          },
          {
            "score": 0.7476738691329956,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.7472295761108398,
            "answer": "doctrine",
            "hit": false
          },
          {
            "score": 0.745764970779419,
            "answer": "strategies",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.887015700340271,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.8399723768234253,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7454173564910889,
            "answer": "estate",
            "hit": false
          },
          {
            "score": 0.725487470626831,
            "answer": "premises",
            "hit": false
          },
          {
            "score": 0.7236379384994507,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.721052348613739,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.716620922088623,
            "answer": "asset",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8399723768234253,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8570090532302856,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7918970584869385,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.7859280109405518,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.785331130027771,
            "answer": "liability",
            "hit": false
          },
          {
            "score": 0.7795371413230896,
            "answer": "accountable",
            "hit": false
          },
          {
            "score": 0.7772989273071289,
            "answer": "accountability",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8570091426372528,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7438682913780212,
            "answer": "safety",
            "hit": false
          },
          {
            "score": 0.73436439037323,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.7325536012649536,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.7294972538948059,
            "answer": "surveillance",
            "hit": false
          },
          {
            "score": 0.7294673919677734,
            "answer": "verification",
            "hit": false
          },
          {
            "score": 0.7273622155189514,
            "answer": "secure",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 180,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6881698668003082,
        "b in neighbourhood of b_prime": 10522,
        "b_prime in neighbourhood of b": 181
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.7073370814323425,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.7019110918045044,
            "answer": "program",
            "hit": false
          },
          {
            "score": 0.7016208171844482,
            "answer": "programme",
            "hit": false
          },
          {
            "score": 0.7003755569458008,
            "answer": "show",
            "hit": false
          },
          {
            "score": 0.699066698551178,
            "answer": "serial",
            "hit": false
          },
          {
            "score": 0.6978590488433838,
            "answer": "sequence",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 1.0,
        "b in neighbourhood of b_prime": 0,
        "b_prime in neighbourhood of b": 0
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8139269351959229,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.7440797090530396,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.726692259311676,
            "answer": "association",
            "hit": false
          },
          {
            "score": 0.7089680433273315,
            "answer": "social",
            "hit": false
          },
          {
            "score": 0.7000568509101868,
            "answer": "institution",
            "hit": false
          },
          {
            "score": 0.6984802484512329,
            "answer": "civilization",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8139269351959229,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.7639195919036865,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.7465938329696655,
            "answer": "specimens",
            "hit": false
          },
          {
            "score": 0.7457334995269775,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.7376058101654053,
            "answer": "breeds",
            "hit": false
          },
          {
            "score": 0.7327895164489746,
            "answer": "specimen",
            "hit": false
          },
          {
            "score": 0.732184648513794,
            "answer": "organisms",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 1.0000000596046448,
        "b in neighbourhood of b_prime": 0,
        "b_prime in neighbourhood of b": 0
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.8670117259025574,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7691411972045898,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.7535500526428223,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7230323553085327,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7213088870048523,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.7188173532485962,
            "answer": "myth",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8670117259025574,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.8854306936264038,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.8100608587265015,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.8034574389457703,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.797104001045227,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.7853507399559021,
            "answer": "ideology",
            "hit": false
          },
          {
            "score": 0.7851971387863159,
            "answer": "aggressively",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8854306936264038,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.8587921857833862,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.8161284923553467,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7718405723571777,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7621155977249146,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7610647678375244,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7576026916503906,
            "answer": "victories",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8587921857833862,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.8627638220787048,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8386541604995728,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7893500924110413,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.7546628713607788,
            "answer": "technical",
            "hit": false
          },
          {
            "score": 0.7509617805480957,
            "answer": "innovation",
            "hit": false
          },
          {
            "score": 0.7508816719055176,
            "answer": "technicians",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8627638220787048,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8615832328796387,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.8043636679649353,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.7973045110702515,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7674093246459961,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.7632938027381897,
            "answer": "ideology",
            "hit": false
          },
          {
            "score": 0.7572776675224304,
            "answer": "principle",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8615832924842834,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.8113839626312256,
            "answer": "college",
            "hit": false
          },
          {
            "score": 0.8055016398429871,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7399930953979492,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7365342378616333,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7305053472518921,
            "answer": "academy",
            "hit": false
          },
          {
            "score": 0.7282679080963135,
            "answer": "campus",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8055016398429871,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8247003555297852,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7557877898216248,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.7457178831100464,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.7447037696838379,
            "answer": "variation",
            "hit": false
          },
          {
            "score": 0.7440966367721558,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.742676854133606,
            "answer": "varied",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8247004151344299,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.8309003114700317,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.826772928237915,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.8241045475006104,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.796622097492218,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7933645844459534,
            "answer": "widow",
            "hit": false
          },
          {
            "score": 0.7930430173873901,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8309003710746765,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.851696252822876,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.8434727787971497,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.8271136283874512,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.8168520927429199,
            "answer": "man",
            "hit": false
          },
          {
            "score": 0.770622968673706,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.7671535015106201,
            "answer": "girls",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.851696252822876,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 44,
      "accuracy": 0.8409090909090909
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "0d2ee167-e02f-4842-ac62-2ce5b601b86b",
      "timestamp": "2025-05-18T12:23:19.336042"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8666321039199829,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.8510527014732361,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.8066471219062805,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7844676971435547,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.7831720113754272,
            "answer": "costly",
            "hit": false
          },
          {
            "score": 0.7814445495605469,
            "answer": "priced",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8510526418685913,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.8263459205627441,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.8051723837852478,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.7889020442962646,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7861967086791992,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7798588871955872,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.7785241603851318,
            "answer": "pleased",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8051723837852478,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.8248040080070496,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.7957847118377686,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.7864357233047485,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.7790182828903198,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7728143334388733,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7674075365066528,
            "answer": "powerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8248039484024048,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.8552837371826172,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.8242624402046204,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.8166923522949219,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.8145226836204529,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.8027293682098389,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7994601130485535,
            "answer": "stronger",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8552837073802948,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 4,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "3d4c6a31-426a-4069-8908-1cece70c0d96",
      "timestamp": "2025-05-18T12:23:19.730701"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7598069310188293,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7553636431694031,
            "answer": "heated",
            "hit": false
          },
          {
            "score": 0.7495690584182739,
            "answer": "warm",
            "hit": false
          },
          {
            "score": 0.738173246383667,
            "answer": "cool",
            "hit": false
          },
          {
            "score": 0.7328792810440063,
            "answer": "heat",
            "hit": false
          },
          {
            "score": 0.7321822643280029,
            "answer": "cold",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7598069906234741,
        "b in neighbourhood of b_prime": 1114,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.8248040080070496,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7957847118377686,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.7864357233047485,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.7790182828903198,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7728143334388733,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7674075365066528,
            "answer": "powerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7790182828903198,
        "b in neighbourhood of b_prime": 29,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 2,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "a26fcc1d-3b8d-4748-91d7-72863d8e2ad8",
      "timestamp": "2025-05-18T12:23:19.764859"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.8983632326126099,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8946914076805115,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.875094473361969,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8246158957481384,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.8103522062301636,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7919024229049683,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8946914374828339,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8571966886520386,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8512294292449951,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.8311465978622437,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7820425033569336,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7646158933639526,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.753502607345581,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8571966886520386,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8933293223381042,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8903093338012695,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8695268034934998,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.845787763595581,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8185182213783264,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7973032593727112,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8933293223381042,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9044910669326782,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.898271918296814,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8731729984283447,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8411328792572021,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8383795022964478,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8371660709381104,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9044910669326782,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9067435264587402,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8980718851089478,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8858983516693115,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.8327136635780334,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8033196926116943,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7991729974746704,
            "answer": "emerge",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.906743586063385,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9259973764419556,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.9166051745414734,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8860697746276855,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8208869099617004,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8047682046890259,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7915410995483398,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9259973466396332,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8640376925468445,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.854180634021759,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.8476423025131226,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7597016096115112,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7514198422431946,
            "answer": "requests",
            "hit": false
          },
          {
            "score": 0.7489078044891357,
            "answer": "invite",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8640376329421997,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.9066163301467896,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.900334894657135,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8885493278503418,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.8276920914649963,
            "answer": "evade",
            "hit": false
          },
          {
            "score": 0.8221240043640137,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8115668296813965,
            "answer": "prevent",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8885492980480194,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8709216117858887,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8617130517959595,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8591955900192261,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7655351758003235,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.7497161030769348,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7309648990631104,
            "answer": "acquire",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8617130517959595,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8757528066635132,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8602850437164307,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.85483717918396,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7787802219390869,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7690629959106445,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7632874250411987,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.875752866268158,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8839224576950073,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8498429656028748,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.8174730539321899,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7856860160827637,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7795464396476746,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7774255871772766,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8839224874973297,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9081952571868896,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8838949799537659,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8540921211242676,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8079713582992554,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.80064857006073,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7880100607872009,
            "answer": "dispose",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9081952571868896,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8883761167526245,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8880596160888672,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8785503506660461,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8130935430526733,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.8025766611099243,
            "answer": "restrain",
            "hit": false
          },
          {
            "score": 0.8010347485542297,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8883761167526245,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9142158031463623,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8936446905136108,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8817631602287292,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8084533214569092,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.8043540716171265,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.8022714853286743,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9142158627510071,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9197313785552979,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.9000522494316101,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8780682682991028,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8345492482185364,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8136718273162842,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8078019022941589,
            "answer": "creation",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9000522792339325,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8938760757446289,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.893113374710083,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8521619439125061,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.8403527736663818,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8151251077651978,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.8055692911148071,
            "answer": "classify",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8938761353492737,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.9150981307029724,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.9078752994537354,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8873330950737,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8259669542312622,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.8146018385887146,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8114505410194397,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9150981307029724,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.9105805158615112,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8991588950157166,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.8979254961013794,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8747463226318359,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8499389886856079,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8478498458862305,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9105804562568665,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.9142763018608093,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.9045725464820862,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.903662383556366,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8256145715713501,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8100818395614624,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.795230507850647,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9045725464820862,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.927005410194397,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.9171294569969177,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.9028818607330322,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.8495049476623535,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.8198128938674927,
            "answer": "guarantee",
            "hit": false
          },
          {
            "score": 0.8180087804794312,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9171294569969177,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.9220635890960693,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.8926429152488708,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.8038210868835449,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7918051481246948,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7870382070541382,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7801103591918945,
            "answer": "existing",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9220636188983917,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8854026794433594,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8830115795135498,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8814031481742859,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8450973033905029,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.8391320109367371,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7978042960166931,
            "answer": "justify",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8854026794433594,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8783487677574158,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.8678023815155029,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.8022472858428955,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7467734813690186,
            "answer": "accompany",
            "hit": false
          },
          {
            "score": 0.7438635230064392,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7427729964256287,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8678024113178253,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8884302377700806,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8776237964630127,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8404629230499268,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8332129716873169,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7967727184295654,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7921964526176453,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8884303271770477,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8708337545394897,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.8363567590713501,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.823119044303894,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7728317975997925,
            "answer": "audible",
            "hit": false
          },
          {
            "score": 0.7493689656257629,
            "answer": "perceive",
            "hit": false
          },
          {
            "score": 0.7493635416030884,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8363567590713501,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.922132134437561,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.9216601848602295,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8971700072288513,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8540855646133423,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8376580476760864,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.8049492835998535,
            "answer": "differentiated",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9216601848602295,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9298075437545776,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.9144061207771301,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8866791129112244,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8620775938034058,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8527919054031372,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8508940935134888,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9144061505794525,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8803422451019287,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.8760924935340881,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.8100513219833374,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7844526171684265,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.783656120300293,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7779709696769714,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8803422451019287,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9149647951126099,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8857265114784241,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8460173606872559,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.831051230430603,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.8210888504981995,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.817597508430481,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9149648249149323,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8956886529922485,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.8755648732185364,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8601009249687195,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.847612202167511,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.7932529449462891,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7892578840255737,
            "answer": "discover",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8956886529922485,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.9306422472000122,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.9114900827407837,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.9082741737365723,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8263388872146606,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.8210158348083496,
            "answer": "sustain",
            "hit": false
          },
          {
            "score": 0.8162668347358704,
            "answer": "retains",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9082742035388947,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9192324280738831,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.9013803601264954,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8843971490859985,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8404629230499268,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8194340467453003,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.8189377784729004,
            "answer": "occurrences",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9192323982715607,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.9162928462028503,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8974660634994507,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.8647352457046509,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.815845787525177,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.7988571524620056,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.7963587045669556,
            "answer": "activate",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9162928462028503,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.9191804528236389,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.9063052535057068,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.8968331217765808,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8265039324760437,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8237512707710266,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8230978846549988,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9063052833080292,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9330500960350037,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.9324357509613037,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.876151442527771,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8385142087936401,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.8280538320541382,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.8239589929580688,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9324357807636261,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.9073222279548645,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.8999450206756592,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.8533008098602295,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.8376009464263916,
            "answer": "defend",
            "hit": false
          },
          {
            "score": 0.825663685798645,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.8188012838363647,
            "answer": "protections",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8999450206756592,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9189122319221497,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.9147403240203857,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.887020468711853,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8210726976394653,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7991969585418701,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.7987419962882996,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9189121723175049,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9078066945075989,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8932152390480042,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8900257349014282,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8021705746650696,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7931883931159973,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7907649278640747,
            "answer": "undergo",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9078066647052765,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9271069169044495,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.9178338050842285,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8865858912467957,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8694915771484375,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8566522598266602,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8511766195297241,
            "answer": "minimize",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9271070063114166,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8828813433647156,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.863158106803894,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8606690168380737,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.806861162185669,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.7953035831451416,
            "answer": "correspond",
            "hit": false
          },
          {
            "score": 0.7927727103233337,
            "answer": "referencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8828813433647156,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8969013094902039,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8614845275878906,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8202628493309021,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.8154057264328003,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.8046963810920715,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.800399661064148,
            "answer": "retain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8614845275878906,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.8575671315193176,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.8544095158576965,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.8480427265167236,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.8258931636810303,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.7871465682983398,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.7852413058280945,
            "answer": "recalls",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8575671315193176,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.9236042499542236,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.9019237756729126,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.9004205465316772,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8168030977249146,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.8166612386703491,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.8073623776435852,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9236043095588684,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9241580367088318,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.9082425832748413,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8647221326828003,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8212431073188782,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.8134450912475586,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8127132654190063,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9241580367088318,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8949459791183472,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8882611393928528,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8327137231826782,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8256047964096069,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7922535538673401,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7607243061065674,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8949460089206696,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.8987424969673157,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.8975338935852051,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8768355250358582,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.8034763336181641,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7637276649475098,
            "answer": "bring",
            "hit": false
          },
          {
            "score": 0.7620758414268494,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8987424969673157,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8816474080085754,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.869764506816864,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8600751757621765,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.8257064819335938,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.8225088715553284,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.8128640055656433,
            "answer": "recommend",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8816474378108978,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8427900075912476,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8316373229026794,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8309626579284668,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7448982000350952,
            "answer": "tel",
            "hit": false
          },
          {
            "score": 0.7400595545768738,
            "answer": "inform",
            "hit": false
          },
          {
            "score": 0.7357056140899658,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8427900075912476,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8844375014305115,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8611114025115967,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8166418075561523,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7982780337333679,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.778049647808075,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7739430665969849,
            "answer": "realize",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8611114025115967,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 33,
      "cnt_questions_total": 49,
      "accuracy": 0.673469387755102
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "8e3ef08e-1942-4edf-806b-bd9de4067d8b",
      "timestamp": "2025-05-18T12:23:19.784155"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9212468862533569,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.9064386487007141,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8685361742973328,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.8556057214736938,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.8438686728477478,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.8403669595718384,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9212469458580017,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.8571966886520386,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.8512294292449951,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.8311465978622437,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7820425033569336,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7646158933639526,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.753502607345581,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8512293994426727,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.9044910669326782,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.898271918296814,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.8731729984283447,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8411328792572021,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8383795022964478,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8371660709381104,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.898271918296814,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.9067435264587402,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8980718851089478,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8858983516693115,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.8327136635780334,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8033196926116943,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7991729974746704,
            "answer": "emerge",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8858983516693115,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.9259973764419556,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.9166051745414734,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.8860697746276855,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8208869099617004,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8047682046890259,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7915410995483398,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9166051745414734,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.8640376925468445,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.854180634021759,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.8476423025131226,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7597016096115112,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7514198422431946,
            "answer": "requests",
            "hit": false
          },
          {
            "score": 0.7489078044891357,
            "answer": "invite",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.847642332315445,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.9089874625205994,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8965243697166443,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.7973626255989075,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7964834570884705,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7891268730163574,
            "answer": "enroll",
            "hit": false
          },
          {
            "score": 0.7860310077667236,
            "answer": "undergo",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9089874923229218,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.9066163301467896,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.900334894657135,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.8885493278503418,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.8276920914649963,
            "answer": "evade",
            "hit": false
          },
          {
            "score": 0.8221240043640137,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8115668296813965,
            "answer": "prevent",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.900334894657135,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8709216117858887,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8617130517959595,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8591955900192261,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7655351758003235,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.7497161030769348,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7309648990631104,
            "answer": "acquire",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8709215521812439,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8757528066635132,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8602850437164307,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.85483717918396,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7787802219390869,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7690629959106445,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7632874250411987,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8548372089862823,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.8839224576950073,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8498429656028748,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.8174730539321899,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.7856860160827637,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7795464396476746,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7774255871772766,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8174729943275452,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8883761167526245,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8880596160888672,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8785503506660461,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8130935430526733,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.8025766611099243,
            "answer": "restrain",
            "hit": false
          },
          {
            "score": 0.8010347485542297,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8785503804683685,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.9142158031463623,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8936446905136108,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8817631602287292,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.8084533214569092,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.8043540716171265,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.8022714853286743,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8817631900310516,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.9197313785552979,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.9000522494316101,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8780682682991028,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8345492482185364,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8136718273162842,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8078019022941589,
            "answer": "creation",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9197314381599426,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.9150981307029724,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.9078752994537354,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.8873330950737,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8259669542312622,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.8146018385887146,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8114505410194397,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9078752398490906,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.9181928634643555,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8843684792518616,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8787548542022705,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8770283460617065,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8618279695510864,
            "answer": "stimulate",
            "hit": false
          },
          {
            "score": 0.8457260727882385,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8787548542022705,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.9142763018608093,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.9045725464820862,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.903662383556366,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.8256145715713501,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8100818395614624,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.795230507850647,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9036624133586884,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.927005410194397,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.9171294569969177,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.9028818607330322,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.8495049476623535,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.8198128938674927,
            "answer": "guarantee",
            "hit": false
          },
          {
            "score": 0.8180087804794312,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.927005410194397,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.927820086479187,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.9093228578567505,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8759055733680725,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.8220641016960144,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8214178085327148,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.8209626078605652,
            "answer": "assert",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.927820086479187,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.9220635890960693,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.8926429152488708,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.8038210868835449,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7918051481246948,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7870382070541382,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7801103591918945,
            "answer": "existing",
            "hit": true
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7801103591918945,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.8631632924079895,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8477756977081299,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.8260828256607056,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.7778308391571045,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7771221995353699,
            "answer": "predict",
            "hit": false
          },
          {
            "score": 0.776112973690033,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8477756977081299,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.8783487677574158,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.8678023815155029,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.8022472858428955,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.7467734813690186,
            "answer": "accompany",
            "hit": false
          },
          {
            "score": 0.7438635230064392,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7427729964256287,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8022472858428955,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8884302377700806,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8776237964630127,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8404629230499268,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8332129716873169,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.7967727184295654,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7921964526176453,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8332129418849945,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.922132134437561,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.9216601848602295,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8971700072288513,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8540855646133423,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8376580476760864,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.8049492835998535,
            "answer": "differentiated",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9221321940422058,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.9298075437545776,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.9144061207771301,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8866791129112244,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8620775938034058,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8527919054031372,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8508940935134888,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9298075735569,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.8803422451019287,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.8760924935340881,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.8100513219833374,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.7844526171684265,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.783656120300293,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7779709696769714,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8100513815879822,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.9149647951126099,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8857265114784241,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.8460173606872559,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.831051230430603,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.8210888504981995,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.817597508430481,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8857265114784241,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.8956886529922485,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.8755648732185364,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8601009249687195,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.847612202167511,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.7932529449462891,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7892578840255737,
            "answer": "discover",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8476122617721558,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.901468813419342,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8752651214599609,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.8320867419242859,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7942951321601868,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7837561368942261,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7741091251373291,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8752651512622833,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9306422472000122,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.9114900827407837,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.9082741737365723,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8263388872146606,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.8210158348083496,
            "answer": "sustain",
            "hit": false
          },
          {
            "score": 0.8162668347358704,
            "answer": "retains",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9306421875953674,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.9106206297874451,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8992851972579956,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8821427226066589,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.8109191060066223,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7881076335906982,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.78635573387146,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8821427226066589,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.9162928462028503,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8974660634994507,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.8647352457046509,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.815845787525177,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.7988571524620056,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.7963587045669556,
            "answer": "activate",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8647351861000061,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.9174794554710388,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.904448390007019,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.9006446599960327,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.8170234560966492,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8168152570724487,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8087434768676758,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9006446599960327,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.9191804528236389,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.9063052535057068,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8968331217765808,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8265039324760437,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8237512707710266,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8230978846549988,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9191804230213165,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9330500960350037,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.9324357509613037,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.876151442527771,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8385142087936401,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.8280538320541382,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.8239589929580688,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9330500662326813,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.9073222279548645,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.8999450206756592,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.8533008098602295,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.8376009464263916,
            "answer": "defend",
            "hit": false
          },
          {
            "score": 0.825663685798645,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.8188012838363647,
            "answer": "protections",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9073222577571869,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.9189122319221497,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.9147403240203857,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.887020468711853,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8210726976394653,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7991969585418701,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.7987419962882996,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9147403538227081,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.9078066945075989,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8932152390480042,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.8900257349014282,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8021705746650696,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7931883931159973,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7907649278640747,
            "answer": "undergo",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8932152390480042,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.9271069169044495,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.9178338050842285,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8865858912467957,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8694915771484375,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8566522598266602,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8511766195297241,
            "answer": "minimize",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9178338646888733,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8828813433647156,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.863158106803894,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.8606690168380737,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.806861162185669,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.7953035831451416,
            "answer": "correspond",
            "hit": false
          },
          {
            "score": 0.7927727103233337,
            "answer": "referencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8631580770015717,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8969013094902039,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8614845275878906,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8202628493309021,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.8154057264328003,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.8046963810920715,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.800399661064148,
            "answer": "retain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8154057264328003,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.8575671315193176,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.8544095158576965,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.8480427265167236,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.8258931636810303,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.7871465682983398,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.7852413058280945,
            "answer": "recalls",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8480427265167236,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.9236042499542236,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.9019237756729126,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.9004205465316772,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8168030977249146,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.8166612386703491,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.8073623776435852,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.901923805475235,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.9241580367088318,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.9082425832748413,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.8647221326828003,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8212431073188782,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.8134450912475586,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8127132654190063,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9082426130771637,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8949459791183472,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8882611393928528,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8327137231826782,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8256047964096069,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7922535538673401,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7607243061065674,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8256047666072845,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.8450160026550293,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.8221757411956787,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.8107677698135376,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.754942774772644,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7393593788146973,
            "answer": "stand",
            "hit": false
          },
          {
            "score": 0.7362046241760254,
            "answer": "suspend",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8221757411956787,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.908430278301239,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8980039954185486,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.886229395866394,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7992342114448547,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7899842858314514,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7894537448883057,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8980039954185486,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.9012791514396667,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8874068260192871,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8538241386413574,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8000293970108032,
            "answer": "instructors",
            "hit": false
          },
          {
            "score": 0.795584499835968,
            "answer": "educators",
            "hit": false
          },
          {
            "score": 0.79510498046875,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8538241684436798,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.8427900075912476,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8316373229026794,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.8309626579284668,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7448982000350952,
            "answer": "tel",
            "hit": false
          },
          {
            "score": 0.7400595545768738,
            "answer": "inform",
            "hit": false
          },
          {
            "score": 0.7357056140899658,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8316373527050018,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8844375014305115,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8611114025115967,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8166418075561523,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7982780337333679,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.778049647808075,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7739430665969849,
            "answer": "realize",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7982780933380127,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 12,
      "cnt_questions_total": 50,
      "accuracy": 0.24
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "cb92d314-3e47-4e98-bab1-26b547996ee7",
      "timestamp": "2025-05-18T12:23:20.202393"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8983632326126099,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8946914076805115,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.875094473361969,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8246158957481384,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.8103522062301636,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7919024229049683,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8750945329666138,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.9212468862533569,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.9064386487007141,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.8685361742973328,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.8556057214736938,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.8438686728477478,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.8403669595718384,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9064386785030365,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8571966886520386,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.8512294292449951,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.8311465978622437,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7820425033569336,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7646158933639526,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.753502607345581,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8311465978622437,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8933293223381042,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8903093338012695,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8695268034934998,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.845787763595581,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8185182213783264,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7973032593727112,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8695268332958221,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9044910669326782,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.898271918296814,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8731729984283447,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8411328792572021,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8383795022964478,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8371660709381104,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8731729686260223,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9271755218505859,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.9095021486282349,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8700517416000366,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.855491578578949,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.854992687702179,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8444450497627258,
            "answer": "declares",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8700517117977142,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9067435264587402,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8980718851089478,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8858983516693115,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.8327136635780334,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8033196926116943,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7991729974746704,
            "answer": "emerge",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8980719149112701,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9259973764419556,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.9166051745414734,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8860697746276855,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8208869099617004,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8047682046890259,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7915410995483398,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8860698640346527,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8640376925468445,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.854180634021759,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8476423025131226,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7597016096115112,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7514198422431946,
            "answer": "requests",
            "hit": false
          },
          {
            "score": 0.7489078044891357,
            "answer": "invite",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8541807234287262,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.9089874625205994,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.8965243697166443,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7973626255989075,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7964834570884705,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7891268730163574,
            "answer": "enroll",
            "hit": false
          },
          {
            "score": 0.7860310077667236,
            "answer": "undergo",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8965243995189667,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8709216117858887,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8617130517959595,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8591955900192261,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7655351758003235,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.7497161030769348,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7309648990631104,
            "answer": "acquire",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8591956496238708,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8757528066635132,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8602850437164307,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.85483717918396,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7787802219390869,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7690629959106445,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7632874250411987,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8602850437164307,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8839224576950073,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8498429656028748,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8174730539321899,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7856860160827637,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7795464396476746,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7774255871772766,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.84984290599823,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9142158031463623,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8936446905136108,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8817631602287292,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8084533214569092,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.8043540716171265,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.8022714853286743,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.893644779920578,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.9197313785552979,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.9000522494316101,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8780682682991028,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8345492482185364,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8136718273162842,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8078019022941589,
            "answer": "creation",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8780683279037476,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8974717855453491,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8753067255020142,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.865760862827301,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8433009386062622,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.8260406851768494,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8132282495498657,
            "answer": "determining",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.865760862827301,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8938760757446289,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.893113374710083,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8521619439125061,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8403527736663818,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8151251077651978,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.8055692911148071,
            "answer": "classify",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8521619439125061,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.9150981307029724,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.9078752994537354,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8873330950737,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8259669542312622,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.8146018385887146,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8114505410194397,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8873330950737,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.8856216073036194,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.8686090111732483,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.8503749370574951,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.8238372206687927,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.8198454976081848,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.8118399381637573,
            "answer": "discovery",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8503749370574951,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.9142763018608093,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.9045725464820862,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.903662383556366,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8256145715713501,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8100818395614624,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.795230507850647,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9142763018608093,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.927005410194397,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.9171294569969177,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.9028818607330322,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.8495049476623535,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.8198128938674927,
            "answer": "guarantee",
            "hit": false
          },
          {
            "score": 0.8180087804794312,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9028818905353546,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.927820086479187,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.9093228578567505,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8759055733680725,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8220641016960144,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8214178085327148,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.8209626078605652,
            "answer": "assert",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8759055733680725,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8631632924079895,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8477756977081299,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.8260828256607056,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7778308391571045,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7771221995353699,
            "answer": "predict",
            "hit": false
          },
          {
            "score": 0.776112973690033,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8260827958583832,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8783487677574158,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8678023815155029,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.8022472858428955,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7467734813690186,
            "answer": "accompany",
            "hit": false
          },
          {
            "score": 0.7438635230064392,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7427729964256287,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8783487677574158,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8708337545394897,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8363567590713501,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.823119044303894,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7728317975997925,
            "answer": "audible",
            "hit": false
          },
          {
            "score": 0.7493689656257629,
            "answer": "perceive",
            "hit": false
          },
          {
            "score": 0.7493635416030884,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8708338141441345,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.922132134437561,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.9216601848602295,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8971700072288513,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.8540855646133423,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8376580476760864,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.8049492835998535,
            "answer": "differentiated",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8971700072288513,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.9298075437545776,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.9144061207771301,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8866791129112244,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8620775938034058,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8527919054031372,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8508940935134888,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8866792023181915,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8803422451019287,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.8760924935340881,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.8100513219833374,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7844526171684265,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.783656120300293,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7779709696769714,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8760924935340881,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9277023673057556,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.9244400262832642,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.9017870426177979,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.848884642124176,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.8141181468963623,
            "answer": "introductory",
            "hit": false
          },
          {
            "score": 0.8103150725364685,
            "answer": "announce",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9017870426177979,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.9149647951126099,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8857265114784241,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8460173606872559,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.831051230430603,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.8210888504981995,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.817597508430481,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8460173010826111,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.9176007509231567,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.8215538859367371,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.8212631344795227,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8208726644515991,
            "answer": "disclose",
            "hit": false
          },
          {
            "score": 0.8201800584793091,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.8161169290542603,
            "answer": "securely",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 81,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7958017587661743,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 82
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.901468813419342,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8752651214599609,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8320867419242859,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7942951321601868,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7837561368942261,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7741091251373291,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8320867121219635,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.9106206297874451,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8992851972579956,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8821427226066589,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.8109191060066223,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7881076335906982,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.78635573387146,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8992851972579956,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.907547116279602,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8483113050460815,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8214737772941589,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8008876442909241,
            "answer": "wed",
            "hit": false
          },
          {
            "score": 0.7941256761550903,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.7935845255851746,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8483112454414368,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9174794554710388,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.904448390007019,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.9006446599960327,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8170234560966492,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8168152570724487,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8087434768676758,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9044484496116638,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9189122319221497,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.9147403240203857,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.887020468711853,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8210726976394653,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7991969585418701,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.7987419962882996,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8870204985141754,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8796524405479431,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.86688232421875,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8388799428939819,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8368470668792725,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.8319700360298157,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8277172446250916,
            "answer": "publishers",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8796524405479431,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9078066945075989,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8932152390480042,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8900257349014282,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8021705746650696,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7931883931159973,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7907649278640747,
            "answer": "undergo",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8900257647037506,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.9271069169044495,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.9178338050842285,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8865858912467957,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8694915771484375,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8566522598266602,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8511766195297241,
            "answer": "minimize",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8865858912467957,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8828813433647156,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.863158106803894,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8606690168380737,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.806861162185669,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.7953035831451416,
            "answer": "correspond",
            "hit": false
          },
          {
            "score": 0.7927727103233337,
            "answer": "referencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8606689870357513,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.9033911824226379,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8707638382911682,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.8290444612503052,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8097838759422302,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.8087172508239746,
            "answer": "adapting",
            "hit": false
          },
          {
            "score": 0.8086370825767517,
            "answer": "derive",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 461,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7749907076358795,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 462
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8969013094902039,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8614845275878906,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8202628493309021,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.8154057264328003,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.8046963810920715,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.800399661064148,
            "answer": "retain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8969012796878815,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.9095603227615356,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8951383233070374,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8946242332458496,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8316130638122559,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.8171306848526001,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.8022470474243164,
            "answer": "supplemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8951383233070374,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.9241580367088318,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.9082425832748413,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8647221326828003,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8212431073188782,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.8134450912475586,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8127132654190063,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8647220730781555,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8949459791183472,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8882611393928528,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8327137231826782,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8256047964096069,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7922535538673401,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7607243061065674,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8882611691951752,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8987424969673157,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.8975338935852051,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8768355250358582,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8034763336181641,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7637276649475098,
            "answer": "bring",
            "hit": false
          },
          {
            "score": 0.7620758414268494,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8768355250358582,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.908430278301239,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8980039954185486,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.886229395866394,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7992342114448547,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7899842858314514,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7894537448883057,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8862294256687164,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8427900075912476,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8316373229026794,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8309626579284668,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7448982000350952,
            "answer": "tel",
            "hit": false
          },
          {
            "score": 0.7400595545768738,
            "answer": "inform",
            "hit": false
          },
          {
            "score": 0.7357056140899658,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8309626579284668,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8844375014305115,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8611114025115967,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8166418075561523,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7982780337333679,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.778049647808075,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7739430665969849,
            "answer": "realize",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8844375312328339,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.8145968914031982,
            "answer": "merging",
            "hit": false
          },
          {
            "score": 0.814345121383667,
            "answer": "reconcile",
            "hit": false
          },
          {
            "score": 0.8082165718078613,
            "answer": "empowered",
            "hit": false
          },
          {
            "score": 0.8055557012557983,
            "answer": "astonishing",
            "hit": false
          },
          {
            "score": 0.8051644563674927,
            "answer": "clustered",
            "hit": false
          },
          {
            "score": 0.8034791350364685,
            "answer": "align",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 308,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7784057855606079,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 309
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 50,
      "accuracy": 0.12
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "7f3562cc-b1ec-4dcb-b3f4-8b720e448bf1",
      "timestamp": "2025-05-18T12:23:20.621522"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8954148888587952,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8685434460639954,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.8512294292449951,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8279964923858643,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.8001242280006409,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.7975208759307861,
            "answer": "emphasizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8954149186611176,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9138472080230713,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.898271918296814,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8644561171531677,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8615258932113647,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8548951148986816,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8489928245544434,
            "answer": "permitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9138472080230713,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8892973065376282,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8858983516693115,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8718048334121704,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8217365145683289,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.8111988306045532,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.8039604425430298,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8718048632144928,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9166051745414734,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8967052698135376,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.887039303779602,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.826873242855072,
            "answer": "implementing",
            "hit": false
          },
          {
            "score": 0.8249088525772095,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.821532130241394,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8967053294181824,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8675459027290344,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8476423025131226,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8475791215896606,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.8112953305244446,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7942792177200317,
            "answer": "begging",
            "hit": false
          },
          {
            "score": 0.7889206409454346,
            "answer": "inquired",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8675459027290344,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8709216117858887,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8608808517456055,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8519954085350037,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7730484008789062,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7690061926841736,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.7633096575737,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8608808517456055,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8863602876663208,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.85483717918396,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.8516945838928223,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.827428936958313,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.8213752508163452,
            "answer": "trusting",
            "hit": false
          },
          {
            "score": 0.8174093961715698,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8863603472709656,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8280283212661743,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8174730539321899,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7844557166099548,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7831863760948181,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7778807878494263,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7735448479652405,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8280283510684967,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8828239440917969,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8792068362236023,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8540921211242676,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8474975824356079,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8380720615386963,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.8161137104034424,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8828239440917969,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8785503506660461,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8712300062179565,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8467463850975037,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8297303915023804,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7921543121337891,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7871537804603577,
            "answer": "transporting",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8712300062179565,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.881763219833374,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8798187971115112,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8796614408493042,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8196966648101807,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.808220624923706,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.8004783987998962,
            "answer": "proceeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8798188269138336,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9197314381599426,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.9048311710357666,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8760865330696106,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8392308354377747,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8356324434280396,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8275794386863708,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9048311710357666,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8468167185783386,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.8099684119224548,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.8065066933631897,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.7814221978187561,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7771870493888855,
            "answer": "rely",
            "hit": false
          },
          {
            "score": 0.7711426615715027,
            "answer": "relying",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8468166887760162,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.915394127368927,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8931134939193726,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8671203851699829,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8646882772445679,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.8322732448577881,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.8309418559074402,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9153941571712494,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.9078752398490906,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8839505314826965,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.877825140953064,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8267233967781067,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8208330869674683,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8150346279144287,
            "answer": "progressing",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8839505612850189,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8965446949005127,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8856216669082642,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.8800362348556519,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8703110218048096,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.8434077501296997,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.8401485681533813,
            "answer": "detecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8965446352958679,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8979254961013794,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8879197835922241,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8858438730239868,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.8671960830688477,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8615258932113647,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8519338369369507,
            "answer": "permitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8879197835922241,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7803229093551636,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7801103591918945,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7734599113464355,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7694283723831177,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.763238251209259,
            "answer": "prevailing",
            "hit": false
          },
          {
            "score": 0.7622018456459045,
            "answer": "existent",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7694284021854401,
        "b in neighbourhood of b_prime": 45,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8888694643974304,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8857016563415527,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8814031481742859,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.849214494228363,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.848476767539978,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.8297483325004578,
            "answer": "describing",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.888869434595108,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8033066391944885,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.8022473454475403,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.782600998878479,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7662975788116455,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7274199724197388,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7178413271903992,
            "answer": "ensuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7826010584831238,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8345052003860474,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8332129716873169,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8251361846923828,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8154692649841309,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.7952731847763062,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7821073532104492,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8154692649841309,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.823119044303894,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.8029768466949463,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8029053807258606,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7800050377845764,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7598023414611816,
            "answer": "witnessing",
            "hit": false
          },
          {
            "score": 0.7545350790023804,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8029768764972687,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9298075437545776,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.9142966270446777,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8939781785011292,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8662537336349487,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8659341335296631,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8584917783737183,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9142966270446777,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8100513815879822,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.8011112213134766,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7885974049568176,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7721495628356934,
            "answer": "notably",
            "hit": false
          },
          {
            "score": 0.7522250413894653,
            "answer": "namely",
            "hit": false
          },
          {
            "score": 0.7452154159545898,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8011112809181213,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8857265710830688,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8759288787841797,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8215063214302063,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.8133633136749268,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.8068096041679382,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8005495071411133,
            "answer": "utilizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8759288787841797,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8476122617721558,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.8195099830627441,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.8069092035293579,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7994239330291748,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7752471566200256,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7691841125488281,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8195099830627441,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8772426843643188,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8752651214599609,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8282063603401184,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7948177456855774,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7893664836883545,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.784018337726593,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8772427141666412,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8821426630020142,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8799048066139221,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.8590936064720154,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8121217489242554,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7927286624908447,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.790885329246521,
            "answer": "regulating",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8799048662185669,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8843971490859985,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8700538277626038,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8465024828910828,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.8437646627426147,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8430355787277222,
            "answer": "occurrences",
            "hit": false
          },
          {
            "score": 0.8345052003860474,
            "answer": "happening",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8700538277626038,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8647351861000061,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8455369472503662,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8450769186019897,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.810581386089325,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7863444685935974,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7778065800666809,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.845537006855011,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.9006446003913879,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8876267671585083,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.8709373474121094,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8191941380500793,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8170648217201233,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8096805810928345,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8876268267631531,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9330500364303589,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.9238659739494324,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.872900664806366,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.847943902015686,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8404667377471924,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.8364085555076599,
            "answer": "promotion",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9238659739494324,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9226656556129456,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.9147403240203857,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8948092460632324,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8665775656700134,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8222895264625549,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8172069787979126,
            "answer": "delivering",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9226656258106232,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8932152390480042,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8798074126243591,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8619621992111206,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8004910945892334,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7954490780830383,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.790858268737793,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8798074126243591,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9178338050842285,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.907301664352417,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.872848629951477,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.864206075668335,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8604331016540527,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8541544675827026,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9073017537593842,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8813886046409607,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.863158106803894,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8583986759185791,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.8501452803611755,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8320388197898865,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8299442529678345,
            "answer": "describing",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8813886046409607,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8965973854064941,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8862696290016174,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8707638382911682,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8051944971084595,
            "answer": "detrimental",
            "hit": false
          },
          {
            "score": 0.8044483661651611,
            "answer": "illustrating",
            "hit": false
          },
          {
            "score": 0.803964376449585,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8965973854064941,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8154057264328003,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8078356981277466,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7974206209182739,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7773756384849548,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7765617370605469,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7606216073036194,
            "answer": "staying",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7765617370605469,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.9035073518753052,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.9019237756729126,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.8931892514228821,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8159011602401733,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.8114817142486572,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7942194938659668,
            "answer": "illustrating",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.90350741147995,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9082425832748413,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.900102436542511,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.8519036173820496,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8511323928833008,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.834256649017334,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8321945667266846,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.900102436542511,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8389631509780884,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.8350626230239868,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8280300498008728,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8256047964096069,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8217365741729736,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.8064349889755249,
            "answer": "looming",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8280301094055176,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8314317464828491,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.8222082853317261,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.8221756815910339,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.7995743751525879,
            "answer": "standing",
            "hit": false
          },
          {
            "score": 0.7976881265640259,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7685646414756775,
            "answer": "lying",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8222082853317261,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8980039954185486,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8765987157821655,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.8350546956062317,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8272470831871033,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.8128746747970581,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7839565277099609,
            "answer": "purchasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8765987157821655,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8977871537208557,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8866289854049683,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8758246898651123,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.869764506816864,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.8580499887466431,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8577163219451904,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8866290152072906,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8608849048614502,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8538241386413574,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8499224781990051,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8127500414848328,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7982503175735474,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7974454760551453,
            "answer": "preaching",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8608849048614502,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8750631213188171,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8468402624130249,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.8316373229026794,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8164085149765015,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.786601185798645,
            "answer": "reminding",
            "hit": false
          },
          {
            "score": 0.7824642658233643,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8750631809234619,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8213738799095154,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8094403743743896,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7982780337333679,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7950206995010376,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7749768495559692,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.7737657427787781,
            "answer": "comprehend",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8213738799095154,
        "b in neighbourhood of b_prime": 95,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 18,
      "cnt_questions_total": 47,
      "accuracy": 0.3829787234042553
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "cf27a701-f542-4e00-9c8e-887ba04c1060",
      "timestamp": "2025-05-18T12:23:21.025027"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8954148888587952,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.8685434460639954,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8512294292449951,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8279964923858643,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.8001242280006409,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.7975208759307861,
            "answer": "emphasizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.868543416261673,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.9009855389595032,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8903093338012695,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8676590323448181,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8437610864639282,
            "answer": "acknowledging",
            "hit": false
          },
          {
            "score": 0.8430029153823853,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8386313915252686,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8676590621471405,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9138472080230713,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.898271918296814,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8644561171531677,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8615258932113647,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8548951148986816,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8489928245544434,
            "answer": "permitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8644561767578125,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9271755218505859,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.9043865203857422,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.871880292892456,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8624514937400818,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8603187799453735,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8550035953521729,
            "answer": "declaring",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8718802332878113,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8892973065376282,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8858983516693115,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8718048334121704,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8217365145683289,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.8111988306045532,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.8039604425430298,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.889297366142273,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9166051745414734,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8967052698135376,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.887039303779602,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.826873242855072,
            "answer": "implementing",
            "hit": false
          },
          {
            "score": 0.8249088525772095,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.821532130241394,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.887039303779602,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8675459027290344,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8476423025131226,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8475791215896606,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8112953305244446,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7942792177200317,
            "answer": "begging",
            "hit": false
          },
          {
            "score": 0.7889206409454346,
            "answer": "inquired",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.847579151391983,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.9089874029159546,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.8922041654586792,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8022459149360657,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7959408164024353,
            "answer": "tending",
            "hit": false
          },
          {
            "score": 0.7948634624481201,
            "answer": "witnessing",
            "hit": false
          },
          {
            "score": 0.7897035479545593,
            "answer": "participating",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8922041952610016,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8709216117858887,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8608808517456055,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8519954085350037,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7730484008789062,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7690061926841736,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.7633096575737,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8519954085350037,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8280283212661743,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8174730539321899,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7844557166099548,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7831863760948181,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7778807878494263,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7735448479652405,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7778807580471039,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8785503506660461,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8712300062179565,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8467463850975037,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8297303915023804,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7921543121337891,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7871537804603577,
            "answer": "transporting",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8467463552951813,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.881763219833374,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8798187971115112,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8796614408493042,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8196966648101807,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.808220624923706,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.8004783987998962,
            "answer": "proceeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.879661500453949,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.9197314381599426,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.9048311710357666,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8760865330696106,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8392308354377747,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8356324434280396,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8275794386863708,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8760865330696106,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8753067255020142,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8737938404083252,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8651096820831299,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.84442138671875,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8229892253875732,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8193567991256714,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8444213569164276,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.915394127368927,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8931134939193726,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8671203851699829,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8646882772445679,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8322732448577881,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.8309418559074402,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8646883368492126,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.9078752398490906,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8839505314826965,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.877825140953064,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8267233967781067,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8208330869674683,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8150346279144287,
            "answer": "progressing",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.877825140953064,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.927820086479187,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.9089431762695312,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8622923493385315,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8401169180870056,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8356324434280396,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8320424556732178,
            "answer": "constructing",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8622923493385315,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7803229093551636,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.7801103591918945,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7734599113464355,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7694283723831177,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.763238251209259,
            "answer": "prevailing",
            "hit": false
          },
          {
            "score": 0.7622018456459045,
            "answer": "existent",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7803229093551636,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8617165088653564,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8477756977081299,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8198590874671936,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7901257276535034,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.789046049118042,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.7868425846099854,
            "answer": "predicting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8198590576648712,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8534851670265198,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8458055257797241,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.832129955291748,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8257995843887329,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.8237539529800415,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.8071432113647461,
            "answer": "declining",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8534852266311646,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8033066391944885,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8022473454475403,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.782600998878479,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7662975788116455,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7274199724197388,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7178413271903992,
            "answer": "ensuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8033066391944885,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.823119044303894,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.8029768466949463,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.8029053807258606,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7800050377845764,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7598023414611816,
            "answer": "witnessing",
            "hit": false
          },
          {
            "score": 0.7545350790023804,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8029054403305054,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.9298075437545776,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.9142966270446777,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8939781785011292,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8662537336349487,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8659341335296631,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8584917783737183,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8939782083034515,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8100513815879822,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.8011112213134766,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7885974049568176,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7721495628356934,
            "answer": "notably",
            "hit": false
          },
          {
            "score": 0.7522250413894653,
            "answer": "namely",
            "hit": false
          },
          {
            "score": 0.7452154159545898,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.78859743475914,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9244400262832642,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.9139832258224487,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8831796646118164,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8476455807685852,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.824801504611969,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.8202773332595825,
            "answer": "introductory",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8831796646118164,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8857265710830688,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8759288787841797,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8215063214302063,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.8133633136749268,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.8068096041679382,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8005495071411133,
            "answer": "utilizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7953516840934753,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.9176007509231567,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.8544055223464966,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.845605194568634,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8435003757476807,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8428176045417786,
            "answer": "securely",
            "hit": false
          },
          {
            "score": 0.8400475382804871,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1352,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7898611724376678,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1353
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8772426843643188,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8752651214599609,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8282063603401184,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7948177456855774,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7893664836883545,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.784018337726593,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.828206330537796,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8821426630020142,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8799048066139221,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8590936064720154,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8121217489242554,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7927286624908447,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.790885329246521,
            "answer": "regulating",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8590936064720154,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.907547116279602,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.8459936380386353,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8394680619239807,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8191354274749756,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.8183794617652893,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.8144329190254211,
            "answer": "adopting",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8459936380386353,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8647351861000061,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8455369472503662,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8450769186019897,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.810581386089325,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7863444685935974,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7778065800666809,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8450769782066345,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9006446003913879,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8876267671585083,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8709373474121094,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8191941380500793,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8170648217201233,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8096805810928345,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8709373474121094,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.9202620983123779,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.9113138914108276,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8810349702835083,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8715636134147644,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8653473854064941,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8625560998916626,
            "answer": "proposed",
            "hit": true
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8625560998916626,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9226656556129456,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.9147403240203857,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8948092460632324,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8665775656700134,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8222895264625549,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8172069787979126,
            "answer": "delivering",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8948092758655548,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.86688232421875,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.8360069990158081,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.8358513116836548,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8316991329193115,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.8271670937538147,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.8236828446388245,
            "answer": "publications",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8360069394111633,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8932152390480042,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8798074126243591,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8619621992111206,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8004910945892334,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7954490780830383,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.790858268737793,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.861962229013443,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.9178338050842285,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.907301664352417,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.872848629951477,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.864206075668335,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8604331016540527,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8541544675827026,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8728486597537994,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8965973854064941,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8862696290016174,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8707638382911682,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8051944971084595,
            "answer": "detrimental",
            "hit": false
          },
          {
            "score": 0.8044483661651611,
            "answer": "illustrating",
            "hit": false
          },
          {
            "score": 0.803964376449585,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7941211760044098,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8154057264328003,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8078356981277466,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7974206209182739,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7773756384849548,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7765617370605469,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7606216073036194,
            "answer": "staying",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.807835727930069,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.911213755607605,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.9104395508766174,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.9095602035522461,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8127906322479248,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.8046128749847412,
            "answer": "removing",
            "hit": false
          },
          {
            "score": 0.8040977716445923,
            "answer": "substituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.911213755607605,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.9035073518753052,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.9019237756729126,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.8931892514228821,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8159011602401733,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.8114817142486572,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7942194938659668,
            "answer": "illustrating",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8931893110275269,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.9082425832748413,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.900102436542511,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8519036173820496,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8511323928833008,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.834256649017334,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8321945667266846,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8519035577774048,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9169425368309021,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.8975338935852051,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8801729679107666,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8143921494483948,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7929108142852783,
            "answer": "bringing",
            "hit": false
          },
          {
            "score": 0.7884705066680908,
            "answer": "transmitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8801730275154114,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8980039954185486,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8765987157821655,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8350546956062317,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8272470831871033,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.8128746747970581,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7839565277099609,
            "answer": "purchasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8350546658039093,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.86705082654953,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.864177405834198,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8631477355957031,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8126354217529297,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7865082025527954,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7839120626449585,
            "answer": "endured",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8631477653980255,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8608849048614502,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8538241386413574,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8499224781990051,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.8127500414848328,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7982503175735474,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7974454760551453,
            "answer": "preaching",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8499224781990051,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8750631213188171,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8468402624130249,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8316373229026794,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8164085149765015,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.786601185798645,
            "answer": "reminding",
            "hit": false
          },
          {
            "score": 0.7824642658233643,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8468402326107025,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8213738799095154,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8094403743743896,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7982780337333679,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7950206995010376,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7749768495559692,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.7737657427787781,
            "answer": "comprehend",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8094403743743896,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 48,
      "accuracy": 0.10416666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "df65a26d-701f-4418-930d-47bfbe6a273c",
      "timestamp": "2025-05-18T12:23:21.373761"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8954148888587952,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.8728482723236084,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8571966886520386,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8469924926757812,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.8374117612838745,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.8331565856933594,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8728483021259308,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.9009855389595032,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8933293223381042,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8778051137924194,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8434963226318359,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8384730815887451,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8336822390556335,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8778051733970642,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9138472676277161,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.9044910669326782,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.9031187295913696,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8690475225448608,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8507764339447021,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8446651101112366,
            "answer": "permits",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8690474927425385,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9095020890235901,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.9043865203857422,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8877220749855042,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8714224696159363,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.867236852645874,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8539723753929138,
            "answer": "announcement",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8714224696159363,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9067435264587402,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8978977799415588,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8718048334121704,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.8505450487136841,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8039237856864929,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.797549843788147,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8978977799415588,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9259973764419556,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8967052102088928,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8724409937858582,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8352534174919128,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8182501792907715,
            "answer": "extends",
            "hit": false
          },
          {
            "score": 0.8180350661277771,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8724409937858582,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8981482982635498,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8675459027290344,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8640376925468445,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8447535037994385,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.8090755343437195,
            "answer": "requests",
            "hit": false
          },
          {
            "score": 0.8057361245155334,
            "answer": "questioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8981483280658722,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8662126064300537,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8617130517959595,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8608808517456055,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7996581792831421,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.7938379049301147,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.7936328053474426,
            "answer": "proves",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8662126362323761,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8921322822570801,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8863603472709656,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.8757528066635132,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.8531495332717896,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8316211104393005,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8260708451271057,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8921322524547577,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8839224576950073,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.8439838886260986,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8293452262878418,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8280283808708191,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.8255096673965454,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8247820138931274,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8439838886260986,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9237167239189148,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.9081952571868896,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8828239440917969,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8367379903793335,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7996677160263062,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7886627912521362,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9237167239189148,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8883761167526245,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8712300062179565,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.859195351600647,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8346347808837891,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.8214454650878906,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8014149069786072,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.859195351600647,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9142159223556519,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8934231996536255,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8798187971115112,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8167108297348022,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.8122744560241699,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.8044381141662598,
            "answer": "persisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8934232294559479,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.9048311710357666,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.9000522494316101,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8663136959075928,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8450847864151001,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8407585620880127,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8404828310012817,
            "answer": "destroys",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8407586216926575,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8974717855453491,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8811699151992798,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8658750057220459,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8651096820831299,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8580227494239807,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.8360034823417664,
            "answer": "realizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8811699151992798,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.915394127368927,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8938761949539185,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.87785804271698,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8473549485206604,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8415102362632751,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8385534882545471,
            "answer": "defines",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.87785804271698,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.9150981903076172,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8839505910873413,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8645673394203186,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8488226532936096,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8455691933631897,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8440418839454651,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8645673394203186,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.9093228578567505,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.9089431762695312,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8647941946983337,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8610435724258423,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8573455810546875,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.8569356203079224,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8375205397605896,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 36
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8631632924079895,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8617165088653564,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.8601047992706299,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.8463901877403259,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.8459651470184326,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8395901918411255,
            "answer": "predicting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8459650874137878,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8765961527824402,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8633738160133362,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8458055257797241,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8447433114051819,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.8403850793838501,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.8245995044708252,
            "answer": "failure",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8633738160133362,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8678023815155029,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.8616020679473877,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7870765924453735,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.782600998878479,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7552883625030518,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7509162425994873,
            "answer": "preceded",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8616020083427429,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.8947767019271851,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8884302377700806,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.832889974117279,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8154692649841309,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8081506490707397,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7916625142097473,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8947766721248627,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8363567590713501,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.8325211405754089,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8029768466949463,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7968044877052307,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7957903146743774,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7944445610046387,
            "answer": "learns",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8325212001800537,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8803422451019287,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.8657294511795044,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.8346347808837891,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8232060670852661,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8133297562599182,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.8011112213134766,
            "answer": "including",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8657294511795044,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8790285587310791,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.8756824731826782,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.8601047992706299,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8476744294166565,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8466403484344482,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8464605808258057,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8363335728645325,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9277023673057556,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.9139832258224487,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8809465765953064,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8447390794754028,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8441944122314453,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8359506130218506,
            "answer": "introductory",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8809465765953064,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.9149648547172546,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8759288787841797,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8291730284690857,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8284561038017273,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8266269564628601,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8196767568588257,
            "answer": "implicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8138742446899414,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.901468813419342,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8772426843643188,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8442373275756836,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.8312273621559143,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8291307687759399,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.8274449110031128,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8312273621559143,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.9106206297874451,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8947370052337646,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8799048662185669,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.8299275636672974,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8260557055473328,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8253297805786133,
            "answer": "utilizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8947370648384094,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9192324280738831,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8935016393661499,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8700538277626038,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.832889974117279,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.821526288986206,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.8145388960838318,
            "answer": "occurrence",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8935016393661499,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.9162927865982056,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8961695432662964,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.8455369472503662,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.830881655216217,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8264304995536804,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8146725296974182,
            "answer": "owns",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8961695432662964,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9174794554710388,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8977336287498474,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8876268267631531,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8397772312164307,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8347523808479309,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8311017751693726,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8977336287498474,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.9202620387077332,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.9136319160461426,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8745405077934265,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8560512065887451,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8523226976394653,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8446274995803833,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8745405673980713,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9226655960083008,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.9189121127128601,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8906245827674866,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8340899348258972,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.829459547996521,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8251388669013977,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.890624612569809,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9078066945075989,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8798074126243591,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8650603294372559,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8301213979721069,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8279434442520142,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8214653730392456,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8650602698326111,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8828813433647156,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8813886046409607,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8646743297576904,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8203480243682861,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8144019246101379,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.8119246959686279,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8646743893623352,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.9033911228179932,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8965973854064941,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.849419116973877,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8349654674530029,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8331944346427917,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8325601816177368,
            "answer": "illustrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 919,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7837970852851868,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 920
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8614845275878906,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8521876335144043,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7886768579483032,
            "answer": "remnants",
            "hit": false
          },
          {
            "score": 0.7776221036911011,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.7769455313682556,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7765617370605469,
            "answer": "remaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8521876335144043,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.9104395508766174,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8946242332458496,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8941784501075745,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8653692007064819,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.8456242680549622,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.8440523743629456,
            "answer": "supplemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8941784799098969,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.9236043095588684,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.9035074710845947,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.8951020240783691,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.819938063621521,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.804916262626648,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.803719162940979,
            "answer": "illustrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8951019942760468,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.9241580367088318,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.9001023769378662,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8687350749969482,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8304113149642944,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.8291730284690857,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.827800989151001,
            "answer": "requirement",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8687350153923035,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.9069392085075378,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8949459791183472,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8505450487136841,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8280300498008728,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7857260704040527,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7818744778633118,
            "answer": "proves",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9069391787052155,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9169424772262573,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8987424373626709,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8695879578590393,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8415645956993103,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.8198443055152893,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.807536244392395,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8695879578590393,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.908430278301239,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8765987157821655,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.8716614246368408,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8255406022071838,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.825049638748169,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8242117762565613,
            "answer": "occupies",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8716614246368408,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8890132904052734,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8866289854049683,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8816473484039307,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.8496404886245728,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8484916687011719,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8360855579376221,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8890133500099182,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8762553930282593,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8750631213188171,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8586369752883911,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.8427900075912476,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8175737857818604,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.8160213232040405,
            "answer": "warns",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8762553632259369,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 46,
      "accuracy": 0.17391304347826086
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "5cbc533a-e0c7-45d2-82fd-255d28da4009",
      "timestamp": "2025-05-18T12:23:21.742550"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7583726644515991,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.7248109579086304,
            "answer": "house",
            "hit": false
          },
          {
            "score": 0.692318320274353,
            "answer": "back",
            "hit": false
          },
          {
            "score": 0.6805663704872131,
            "answer": "family",
            "hit": false
          },
          {
            "score": 0.6760256290435791,
            "answer": "host",
            "hit": false
          },
          {
            "score": 0.6732818484306335,
            "answer": "homeland",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 8970,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5786302834749222,
        "b in neighbourhood of b_prime": 14092,
        "b_prime in neighbourhood of b": 8971
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7578984498977661,
            "answer": "astonished",
            "hit": false
          },
          {
            "score": 0.7568849921226501,
            "answer": "shrinking",
            "hit": false
          },
          {
            "score": 0.7554430961608887,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7541236281394958,
            "answer": "relocation",
            "hit": false
          },
          {
            "score": 0.7539294362068176,
            "answer": "deborah",
            "hit": false
          },
          {
            "score": 0.7535963654518127,
            "answer": "securely",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 354,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7337463647127151,
        "b in neighbourhood of b_prime": 8375,
        "b_prime in neighbourhood of b": 355
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "d68c513b-3c67-45ba-bcb2-8a9f29d0614c",
      "timestamp": "2025-05-18T12:23:22.132775"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.8281036615371704,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.7841197848320007,
            "answer": "ability",
            "hit": false
          },
          {
            "score": 0.7640384435653687,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7637538909912109,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7626339197158813,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.7596396207809448,
            "answer": "capable",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8281036615371704,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8894883394241333,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.8502013087272644,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.8233195543289185,
            "answer": "respectable",
            "hit": false
          },
          {
            "score": 0.8227337598800659,
            "answer": "desirable",
            "hit": false
          },
          {
            "score": 0.817908763885498,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.81722092628479,
            "answer": "usable",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8894883990287781,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8731856942176819,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.8592429757118225,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.8494505882263184,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8475230932235718,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.8346409201622009,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7905662059783936,
            "answer": "susceptible",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8346409499645233,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8096741437911987,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.780228316783905,
            "answer": "availability",
            "hit": false
          },
          {
            "score": 0.774904727935791,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.7456181049346924,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7428508996963501,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.7353529930114746,
            "answer": "applicable",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.809674084186554,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.8190728425979614,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.8177570700645447,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.7927858829498291,
            "answer": "realizing",
            "hit": false
          },
          {
            "score": 0.7888198494911194,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.7843390107154846,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7825630307197571,
            "answer": "acquainted",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8190729022026062,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7973189353942871,
            "answer": "sure",
            "hit": false
          },
          {
            "score": 0.7454081773757935,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7419533729553223,
            "answer": "specified",
            "hit": false
          },
          {
            "score": 0.7367093563079834,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7363353967666626,
            "answer": "definite",
            "hit": false
          },
          {
            "score": 0.7363237142562866,
            "answer": "particular",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7050373554229736,
        "b in neighbourhood of b_prime": 6910,
        "b_prime in neighbourhood of b": 34
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.8664897084236145,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.8516436219215393,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.8499763607978821,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.8221864700317383,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.7926589846611023,
            "answer": "switched",
            "hit": false
          },
          {
            "score": 0.7842255234718323,
            "answer": "altering",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 67,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7228958308696747,
        "b in neighbourhood of b_prime": 5760,
        "b_prime in neighbourhood of b": 68
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8606550097465515,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.8325813412666321,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.8004853129386902,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7944421768188477,
            "answer": "cozy",
            "hit": false
          },
          {
            "score": 0.7926381826400757,
            "answer": "luxurious",
            "hit": false
          },
          {
            "score": 0.7892132997512817,
            "answer": "uneasy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8606550395488739,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.8335245847702026,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.8263053894042969,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.8177571296691895,
            "answer": "aware",
            "hit": false
          },
          {
            "score": 0.7890469431877136,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.7741880416870117,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.771414041519165,
            "answer": "coherent",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7890470027923584,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8898961544036865,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.8790500164031982,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.8773889541625977,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.8320732712745667,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.8137876987457275,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.8083617687225342,
            "answer": "utilizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8027988374233246,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.8459651470184326,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8387280106544495,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.8260828256607056,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8198590874671936,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7914993762969971,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7639539241790771,
            "answer": "expectation",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7404851615428925,
        "b in neighbourhood of b_prime": 1097,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.8689019083976746,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.8473473191261292,
            "answer": "finish",
            "hit": false
          },
          {
            "score": 0.8396255970001221,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.8300250768661499,
            "answer": "completed",
            "hit": false
          },
          {
            "score": 0.7737354040145874,
            "answer": "completing",
            "hit": false
          },
          {
            "score": 0.7638550996780396,
            "answer": "concluded",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7497396171092987,
        "b in neighbourhood of b_prime": 961,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8412859439849854,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.839114248752594,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.8271495699882507,
            "answer": "privileged",
            "hit": false
          },
          {
            "score": 0.8105982542037964,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.808930516242981,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.8073352575302124,
            "answer": "foolish",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8412860035896301,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.8263459205627441,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.8051723837852478,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7889020442962646,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7861967086791992,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7798588871955872,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.7785241603851318,
            "answer": "pleased",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8263459205627441,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.8971700072288513,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.8962252140045166,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8861910104751587,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8315294981002808,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8291468620300293,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.8027346134185791,
            "answer": "detected",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7720656991004944,
        "b in neighbourhood of b_prime": 732,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7492634057998657,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7401044964790344,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.7400932312011719,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7337083220481873,
            "answer": "knew",
            "hit": false
          },
          {
            "score": 0.7314965724945068,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7270816564559937,
            "answer": "famed",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6978600025177002,
        "b in neighbourhood of b_prime": 236,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8886468410491943,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.8315250873565674,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.8299551606178284,
            "answer": "securely",
            "hit": false
          },
          {
            "score": 0.8297967910766602,
            "answer": "illicit",
            "hit": false
          },
          {
            "score": 0.8283859491348267,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.828354001045227,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8886467814445496,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.87554532289505,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.8526730537414551,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.8261480331420898,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7901410460472107,
            "answer": "compensated",
            "hit": false
          },
          {
            "score": 0.7846550941467285,
            "answer": "payment",
            "hit": false
          },
          {
            "score": 0.7825720310211182,
            "answer": "unpaid",
            "hit": true
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7825720310211182,
        "b in neighbourhood of b_prime": 478,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.8419026136398315,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.8248777389526367,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8229633569717407,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7950289249420166,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7906067371368408,
            "answer": "pleasing",
            "hit": false
          },
          {
            "score": 0.7894719839096069,
            "answer": "pleasures",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8419026434421539,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.8101730346679688,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7889313697814941,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7664744257926941,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.7650681138038635,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.7561407089233398,
            "answer": "prevalent",
            "hit": false
          },
          {
            "score": 0.7506273984909058,
            "answer": "controversial",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7889314293861389,
        "b in neighbourhood of b_prime": 316,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8615743517875671,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.830173134803772,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.820899248123169,
            "answer": "repetitive",
            "hit": false
          },
          {
            "score": 0.8207329511642456,
            "answer": "uniformly",
            "hit": false
          },
          {
            "score": 0.8161057233810425,
            "answer": "inevitably",
            "hit": false
          },
          {
            "score": 0.815922737121582,
            "answer": "predictions",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8615743517875671,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.8796524405479431,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.8360069990158081,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8276978731155396,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.813184380531311,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8080741763114929,
            "answer": "printed",
            "hit": false
          },
          {
            "score": 0.7921041250228882,
            "answer": "released",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7788569331169128,
        "b in neighbourhood of b_prime": 1211,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8510562777519226,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.8507522344589233,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.8303413391113281,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.8175380825996399,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.8141345977783203,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.8101081252098083,
            "answer": "respectable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8510562777519226,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.7941211462020874,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.786569356918335,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.7864189147949219,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.783797025680542,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7749906778335571,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7742942571640015,
            "answer": "associated",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7865693867206573,
        "b in neighbourhood of b_prime": 165,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8853563070297241,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.8456239104270935,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.8405929803848267,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.82929527759552,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.8209876418113708,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.8163878917694092,
            "answer": "satisfactory",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8853563368320465,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.8810791969299316,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.8733749389648438,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.836869478225708,
            "answer": "prescribed",
            "hit": false
          },
          {
            "score": 0.8233873844146729,
            "answer": "configured",
            "hit": false
          },
          {
            "score": 0.8202285766601562,
            "answer": "disclosed",
            "hit": false
          },
          {
            "score": 0.8194341659545898,
            "answer": "specifications",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8167061805725098,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8688455820083618,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.8363083004951477,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.8211566805839539,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.8161284327507019,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7837032079696655,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.7820492386817932,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8688455820083618,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.853664755821228,
            "answer": "use",
            "hit": false
          },
          {
            "score": 0.8184582591056824,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.8172227144241333,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.8088944554328918,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.7874060273170471,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.7681035995483398,
            "answer": "utilize",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7372081726789474,
        "b in neighbourhood of b_prime": 3811,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.8137839436531067,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7710206508636475,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7660043835639954,
            "answer": "normal",
            "hit": false
          },
          {
            "score": 0.7561523914337158,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7522460222244263,
            "answer": "aforementioned",
            "hit": false
          },
          {
            "score": 0.749921977519989,
            "answer": "predominant",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.721415713429451,
        "b in neighbourhood of b_prime": 2531,
        "b_prime in neighbourhood of b": 47
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.8566083312034607,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8490561842918396,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.8061859011650085,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.8043376207351685,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.7857280969619751,
            "answer": "desired",
            "hit": false
          },
          {
            "score": 0.767658531665802,
            "answer": "desires",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7240371406078339,
        "b in neighbourhood of b_prime": 7282,
        "b_prime in neighbourhood of b": 26
      }
    ],
    "result": {
      "cnt_questions_correct": 13,
      "cnt_questions_total": 30,
      "accuracy": 0.43333333333333335
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e5569396-b0fe-41f8-8813-e5beda842310",
      "timestamp": "2025-05-18T12:23:22.166373"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7854099869728088,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.7825483083724976,
            "answer": "pursuant",
            "hit": false
          },
          {
            "score": 0.7495995759963989,
            "answer": "adherence",
            "hit": false
          },
          {
            "score": 0.7384036183357239,
            "answer": "adhere",
            "hit": false
          },
          {
            "score": 0.738012433052063,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7341267466545105,
            "answer": "depending",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7226564884185791,
        "b in neighbourhood of b_prime": 6236,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.7979629635810852,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7940516471862793,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.7725908160209656,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7648434638977051,
            "answer": "exact",
            "hit": false
          },
          {
            "score": 0.7633828520774841,
            "answer": "authentic",
            "hit": false
          },
          {
            "score": 0.7579672336578369,
            "answer": "purported",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7940516769886017,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.8051871657371521,
            "answer": "extra",
            "hit": false
          },
          {
            "score": 0.7895663976669312,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.7862913608551025,
            "answer": "supplementary",
            "hit": false
          },
          {
            "score": 0.7831549644470215,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7745855450630188,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7694133520126343,
            "answer": "added",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7895663976669312,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8401871919631958,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8147280216217041,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.792312502861023,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7822415828704834,
            "answer": "perceived",
            "hit": false
          },
          {
            "score": 0.779542863368988,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.7729265093803406,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7599887549877167,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.8592865467071533,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8342418074607849,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8149675130844116,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.8112714290618896,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.8094646334648132,
            "answer": "stunning",
            "hit": false
          },
          {
            "score": 0.8004780411720276,
            "answer": "handsome",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.814967542886734,
        "b in neighbourhood of b_prime": 114,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.8002355098724365,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.7966136932373047,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.7629677057266235,
            "answer": "criticisms",
            "hit": false
          },
          {
            "score": 0.7576125264167786,
            "answer": "supportive",
            "hit": false
          },
          {
            "score": 0.7557288408279419,
            "answer": "imperative",
            "hit": false
          },
          {
            "score": 0.7533637881278992,
            "answer": "vital",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8002354800701141,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.8388328552246094,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.8098036050796509,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.8096597194671631,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7904207706451416,
            "answer": "literary",
            "hit": false
          },
          {
            "score": 0.7855915427207947,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7822639346122742,
            "answer": "ideological",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8388328552246094,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8811699151992798,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.865760862827301,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.84442138671875,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7987229824066162,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7807057499885559,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.7776231169700623,
            "answer": "resolved",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7372868359088898,
        "b in neighbourhood of b_prime": 8191,
        "b_prime in neighbourhood of b": 43
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7935451865196228,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.787808358669281,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7752028107643127,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.766828179359436,
            "answer": "separate",
            "hit": false
          },
          {
            "score": 0.7583072781562805,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.7459731101989746,
            "answer": "varying",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.787808358669281,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.834109902381897,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7903763651847839,
            "answer": "electronic",
            "hit": false
          },
          {
            "score": 0.7837734222412109,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.7657574415206909,
            "answer": "analogue",
            "hit": false
          },
          {
            "score": 0.7646098136901855,
            "answer": "online",
            "hit": false
          },
          {
            "score": 0.760970950126648,
            "answer": "virtual",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8341099321842194,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.8202895522117615,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.8172532916069031,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.8123205900192261,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.8101022243499756,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7721179723739624,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7681281566619873,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8172533512115479,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.8413041830062866,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.8250150084495544,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.8108707666397095,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.8018474578857422,
            "answer": "ecology",
            "hit": false
          },
          {
            "score": 0.7991939783096313,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7990071773529053,
            "answer": "environments",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8250150084495544,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.8448980450630188,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.8441082835197449,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.8283998966217041,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.8260466456413269,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.8212718963623047,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.8098799586296082,
            "answer": "intricate",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8448980450630188,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.8515670299530029,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.8453848361968994,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.8329750299453735,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.802402138710022,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7975612878799438,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7894361019134521,
            "answer": "notable",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8024021685123444,
        "b in neighbourhood of b_prime": 127,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.825347900390625,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.8154781460762024,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7937442064285278,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7869410514831543,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.7857770919799805,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7732092142105103,
            "answer": "funds",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8253479599952698,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8399242758750916,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.8201843500137329,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.771568238735199,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.7529881000518799,
            "answer": "systemic",
            "hit": false
          },
          {
            "score": 0.7514429688453674,
            "answer": "localized",
            "hit": false
          },
          {
            "score": 0.749484658241272,
            "answer": "internationally",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8399243056774139,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.8557642102241516,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.785719633102417,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7856322526931763,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.784797191619873,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.7846118211746216,
            "answer": "history",
            "hit": false
          },
          {
            "score": 0.7758139371871948,
            "answer": "histories",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7847972512245178,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.883291482925415,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.8648919463157654,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.8545466661453247,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.8419730067253113,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.8205208778381348,
            "answer": "large",
            "hit": false
          },
          {
            "score": 0.8191437721252441,
            "answer": "hugely",
            "hit": true
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8191438317298889,
        "b in neighbourhood of b_prime": 109,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.8092442750930786,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7772214412689209,
            "answer": "instant",
            "hit": false
          },
          {
            "score": 0.7732734084129333,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7620446681976318,
            "answer": "promptly",
            "hit": false
          },
          {
            "score": 0.7556930780410767,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.7544267773628235,
            "answer": "abrupt",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8092442750930786,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.815818190574646,
            "answer": "significant",
            "hit": false
          },
          {
            "score": 0.8135051727294922,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.8009693026542664,
            "answer": "importance",
            "hit": false
          },
          {
            "score": 0.7871560454368591,
            "answer": "influential",
            "hit": false
          },
          {
            "score": 0.7744724750518799,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.7720707654953003,
            "answer": "noteworthy",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7345730513334274,
        "b in neighbourhood of b_prime": 2526,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.8922021389007568,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8722110986709595,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.8600658178329468,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.8581439256668091,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.8352308869361877,
            "answer": "expanding",
            "hit": false
          },
          {
            "score": 0.8306969404220581,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8187140226364136,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.8333840370178223,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.8269928097724915,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.7748396396636963,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7695866823196411,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.7626163959503174,
            "answer": "interior",
            "hit": false
          },
          {
            "score": 0.7525026798248291,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8333839774131775,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.771770715713501,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.771568238735199,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.7551208734512329,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7500725388526917,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7344421148300171,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.7341293096542358,
            "answer": "globally",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.771770715713501,
        "b in neighbourhood of b_prime": 98,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.7971049547195435,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7698794603347778,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7692548036575317,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7621093392372131,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.758792519569397,
            "answer": "lawful",
            "hit": false
          },
          {
            "score": 0.7483574151992798,
            "answer": "contractual",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7971049547195435,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.8365864157676697,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7969233989715576,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.7817569375038147,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7658723592758179,
            "answer": "psychic",
            "hit": false
          },
          {
            "score": 0.7654587030410767,
            "answer": "emotional",
            "hit": false
          },
          {
            "score": 0.7640470266342163,
            "answer": "neurological",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8365864455699921,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.7779102325439453,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.7669390439987183,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.7659814357757568,
            "answer": "cute",
            "hit": false
          },
          {
            "score": 0.7460489273071289,
            "answer": "decent",
            "hit": false
          },
          {
            "score": 0.7421307563781738,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7421267032623291,
            "answer": "nasty",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.766939103603363,
        "b in neighbourhood of b_prime": 721,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.8381520509719849,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8147280216217041,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.8020169138908386,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7917124629020691,
            "answer": "obviously",
            "hit": true
          },
          {
            "score": 0.7664390802383423,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.7662339210510254,
            "answer": "evidenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7917124330997467,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8467991352081299,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.7603867650032043,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.7548356056213379,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.7430470585823059,
            "answer": "tangible",
            "hit": false
          },
          {
            "score": 0.7369519472122192,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7360991835594177,
            "answer": "emotional",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8467991650104523,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.8227553367614746,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.8185964226722717,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.7967014908790588,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7923291325569153,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.775536298751831,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.7558400630950928,
            "answer": "economic",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.822755366563797,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7904787063598633,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7884759902954102,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7740344405174255,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7718735337257385,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.7707236409187317,
            "answer": "cynical",
            "hit": false
          },
          {
            "score": 0.7659608721733093,
            "answer": "fundamentally",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 3012,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7096963822841644,
        "b in neighbourhood of b_prime": 4817,
        "b_prime in neighbourhood of b": 3013
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8323268890380859,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.8262574672698975,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.8108751177787781,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.8043779134750366,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7723549008369446,
            "answer": "predecessors",
            "hit": false
          },
          {
            "score": 0.7704309225082397,
            "answer": "subsequent",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8108751177787781,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.8187686204910278,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7646480202674866,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.7598589658737183,
            "answer": "commonplace",
            "hit": false
          },
          {
            "score": 0.7595902681350708,
            "answer": "scarce",
            "hit": false
          },
          {
            "score": 0.7577583193778992,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.7522207498550415,
            "answer": "exceptional",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7577583193778992,
        "b in neighbourhood of b_prime": 60,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.8132545948028564,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.8009824752807617,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7851216793060303,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7667121887207031,
            "answer": "sincere",
            "hit": false
          },
          {
            "score": 0.756929874420166,
            "answer": "solemn",
            "hit": false
          },
          {
            "score": 0.7522240877151489,
            "answer": "earnest",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8132546544075012,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8720443248748779,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.8230341672897339,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.8214091062545776,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.8133602142333984,
            "answer": "erotic",
            "hit": false
          },
          {
            "score": 0.8031536340713501,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.7828893065452576,
            "answer": "sex",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8720443248748779,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.8604841232299805,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.8284709453582764,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.8240889310836792,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.8210752010345459,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.8190997242927551,
            "answer": "notable",
            "hit": false
          },
          {
            "score": 0.815818190574646,
            "answer": "important",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8210752010345459,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.8434026837348938,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.8400334119796753,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.8215468525886536,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7968965768814087,
            "answer": "identical",
            "hit": false
          },
          {
            "score": 0.7717040777206421,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7632210850715637,
            "answer": "akin",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8400334119796753,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.8248040080070496,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7957847118377686,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.7864357233047485,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.7790182828903198,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7728143334388733,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7674075365066528,
            "answer": "powerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7864357233047485,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8549646139144897,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.8469676375389099,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.8250179290771484,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.8146671652793884,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.799845814704895,
            "answer": "succeeding",
            "hit": false
          },
          {
            "score": 0.7956514358520508,
            "answer": "thereafter",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8469676971435547,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8688455820083618,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.8363083004951477,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.8211566805839539,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.8161284327507019,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7837032079696655,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.7820492386817932,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8363082706928253,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.8176252841949463,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.8067627549171448,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7843154668807983,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7715374827384949,
            "answer": "tradition",
            "hit": false
          },
          {
            "score": 0.7633726596832275,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.7608324885368347,
            "answer": "typical",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8176252841949463,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.8146507740020752,
            "answer": "characteristic",
            "hit": false
          },
          {
            "score": 0.7951017618179321,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.7719061970710754,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.7710206508636475,
            "answer": "usual",
            "hit": false
          },
          {
            "score": 0.770365297794342,
            "answer": "indicative",
            "hit": false
          },
          {
            "score": 0.7670921683311462,
            "answer": "reminiscent",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7951018214225769,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.824102520942688,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.8207184076309204,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.804394006729126,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.7902094125747681,
            "answer": "innovative",
            "hit": false
          },
          {
            "score": 0.787274956703186,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.7816891074180603,
            "answer": "peculiar",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.824102520942688,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.7828729152679443,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.777308464050293,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.7765035629272461,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7729211449623108,
            "answer": "interactive",
            "hit": false
          },
          {
            "score": 0.7665038108825684,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.7655794024467468,
            "answer": "simulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.777308464050293,
        "b in neighbourhood of b_prime": 116,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.8130138516426086,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.7832394242286682,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.75642329454422,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.7561397552490234,
            "answer": "graphic",
            "hit": false
          },
          {
            "score": 0.7559082508087158,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.7500605583190918,
            "answer": "conceptual",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.813013881444931,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 18,
      "cnt_questions_total": 44,
      "accuracy": 0.4090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "89421100-c3d0-42ca-94b2-a7282f7eaba9",
      "timestamp": "2025-05-18T12:23:22.434314"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.8190728425979614,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.8177570700645447,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.7927858829498291,
            "answer": "realizing",
            "hit": false
          },
          {
            "score": 0.7888198494911194,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.7843390107154846,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.7825630307197571,
            "answer": "acquainted",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7843390107154846,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.8335245847702026,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.8263053894042969,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.8177571296691895,
            "answer": "aware",
            "hit": false
          },
          {
            "score": 0.7890469431877136,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.7741880416870117,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.771414041519165,
            "answer": "coherent",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8263053894042969,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.8202895522117615,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.8172532916069031,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.8123205900192261,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.8101022243499756,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7721179723739624,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7681281566619873,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8123206198215485,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.8263459205627441,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.8051723837852478,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7889020442962646,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7861967086791992,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.7798588871955872,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.7785241603851318,
            "answer": "pleased",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7861967384815216,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7768568992614746,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.7691742777824402,
            "answer": "angry",
            "hit": false
          },
          {
            "score": 0.7597434520721436,
            "answer": "insane",
            "hit": false
          },
          {
            "score": 0.7350054979324341,
            "answer": "angered",
            "hit": false
          },
          {
            "score": 0.7317487001419067,
            "answer": "mania",
            "hit": false
          },
          {
            "score": 0.7313774824142456,
            "answer": "furious",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7290668189525604,
        "b in neighbourhood of b_prime": 3212,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7927249670028687,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7778928279876709,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.7638620138168335,
            "answer": "sob",
            "hit": false
          },
          {
            "score": 0.7636478543281555,
            "answer": "tragic",
            "hit": false
          },
          {
            "score": 0.7611947059631348,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7602322101593018,
            "answer": "ironic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7927249670028687,
        "b in neighbourhood of b_prime": 111,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.8132545948028564,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.8009824752807617,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7851216793060303,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7667121887207031,
            "answer": "sincere",
            "hit": false
          },
          {
            "score": 0.756929874420166,
            "answer": "solemn",
            "hit": false
          },
          {
            "score": 0.7522240877151489,
            "answer": "earnest",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8009825348854065,
        "b in neighbourhood of b_prime": 111,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.8552837371826172,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.8242624402046204,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.8166923522949219,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.8145226836204529,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.8027293682098389,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7994601130485535,
            "answer": "stronger",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8145227134227753,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 8,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "f4606835-ca69-4d5c-bfbe-a8a2265b591f",
      "timestamp": "2025-05-18T12:23:22.818227"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8983632326126099,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8946914076805115,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.875094473361969,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8246158957481384,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.8103522062301636,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7919024229049683,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 211,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7439756393432617,
        "b in neighbourhood of b_prime": 2950,
        "b_prime in neighbourhood of b": 212
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.9279524087905884,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.9048516750335693,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.8516411185264587,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8515681624412537,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.8421894311904907,
            "answer": "adapting",
            "hit": false
          },
          {
            "score": 0.8304712772369385,
            "answer": "adjustable",
            "hit": true
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8304713070392609,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.8391213417053223,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.7817485332489014,
            "answer": "tolerate",
            "hit": false
          },
          {
            "score": 0.7751510143280029,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7715824842453003,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7687786817550659,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7674238085746765,
            "answer": "cheaper",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7751510739326477,
        "b in neighbourhood of b_prime": 337,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.8839224576950073,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8498429656028748,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.8174730539321899,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7856860160827637,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7795464396476746,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7774255871772766,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 1937,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7109012007713318,
        "b in neighbourhood of b_prime": 8209,
        "b_prime in neighbourhood of b": 1938
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.9142763018608093,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.9045725464820862,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.903662383556366,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8256145715713501,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8100818395614624,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.795230507850647,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8100818395614624,
        "b in neighbourhood of b_prime": 332,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.922132134437561,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.9216601848602295,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8971700072288513,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8540855646133423,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8376580476760864,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.8049492835998535,
            "answer": "differentiated",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8376580476760864,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8891274333000183,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.859863817691803,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.85682213306427,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.8507121801376343,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.8293735980987549,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8106182217597961,
            "answer": "expects",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.806117057800293,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.9276493787765503,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.9169279336929321,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.9036266803741455,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8636119365692139,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.8495030403137207,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.837242841720581,
            "answer": "reliance",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 494,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7656888961791992,
        "b in neighbourhood of b_prime": 659,
        "b_prime in neighbourhood of b": 495
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8995909094810486,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.8719879388809204,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.8283897638320923,
            "answer": "revive",
            "hit": false
          },
          {
            "score": 0.8195673227310181,
            "answer": "repairing",
            "hit": false
          },
          {
            "score": 0.8083492517471313,
            "answer": "verify",
            "hit": false
          },
          {
            "score": 0.8082743287086487,
            "answer": "modify",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 1219,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7610971331596375,
        "b in neighbourhood of b_prime": 472,
        "b_prime in neighbourhood of b": 1220
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8965174555778503,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.8562511205673218,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.8210158348083496,
            "answer": "maintain",
            "hit": false
          },
          {
            "score": 0.8144732117652893,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8104416728019714,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.805949330329895,
            "answer": "endure",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 111,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.782687246799469,
        "b in neighbourhood of b_prime": 89,
        "b_prime in neighbourhood of b": 112
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8915656805038452,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8556406497955322,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.8231604099273682,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8220195770263672,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.8132427930831909,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.812861442565918,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 83,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7429751008749008,
        "b in neighbourhood of b_prime": 270,
        "b_prime in neighbourhood of b": 84
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "3c9f2979-e3fb-4619-9dd4-4303b5978c85",
      "timestamp": "2025-05-18T12:23:22.888086"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.8757528066635132,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8602850437164307,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.85483717918396,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7787802219390869,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7690629959106445,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7632874250411987,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7598999440670013,
        "b in neighbourhood of b_prime": 1882,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.9205659627914429,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.8730183243751526,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.8301458954811096,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.8172540664672852,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.8102422952651978,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.810137152671814,
            "answer": "constitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8172540068626404,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.9103172421455383,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.8868140578269958,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.8436237573623657,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.843160092830658,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.8354551792144775,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.827830970287323,
            "answer": "possessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 1145,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7795754671096802,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1146
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.8344758749008179,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8283205628395081,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.8256462812423706,
            "answer": "assertion",
            "hit": false
          },
          {
            "score": 0.820061445236206,
            "answer": "asserted",
            "hit": false
          },
          {
            "score": 0.8172276616096497,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.8166933655738831,
            "answer": "assert",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 116,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7885843515396118,
        "b in neighbourhood of b_prime": 80,
        "b_prime in neighbourhood of b": 117
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.9032716751098633,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8879868984222412,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.8376009464263916,
            "answer": "protect",
            "hit": false
          },
          {
            "score": 0.8334834575653076,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.8214733600616455,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.8174858093261719,
            "answer": "defenders",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7764141857624054,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 42
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.9150981307029724,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.9078752994537354,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8873330950737,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8259669542312622,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.8146018385887146,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8114505410194397,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8065767586231232,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8990281224250793,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.896689236164093,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8942291736602783,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8600720167160034,
            "answer": "inspect",
            "hit": false
          },
          {
            "score": 0.8492058515548706,
            "answer": "inspected",
            "hit": false
          },
          {
            "score": 0.8408351540565491,
            "answer": "analyze",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 207,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7912154197692871,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 208
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.9246566891670227,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.9200631380081177,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8934720754623413,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8557584881782532,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.8401256799697876,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8247556686401367,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 500,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.770282506942749,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 501
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.8783487677574158,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.8678023815155029,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.8022472858428955,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7467734813690186,
            "answer": "accompany",
            "hit": false
          },
          {
            "score": 0.7438635230064392,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7427729964256287,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7385967075824738,
        "b in neighbourhood of b_prime": 5155,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8960065841674805,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.8801026940345764,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.8744292855262756,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.8643794655799866,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.8283716440200806,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.8191035389900208,
            "answer": "analyze",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8283716440200806,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.8832089304924011,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.8589850664138794,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7623209953308105,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7604341506958008,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.7465848326683044,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7456024885177612,
            "answer": "understands",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.760434091091156,
        "b in neighbourhood of b_prime": 1564,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.901468813419342,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8752651214599609,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8320867419242859,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7942951321601868,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7837561368942261,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7741091251373291,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 75,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7349960505962372,
        "b in neighbourhood of b_prime": 1614,
        "b_prime in neighbourhood of b": 76
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.9106206297874451,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8992851972579956,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8821427226066589,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.8109191060066223,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7881076335906982,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.78635573387146,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7716473937034607,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.9214991331100464,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.9111385345458984,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8889499306678772,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8346426486968994,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.8208867311477661,
            "answer": "monitored",
            "hit": false
          },
          {
            "score": 0.8187642693519592,
            "answer": "witnessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 116,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7894637584686279,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 117
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.9010711908340454,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8849254250526428,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8517202138900757,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.8502209186553955,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.8418000936508179,
            "answer": "arrange",
            "hit": false
          },
          {
            "score": 0.8287889361381531,
            "answer": "arranging",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8502208888530731,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.9174794554710388,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.904448390007019,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.9006446599960327,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8170234560966492,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8168152570724487,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.8087434768676758,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8168153166770935,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8834105730056763,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.8170396089553833,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8158928155899048,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.8144949674606323,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.8129370212554932,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.8117331266403198,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.815892904996872,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.9330500960350037,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.9324357509613037,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.876151442527771,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8385142087936401,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.8280538320541382,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.8239589929580688,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7911483347415924,
        "b in neighbourhood of b_prime": 70,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.9189122319221497,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.9147403240203857,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.887020468711853,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8210726976394653,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7991969585418701,
            "answer": "contribute",
            "hit": false
          },
          {
            "score": 0.7987419962882996,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7795523703098297,
        "b in neighbourhood of b_prime": 47,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8796524405479431,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.86688232421875,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8388799428939819,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8368470668792725,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.8319700360298157,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8277172446250916,
            "answer": "publishers",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8368471264839172,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.9078066945075989,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8932152390480042,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8900257349014282,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8021705746650696,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7931883931159973,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7907649278640747,
            "answer": "undergo",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 246,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7483876645565033,
        "b in neighbourhood of b_prime": 50,
        "b_prime in neighbourhood of b": 247
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8857282996177673,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.8568793535232544,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.8314175605773926,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.8157793283462524,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.7944166660308838,
            "answer": "talk",
            "hit": false
          },
          {
            "score": 0.7747481465339661,
            "answer": "talked",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7299446314573288,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.9012791514396667,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8874068260192871,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8538241386413574,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8000293970108032,
            "answer": "instructors",
            "hit": false
          },
          {
            "score": 0.795584499835968,
            "answer": "educators",
            "hit": false
          },
          {
            "score": 0.79510498046875,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7822812795639038,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8925068378448486,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.8778027296066284,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.8598502278327942,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.841240406036377,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.8009030818939209,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.8005788326263428,
            "answer": "writings",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8009031414985657,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 5
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "f209c0e1-15e0-46e5-be9d-fdc850867cb0",
      "timestamp": "2025-05-18T12:23:22.991354"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.89522385597229,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8609933257102966,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.860724925994873,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.8581691980361938,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.8273320198059082,
            "answer": "denounced",
            "hit": false
          },
          {
            "score": 0.8243113160133362,
            "answer": "allegations",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8607248961925507,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.9029722213745117,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.8533499240875244,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.8145983815193176,
            "answer": "appreciate",
            "hit": false
          },
          {
            "score": 0.8032202124595642,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8031738996505737,
            "answer": "appreciated",
            "hit": false
          },
          {
            "score": 0.8029167652130127,
            "answer": "undermine",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8533499538898468,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.855568528175354,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8465082049369812,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.8387389183044434,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.8329920768737793,
            "answer": "calculating",
            "hit": false
          },
          {
            "score": 0.8279797434806824,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.8212584853172302,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.846508264541626,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.9142158031463623,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8936446905136108,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8817631602287292,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8084533214569092,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.8043540716171265,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.8022714853286743,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8043541014194489,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.9177870750427246,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.9118833541870117,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8793280124664307,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.8316850066184998,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8306580781936646,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.8282232284545898,
            "answer": "announces",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8246659636497498,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8928194642066956,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8869814276695251,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8433009386062622,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.824546754360199,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8219568133354187,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8215206861495972,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7875677347183228,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8990281224250793,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.896689236164093,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8942291736602783,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8600720167160034,
            "answer": "inspect",
            "hit": false
          },
          {
            "score": 0.8492058515548706,
            "answer": "inspected",
            "hit": false
          },
          {
            "score": 0.8408351540565491,
            "answer": "analyze",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8305542767047882,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.9246566891670227,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.9200631380081177,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8934720754623413,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8557584881782532,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.8401256799697876,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8247556686401367,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8557584583759308,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.8397217988967896,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.8309296369552612,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.7967050671577454,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.7838850021362305,
            "answer": "pictured",
            "hit": false
          },
          {
            "score": 0.783847987651825,
            "answer": "suppose",
            "hit": false
          },
          {
            "score": 0.7793673872947693,
            "answer": "simulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 689,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7200828939676285,
        "b in neighbourhood of b_prime": 1318,
        "b_prime in neighbourhood of b": 690
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8807774186134338,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.8430637121200562,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.8408390879631042,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8398153781890869,
            "answer": "provoke",
            "hit": false
          },
          {
            "score": 0.8352533578872681,
            "answer": "stimulate",
            "hit": false
          },
          {
            "score": 0.8311077952384949,
            "answer": "encourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8052870333194733,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 32
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.9214991331100464,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.9111385345458984,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8889499306678772,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8346426486968994,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.8208867311477661,
            "answer": "monitored",
            "hit": false
          },
          {
            "score": 0.8187642693519592,
            "answer": "witnessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8141568303108215,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8830711245536804,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8746227025985718,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8503434658050537,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.7987133264541626,
            "answer": "inhabit",
            "hit": false
          },
          {
            "score": 0.7956570386886597,
            "answer": "occupants",
            "hit": false
          },
          {
            "score": 0.7922075986862183,
            "answer": "oppose",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7871019840240479,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.9010711908340454,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8849254250526428,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8517202138900757,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.8502209186553955,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.8418000936508179,
            "answer": "arrange",
            "hit": false
          },
          {
            "score": 0.8287889361381531,
            "answer": "arranging",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 930,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7673738598823547,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 931
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.9156913757324219,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.9049555659294128,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.8692469596862793,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.8646402359008789,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.8448907136917114,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7973229885101318,
            "answer": "readiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8646402359008789,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.9295698404312134,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8962222337722778,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.8613621592521667,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.8391743302345276,
            "answer": "revive",
            "hit": false
          },
          {
            "score": 0.8355180025100708,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.8280699849128723,
            "answer": "rebuild",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8613621294498444,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8889190554618835,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.8733822107315063,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8508736491203308,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.8489797115325928,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.8360923528671265,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8335927724838257,
            "answer": "unstable",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8733822107315063,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 16,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "ad3f69c9-94e0-4376-a12c-994fa9419d06",
      "timestamp": "2025-05-18T12:23:23.200817"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8823578357696533,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.8685361742973328,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.8494091629981995,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.839618980884552,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.8358044028282166,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.8302353024482727,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.839618980884552,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.9212468862533569,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.9064386487007141,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8685361742973328,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.8556057214736938,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.8438686728477478,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.8403669595718384,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 60,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7907298803329468,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 61
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.9279524087905884,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.9048516750335693,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.8516411185264587,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8515681624412537,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.8421894311904907,
            "answer": "adapting",
            "hit": false
          },
          {
            "score": 0.8304712772369385,
            "answer": "adjustable",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.851568192243576,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8933293223381042,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8903093338012695,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8695268034934998,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.845787763595581,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8185182213783264,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7973032593727112,
            "answer": "agreement",
            "hit": true
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7973032593727112,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.8809003829956055,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.8295688033103943,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.8220442533493042,
            "answer": "positioned",
            "hit": false
          },
          {
            "score": 0.8189515471458435,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.8169956207275391,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8168383836746216,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8295688033103943,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8435906171798706,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.8241093754768372,
            "answer": "modify",
            "hit": false
          },
          {
            "score": 0.8152381181716919,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.8110458850860596,
            "answer": "clarify",
            "hit": false
          },
          {
            "score": 0.8078207969665527,
            "answer": "repeal",
            "hit": false
          },
          {
            "score": 0.8065073490142822,
            "answer": "altering",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 368,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7684054970741272,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 369
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.9271755218505859,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.9095021486282349,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8700517416000366,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.855491578578949,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.854992687702179,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8444450497627258,
            "answer": "declares",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.855491578578949,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8484183549880981,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.8330417275428772,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.823501706123352,
            "answer": "install",
            "hit": false
          },
          {
            "score": 0.8230820298194885,
            "answer": "assign",
            "hit": false
          },
          {
            "score": 0.8200684785842896,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.8181927800178528,
            "answer": "resign",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8040682077407837,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 34
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.9245679974555969,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.9089940190315247,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.8457306623458862,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.8418000936508179,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.8294826149940491,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.8183802366256714,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8161187171936035,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.9023199081420898,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8769634962081909,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8750222325325012,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.8660218715667725,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.8653500080108643,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.8569360971450806,
            "answer": "evaluated",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8524969816207886,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.881149411201477,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.861312210559845,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.8416890501976013,
            "answer": "attach",
            "hit": false
          },
          {
            "score": 0.8249223828315735,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.8230820894241333,
            "answer": "appoint",
            "hit": false
          },
          {
            "score": 0.8222543001174927,
            "answer": "assignments",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8154393434524536,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.9149344563484192,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.9052127599716187,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.8841466903686523,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.8323483467102051,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7945684194564819,
            "answer": "disclose",
            "hit": false
          },
          {
            "score": 0.7910743951797485,
            "answer": "undertake",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8323483467102051,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.9150981307029724,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.9078752994537354,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8873330950737,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8259669542312622,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.8146018385887146,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8114505410194397,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8068602681159973,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8918858170509338,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8596134185791016,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.845787763595581,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8430029153823853,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8336822390556335,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8309056162834167,
            "answer": "collaborate",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8596134781837463,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.9181928634643555,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8843684792518616,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8787548542022705,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.8770283460617065,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8618279695510864,
            "answer": "stimulate",
            "hit": false
          },
          {
            "score": 0.8457260727882385,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8395163416862488,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.9017181396484375,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.867630124092102,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.8369616270065308,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.827104926109314,
            "answer": "imposing",
            "hit": false
          },
          {
            "score": 0.825559139251709,
            "answer": "implementing",
            "hit": false
          },
          {
            "score": 0.8209912776947021,
            "answer": "implemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8369616568088531,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.9154528975486755,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.911813497543335,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8672451376914978,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.807309627532959,
            "answer": "provoke",
            "hit": false
          },
          {
            "score": 0.8059201240539551,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.8039395213127136,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8059201240539551,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.9025671482086182,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8737788200378418,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8691211938858032,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.8660445213317871,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.8640759587287903,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.862077534198761,
            "answer": "improve",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8660445213317871,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.9142763018608093,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.9045725464820862,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.903662383556366,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8256145715713501,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.8100818395614624,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.795230507850647,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8256146609783173,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.9084636569023132,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.881348729133606,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.8139631748199463,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8130483627319336,
            "answer": "amused",
            "hit": false
          },
          {
            "score": 0.8118020296096802,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8061547875404358,
            "answer": "dismissing",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 1986,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7603254318237305,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1987
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.927820086479187,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.9093228578567505,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8759055733680725,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.8220641016960144,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8214178085327148,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.8209626078605652,
            "answer": "assert",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7947836518287659,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 30
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.9114848375320435,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.9047403931617737,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.864987313747406,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.8431072235107422,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.8298306465148926,
            "answer": "undertake",
            "hit": false
          },
          {
            "score": 0.8267565369606018,
            "answer": "fills",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8649873435497284,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.9298075437545776,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.9144061207771301,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8866791129112244,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8620775938034058,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8527919054031372,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.8508940935134888,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8527919352054596,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.8875954151153564,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.8741165399551392,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.8483035564422607,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.8213019967079163,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.8094830513000488,
            "answer": "investors",
            "hit": false
          },
          {
            "score": 0.8037368655204773,
            "answer": "investment",
            "hit": true
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8037368655204773,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.9149647951126099,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8857265114784241,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8460173606872559,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.831051230430603,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.8210888504981995,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.817597508430481,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8210888504981995,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.9106206297874451,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8992851972579956,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8821427226066589,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.8109191060066223,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7881076335906982,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.78635573387146,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 76,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7604132294654846,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 77
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8834624290466309,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.8407047390937805,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.820967972278595,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.8177982568740845,
            "answer": "torment",
            "hit": false
          },
          {
            "score": 0.8135105967521667,
            "answer": "rewarded",
            "hit": false
          },
          {
            "score": 0.813345730304718,
            "answer": "offenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8407047390937805,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.8798915147781372,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8652616143226624,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.8576686382293701,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.8558575510978699,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.8549811244010925,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.853165864944458,
            "answer": "reiterated",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.86526158452034,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.9095603227615356,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8951383233070374,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.8946242332458496,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8316130638122559,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.8171306848526001,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.8022470474243164,
            "answer": "supplemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.831613153219223,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.9241580367088318,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.9082425832748413,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8647221326828003,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8212431073188782,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.8134450912475586,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8127132654190063,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8212431073188782,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 30,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "5a960999-2bdd-42ba-902f-b068fe8a0dd6",
      "timestamp": "2025-05-18T12:23:23.340750"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8269784450531006,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.8193414211273193,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.8160719275474548,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.8131264448165894,
            "answer": "naples",
            "hit": false
          },
          {
            "score": 0.8105635643005371,
            "answer": "crete",
            "hit": false
          },
          {
            "score": 0.806305468082428,
            "answer": "istanbul",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8269784450531006,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8603919744491577,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8505958318710327,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8435268402099609,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.8405441045761108,
            "answer": "kuwait",
            "hit": false
          },
          {
            "score": 0.837365448474884,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8290485143661499,
            "answer": "cairo",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8435268402099609,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.8761460185050964,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8332014083862305,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8322752714157104,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8231805562973022,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.8170979022979736,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8168787956237793,
            "answer": "baghdad",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8761460185050964,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.8350102305412292,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.831623911857605,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.815280556678772,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8133828639984131,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.8085881471633911,
            "answer": "kyoto",
            "hit": false
          },
          {
            "score": 0.8072789311408997,
            "answer": "bangkok",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 196,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7718110680580139,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 197
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.8148120045661926,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.8090412616729736,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.7912107706069946,
            "answer": "hamburg",
            "hit": false
          },
          {
            "score": 0.7875643968582153,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.7856997847557068,
            "answer": "warsaw",
            "hit": false
          },
          {
            "score": 0.7851386666297913,
            "answer": "germany",
            "hit": true
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.785138726234436,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7771191596984863,
            "answer": "jul",
            "hit": false
          },
          {
            "score": 0.7723902463912964,
            "answer": "crises",
            "hit": false
          },
          {
            "score": 0.770171046257019,
            "answer": "lund",
            "hit": false
          },
          {
            "score": 0.7692997455596924,
            "answer": "transformations",
            "hit": false
          },
          {
            "score": 0.7685563564300537,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.7683841586112976,
            "answer": "profoundly",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7685563564300537,
        "b in neighbourhood of b_prime": 74,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8439696431159973,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.8284035325050354,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.8088601231575012,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.805388331413269,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.8028765320777893,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.8008618354797363,
            "answer": "helsinki",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8439696431159973,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.8524328470230103,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8478184938430786,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.8362711668014526,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.828682541847229,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8238834142684937,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.8220819234848022,
            "answer": "helsinki",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8362711668014526,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.8324689269065857,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8290485143661499,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.828144371509552,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8166550993919373,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.8159525990486145,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8150124549865723,
            "answer": "egyptian",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.828144371509552,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8526855111122131,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.8458395600318909,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8370145559310913,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.8299878835678101,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8191499710083008,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.8120812177658081,
            "answer": "bangkok",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8458395898342133,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.8505958318710327,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8418662548065186,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8332803249359131,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8324689269065857,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.831405758857727,
            "answer": "lebanese",
            "hit": false
          },
          {
            "score": 0.8282861709594727,
            "answer": "tehran",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8418662846088409,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.818597137928009,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.8168675303459167,
            "answer": "glasgow",
            "hit": false
          },
          {
            "score": 0.8010359406471252,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.7980414032936096,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7959198951721191,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.7894291877746582,
            "answer": "edinburgh",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8010359108448029,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8463764190673828,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.8451813459396362,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.841407299041748,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.8392910957336426,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8220819234848022,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8191499710083008,
            "answer": "copenhagen",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.845181405544281,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7863720655441284,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7823148965835571,
            "answer": "astonishing",
            "hit": false
          },
          {
            "score": 0.7760605812072754,
            "answer": "richmond",
            "hit": false
          },
          {
            "score": 0.7746576070785522,
            "answer": "sturdy",
            "hit": false
          },
          {
            "score": 0.7741779088973999,
            "answer": "empowered",
            "hit": false
          },
          {
            "score": 0.7741077542304993,
            "answer": "detrimental",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7724113464355469,
        "b in neighbourhood of b_prime": 39,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8465683460235596,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.8279539942741394,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.8271028995513916,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.8238834142684937,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8231719732284546,
            "answer": "amsterdam",
            "hit": false
          },
          {
            "score": 0.8093344569206238,
            "answer": "copenhagen",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8465682864189148,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8279539942741394,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.809481143951416,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.8061870336532593,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8050934076309204,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.8048340082168579,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.8025838136672974,
            "answer": "naples",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8048339486122131,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.817618191242218,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.8150073289871216,
            "answer": "bangkok",
            "hit": false
          },
          {
            "score": 0.8068690299987793,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.7886406779289246,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7863635420799255,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.777417778968811,
            "answer": "helsinki",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8068690598011017,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.813431441783905,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8112726211547852,
            "answer": "vladimir",
            "hit": false
          },
          {
            "score": 0.8106815814971924,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.805753231048584,
            "answer": "warsaw",
            "hit": false
          },
          {
            "score": 0.8055744171142578,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.8037808537483215,
            "answer": "prague",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.81068155169487,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8392910957336426,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.8299878835678101,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.823153555393219,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8201820850372314,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.819794237613678,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8146066665649414,
            "answer": "tehran",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8197942078113556,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.8218368291854858,
            "answer": "toronto",
            "hit": false
          },
          {
            "score": 0.8201433420181274,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.8120084404945374,
            "answer": "montreal",
            "hit": false
          },
          {
            "score": 0.8050891757011414,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.8010283708572388,
            "answer": "calgary",
            "hit": false
          },
          {
            "score": 0.8006123900413513,
            "answer": "edmonton",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 2451,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.738193929195404,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 2452
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.7969425916671753,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.7894318103790283,
            "answer": "london",
            "hit": false
          },
          {
            "score": 0.7774677276611328,
            "answer": "brussels",
            "hit": false
          },
          {
            "score": 0.7675939202308655,
            "answer": "amsterdam",
            "hit": false
          },
          {
            "score": 0.7670240998268127,
            "answer": "berlin",
            "hit": false
          },
          {
            "score": 0.7665848731994629,
            "answer": "copenhagen",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7969425916671753,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.7716841697692871,
            "answer": "naples",
            "hit": false
          },
          {
            "score": 0.766330897808075,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7654901742935181,
            "answer": "venice",
            "hit": false
          },
          {
            "score": 0.7648029327392578,
            "answer": "athens",
            "hit": false
          },
          {
            "score": 0.7647223472595215,
            "answer": "paris",
            "hit": false
          },
          {
            "score": 0.7641400098800659,
            "answer": "romans",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7663309574127197,
        "b in neighbourhood of b_prime": 41,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.7791131734848022,
            "answer": "dismissing",
            "hit": false
          },
          {
            "score": 0.7763607501983643,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7738819122314453,
            "answer": "valencia",
            "hit": false
          },
          {
            "score": 0.7727667093276978,
            "answer": "provocative",
            "hit": false
          },
          {
            "score": 0.772760272026062,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.7712639570236206,
            "answer": "undermine",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7763607800006866,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8526855707168579,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.841407299041748,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.8402528166770935,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8392701148986816,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8201821446418762,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8145724534988403,
            "answer": "vienna",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8402528166770935,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8544944524765015,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8400814533233643,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.8373653888702393,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8332013487815857,
            "answer": "bangkok",
            "hit": false
          },
          {
            "score": 0.8286824822425842,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8282861709594727,
            "answer": "damascus",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8400813937187195,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.8260262608528137,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.8097077012062073,
            "answer": "kyoto",
            "hit": false
          },
          {
            "score": 0.7927395105361938,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.7914218306541443,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.7900339961051941,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7898989915847778,
            "answer": "tehran",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7851973474025726,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8290536999702454,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.8228784799575806,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8210138082504272,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8166776895523071,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.8145724534988403,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.8090412616729736,
            "answer": "berlin",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7968452572822571,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8146221041679382,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.8133870363235474,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.805753231048584,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.8045580387115479,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8043081760406494,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8022176027297974,
            "answer": "vienna",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8133870363235474,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 28,
      "accuracy": 0.17857142857142858
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "5f781ea2-f46b-48b3-ba97-d68caf2c5f01",
      "timestamp": "2025-05-18T12:23:23.598483"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8664808869361877,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8258543014526367,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8243969678878784,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8220813274383545,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.813906192779541,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.8058822154998779,
            "answer": "brazil",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 3796,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.728493332862854,
        "b in neighbourhood of b_prime": 53,
        "b_prime in neighbourhood of b": 3797
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.851109504699707,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.8321346640586853,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7924036979675293,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.7770617008209229,
            "answer": "ireland",
            "hit": false
          },
          {
            "score": 0.7720838189125061,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.771507978439331,
            "answer": "melbourne",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 9609,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6526736170053482,
        "b in neighbourhood of b_prime": 1293,
        "b_prime in neighbourhood of b": 9610
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8632230758666992,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8092005252838135,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.8088650107383728,
            "answer": "croatia",
            "hit": false
          },
          {
            "score": 0.8063734173774719,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.8043792843818665,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8008323907852173,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 5605,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7071434259414673,
        "b in neighbourhood of b_prime": 70,
        "b_prime in neighbourhood of b": 5606
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8601970076560974,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8076156377792358,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8066810965538025,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8058822154998779,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8009740710258484,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7917823791503906,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7685683369636536,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8289504051208496,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7993158102035522,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.7924036979675293,
            "answer": "australia",
            "hit": false
          },
          {
            "score": 0.7703948616981506,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.7620033621788025,
            "answer": "india",
            "hit": false
          },
          {
            "score": 0.761162281036377,
            "answer": "toronto",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 10293,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6335589587688446,
        "b in neighbourhood of b_prime": 4667,
        "b_prime in neighbourhood of b": 10294
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8220813274383545,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8060658574104309,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8032365441322327,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.7958320379257202,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.7956481575965881,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7938560247421265,
            "answer": "argentine",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 3190,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7209831476211548,
        "b in neighbourhood of b_prime": 83,
        "b_prime in neighbourhood of b": 3191
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8523173928260803,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8438855409622192,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.82496178150177,
            "answer": "guatemala",
            "hit": false
          },
          {
            "score": 0.8243969678878784,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8076156377792358,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.8060658574104309,
            "answer": "chile",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 6544,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7255513072013855,
        "b in neighbourhood of b_prime": 69,
        "b_prime in neighbourhood of b": 6545
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.856951892375946,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.8152799606323242,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8105487823486328,
            "answer": "haiti",
            "hit": false
          },
          {
            "score": 0.8053349256515503,
            "answer": "jamaica",
            "hit": false
          },
          {
            "score": 0.8011265993118286,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7993961572647095,
            "answer": "argentina",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 4935,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7240507304668427,
        "b in neighbourhood of b_prime": 75,
        "b_prime in neighbourhood of b": 4936
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8173524737358093,
            "answer": "crete",
            "hit": false
          },
          {
            "score": 0.8148629665374756,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.8034852743148804,
            "answer": "naples",
            "hit": false
          },
          {
            "score": 0.8023240566253662,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.801973819732666,
            "answer": "lebanese",
            "hit": false
          },
          {
            "score": 0.7999404668807983,
            "answer": "syria",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 113,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.740246519446373,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 114
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8632853627204895,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.828144371509552,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.8022799491882324,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7954747080802917,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7947779893875122,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7908033728599548,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 233,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7506966292858124,
        "b in neighbourhood of b_prime": 291,
        "b_prime in neighbourhood of b": 234
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8281974792480469,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.82496178150177,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8239141702651978,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.823218584060669,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8215434551239014,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8188397884368896,
            "answer": "somalia",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 8154,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7250804603099823,
        "b in neighbourhood of b_prime": 71,
        "b_prime in neighbourhood of b": 8155
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8696855306625366,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8400814533233643,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.798487663269043,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.7963053584098816,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.7923516035079956,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7886598706245422,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7963053584098816,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8663029670715332,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8435268402099609,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8413194417953491,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.8199586868286133,
            "answer": "vietnam",
            "hit": false
          },
          {
            "score": 0.8180170059204102,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8173607587814331,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7549249827861786,
        "b in neighbourhood of b_prime": 180,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8405678868293762,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7996424436569214,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.7749386429786682,
            "answer": "jerusalem",
            "hit": false
          },
          {
            "score": 0.7694848775863647,
            "answer": "palestine",
            "hit": false
          },
          {
            "score": 0.7660285234451294,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.7631078362464905,
            "answer": "judah",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7622367143630981,
        "b in neighbourhood of b_prime": 38,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.736545205116272,
            "answer": "chad",
            "hit": false
          },
          {
            "score": 0.7344692945480347,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.734036922454834,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7336598634719849,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.7313847541809082,
            "answer": "montgomery",
            "hit": false
          },
          {
            "score": 0.7296673059463501,
            "answer": "clarified",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 394,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7021304219961166,
        "b in neighbourhood of b_prime": 6541,
        "b_prime in neighbourhood of b": 395
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8598124384880066,
            "answer": "qatar",
            "hit": false
          },
          {
            "score": 0.8405441045761108,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8356999754905701,
            "answer": "oman",
            "hit": false
          },
          {
            "score": 0.823859453201294,
            "answer": "hussein",
            "hit": false
          },
          {
            "score": 0.8226712942123413,
            "answer": "uae",
            "hit": false
          },
          {
            "score": 0.8205273151397705,
            "answer": "yemen",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 1968,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.76326984167099,
        "b in neighbourhood of b_prime": 69,
        "b_prime in neighbourhood of b": 1969
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8415181636810303,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.8382818698883057,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.8131363391876221,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8067478537559509,
            "answer": "gaza",
            "hit": false
          },
          {
            "score": 0.8038280010223389,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.8005598783493042,
            "answer": "arabs",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 1994,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7434909343719482,
        "b in neighbourhood of b_prime": 622,
        "b_prime in neighbourhood of b": 1995
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7981337308883667,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7975154519081116,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7958320379257202,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.7936519384384155,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.7883238792419434,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.777837872505188,
            "answer": "panama",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 4377,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7099164128303528,
        "b in neighbourhood of b_prime": 249,
        "b_prime in neighbourhood of b": 4378
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.846263587474823,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.8240285515785217,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.8091045022010803,
            "answer": "geneva",
            "hit": false
          },
          {
            "score": 0.8063734173774719,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8018411993980408,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.799410343170166,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 6285,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6978949010372162,
        "b in neighbourhood of b_prime": 149,
        "b_prime in neighbourhood of b": 6286
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8613600730895996,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8418663144111633,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8355996608734131,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.8245964050292969,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.8180170655250549,
            "answer": "iraq",
            "hit": false
          },
          {
            "score": 0.8142104148864746,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 773,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7629717886447906,
        "b in neighbourhood of b_prime": 73,
        "b_prime in neighbourhood of b": 774
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.7924309968948364,
            "answer": "singapore",
            "hit": false
          },
          {
            "score": 0.7914186716079712,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.7910710573196411,
            "answer": "philippines",
            "hit": false
          },
          {
            "score": 0.7893598079681396,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7893588542938232,
            "answer": "hawaii",
            "hit": false
          },
          {
            "score": 0.7869495153427124,
            "answer": "korea",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 6589,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7090377509593964,
        "b in neighbourhood of b_prime": 109,
        "b_prime in neighbourhood of b": 6590
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.769438624382019,
            "answer": "america",
            "hit": false
          },
          {
            "score": 0.7492932081222534,
            "answer": "americas",
            "hit": false
          },
          {
            "score": 0.7467104196548462,
            "answer": "americans",
            "hit": false
          },
          {
            "score": 0.7390222549438477,
            "answer": "uae",
            "hit": false
          },
          {
            "score": 0.7348778247833252,
            "answer": "ussr",
            "hit": false
          },
          {
            "score": 0.7323198318481445,
            "answer": "canada",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 8169,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6551491916179657,
        "b in neighbourhood of b_prime": 1034,
        "b_prime in neighbourhood of b": 8170
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8523173928260803,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8448854088783264,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.8258542418479919,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8215434551239014,
            "answer": "guatemala",
            "hit": false
          },
          {
            "score": 0.8152799606323242,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.8120241761207581,
            "answer": "tanzania",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 8931,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7136834114789963,
        "b in neighbourhood of b_prime": 171,
        "b_prime in neighbourhood of b": 8932
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 23,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "c801548c-8831-41d9-9ba6-1f7ecf64854f",
      "timestamp": "2025-05-18T12:23:23.840091"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8164482116699219,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7844823598861694,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.773213803768158,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.761305570602417,
            "answer": "showers",
            "hit": false
          },
          {
            "score": 0.7583093643188477,
            "answer": "washing",
            "hit": false
          },
          {
            "score": 0.7487610578536987,
            "answer": "bathrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7358549535274506,
        "b in neighbourhood of b_prime": 4183,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7976213693618774,
            "answer": "assaults",
            "hit": false
          },
          {
            "score": 0.7910064458847046,
            "answer": "consume",
            "hit": false
          },
          {
            "score": 0.7907267808914185,
            "answer": "perceptions",
            "hit": false
          },
          {
            "score": 0.7903597950935364,
            "answer": "worcester",
            "hit": false
          },
          {
            "score": 0.7902835011482239,
            "answer": "birmingham",
            "hit": false
          },
          {
            "score": 0.7889881134033203,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 213,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7697349786758423,
        "b in neighbourhood of b_prime": 36,
        "b_prime in neighbourhood of b": 214
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8060771226882935,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7986177802085876,
            "answer": "hugely",
            "hit": false
          },
          {
            "score": 0.7966115474700928,
            "answer": "detrimental",
            "hit": false
          },
          {
            "score": 0.7962722778320312,
            "answer": "plymouth",
            "hit": false
          },
          {
            "score": 0.7932627201080322,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7930845022201538,
            "answer": "plastics",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8060771226882935,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7629618048667908,
            "answer": "bradford",
            "hit": false
          },
          {
            "score": 0.7541955709457397,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.7507894039154053,
            "answer": "radically",
            "hit": false
          },
          {
            "score": 0.7500503659248352,
            "answer": "docking",
            "hit": false
          },
          {
            "score": 0.7489147782325745,
            "answer": "orr",
            "hit": false
          },
          {
            "score": 0.7475575804710388,
            "answer": "sturdy",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 1005,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7145824134349823,
        "b in neighbourhood of b_prime": 6558,
        "b_prime in neighbourhood of b": 1006
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8108578324317932,
            "answer": "manchester",
            "hit": false
          },
          {
            "score": 0.8052765130996704,
            "answer": "newcastle",
            "hit": false
          },
          {
            "score": 0.7996941804885864,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7996734380722046,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.7983177900314331,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7951372265815735,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7996942102909088,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.7981842160224915,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.7962722778320312,
            "answer": "brighton",
            "hit": false
          },
          {
            "score": 0.7941900491714478,
            "answer": "bristol",
            "hit": false
          },
          {
            "score": 0.7938836216926575,
            "answer": "acknowledging",
            "hit": false
          },
          {
            "score": 0.7938054800033569,
            "answer": "chrysler",
            "hit": false
          },
          {
            "score": 0.7873194813728333,
            "answer": "collisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2080,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.745358407497406,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2081
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8238663673400879,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.8092733025550842,
            "answer": "manchester",
            "hit": false
          },
          {
            "score": 0.7996733784675598,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7977527976036072,
            "answer": "glasgow",
            "hit": false
          },
          {
            "score": 0.7975157499313354,
            "answer": "birmingham",
            "hit": false
          },
          {
            "score": 0.7974793910980225,
            "answer": "newcastle",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.777002215385437,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7583743929862976,
            "answer": "pumps",
            "hit": false
          },
          {
            "score": 0.7543609738349915,
            "answer": "inspections",
            "hit": false
          },
          {
            "score": 0.7541345953941345,
            "answer": "unconventional",
            "hit": false
          },
          {
            "score": 0.7533199787139893,
            "answer": "lynn",
            "hit": false
          },
          {
            "score": 0.7521231174468994,
            "answer": "drilling",
            "hit": false
          },
          {
            "score": 0.7514240741729736,
            "answer": "reservoirs",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 189,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7308700531721115,
        "b in neighbourhood of b_prime": 5063,
        "b_prime in neighbourhood of b": 190
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7544931769371033,
            "answer": "orleans",
            "hit": false
          },
          {
            "score": 0.75173419713974,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7411515712738037,
            "answer": "jersey",
            "hit": false
          },
          {
            "score": 0.7345481514930725,
            "answer": "delhi",
            "hit": false
          },
          {
            "score": 0.7324830293655396,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.7211288809776306,
            "answer": "zealand",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7147981524467468,
        "b in neighbourhood of b_prime": 6514,
        "b_prime in neighbourhood of b": 8
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 9,
      "accuracy": 0.1111111111111111
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "dfe00ff2-01f8-4647-8302-6909b0435401",
      "timestamp": "2025-05-18T12:23:24.116681"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8189380168914795,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8115139007568359,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8075712323188782,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7956082820892334,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7954550385475159,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7952218055725098,
            "answer": "greeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 3963,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7331385612487793,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 3964
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7716389298439026,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7566028833389282,
            "answer": "anterior",
            "hit": false
          },
          {
            "score": 0.7559107542037964,
            "answer": "napoleon",
            "hit": false
          },
          {
            "score": 0.7558514475822449,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7554636597633362,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.7550983428955078,
            "answer": "markedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 8706,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6814754754304886,
        "b in neighbourhood of b_prime": 414,
        "b_prime in neighbourhood of b": 8707
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7721723318099976,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7707617878913879,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.7702797055244446,
            "answer": "morphology",
            "hit": false
          },
          {
            "score": 0.7701162099838257,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7698081731796265,
            "answer": "upgrades",
            "hit": false
          },
          {
            "score": 0.7686487436294556,
            "answer": "stimulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 12783,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6301906108856201,
        "b in neighbourhood of b_prime": 5533,
        "b_prime in neighbourhood of b": 12784
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7919244766235352,
            "answer": "astonished",
            "hit": false
          },
          {
            "score": 0.7887993454933167,
            "answer": "defective",
            "hit": false
          },
          {
            "score": 0.7866392731666565,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.7852717638015747,
            "answer": "disclose",
            "hit": false
          },
          {
            "score": 0.7851008772850037,
            "answer": "alarmed",
            "hit": false
          },
          {
            "score": 0.7843320369720459,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 13124,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6531229019165039,
        "b in neighbourhood of b_prime": 1496,
        "b_prime in neighbourhood of b": 13125
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7887264490127563,
            "answer": "hilbert",
            "hit": false
          },
          {
            "score": 0.786621630191803,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7840567231178284,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7806141376495361,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7803266048431396,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.780234694480896,
            "answer": "freud",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 4347,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7215087562799454,
        "b in neighbourhood of b_prime": 971,
        "b_prime in neighbourhood of b": 4348
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8097785711288452,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8063650131225586,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7942162752151489,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.7936983108520508,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.791494607925415,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.7907920479774475,
            "answer": "nietzsche",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 2136,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6887394338846207,
        "b in neighbourhood of b_prime": 372,
        "b_prime in neighbourhood of b": 2137
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7679728865623474,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.7646101117134094,
            "answer": "inaccurate",
            "hit": false
          },
          {
            "score": 0.7628934979438782,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7609211206436157,
            "answer": "antics",
            "hit": false
          },
          {
            "score": 0.760904848575592,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7594376802444458,
            "answer": "journeys",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 7451,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6938772946596146,
        "b in neighbourhood of b_prime": 912,
        "b_prime in neighbourhood of b": 7452
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7872174382209778,
            "answer": "intellect",
            "hit": false
          },
          {
            "score": 0.7839730978012085,
            "answer": "kant",
            "hit": false
          },
          {
            "score": 0.7827458381652832,
            "answer": "declines",
            "hit": false
          },
          {
            "score": 0.7823812365531921,
            "answer": "invariably",
            "hit": false
          },
          {
            "score": 0.7808205485343933,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.7789860367774963,
            "answer": "hostility",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 4856,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7220311313867569,
        "b in neighbourhood of b_prime": 1205,
        "b_prime in neighbourhood of b": 4857
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8132356405258179,
            "answer": "constantin",
            "hit": false
          },
          {
            "score": 0.7962999939918518,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7944954633712769,
            "answer": "aesthetics",
            "hit": false
          },
          {
            "score": 0.7933886051177979,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7928850650787354,
            "answer": "crises",
            "hit": false
          },
          {
            "score": 0.7921832203865051,
            "answer": "lund",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 12447,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6760722398757935,
        "b in neighbourhood of b_prime": 1222,
        "b_prime in neighbourhood of b": 12448
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.793169379234314,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.7904489040374756,
            "answer": "telescopes",
            "hit": false
          },
          {
            "score": 0.7902713418006897,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.7890726327896118,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.7881186008453369,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7880234718322754,
            "answer": "variability",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 13381,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.641998678445816,
        "b in neighbourhood of b_prime": 8010,
        "b_prime in neighbourhood of b": 13382
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.8472423553466797,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.8387404084205627,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.8045629262924194,
            "answer": "gandhi",
            "hit": false
          },
          {
            "score": 0.801025927066803,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.8002010583877563,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7966246008872986,
            "answer": "socialism",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 473,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7625234425067902,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 474
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7555991411209106,
            "answer": "worcester",
            "hit": false
          },
          {
            "score": 0.7483228445053101,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.7448890209197998,
            "answer": "chester",
            "hit": false
          },
          {
            "score": 0.7447264194488525,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.741732656955719,
            "answer": "hostility",
            "hit": false
          },
          {
            "score": 0.7413924932479858,
            "answer": "nebraska",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 10734,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6540291756391525,
        "b in neighbourhood of b_prime": 1378,
        "b_prime in neighbourhood of b": 10735
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7872172594070435,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.7776294946670532,
            "answer": "distrust",
            "hit": false
          },
          {
            "score": 0.7774742245674133,
            "answer": "activate",
            "hit": false
          },
          {
            "score": 0.7773524522781372,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7772030234336853,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7769584059715271,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 13494,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6420381367206573,
        "b in neighbourhood of b_prime": 2868,
        "b_prime in neighbourhood of b": 13495
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8061355352401733,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7975121140480042,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.7819303274154663,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.7805403470993042,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7779288291931152,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7773163318634033,
            "answer": "capitalism",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 12337,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6554090976715088,
        "b in neighbourhood of b_prime": 4741,
        "b_prime in neighbourhood of b": 12338
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7747419476509094,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7731243968009949,
            "answer": "integrating",
            "hit": false
          },
          {
            "score": 0.7720273733139038,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7718365788459778,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7708197832107544,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.7707619667053223,
            "answer": "calculating",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 9216,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6929354965686798,
        "b in neighbourhood of b_prime": 6087,
        "b_prime in neighbourhood of b": 9217
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7657989263534546,
            "answer": "accelerate",
            "hit": false
          },
          {
            "score": 0.7610341310501099,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.7579218149185181,
            "answer": "accelerating",
            "hit": false
          },
          {
            "score": 0.7579091787338257,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7576835751533508,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.757556140422821,
            "answer": "angular",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 13610,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6224538758397102,
        "b in neighbourhood of b_prime": 7648,
        "b_prime in neighbourhood of b": 13611
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8092311024665833,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8075712323188782,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.8050607442855835,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7882628440856934,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7864068150520325,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7854203581809998,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 4874,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7191748768091202,
        "b in neighbourhood of b_prime": 71,
        "b_prime in neighbourhood of b": 4875
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.781229555606842,
            "answer": "mcconnell",
            "hit": false
          },
          {
            "score": 0.7754428386688232,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.770148754119873,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7700810432434082,
            "answer": "intellectuals",
            "hit": false
          },
          {
            "score": 0.7676743268966675,
            "answer": "ambiguity",
            "hit": false
          },
          {
            "score": 0.7673322558403015,
            "answer": "undermine",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 13322,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6364873796701431,
        "b in neighbourhood of b_prime": 4443,
        "b_prime in neighbourhood of b": 13323
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7813456058502197,
            "answer": "consolidation",
            "hit": false
          },
          {
            "score": 0.780269980430603,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7800155282020569,
            "answer": "mueller",
            "hit": false
          },
          {
            "score": 0.7789371013641357,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.7775418162345886,
            "answer": "horrific",
            "hit": false
          },
          {
            "score": 0.776537299156189,
            "answer": "aesthetics",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 8589,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7005387842655182,
        "b in neighbourhood of b_prime": 118,
        "b_prime in neighbourhood of b": 8590
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 19,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "1a8209b4-8c83-4b3a-b183-5cec7f4594fc",
      "timestamp": "2025-05-18T12:23:24.211702"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8189380168914795,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8115139007568359,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8075712323188782,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7956082820892334,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7954550385475159,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7952218055725098,
            "answer": "greeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7919162213802338,
        "b in neighbourhood of b_prime": 62,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7716389298439026,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7566028833389282,
            "answer": "anterior",
            "hit": false
          },
          {
            "score": 0.7559107542037964,
            "answer": "napoleon",
            "hit": false
          },
          {
            "score": 0.7558514475822449,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7554636597633362,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.7550983428955078,
            "answer": "markedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 1665,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7192837297916412,
        "b in neighbourhood of b_prime": 879,
        "b_prime in neighbourhood of b": 1666
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7928770780563354,
            "answer": "migrating",
            "hit": false
          },
          {
            "score": 0.7788015604019165,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.7784052491188049,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.7741118669509888,
            "answer": "migrate",
            "hit": false
          },
          {
            "score": 0.7740736603736877,
            "answer": "albany",
            "hit": false
          },
          {
            "score": 0.7724858522415161,
            "answer": "athens",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 3227,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7211995422840118,
        "b in neighbourhood of b_prime": 2743,
        "b_prime in neighbourhood of b": 3228
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7502011060714722,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7463139891624451,
            "answer": "naples",
            "hit": false
          },
          {
            "score": 0.7419968247413635,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7416452765464783,
            "answer": "creators",
            "hit": false
          },
          {
            "score": 0.7415779829025269,
            "answer": "disgusting",
            "hit": false
          },
          {
            "score": 0.7415726184844971,
            "answer": "instructors",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 5988,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.684277355670929,
        "b in neighbourhood of b_prime": 9789,
        "b_prime in neighbourhood of b": 5989
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7919244766235352,
            "answer": "astonished",
            "hit": false
          },
          {
            "score": 0.7887993454933167,
            "answer": "defective",
            "hit": false
          },
          {
            "score": 0.7866392731666565,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.7852717638015747,
            "answer": "disclose",
            "hit": false
          },
          {
            "score": 0.7851008772850037,
            "answer": "alarmed",
            "hit": false
          },
          {
            "score": 0.7843320369720459,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 62,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7704811096191406,
        "b in neighbourhood of b_prime": 207,
        "b_prime in neighbourhood of b": 63
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7887264490127563,
            "answer": "hilbert",
            "hit": false
          },
          {
            "score": 0.786621630191803,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7840567231178284,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7806141376495361,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7803266048431396,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.780234694480896,
            "answer": "freud",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7866216599941254,
        "b in neighbourhood of b_prime": 342,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.8097785711288452,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8063650131225586,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7942162752151489,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.7936983108520508,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.791494607925415,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.7907920479774475,
            "answer": "nietzsche",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7751466333866119,
        "b in neighbourhood of b_prime": 868,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7872174382209778,
            "answer": "intellect",
            "hit": false
          },
          {
            "score": 0.7839730978012085,
            "answer": "kant",
            "hit": false
          },
          {
            "score": 0.7827458381652832,
            "answer": "declines",
            "hit": false
          },
          {
            "score": 0.7823812365531921,
            "answer": "invariably",
            "hit": false
          },
          {
            "score": 0.7808205485343933,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.7789860367774963,
            "answer": "hostility",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 577,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.753411054611206,
        "b in neighbourhood of b_prime": 2710,
        "b_prime in neighbourhood of b": 578
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8132356405258179,
            "answer": "constantin",
            "hit": false
          },
          {
            "score": 0.7962999939918518,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7944954633712769,
            "answer": "aesthetics",
            "hit": false
          },
          {
            "score": 0.7933886051177979,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7928850650787354,
            "answer": "crises",
            "hit": false
          },
          {
            "score": 0.7921832203865051,
            "answer": "lund",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 392,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7662999629974365,
        "b in neighbourhood of b_prime": 1171,
        "b_prime in neighbourhood of b": 393
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7555991411209106,
            "answer": "worcester",
            "hit": false
          },
          {
            "score": 0.7483228445053101,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.7448890209197998,
            "answer": "chester",
            "hit": false
          },
          {
            "score": 0.7447264194488525,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.741732656955719,
            "answer": "hostility",
            "hit": false
          },
          {
            "score": 0.7413924932479858,
            "answer": "nebraska",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 10717,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6541500091552734,
        "b in neighbourhood of b_prime": 5175,
        "b_prime in neighbourhood of b": 10718
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7872172594070435,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.7776294946670532,
            "answer": "distrust",
            "hit": false
          },
          {
            "score": 0.7774742245674133,
            "answer": "activate",
            "hit": false
          },
          {
            "score": 0.7773524522781372,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7772030234336853,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7769584059715271,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 676,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7488361597061157,
        "b in neighbourhood of b_prime": 3385,
        "b_prime in neighbourhood of b": 677
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.8061355352401733,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7975121140480042,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.7819303274154663,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.7805403470993042,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7779288291931152,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7773163318634033,
            "answer": "capitalism",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7659874558448792,
        "b in neighbourhood of b_prime": 1202,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7747419476509094,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7731243968009949,
            "answer": "integrating",
            "hit": false
          },
          {
            "score": 0.7720273733139038,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7718365788459778,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7708197832107544,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.7707619667053223,
            "answer": "calculating",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 114,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7565670609474182,
        "b in neighbourhood of b_prime": 3359,
        "b_prime in neighbourhood of b": 115
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.786016047000885,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.7804548740386963,
            "answer": "abraham",
            "hit": false
          },
          {
            "score": 0.7700480818748474,
            "answer": "umar",
            "hit": false
          },
          {
            "score": 0.7683055400848389,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.7666122913360596,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7659479379653931,
            "answer": "sturdy",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 458,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7430966794490814,
        "b in neighbourhood of b_prime": 1032,
        "b_prime in neighbourhood of b": 459
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7777248620986938,
            "answer": "lafayette",
            "hit": false
          },
          {
            "score": 0.7746632099151611,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7742648124694824,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7735353112220764,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.7726624011993408,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7688154578208923,
            "answer": "lenin",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 82,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7535143494606018,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 83
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8092311024665833,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8075712323188782,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.8050607442855835,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7882628440856934,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7864068150520325,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7854203581809998,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7864068150520325,
        "b in neighbourhood of b_prime": 127,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.781229555606842,
            "answer": "mcconnell",
            "hit": false
          },
          {
            "score": 0.7754428386688232,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.770148754119873,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7700810432434082,
            "answer": "intellectuals",
            "hit": false
          },
          {
            "score": 0.7676743268966675,
            "answer": "ambiguity",
            "hit": false
          },
          {
            "score": 0.7673322558403015,
            "answer": "undermine",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 13173,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6413628458976746,
        "b in neighbourhood of b_prime": 8143,
        "b_prime in neighbourhood of b": 13174
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7813456058502197,
            "answer": "consolidation",
            "hit": false
          },
          {
            "score": 0.780269980430603,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7800155282020569,
            "answer": "mueller",
            "hit": false
          },
          {
            "score": 0.7789371013641357,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.7775418162345886,
            "answer": "horrific",
            "hit": false
          },
          {
            "score": 0.776537299156189,
            "answer": "aesthetics",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 2236,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7357002198696136,
        "b in neighbourhood of b_prime": 2305,
        "b_prime in neighbourhood of b": 2237
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 18,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "b2f60ae3-fdd5-4e79-8966-2983b364942c",
      "timestamp": "2025-05-18T12:23:24.522428"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8033345937728882,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7748169302940369,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7704498171806335,
            "answer": "poorer",
            "hit": false
          },
          {
            "score": 0.7699949741363525,
            "answer": "exhibiting",
            "hit": false
          },
          {
            "score": 0.7687159776687622,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7683050632476807,
            "answer": "umar",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 5479,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6506728529930115,
        "b in neighbourhood of b_prime": 4374,
        "b_prime in neighbourhood of b": 5480
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8521096706390381,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7608425617218018,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7532793879508972,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7319597005844116,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.7233730554580688,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7229219079017639,
            "answer": "tiger",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 84,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.69184510409832,
        "b in neighbourhood of b_prime": 7056,
        "b_prime in neighbourhood of b": 85
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.772354781627655,
            "answer": "rochester",
            "hit": false
          },
          {
            "score": 0.7678251266479492,
            "answer": "albany",
            "hit": false
          },
          {
            "score": 0.7676727175712585,
            "answer": "erie",
            "hit": false
          },
          {
            "score": 0.7531065940856934,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.7494558691978455,
            "answer": "hartford",
            "hit": false
          },
          {
            "score": 0.7493146657943726,
            "answer": "utilizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 726,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7189570963382721,
        "b in neighbourhood of b_prime": 7499,
        "b_prime in neighbourhood of b": 727
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8701839447021484,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7748276591300964,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7672331929206848,
            "answer": "oppressive",
            "hit": false
          },
          {
            "score": 0.7658564448356628,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.765727162361145,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.7645268440246582,
            "answer": "unreasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 343,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7386769503355026,
        "b in neighbourhood of b_prime": 3960,
        "b_prime in neighbourhood of b": 344
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.8569216728210449,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.78707355260849,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7739570140838623,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7713523507118225,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7701029777526855,
            "answer": "reiterated",
            "hit": false
          },
          {
            "score": 0.7698348164558411,
            "answer": "utilizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 8674,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6899299919605255,
        "b in neighbourhood of b_prime": 1746,
        "b_prime in neighbourhood of b": 8675
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8268213272094727,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7683402299880981,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7594477534294128,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7574435472488403,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7481061816215515,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.7469645142555237,
            "answer": "wolves",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 2074,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7003691494464874,
        "b in neighbourhood of b_prime": 5130,
        "b_prime in neighbourhood of b": 2075
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8673248291015625,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7894406318664551,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.781282365322113,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7787445187568665,
            "answer": "manipulating",
            "hit": false
          },
          {
            "score": 0.7781081199645996,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7772682905197144,
            "answer": "antics",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 3839,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7180421650409698,
        "b in neighbourhood of b_prime": 2036,
        "b_prime in neighbourhood of b": 3840
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8823068141937256,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.8345311880111694,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.8000078797340393,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.7292904853820801,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.7258718609809875,
            "answer": "logos",
            "hit": false
          },
          {
            "score": 0.7256951332092285,
            "answer": "coating",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 1644,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6836041212081909,
        "b in neighbourhood of b_prime": 8950,
        "b_prime in neighbourhood of b": 1645
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8723850250244141,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7995611429214478,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7929056882858276,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7797048687934875,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7727108001708984,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7725271582603455,
            "answer": "fishermen",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 3591,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7198161482810974,
        "b in neighbourhood of b_prime": 1494,
        "b_prime in neighbourhood of b": 3592
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8285109996795654,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7683402299880981,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7480697631835938,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.747738778591156,
            "answer": "panthers",
            "hit": false
          },
          {
            "score": 0.7430725693702698,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7422769069671631,
            "answer": "shredded",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 173,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7168610692024231,
        "b in neighbourhood of b_prime": 1931,
        "b_prime in neighbourhood of b": 174
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8854213953018188,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.799561083316803,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7817314863204956,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7799466848373413,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7768010497093201,
            "answer": "radically",
            "hit": false
          },
          {
            "score": 0.7762706875801086,
            "answer": "reiterated",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.76716148853302,
        "b in neighbourhood of b_prime": 550,
        "b_prime in neighbourhood of b": 16
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "ccf49cd4-79b7-4e16-b213-63fac0f9f242",
      "timestamp": "2025-05-18T12:23:24.726072"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.8229907751083374,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.7419793605804443,
            "answer": "crab",
            "hit": false
          },
          {
            "score": 0.7349147796630859,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.7340759038925171,
            "answer": "ding",
            "hit": false
          },
          {
            "score": 0.7338839173316956,
            "answer": "plum",
            "hit": false
          },
          {
            "score": 0.7337309122085571,
            "answer": "insect",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 144,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7036711126565933,
        "b in neighbourhood of b_prime": 1906,
        "b_prime in neighbourhood of b": 145
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.8443004488945007,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7981680631637573,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7895328998565674,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7722950577735901,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7184852361679077,
            "answer": "airplane",
            "hit": false
          },
          {
            "score": 0.7176811695098877,
            "answer": "bees",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2650,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6633028835058212,
        "b in neighbourhood of b_prime": 10061,
        "b_prime in neighbourhood of b": 2651
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.8823068141937256,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.8345311880111694,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.8000078797340393,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.7292904853820801,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.7258718609809875,
            "answer": "logos",
            "hit": false
          },
          {
            "score": 0.7256951332092285,
            "answer": "coating",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 5246,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.664642259478569,
        "b in neighbourhood of b_prime": 10518,
        "b_prime in neighbourhood of b": 5247
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.8854213953018188,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.799561083316803,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7817314863204956,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7799466848373413,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7768010497093201,
            "answer": "radically",
            "hit": false
          },
          {
            "score": 0.7762706875801086,
            "answer": "reiterated",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 12377,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6635909825563431,
        "b in neighbourhood of b_prime": 8680,
        "b_prime in neighbourhood of b": 12378
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "4654e705-79b7-41df-bbde-264216199871",
      "timestamp": "2025-05-18T12:23:24.861841"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8033345937728882,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7748169302940369,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7704498171806335,
            "answer": "poorer",
            "hit": false
          },
          {
            "score": 0.7699949741363525,
            "answer": "exhibiting",
            "hit": false
          },
          {
            "score": 0.7687159776687622,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7683050632476807,
            "answer": "umar",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 5369,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6940801292657852,
        "b in neighbourhood of b_prime": 5988,
        "b_prime in neighbourhood of b": 5370
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8127959370613098,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.7220078706741333,
            "answer": "constantin",
            "hit": false
          },
          {
            "score": 0.721748948097229,
            "answer": "ape",
            "hit": false
          },
          {
            "score": 0.7215956449508667,
            "answer": "insect",
            "hit": false
          },
          {
            "score": 0.7198654413223267,
            "answer": "umar",
            "hit": false
          },
          {
            "score": 0.7168556451797485,
            "answer": "bash",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 2672,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6597380042076111,
        "b in neighbourhood of b_prime": 6614,
        "b_prime in neighbourhood of b": 2673
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8521096706390381,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7608425617218018,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7532793879508972,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7319597005844116,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.7233730554580688,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7229219079017639,
            "answer": "tiger",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 1782,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6502987444400787,
        "b in neighbourhood of b_prime": 7919,
        "b_prime in neighbourhood of b": 1783
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.8557607531547546,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8247122168540955,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8105851411819458,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.8048889636993408,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.795203447341919,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7798424363136292,
            "answer": "poultry",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 5859,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6915338635444641,
        "b in neighbourhood of b_prime": 5791,
        "b_prime in neighbourhood of b": 5860
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7908959984779358,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.774337112903595,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7614631652832031,
            "answer": "hockey",
            "hit": false
          },
          {
            "score": 0.7584621906280518,
            "answer": "football",
            "hit": false
          },
          {
            "score": 0.7509255409240723,
            "answer": "tennis",
            "hit": false
          },
          {
            "score": 0.7467336654663086,
            "answer": "basketball",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 8622,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6521069705486298,
        "b in neighbourhood of b_prime": 12102,
        "b_prime in neighbourhood of b": 8623
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.74727463722229,
            "answer": "sturdy",
            "hit": false
          },
          {
            "score": 0.7463931441307068,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7451297640800476,
            "answer": "dismay",
            "hit": false
          },
          {
            "score": 0.7440097332000732,
            "answer": "doe",
            "hit": false
          },
          {
            "score": 0.7432339191436768,
            "answer": "remark",
            "hit": false
          },
          {
            "score": 0.7427202463150024,
            "answer": "locating",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 4246,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6831056773662567,
        "b in neighbourhood of b_prime": 7358,
        "b_prime in neighbourhood of b": 4247
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8595390915870667,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.7668642997741699,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7607113718986511,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7533333897590637,
            "answer": "swan",
            "hit": false
          },
          {
            "score": 0.7504655122756958,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.749245822429657,
            "answer": "redesign",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 1581,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7075718939304352,
        "b in neighbourhood of b_prime": 4515,
        "b_prime in neighbourhood of b": 1582
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8443004488945007,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7981680631637573,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7895328998565674,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7722950577735901,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7184852361679077,
            "answer": "airplane",
            "hit": false
          },
          {
            "score": 0.7176811695098877,
            "answer": "bees",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2331,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.665117472410202,
        "b in neighbourhood of b_prime": 10585,
        "b_prime in neighbourhood of b": 2332
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7430808544158936,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.7356295585632324,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.7257689833641052,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.7210865020751953,
            "answer": "hawks",
            "hit": false
          },
          {
            "score": 0.7207326292991638,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.7202712297439575,
            "answer": "rodents",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 3059,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6491653621196747,
        "b in neighbourhood of b_prime": 8175,
        "b_prime in neighbourhood of b": 3060
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.8747729063034058,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.8200543522834778,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.8014802932739258,
            "answer": "organism",
            "hit": false
          },
          {
            "score": 0.7984893321990967,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7966769933700562,
            "answer": "parasites",
            "hit": false
          },
          {
            "score": 0.7934566736221313,
            "answer": "pest",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 5786,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7218545973300934,
        "b in neighbourhood of b_prime": 636,
        "b_prime in neighbourhood of b": 5787
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7562403678894043,
            "answer": "cooks",
            "hit": false
          },
          {
            "score": 0.7561167478561401,
            "answer": "distrust",
            "hit": false
          },
          {
            "score": 0.7544308304786682,
            "answer": "shrinking",
            "hit": false
          },
          {
            "score": 0.7538981437683105,
            "answer": "nsa",
            "hit": false
          },
          {
            "score": 0.7536206245422363,
            "answer": "holm",
            "hit": false
          },
          {
            "score": 0.752428412437439,
            "answer": "systematically",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 3943,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6995094269514084,
        "b in neighbourhood of b_prime": 337,
        "b_prime in neighbourhood of b": 3944
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8673248291015625,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7894406318664551,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.781282365322113,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7787445187568665,
            "answer": "manipulating",
            "hit": false
          },
          {
            "score": 0.7781081199645996,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7772682905197144,
            "answer": "antics",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 3195,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7052291333675385,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 3196
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8222402930259705,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7890745401382446,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7594424486160278,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7547036409378052,
            "answer": "rabbits",
            "hit": false
          },
          {
            "score": 0.7546688914299011,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.7443783283233643,
            "answer": "rats",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 6701,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6577225029468536,
        "b in neighbourhood of b_prime": 11518,
        "b_prime in neighbourhood of b": 6702
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8170865774154663,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.7747767567634583,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7465622425079346,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7449020147323608,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7439756393432617,
            "answer": "mouse",
            "hit": false
          },
          {
            "score": 0.7436718344688416,
            "answer": "pig",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 7744,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6488795280456543,
        "b in neighbourhood of b_prime": 12412,
        "b_prime in neighbourhood of b": 7745
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7716584205627441,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.7450964450836182,
            "answer": "holm",
            "hit": false
          },
          {
            "score": 0.7438459396362305,
            "answer": "richmond",
            "hit": false
          },
          {
            "score": 0.7411284446716309,
            "answer": "lund",
            "hit": false
          },
          {
            "score": 0.7400400638580322,
            "answer": "parasite",
            "hit": false
          },
          {
            "score": 0.7390546798706055,
            "answer": "parasites",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 2732,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6860513836145401,
        "b in neighbourhood of b_prime": 6770,
        "b_prime in neighbourhood of b": 2733
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8285109996795654,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7683402299880981,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7480697631835938,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.747738778591156,
            "answer": "panthers",
            "hit": false
          },
          {
            "score": 0.7430725693702698,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7422769069671631,
            "answer": "shredded",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 3635,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6475479602813721,
        "b in neighbourhood of b_prime": 8528,
        "b_prime in neighbourhood of b": 3636
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8854213953018188,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.799561083316803,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7817314863204956,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7799466848373413,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7768010497093201,
            "answer": "radically",
            "hit": false
          },
          {
            "score": 0.7762706875801086,
            "answer": "reiterated",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2919,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7252366244792938,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2920
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8186221122741699,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7340592741966248,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7317192554473877,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7298018932342529,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7261321544647217,
            "answer": "beast",
            "hit": false
          },
          {
            "score": 0.7225686311721802,
            "answer": "tiger",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 5383,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6506560295820236,
        "b in neighbourhood of b_prime": 7852,
        "b_prime in neighbourhood of b": 5384
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 18,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "f9e0bc82-c9f3-4eaf-a9e6-ad02674e83b3",
      "timestamp": "2025-05-18T12:23:24.924115"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.8062800168991089,
            "answer": "ants",
            "hit": false
          },
          {
            "score": 0.7457067966461182,
            "answer": "adapting",
            "hit": false
          },
          {
            "score": 0.7450357675552368,
            "answer": "rabbits",
            "hit": false
          },
          {
            "score": 0.7431775331497192,
            "answer": "fern",
            "hit": false
          },
          {
            "score": 0.7426010370254517,
            "answer": "illustrating",
            "hit": false
          },
          {
            "score": 0.7418326139450073,
            "answer": "bert",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 9074,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6452338546514511,
        "b in neighbourhood of b_prime": 524,
        "b_prime in neighbourhood of b": 9075
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.8224443793296814,
            "answer": "apples",
            "hit": false
          },
          {
            "score": 0.7505364418029785,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7487286925315857,
            "answer": "pear",
            "hit": false
          },
          {
            "score": 0.7480801343917847,
            "answer": "iphone",
            "hit": false
          },
          {
            "score": 0.7460967898368835,
            "answer": "almond",
            "hit": false
          },
          {
            "score": 0.7389387488365173,
            "answer": "infused",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 266,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.630579799413681,
        "b in neighbourhood of b_prime": 1472,
        "b_prime in neighbourhood of b": 267
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7107924818992615,
            "answer": "bleeding",
            "hit": false
          },
          {
            "score": 0.7104233503341675,
            "answer": "urine",
            "hit": false
          },
          {
            "score": 0.7046865224838257,
            "answer": "bleed",
            "hit": false
          },
          {
            "score": 0.7038686275482178,
            "answer": "serum",
            "hit": false
          },
          {
            "score": 0.7027407884597778,
            "answer": "flesh",
            "hit": false
          },
          {
            "score": 0.7017404437065125,
            "answer": "fluids",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 1148,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.647178053855896,
        "b in neighbourhood of b_prime": 300,
        "b_prime in neighbourhood of b": 1149
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.8246870636940002,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.823505163192749,
            "answer": "sausage",
            "hit": false
          },
          {
            "score": 0.8223084211349487,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.8196399807929993,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.8195521831512451,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.8175219297409058,
            "answer": "notions",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 13815,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6435729265213013,
        "b in neighbourhood of b_prime": 1321,
        "b_prime in neighbourhood of b": 13816
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7992458939552307,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7953187227249146,
            "answer": "potato",
            "hit": false
          },
          {
            "score": 0.7902894020080566,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7900229692459106,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.789704442024231,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.7874429821968079,
            "answer": "insulting",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 7774,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7022361159324646,
        "b in neighbourhood of b_prime": 267,
        "b_prime in neighbourhood of b": 7775
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7700936794281006,
            "answer": "almond",
            "hit": false
          },
          {
            "score": 0.7557462453842163,
            "answer": "berries",
            "hit": false
          },
          {
            "score": 0.755225419998169,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7531321048736572,
            "answer": "boosted",
            "hit": false
          },
          {
            "score": 0.7514570951461792,
            "answer": "plum",
            "hit": false
          },
          {
            "score": 0.7478663921356201,
            "answer": "analyzed",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 11118,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6458512544631958,
        "b in neighbourhood of b_prime": 349,
        "b_prime in neighbourhood of b": 11119
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8120242357254028,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7978310585021973,
            "answer": "nutritional",
            "hit": false
          },
          {
            "score": 0.7858685851097107,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.7806636095046997,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7790105938911438,
            "answer": "candy",
            "hit": false
          },
          {
            "score": 0.776732325553894,
            "answer": "cookies",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 8536,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6081209778785706,
        "b in neighbourhood of b_prime": 8391,
        "b_prime in neighbourhood of b": 8537
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8426285982131958,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7247159481048584,
            "answer": "vortex",
            "hit": false
          },
          {
            "score": 0.7229234576225281,
            "answer": "obscured",
            "hit": false
          },
          {
            "score": 0.7220871448516846,
            "answer": "fog",
            "hit": false
          },
          {
            "score": 0.7197846174240112,
            "answer": "mist",
            "hit": false
          },
          {
            "score": 0.7195238471031189,
            "answer": "centralized",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 2871,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6363850235939026,
        "b in neighbourhood of b_prime": 2148,
        "b_prime in neighbourhood of b": 2872
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.755744218826294,
            "answer": "petroleum",
            "hit": false
          },
          {
            "score": 0.7475578188896179,
            "answer": "biomass",
            "hit": false
          },
          {
            "score": 0.7475481033325195,
            "answer": "miners",
            "hit": false
          },
          {
            "score": 0.7458352446556091,
            "answer": "methane",
            "hit": false
          },
          {
            "score": 0.7455066442489624,
            "answer": "boiler",
            "hit": false
          },
          {
            "score": 0.7451165914535522,
            "answer": "minerals",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 13162,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6222598850727081,
        "b in neighbourhood of b_prime": 3057,
        "b_prime in neighbourhood of b": 13163
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7974075675010681,
            "answer": "tea",
            "hit": false
          },
          {
            "score": 0.7685253024101257,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7651205062866211,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.7603938579559326,
            "answer": "starbucks",
            "hit": false
          },
          {
            "score": 0.7553191781044006,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.744381844997406,
            "answer": "breakfast",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 9708,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6082708239555359,
        "b in neighbourhood of b_prime": 5940,
        "b_prime in neighbourhood of b": 9709
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7893230319023132,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.756342887878418,
            "answer": "cinnamon",
            "hit": false
          },
          {
            "score": 0.7534535527229309,
            "answer": "vanilla",
            "hit": false
          },
          {
            "score": 0.751776397228241,
            "answer": "textures",
            "hit": false
          },
          {
            "score": 0.7467095851898193,
            "answer": "fluids",
            "hit": false
          },
          {
            "score": 0.7464877367019653,
            "answer": "markedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 10056,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6621072888374329,
        "b in neighbourhood of b_prime": 190,
        "b_prime in neighbourhood of b": 10057
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.74727463722229,
            "answer": "sturdy",
            "hit": false
          },
          {
            "score": 0.7463931441307068,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7451297640800476,
            "answer": "dismay",
            "hit": false
          },
          {
            "score": 0.7440097332000732,
            "answer": "doe",
            "hit": false
          },
          {
            "score": 0.7432339191436768,
            "answer": "remark",
            "hit": false
          },
          {
            "score": 0.7427202463150024,
            "answer": "locating",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 10783,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6578357517719269,
        "b in neighbourhood of b_prime": 164,
        "b_prime in neighbourhood of b": 10784
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.9084731936454773,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.8128396272659302,
            "answer": "bathrooms",
            "hit": false
          },
          {
            "score": 0.8028706312179565,
            "answer": "cabinets",
            "hit": false
          },
          {
            "score": 0.802700936794281,
            "answer": "shelves",
            "hit": false
          },
          {
            "score": 0.8013221025466919,
            "answer": "vaccines",
            "hit": false
          },
          {
            "score": 0.8009252548217773,
            "answer": "detrimental",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 13723,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5826542228460312,
        "b in neighbourhood of b_prime": 12944,
        "b_prime in neighbourhood of b": 13724
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.7710623741149902,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7705528736114502,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7696437239646912,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7667372226715088,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.766060471534729,
            "answer": "boosted",
            "hit": false
          },
          {
            "score": 0.7656915187835693,
            "answer": "donkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 12279,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6434255093336105,
        "b in neighbourhood of b_prime": 1335,
        "b_prime in neighbourhood of b": 12280
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.8520430326461792,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.822675347328186,
            "answer": "berries",
            "hit": false
          },
          {
            "score": 0.8064850568771362,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.806472897529602,
            "answer": "apples",
            "hit": false
          },
          {
            "score": 0.8030174970626831,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8002189993858337,
            "answer": "economists",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 9309,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5812985152006149,
        "b in neighbourhood of b_prime": 11600,
        "b_prime in neighbourhood of b": 9310
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7690161466598511,
            "answer": "weeds",
            "hit": false
          },
          {
            "score": 0.7653059959411621,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.7573242783546448,
            "answer": "gravel",
            "hit": false
          },
          {
            "score": 0.753076434135437,
            "answer": "weed",
            "hit": false
          },
          {
            "score": 0.7518908977508545,
            "answer": "bushes",
            "hit": false
          },
          {
            "score": 0.742896556854248,
            "answer": "herbs",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 4821,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.674322783946991,
        "b in neighbourhood of b_prime": 53,
        "b_prime in neighbourhood of b": 4822
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.815563976764679,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.8091815114021301,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.8064477443695068,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.7904447317123413,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.7729963064193726,
            "answer": "departed",
            "hit": false
          },
          {
            "score": 0.765766441822052,
            "answer": "departing",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 7855,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6365730166435242,
        "b in neighbourhood of b_prime": 2272,
        "b_prime in neighbourhood of b": 7856
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7700614929199219,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.7606850266456604,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7569621801376343,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7517458200454712,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7480796575546265,
            "answer": "butter",
            "hit": false
          },
          {
            "score": 0.7445646524429321,
            "answer": "juice",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 11932,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6369995176792145,
        "b in neighbourhood of b_prime": 2059,
        "b_prime in neighbourhood of b": 11933
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.808077871799469,
            "answer": "papers",
            "hit": false
          },
          {
            "score": 0.7525663375854492,
            "answer": "newspaper",
            "hit": false
          },
          {
            "score": 0.7419208288192749,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7268844842910767,
            "answer": "newspapers",
            "hit": false
          },
          {
            "score": 0.7245583534240723,
            "answer": "parchment",
            "hit": false
          },
          {
            "score": 0.7201266288757324,
            "answer": "publications",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 4283,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.638600081205368,
        "b in neighbourhood of b_prime": 1813,
        "b_prime in neighbourhood of b": 4284
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.8258616328239441,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.7610903978347778,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7605879306793213,
            "answer": "onions",
            "hit": false
          },
          {
            "score": 0.759228527545929,
            "answer": "spice",
            "hit": false
          },
          {
            "score": 0.7574818134307861,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.7559602856636047,
            "answer": "bean",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 8628,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.609028771519661,
        "b in neighbourhood of b_prime": 5791,
        "b_prime in neighbourhood of b": 8629
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8795713186264038,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.8129045367240906,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7975916862487793,
            "answer": "obesity",
            "hit": false
          },
          {
            "score": 0.7966421842575073,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7957750558853149,
            "answer": "onion",
            "hit": false
          },
          {
            "score": 0.7953187227249146,
            "answer": "carrot",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 12708,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6646809279918671,
        "b in neighbourhood of b_prime": 3437,
        "b_prime in neighbourhood of b": 12709
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7716584205627441,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.7450964450836182,
            "answer": "holm",
            "hit": false
          },
          {
            "score": 0.7438459396362305,
            "answer": "richmond",
            "hit": false
          },
          {
            "score": 0.7411284446716309,
            "answer": "lund",
            "hit": false
          },
          {
            "score": 0.7400400638580322,
            "answer": "parasite",
            "hit": false
          },
          {
            "score": 0.7390546798706055,
            "answer": "parasites",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 10137,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6572238951921463,
        "b in neighbourhood of b_prime": 182,
        "b_prime in neighbourhood of b": 10138
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7713885307312012,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7660658359527588,
            "answer": "rise",
            "hit": false
          },
          {
            "score": 0.7520163655281067,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7263771295547485,
            "answer": "flower",
            "hit": false
          },
          {
            "score": 0.7255874872207642,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7149298191070557,
            "answer": "arose",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 241,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6640499830245972,
        "b in neighbourhood of b_prime": 46,
        "b_prime in neighbourhood of b": 242
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.766797661781311,
            "answer": "crystals",
            "hit": false
          },
          {
            "score": 0.762850284576416,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7613526582717896,
            "answer": "magnesium",
            "hit": false
          },
          {
            "score": 0.7608240842819214,
            "answer": "denounced",
            "hit": false
          },
          {
            "score": 0.7603033185005188,
            "answer": "revoked",
            "hit": false
          },
          {
            "score": 0.7590534687042236,
            "answer": "fiery",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 12537,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6511577069759369,
        "b in neighbourhood of b_prime": 199,
        "b_prime in neighbourhood of b": 12538
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7760883569717407,
            "answer": "salts",
            "hit": false
          },
          {
            "score": 0.7665575742721558,
            "answer": "saline",
            "hit": false
          },
          {
            "score": 0.7409540414810181,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.7342567443847656,
            "answer": "spice",
            "hit": false
          },
          {
            "score": 0.7330635190010071,
            "answer": "weed",
            "hit": false
          },
          {
            "score": 0.7312546372413635,
            "answer": "insults",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 6853,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6599887311458588,
        "b in neighbourhood of b_prime": 236,
        "b_prime in neighbourhood of b": 6854
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7793220281600952,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7702867984771729,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.729520320892334,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7260138392448425,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7252366542816162,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7153841257095337,
            "answer": "marine",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 4256,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6422568261623383,
        "b in neighbourhood of b_prime": 2258,
        "b_prime in neighbourhood of b": 4257
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8092712759971619,
            "answer": "skies",
            "hit": false
          },
          {
            "score": 0.7499161958694458,
            "answer": "heavens",
            "hit": false
          },
          {
            "score": 0.7124998569488525,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7109193205833435,
            "answer": "horizon",
            "hit": false
          },
          {
            "score": 0.7097130417823792,
            "answer": "ceiling",
            "hit": false
          },
          {
            "score": 0.7057597637176514,
            "answer": "sun",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 2115,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.659768670797348,
        "b in neighbourhood of b_prime": 419,
        "b_prime in neighbourhood of b": 2116
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7448011040687561,
            "answer": "rain",
            "hit": false
          },
          {
            "score": 0.7429684400558472,
            "answer": "sand",
            "hit": false
          },
          {
            "score": 0.7401705980300903,
            "answer": "frost",
            "hit": false
          },
          {
            "score": 0.7400637865066528,
            "answer": "rained",
            "hit": false
          },
          {
            "score": 0.7388434410095215,
            "answer": "rains",
            "hit": false
          },
          {
            "score": 0.7372350692749023,
            "answer": "winter",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 7276,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6542577296495438,
        "b in neighbourhood of b_prime": 438,
        "b_prime in neighbourhood of b": 7277
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.8443050980567932,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7684266567230225,
            "answer": "sediment",
            "hit": false
          },
          {
            "score": 0.7546266913414001,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.7429732084274292,
            "answer": "dirt",
            "hit": false
          },
          {
            "score": 0.7426344752311707,
            "answer": "turf",
            "hit": false
          },
          {
            "score": 0.7409486174583435,
            "answer": "nutritional",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 11612,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6090631857514381,
        "b in neighbourhood of b_prime": 5783,
        "b_prime in neighbourhood of b": 11613
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7555261850357056,
            "answer": "sweetness",
            "hit": false
          },
          {
            "score": 0.7555124759674072,
            "answer": "candy",
            "hit": false
          },
          {
            "score": 0.7538012862205505,
            "answer": "honey",
            "hit": false
          },
          {
            "score": 0.7537269592285156,
            "answer": "syrup",
            "hit": false
          },
          {
            "score": 0.7479637861251831,
            "answer": "alcohol",
            "hit": false
          },
          {
            "score": 0.7459715604782104,
            "answer": "cocoa",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 9294,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6483863443136215,
        "b in neighbourhood of b_prime": 755,
        "b_prime in neighbourhood of b": 9295
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7824269533157349,
            "answer": "sunlight",
            "hit": false
          },
          {
            "score": 0.7512519359588623,
            "answer": "moon",
            "hit": false
          },
          {
            "score": 0.7241689562797546,
            "answer": "sunshine",
            "hit": false
          },
          {
            "score": 0.7057597637176514,
            "answer": "sky",
            "hit": false
          },
          {
            "score": 0.7052081227302551,
            "answer": "rain",
            "hit": false
          },
          {
            "score": 0.7005553841590881,
            "answer": "moonlight",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 983,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6570292413234711,
        "b in neighbourhood of b_prime": 8228,
        "b_prime in neighbourhood of b": 984
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7533333897590637,
            "answer": "duck",
            "hit": false
          },
          {
            "score": 0.7524555325508118,
            "answer": "distressed",
            "hit": false
          },
          {
            "score": 0.7499608397483826,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7495085597038269,
            "answer": "serge",
            "hit": false
          },
          {
            "score": 0.7469483017921448,
            "answer": "amin",
            "hit": false
          },
          {
            "score": 0.7465294003486633,
            "answer": "kun",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 10484,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6455315351486206,
        "b in neighbourhood of b_prime": 996,
        "b_prime in neighbourhood of b": 10485
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7974075675010681,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.7568304538726807,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7434670329093933,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.733673095703125,
            "answer": "dinner",
            "hit": false
          },
          {
            "score": 0.7317665815353394,
            "answer": "soup",
            "hit": false
          },
          {
            "score": 0.7316898107528687,
            "answer": "pudding",
            "hit": false
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 4570,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6133103221654892,
        "b in neighbourhood of b_prime": 4823,
        "b_prime in neighbourhood of b": 4571
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.8520111441612244,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.8375877141952515,
            "answer": "onions",
            "hit": false
          },
          {
            "score": 0.8232637047767639,
            "answer": "onion",
            "hit": false
          },
          {
            "score": 0.820762038230896,
            "answer": "citrus",
            "hit": false
          },
          {
            "score": 0.8195521831512451,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.8189694285392761,
            "answer": "vinegar",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 13616,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6540715545415878,
        "b in neighbourhood of b_prime": 145,
        "b_prime in neighbourhood of b": 13617
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 34,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "00179392-8b7b-4d03-8749-d55e1282ccad",
      "timestamp": "2025-05-18T12:23:25.186156"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.9051494598388672,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.886947512626648,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.8144829273223877,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7989482879638672,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7807551026344299,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7789704203605652,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9051494300365448,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.8499380350112915,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.8170826435089111,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7520321607589722,
            "answer": "man",
            "hit": false
          },
          {
            "score": 0.7511764168739319,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.7421250939369202,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.7396571636199951,
            "answer": "guy",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8499380052089691,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.8674570322036743,
            "answer": "sister",
            "hit": true
          },
          {
            "score": 0.8261863589286804,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.8127219080924988,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8081687092781067,
            "answer": "son",
            "hit": false
          },
          {
            "score": 0.8009642362594604,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7877461910247803,
            "answer": "uncle",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8674570918083191,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.7621680498123169,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.7469282746315002,
            "answer": "sock",
            "hit": false
          },
          {
            "score": 0.7443735599517822,
            "answer": "accelerating",
            "hit": false
          },
          {
            "score": 0.7443089485168457,
            "answer": "distrust",
            "hit": false
          },
          {
            "score": 0.7394932508468628,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7370781302452087,
            "answer": "hog",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 530,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7102134227752686,
        "b in neighbourhood of b_prime": 3387,
        "b_prime in neighbourhood of b": 531
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.8118313550949097,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.7349783182144165,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.7329022884368896,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7265987992286682,
            "answer": "hog",
            "hit": false
          },
          {
            "score": 0.716924786567688,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7142879366874695,
            "answer": "cow",
            "hit": true
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7142879664897919,
        "b in neighbourhood of b_prime": 424,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.8530015349388123,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.8127894997596741,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7910376787185669,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.7810016870498657,
            "answer": "mum",
            "hit": true
          },
          {
            "score": 0.774966299533844,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7698994874954224,
            "answer": "grandmother",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8530015647411346,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.829585611820221,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.7782865166664124,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.7567821741104126,
            "answer": "prince",
            "hit": false
          },
          {
            "score": 0.7332521677017212,
            "answer": "duc",
            "hit": false
          },
          {
            "score": 0.730056881904602,
            "answer": "king",
            "hit": false
          },
          {
            "score": 0.7269372344017029,
            "answer": "wizard",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8295856714248657,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.8719597458839417,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.8127894401550293,
            "answer": "dad",
            "hit": false
          },
          {
            "score": 0.8127219080924988,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.807778000831604,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7975799441337585,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7944965362548828,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8719597458839417,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7899547219276428,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.778424859046936,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7676933407783508,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.7529815435409546,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.7487075328826904,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7361624240875244,
            "answer": "heaven",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7676933407783508,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8783414363861084,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8667371273040771,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.8331605195999146,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8162094950675964,
            "answer": "ancestors",
            "hit": false
          },
          {
            "score": 0.807778000831604,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7996193766593933,
            "answer": "uncle",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8783414959907532,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.7786427736282349,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7759522199630737,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7733768820762634,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7717932462692261,
            "answer": "bathrooms",
            "hit": false
          },
          {
            "score": 0.7716991901397705,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.7710212469100952,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7786427736282349,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8483816385269165,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8327851295471191,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.8311517238616943,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.8241045475006104,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.764197826385498,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.758347749710083,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8241046369075775,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.8234256505966187,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.7869352102279663,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.7671692967414856,
            "answer": "prince",
            "hit": false
          },
          {
            "score": 0.7540794610977173,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.7512803673744202,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.742519736289978,
            "answer": "ruler",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8234256505966187,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.8168520927429199,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.7835291624069214,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.7520321607589722,
            "answer": "boy",
            "hit": false
          },
          {
            "score": 0.7463517189025879,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7449222803115845,
            "answer": "person",
            "hit": false
          },
          {
            "score": 0.7327761650085449,
            "answer": "guy",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8168520927429199,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9134111404418945,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8964883685112,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.839535117149353,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.8275718688964844,
            "answer": "uncle",
            "hit": false
          },
          {
            "score": 0.8108065128326416,
            "answer": "cousins",
            "hit": false
          },
          {
            "score": 0.8085339069366455,
            "answer": "grandchildren",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9134111106395721,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8286510705947876,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.818744421005249,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7671692967414856,
            "answer": "king",
            "hit": false
          },
          {
            "score": 0.7567821741104126,
            "answer": "duke",
            "hit": false
          },
          {
            "score": 0.7506034970283508,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.7324180006980896,
            "answer": "ruler",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8286511301994324,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.8585981130599976,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.8403339385986328,
            "answer": "sons",
            "hit": false
          },
          {
            "score": 0.8081687092781067,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.8074936270713806,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7821909785270691,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.772254228591919,
            "answer": "father",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8585981130599976,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8462808132171631,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.8275718688964844,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7996194362640381,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7958378791809082,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7894262671470642,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7877461910247803,
            "answer": "brother",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8462808728218079,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 18,
      "accuracy": 0.7777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "a85e7222-0ba3-4c00-8b2b-209af2cb7381",
      "timestamp": "2025-05-18T12:23:25.737107"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.8002499341964722,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.7949613928794861,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.774749755859375,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.7604258060455322,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7585179805755615,
            "answer": "disturbances",
            "hit": false
          },
          {
            "score": 0.7560713887214661,
            "answer": "spirituality",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6827211976051331,
        "b in neighbourhood of b_prime": 385,
        "b_prime in neighbourhood of b": 31
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8465343713760376,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.7818678021430969,
            "answer": "backpack",
            "hit": false
          },
          {
            "score": 0.7689349055290222,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.7579290270805359,
            "answer": "sack",
            "hit": false
          },
          {
            "score": 0.7476069927215576,
            "answer": "pouch",
            "hit": false
          },
          {
            "score": 0.7475496530532837,
            "answer": "luggage",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 3289,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6682558208703995,
        "b in neighbourhood of b_prime": 9601,
        "b_prime in neighbourhood of b": 3290
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7628312110900879,
            "answer": "disclose",
            "hit": false
          },
          {
            "score": 0.7594543695449829,
            "answer": "onions",
            "hit": false
          },
          {
            "score": 0.7588064670562744,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7585196495056152,
            "answer": "disdain",
            "hit": false
          },
          {
            "score": 0.7564793229103088,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7561226487159729,
            "answer": "resentment",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 780,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7256223559379578,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 781
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.853124737739563,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.728939414024353,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.7134600877761841,
            "answer": "head",
            "hit": false
          },
          {
            "score": 0.7023563385009766,
            "answer": "chest",
            "hit": false
          },
          {
            "score": 0.7011257410049438,
            "answer": "frame",
            "hit": false
          },
          {
            "score": 0.699649453163147,
            "answer": "bodily",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6906987726688385,
        "b in neighbourhood of b_prime": 4203,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.8322223424911499,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7792468070983887,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.7709794640541077,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7674451470375061,
            "answer": "hats",
            "hit": false
          },
          {
            "score": 0.7600333094596863,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7596363425254822,
            "answer": "garments",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 1224,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7105477750301361,
        "b in neighbourhood of b_prime": 1649,
        "b_prime in neighbourhood of b": 1225
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8735752105712891,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7593218088150024,
            "answer": "crate",
            "hit": false
          },
          {
            "score": 0.7557467222213745,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7527253031730652,
            "answer": "brewery",
            "hit": false
          },
          {
            "score": 0.7503097653388977,
            "answer": "containers",
            "hit": false
          },
          {
            "score": 0.7492448091506958,
            "answer": "pills",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 973,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7100494503974915,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 974
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8429361581802368,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7457823753356934,
            "answer": "spoon",
            "hit": false
          },
          {
            "score": 0.7391407489776611,
            "answer": "pitcher",
            "hit": false
          },
          {
            "score": 0.7356204390525818,
            "answer": "lobe",
            "hit": false
          },
          {
            "score": 0.7334705591201782,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.7312917113304138,
            "answer": "trough",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 5402,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6724061369895935,
        "b in neighbourhood of b_prime": 490,
        "b_prime in neighbourhood of b": 5403
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.8073390126228333,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.8020308017730713,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7890151143074036,
            "answer": "provocative",
            "hit": false
          },
          {
            "score": 0.7864363789558411,
            "answer": "snack",
            "hit": false
          },
          {
            "score": 0.7864022254943848,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.7856913805007935,
            "answer": "toxin",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 732,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.723717451095581,
        "b in neighbourhood of b_prime": 723,
        "b_prime in neighbourhood of b": 733
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7912610769271851,
            "answer": "desktop",
            "hit": false
          },
          {
            "score": 0.7526867389678955,
            "answer": "keyboard",
            "hit": false
          },
          {
            "score": 0.7468576431274414,
            "answer": "laptop",
            "hit": false
          },
          {
            "score": 0.74391770362854,
            "answer": "briefing",
            "hit": false
          },
          {
            "score": 0.7417799234390259,
            "answer": "podium",
            "hit": false
          },
          {
            "score": 0.7399808168411255,
            "answer": "table",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 12688,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6053842231631279,
        "b in neighbourhood of b_prime": 13321,
        "b_prime in neighbourhood of b": 12689
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.8399315476417542,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7551578879356384,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7514771223068237,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.7448143362998962,
            "answer": "nickel",
            "hit": false
          },
          {
            "score": 0.7438069581985474,
            "answer": "titanium",
            "hit": false
          },
          {
            "score": 0.7410971522331238,
            "answer": "gem",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 6706,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6635511964559555,
        "b in neighbourhood of b_prime": 9374,
        "b_prime in neighbourhood of b": 6707
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.8359622955322266,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.7429680824279785,
            "answer": "banner",
            "hit": false
          },
          {
            "score": 0.717125654220581,
            "answer": "anthem",
            "hit": false
          },
          {
            "score": 0.7164654731750488,
            "answer": "lamps",
            "hit": false
          },
          {
            "score": 0.7158200740814209,
            "answer": "declare",
            "hit": false
          },
          {
            "score": 0.7134406566619873,
            "answer": "credentials",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 6752,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6514117568731308,
        "b in neighbourhood of b_prime": 12336,
        "b_prime in neighbourhood of b": 6753
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8267156481742859,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7248109579086304,
            "answer": "home",
            "hit": false
          },
          {
            "score": 0.724790096282959,
            "answer": "building",
            "hit": false
          },
          {
            "score": 0.7174084186553955,
            "answer": "room",
            "hit": false
          },
          {
            "score": 0.7112154960632324,
            "answer": "castle",
            "hit": false
          },
          {
            "score": 0.710610568523407,
            "answer": "hall",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 71,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6096898168325424,
        "b in neighbourhood of b_prime": 14027,
        "b_prime in neighbourhood of b": 72
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7403324246406555,
            "answer": "jul",
            "hit": false
          },
          {
            "score": 0.7394471168518066,
            "answer": "lund",
            "hit": false
          },
          {
            "score": 0.7380775213241577,
            "answer": "agra",
            "hit": false
          },
          {
            "score": 0.7377060055732727,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.7366757392883301,
            "answer": "essen",
            "hit": false
          },
          {
            "score": 0.7351199388504028,
            "answer": "ike",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 440,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6617793440818787,
        "b in neighbourhood of b_prime": 8272,
        "b_prime in neighbourhood of b": 441
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7923811674118042,
            "answer": "backyard",
            "hit": false
          },
          {
            "score": 0.7825870513916016,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7724811434745789,
            "answer": "gardening",
            "hit": false
          },
          {
            "score": 0.7671017646789551,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.761321485042572,
            "answer": "weeds",
            "hit": false
          },
          {
            "score": 0.7591270208358765,
            "answer": "destroys",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 396,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7338011115789413,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 397
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8774052858352661,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.7787380218505859,
            "answer": "prism",
            "hit": false
          },
          {
            "score": 0.7730916142463684,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.7719115614891052,
            "answer": "opaque",
            "hit": false
          },
          {
            "score": 0.7701717615127563,
            "answer": "photographers",
            "hit": false
          },
          {
            "score": 0.7684531211853027,
            "answer": "cynical",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 3972,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6918266713619232,
        "b in neighbourhood of b_prime": 53,
        "b_prime in neighbourhood of b": 3973
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.8675566911697388,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7559993267059326,
            "answer": "reflection",
            "hit": false
          },
          {
            "score": 0.7456972002983093,
            "answer": "reflections",
            "hit": false
          },
          {
            "score": 0.7438327074050903,
            "answer": "vanity",
            "hit": false
          },
          {
            "score": 0.7391207814216614,
            "answer": "reflecting",
            "hit": false
          },
          {
            "score": 0.7355871200561523,
            "answer": "echoes",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 697,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6945628374814987,
        "b in neighbourhood of b_prime": 43,
        "b_prime in neighbourhood of b": 698
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7805142402648926,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7634687423706055,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.7424143552780151,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.7387381792068481,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.732633650302887,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.7286138534545898,
            "answer": "wealth",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 78,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6643165647983551,
        "b in neighbourhood of b_prime": 530,
        "b_prime in neighbourhood of b": 79
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.841542661190033,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7793220281600952,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.7575441598892212,
            "answer": "atlantic",
            "hit": false
          },
          {
            "score": 0.7487567067146301,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7481153011322021,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7464600205421448,
            "answer": "coastal",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 2345,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6833525896072388,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 2346
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.8299434781074524,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.8292706608772278,
            "answer": "cakes",
            "hit": false
          },
          {
            "score": 0.8179770708084106,
            "answer": "cookies",
            "hit": false
          },
          {
            "score": 0.8175015449523926,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.8152220845222473,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.8131096363067627,
            "answer": "sandwiches",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 148,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.785705029964447,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 149
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7548189163208008,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.7541855573654175,
            "answer": "unpaid",
            "hit": false
          },
          {
            "score": 0.753197193145752,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.752088189125061,
            "answer": "commodity",
            "hit": false
          },
          {
            "score": 0.7471558451652527,
            "answer": "regulating",
            "hit": false
          },
          {
            "score": 0.7465788125991821,
            "answer": "commodities",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 73,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6574239730834961,
        "b in neighbourhood of b_prime": 4715,
        "b_prime in neighbourhood of b": 74
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.8208603262901306,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7722989320755005,
            "answer": "medication",
            "hit": false
          },
          {
            "score": 0.7677385807037354,
            "answer": "medications",
            "hit": false
          },
          {
            "score": 0.7612496614456177,
            "answer": "tablets",
            "hit": false
          },
          {
            "score": 0.7578723430633545,
            "answer": "heroin",
            "hit": false
          },
          {
            "score": 0.7567316889762878,
            "answer": "cosmetic",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 2638,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7118851542472839,
        "b in neighbourhood of b_prime": 140,
        "b_prime in neighbourhood of b": 2639
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.8221595883369446,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7877376675605774,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7851439714431763,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.7811378836631775,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.7786620259284973,
            "answer": "cosmetic",
            "hit": false
          },
          {
            "score": 0.7732112407684326,
            "answer": "nylon",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7555031776428223,
        "b in neighbourhood of b_prime": 1130,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7793220281600952,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7702867984771729,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.729520320892334,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7260138392448425,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7252366542816162,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7153841257095337,
            "answer": "marine",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.701056957244873,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.792792022228241,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.7716267108917236,
            "answer": "paddle",
            "hit": false
          },
          {
            "score": 0.7709270119667053,
            "answer": "scoop",
            "hit": false
          },
          {
            "score": 0.7696605920791626,
            "answer": "collapsing",
            "hit": false
          },
          {
            "score": 0.7690572142601013,
            "answer": "unconventional",
            "hit": false
          },
          {
            "score": 0.7680274248123169,
            "answer": "sweetness",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 1985,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7308151870965958,
        "b in neighbourhood of b_prime": 7943,
        "b_prime in neighbourhood of b": 1986
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8444878458976746,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.7399808168411255,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.7235689759254456,
            "answer": "counter",
            "hit": false
          },
          {
            "score": 0.7128188610076904,
            "answer": "couch",
            "hit": false
          },
          {
            "score": 0.7111616134643555,
            "answer": "discussion",
            "hit": false
          },
          {
            "score": 0.7082849740982056,
            "answer": "sofa",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 4626,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6376976370811462,
        "b in neighbourhood of b_prime": 8023,
        "b_prime in neighbourhood of b": 4627
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.771450936794281,
            "answer": "outfits",
            "hit": false
          },
          {
            "score": 0.7673644423484802,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.766855776309967,
            "answer": "hats",
            "hit": false
          },
          {
            "score": 0.7667199969291687,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.76473069190979,
            "answer": "astonishing",
            "hit": false
          },
          {
            "score": 0.7643083930015564,
            "answer": "bulky",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 7798,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.696586400270462,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 7799
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.8372784852981567,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7805269956588745,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7586846351623535,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7553777694702148,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7515691518783569,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.746566891670227,
            "answer": "vodka",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7400044947862625,
        "b in neighbourhood of b_prime": 3193,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.8282421827316284,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.781025230884552,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.7632870674133301,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7597266435623169,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.7496696710586548,
            "answer": "cables",
            "hit": false
          },
          {
            "score": 0.7388643026351929,
            "answer": "tape",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 6233,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6693470776081085,
        "b in neighbourhood of b_prime": 2343,
        "b_prime in neighbourhood of b": 6234
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 28,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "1fba6b34-7049-445c-a540-e9d8ed2ac77c",
      "timestamp": "2025-05-18T12:23:25.892848"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.848049521446228,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.7556170225143433,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7397987842559814,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7381457090377808,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.7380251884460449,
            "answer": "flower",
            "hit": false
          },
          {
            "score": 0.7375456094741821,
            "answer": "insect",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 330,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7011141777038574,
        "b in neighbourhood of b_prime": 7477,
        "b_prime in neighbourhood of b": 331
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.892729640007019,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.8213598728179932,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.8057461977005005,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.8043081760406494,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.8038806319236755,
            "answer": "forearm",
            "hit": false
          },
          {
            "score": 0.7985181212425232,
            "answer": "markedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 2297,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7459278702735901,
        "b in neighbourhood of b_prime": 49,
        "b_prime in neighbourhood of b": 2298
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.81975919008255,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.7956697940826416,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.7778321504592896,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7739416360855103,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7534350752830505,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.7375367879867554,
            "answer": "automobiles",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.695439487695694,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 35
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8557607531547546,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8247122168540955,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8105851411819458,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.8048889636993408,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.795203447341919,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7798424363136292,
            "answer": "poultry",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7616937160491943,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.8049776554107666,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.7874284982681274,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.7646602392196655,
            "answer": "muslim",
            "hit": false
          },
          {
            "score": 0.7637577056884766,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.7595880627632141,
            "answer": "pagan",
            "hit": false
          },
          {
            "score": 0.7575619220733643,
            "answer": "protestant",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6567116230726242,
        "b in neighbourhood of b_prime": 11560,
        "b_prime in neighbourhood of b": 30
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.8267761468887329,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.8113839626312256,
            "answer": "university",
            "hit": true
          },
          {
            "score": 0.7907925844192505,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7326310276985168,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.7291486263275146,
            "answer": "academy",
            "hit": false
          },
          {
            "score": 0.7259975671768188,
            "answer": "campus",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8113839626312256,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.8307289481163025,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7546263337135315,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7455023527145386,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7340063452720642,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7332342863082886,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.7303814888000488,
            "answer": "city",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7099422067403793,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.813579797744751,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7641692757606506,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.7588043808937073,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7563749551773071,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7521811723709106,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.74996018409729,
            "answer": "cattle",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 226,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7187325060367584,
        "b in neighbourhood of b_prime": 3069,
        "b_prime in neighbourhood of b": 227
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.74727463722229,
            "answer": "sturdy",
            "hit": false
          },
          {
            "score": 0.7463931441307068,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7451297640800476,
            "answer": "dismay",
            "hit": false
          },
          {
            "score": 0.7440097332000732,
            "answer": "doe",
            "hit": false
          },
          {
            "score": 0.7432339191436768,
            "answer": "remark",
            "hit": false
          },
          {
            "score": 0.7427202463150024,
            "answer": "locating",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 8155,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6727980673313141,
        "b in neighbourhood of b_prime": 6827,
        "b_prime in neighbourhood of b": 8156
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8701839447021484,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7748276591300964,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7672331929206848,
            "answer": "oppressive",
            "hit": false
          },
          {
            "score": 0.7658564448356628,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.765727162361145,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.7645268440246582,
            "answer": "unreasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 3435,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7112438827753067,
        "b in neighbourhood of b_prime": 4453,
        "b_prime in neighbourhood of b": 3436
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.903599739074707,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.8142629861831665,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.8134149312973022,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.8025118112564087,
            "answer": "inmate",
            "hit": false
          },
          {
            "score": 0.7981376647949219,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.7951340675354004,
            "answer": "customer",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 5914,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7176303863525391,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5915
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.8199326992034912,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7661271095275879,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.7615253925323486,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.7609109878540039,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7607893347740173,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.7559103965759277,
            "answer": "trout",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 11016,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6266238987445831,
        "b in neighbourhood of b_prime": 843,
        "b_prime in neighbourhood of b": 11017
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8584007620811462,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.7993927001953125,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.7690541744232178,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7678301334381104,
            "answer": "planetary",
            "hit": false
          },
          {
            "score": 0.7665953040122986,
            "answer": "universe",
            "hit": true
          },
          {
            "score": 0.7619298696517944,
            "answer": "planets",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.766595333814621,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.8599105477333069,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7356163263320923,
            "answer": "email",
            "hit": false
          },
          {
            "score": 0.7355952858924866,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7314021587371826,
            "answer": "emails",
            "hit": false
          },
          {
            "score": 0.7276321053504944,
            "answer": "paragraph",
            "hit": false
          },
          {
            "score": 0.7266757488250732,
            "answer": "message",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 95,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6972036808729172,
        "b in neighbourhood of b_prime": 5384,
        "b_prime in neighbourhood of b": 96
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.8268213272094727,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7683402299880981,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7594477534294128,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7574435472488403,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7481061816215515,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.7469645142555237,
            "answer": "wolves",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 4447,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6882146447896957,
        "b in neighbourhood of b_prime": 1294,
        "b_prime in neighbourhood of b": 4448
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8818557262420654,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.841670036315918,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.8188596963882446,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.8095588684082031,
            "answer": "viewers",
            "hit": false
          },
          {
            "score": 0.8009734153747559,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.8000640273094177,
            "answer": "reader",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 735,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7696778476238251,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 736
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.8885610103607178,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7599232196807861,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7521191835403442,
            "answer": "participant",
            "hit": false
          },
          {
            "score": 0.7346371412277222,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7248547077178955,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7241908311843872,
            "answer": "supporter",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 888,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6260239034891129,
        "b in neighbourhood of b_prime": 2071,
        "b_prime in neighbourhood of b": 889
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8797886371612549,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8332484364509583,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8308628797531128,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.8151671290397644,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.8080357313156128,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.8072533011436462,
            "answer": "rapper",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 531,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7534000873565674,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 532
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.8051659464836121,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7652591466903687,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.7561653852462769,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.7479725480079651,
            "answer": "individual",
            "hit": false
          },
          {
            "score": 0.7478938102722168,
            "answer": "individuals",
            "hit": false
          },
          {
            "score": 0.7449222803115845,
            "answer": "man",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 1903,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6245507448911667,
        "b in neighbourhood of b_prime": 7241,
        "b_prime in neighbourhood of b": 1904
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.8750795125961304,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.8638341426849365,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.8362200260162354,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.8092288970947266,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.806097686290741,
            "answer": "photography",
            "hit": false
          },
          {
            "score": 0.802876353263855,
            "answer": "photographer",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 11498,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6390623152256012,
        "b in neighbourhood of b_prime": 8220,
        "b_prime in neighbourhood of b": 11499
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.8820763826370239,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7600159645080566,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7438198328018188,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.7406581044197083,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7386939525604248,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7346110343933105,
            "answer": "athlete",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 538,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6840142011642456,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 539
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8268318176269531,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.8120160698890686,
            "answer": "psychiatrist",
            "hit": false
          },
          {
            "score": 0.8086556196212769,
            "answer": "disturbances",
            "hit": false
          },
          {
            "score": 0.8085278272628784,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8070446848869324,
            "answer": "detectives",
            "hit": false
          },
          {
            "score": 0.8070411682128906,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 1497,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.764972984790802,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1498
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.754149317741394,
            "answer": "auditor",
            "hit": false
          },
          {
            "score": 0.753800630569458,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.7537003755569458,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.7495205998420715,
            "answer": "ministers",
            "hit": false
          },
          {
            "score": 0.7494829893112183,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7490428686141968,
            "answer": "administrator",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 12654,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6303068101406097,
        "b in neighbourhood of b_prime": 5617,
        "b_prime in neighbourhood of b": 12655
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8641684055328369,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8505548238754272,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.8201814889907837,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.8065237998962402,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.7879019975662231,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7786545753479004,
            "answer": "politician",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8201815485954285,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.8105851411819458,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.796772837638855,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7965396642684937,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7872548699378967,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7764395475387573,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7697182893753052,
            "answer": "rabbits",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7566091418266296,
        "b in neighbourhood of b_prime": 131,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8742703199386597,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7643756866455078,
            "answer": "policeman",
            "hit": false
          },
          {
            "score": 0.7639487981796265,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7637701034545898,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.7622252106666565,
            "answer": "diplomat",
            "hit": false
          },
          {
            "score": 0.7607566118240356,
            "answer": "diplomats",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7334722280502319,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 53
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.8382881283760071,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8311517238616943,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.8114223480224609,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8099856972694397,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.8089859485626221,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.8088077306747437,
            "answer": "boyfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 6921,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7202824503183365,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 6922
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7693723440170288,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.7410731911659241,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7291185259819031,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.723198652267456,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7099421620368958,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.7064659595489502,
            "answer": "country",
            "hit": true
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.706465944647789,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8731222748756409,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7913932204246521,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7583470940589905,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7543283700942993,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7522435188293457,
            "answer": "pupils",
            "hit": false
          },
          {
            "score": 0.7518979907035828,
            "answer": "undergraduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6624220460653305,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 33
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.8570314645767212,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7245060205459595,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.7200062870979309,
            "answer": "node",
            "hit": false
          },
          {
            "score": 0.7195417881011963,
            "answer": "bushes",
            "hit": false
          },
          {
            "score": 0.7134298086166382,
            "answer": "vine",
            "hit": false
          },
          {
            "score": 0.7073626518249512,
            "answer": "bird",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7068896442651749,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.8186221122741699,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7340592741966248,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7317192554473877,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7298018932342529,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7261321544647217,
            "answer": "beast",
            "hit": false
          },
          {
            "score": 0.7225686311721802,
            "answer": "tiger",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 352,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6888810098171234,
        "b in neighbourhood of b_prime": 143,
        "b_prime in neighbourhood of b": 353
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7850883603096008,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7330418825149536,
            "answer": "term",
            "hit": false
          },
          {
            "score": 0.7326385974884033,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.7025495171546936,
            "answer": "sentence",
            "hit": true
          },
          {
            "score": 0.7003660798072815,
            "answer": "name",
            "hit": false
          },
          {
            "score": 0.6907127499580383,
            "answer": "terminology",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6718979030847549,
        "b in neighbourhood of b_prime": 13008,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 32,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e674c952-9ac2-4cd5-809a-4d894edd177d",
      "timestamp": "2025-05-18T12:23:26.228679"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.8480404615402222,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.7468141317367554,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7447482347488403,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.7392964363098145,
            "answer": "train",
            "hit": false
          },
          {
            "score": 0.734094500541687,
            "answer": "bicycle",
            "hit": false
          },
          {
            "score": 0.7314356565475464,
            "answer": "trucks",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 1568,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6451719403266907,
        "b in neighbourhood of b_prime": 12152,
        "b_prime in neighbourhood of b": 1569
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.8821005821228027,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.8150779604911804,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.8130353689193726,
            "answer": "pixels",
            "hit": false
          },
          {
            "score": 0.8118889927864075,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8105266690254211,
            "answer": "pixel",
            "hit": false
          },
          {
            "score": 0.8085842132568359,
            "answer": "programmer",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 10899,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.696251392364502,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 10900
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.7730274796485901,
            "answer": "brushes",
            "hit": false
          },
          {
            "score": 0.7650241851806641,
            "answer": "inspections",
            "hit": false
          },
          {
            "score": 0.7629220485687256,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.761244535446167,
            "answer": "splendid",
            "hit": false
          },
          {
            "score": 0.7598892450332642,
            "answer": "inspect",
            "hit": false
          },
          {
            "score": 0.758565366268158,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 4118,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6730102002620697,
        "b in neighbourhood of b_prime": 5159,
        "b_prime in neighbourhood of b": 4119
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.8339192271232605,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7701209187507629,
            "answer": "gallon",
            "hit": false
          },
          {
            "score": 0.760108232498169,
            "answer": "pound",
            "hit": false
          },
          {
            "score": 0.756608784198761,
            "answer": "nickel",
            "hit": false
          },
          {
            "score": 0.7543725371360779,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.7541235089302063,
            "answer": "cents",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 1233,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7108955830335617,
        "b in neighbourhood of b_prime": 333,
        "b_prime in neighbourhood of b": 1234
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "5ec34177-dd52-46b2-b89c-e8f6a09d5e0f",
      "timestamp": "2025-05-18T12:23:26.588877"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.8397929668426514,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.8334015607833862,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8274392485618591,
            "answer": "anxious",
            "hit": false
          },
          {
            "score": 0.8254592418670654,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.825106143951416,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.810662031173706,
            "answer": "stimulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8081936538219452,
        "b in neighbourhood of b_prime": 79,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8267156481742859,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7248109579086304,
            "answer": "home",
            "hit": false
          },
          {
            "score": 0.724790096282959,
            "answer": "building",
            "hit": false
          },
          {
            "score": 0.7174084186553955,
            "answer": "room",
            "hit": false
          },
          {
            "score": 0.7112154960632324,
            "answer": "castle",
            "hit": true
          },
          {
            "score": 0.710610568523407,
            "answer": "hall",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7026285529136658,
        "b in neighbourhood of b_prime": 1169,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.8099076151847839,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7694068551063538,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7657462358474731,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.7479246854782104,
            "answer": "reservoir",
            "hit": false
          },
          {
            "score": 0.7452943325042725,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7255295515060425,
            "answer": "pool",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7026462852954865,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.8051213026046753,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.7810437679290771,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7751836776733398,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.7664068937301636,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7627967000007629,
            "answer": "pains",
            "hit": false
          },
          {
            "score": 0.7512367367744446,
            "answer": "hurting",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.745591789484024,
        "b in neighbourhood of b_prime": 4446,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.78737473487854,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7715475559234619,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7706093192100525,
            "answer": "rabbits",
            "hit": false
          },
          {
            "score": 0.7703801393508911,
            "answer": "discouraged",
            "hit": false
          },
          {
            "score": 0.7659180164337158,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.763703465461731,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 99,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7492279559373856,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 100
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7793220281600952,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.7702867984771729,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.729520320892334,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7260138392448425,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7252366542816162,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7153841257095337,
            "answer": "marine",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7793220281600952,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8895606398582458,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.8260042071342468,
            "answer": "beverages",
            "hit": false
          },
          {
            "score": 0.8248427510261536,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.8209632039070129,
            "answer": "sandwiches",
            "hit": false
          },
          {
            "score": 0.8149821758270264,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8136023879051208,
            "answer": "meals",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7974792122840881,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 40
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.861321747303009,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8216200470924377,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.7991625070571899,
            "answer": "exhaustion",
            "hit": false
          },
          {
            "score": 0.78757244348526,
            "answer": "fatigue",
            "hit": false
          },
          {
            "score": 0.7848812341690063,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.7791677713394165,
            "answer": "sleepy",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8216200470924377,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 8,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "21bd60e5-03e4-47b0-8aef-7f7be2fa42da",
      "timestamp": "2025-05-18T12:23:26.646589"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8685307502746582,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.8417022228240967,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.8411665558815002,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.8370380997657776,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.8357936143875122,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.8223938345909119,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8685306906700134,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7910922765731812,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.784018874168396,
            "answer": "fabric",
            "hit": true
          },
          {
            "score": 0.7839099764823914,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.7755515575408936,
            "answer": "textile",
            "hit": true
          },
          {
            "score": 0.7736117243766785,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7688198089599609,
            "answer": "yarn",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.784018874168396,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8339192867279053,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7958194613456726,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7789466977119446,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.778589129447937,
            "answer": "pounds",
            "hit": false
          },
          {
            "score": 0.7709687948226929,
            "answer": "taxpayers",
            "hit": false
          },
          {
            "score": 0.7703945636749268,
            "answer": "euros",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7789467573165894,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.8719597458839417,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8127894401550293,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.8127219080924988,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.807778000831604,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7975799441337585,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7944965362548828,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8127894997596741,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.8350653648376465,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.8341185450553894,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.8193899393081665,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.8037112355232239,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7687230706214905,
            "answer": "assist",
            "hit": true
          },
          {
            "score": 0.768699586391449,
            "answer": "aid",
            "hit": true
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.768699586391449,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.8051117658615112,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7942800521850586,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.789314329624176,
            "answer": "cunning",
            "hit": false
          },
          {
            "score": 0.7852107286453247,
            "answer": "intellect",
            "hit": false
          },
          {
            "score": 0.7830936908721924,
            "answer": "cynical",
            "hit": false
          },
          {
            "score": 0.7811449766159058,
            "answer": "intellectuals",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7942800521850586,
        "b in neighbourhood of b_prime": 37,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8270029425621033,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7783511877059937,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7703052759170532,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7581458687782288,
            "answer": "treasures",
            "hit": false
          },
          {
            "score": 0.7580629587173462,
            "answer": "glitter",
            "hit": false
          },
          {
            "score": 0.7579169273376465,
            "answer": "luxurious",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.751499354839325,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.8737781047821045,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.7884899973869324,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7706595063209534,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.759377121925354,
            "answer": "statues",
            "hit": false
          },
          {
            "score": 0.7542895078659058,
            "answer": "tomb",
            "hit": false
          },
          {
            "score": 0.7541205883026123,
            "answer": "shrine",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7884900569915771,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7464488744735718,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.7445045709609985,
            "answer": "old",
            "hit": false
          },
          {
            "score": 0.7305518388748169,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.7201298475265503,
            "answer": "fresh",
            "hit": false
          },
          {
            "score": 0.7176241874694824,
            "answer": "young",
            "hit": false
          },
          {
            "score": 0.7163628339767456,
            "answer": "second",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7033604979515076,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.9034721255302429,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.797171413898468,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.7810681462287903,
            "answer": "bundle",
            "hit": true
          },
          {
            "score": 0.7771909236907959,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7740377187728882,
            "answer": "bundled",
            "hit": false
          },
          {
            "score": 0.7728073000907898,
            "answer": "bundles",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7450473606586456,
        "b in neighbourhood of b_prime": 632,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8545067310333252,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.7626694440841675,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.7501100301742554,
            "answer": "subway",
            "hit": false
          },
          {
            "score": 0.7499194145202637,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7373562455177307,
            "answer": "train",
            "hit": false
          },
          {
            "score": 0.7365366220474243,
            "answer": "rails",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.85450679063797,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.8378046751022339,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.8081812262535095,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.8059157133102417,
            "answer": "logical",
            "hit": true
          },
          {
            "score": 0.798814058303833,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.7957338094711304,
            "answer": "coherent",
            "hit": true
          },
          {
            "score": 0.7948375940322876,
            "answer": "reasonable",
            "hit": true
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8059157431125641,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.8510562777519226,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.8507522344589233,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.8303413391113281,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.8175380825996399,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.8141345977783203,
            "answer": "sensible",
            "hit": true
          },
          {
            "score": 0.8101081252098083,
            "answer": "respectable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8141345381736755,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8039095401763916,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.7543900012969971,
            "answer": "stone",
            "hit": true
          },
          {
            "score": 0.718695878982544,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.7086833715438843,
            "answer": "pop",
            "hit": false
          },
          {
            "score": 0.6974790692329407,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6957749128341675,
            "answer": "rocky",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7543900609016418,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.8708263039588928,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.7942477464675903,
            "answer": "bedrooms",
            "hit": false
          },
          {
            "score": 0.7867760062217712,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.7823927998542786,
            "answer": "sweater",
            "hit": false
          },
          {
            "score": 0.7821771502494812,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7815062999725342,
            "answer": "dementia",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8708263635635376,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.8248022198677063,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7757758498191833,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7429042458534241,
            "answer": "type",
            "hit": false
          },
          {
            "score": 0.739456295967102,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.7230775356292725,
            "answer": "fashion",
            "hit": true
          },
          {
            "score": 0.7206602096557617,
            "answer": "technique",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7073859870433807,
        "b in neighbourhood of b_prime": 527,
        "b_prime in neighbourhood of b": 5
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "48d735c1-fe4e-4b15-a38c-de9ec23cff84",
      "timestamp": "2025-05-18T12:23:26.717244"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7737576961517334,
            "answer": "before",
            "hit": true
          },
          {
            "score": 0.7662975192070007,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7440358996391296,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.7167783975601196,
            "answer": "with",
            "hit": false
          },
          {
            "score": 0.7151448130607605,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.6984513401985168,
            "answer": "from",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7737577259540558,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.7231011390686035,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.7182685136795044,
            "answer": "overhead",
            "hit": false
          },
          {
            "score": 0.7141726016998291,
            "answer": "looming",
            "hit": false
          },
          {
            "score": 0.7106994390487671,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7053641080856323,
            "answer": "overview",
            "hit": false
          },
          {
            "score": 0.7053267359733582,
            "answer": "outlined",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6981773525476456,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.9087197780609131,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8279097676277161,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.8192123174667358,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.817902147769928,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.816718339920044,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.8161126375198364,
            "answer": "cervical",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9087198376655579,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.7737576961517334,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.7297136783599854,
            "answer": "until",
            "hit": false
          },
          {
            "score": 0.722761869430542,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7203313112258911,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.710883617401123,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.7070133686065674,
            "answer": "preceding",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7737577259540558,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.883313775062561,
            "answer": "starting",
            "hit": false
          },
          {
            "score": 0.8200212717056274,
            "answer": "start",
            "hit": false
          },
          {
            "score": 0.8140608668327332,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.8075769543647766,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.8013774752616882,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.8009071350097656,
            "answer": "beginnings",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7149325907230377,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7695398926734924,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.7419862747192383,
            "answer": "slain",
            "hit": false
          },
          {
            "score": 0.7339275479316711,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.7328588962554932,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.7290236353874207,
            "answer": "lifeless",
            "hit": false
          },
          {
            "score": 0.727272093296051,
            "answer": "died",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6919455230236053,
        "b in neighbourhood of b_prime": 270,
        "b_prime in neighbourhood of b": 23
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8362572193145752,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7803832292556763,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.7626149654388428,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7622464895248413,
            "answer": "diver",
            "hit": false
          },
          {
            "score": 0.7602154612541199,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7518861293792725,
            "answer": "fishermen",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 1560,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7098502814769745,
        "b in neighbourhood of b_prime": 9074,
        "b_prime in neighbourhood of b": 1561
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.8292133212089539,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.8196092247962952,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.8195787668228149,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.7887530326843262,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7587833404541016,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7447875738143921,
            "answer": "autumn",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 71,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.674804612994194,
        "b in neighbourhood of b_prime": 2965,
        "b_prime in neighbourhood of b": 72
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8339641094207764,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.7807749509811401,
            "answer": "third",
            "hit": false
          },
          {
            "score": 0.7758728265762329,
            "answer": "last",
            "hit": true
          },
          {
            "score": 0.7404390573501587,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7389575242996216,
            "answer": "fourth",
            "hit": false
          },
          {
            "score": 0.7268804311752319,
            "answer": "only",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7758728265762329,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.8921306729316711,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.819981575012207,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.8043771982192993,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.7795411348342896,
            "answer": "feedback",
            "hit": false
          },
          {
            "score": 0.7690325379371643,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.7672924995422363,
            "answer": "submissions",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.819981575012207,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7999336123466492,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7779334783554077,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7339496612548828,
            "answer": "upstairs",
            "hit": false
          },
          {
            "score": 0.721015214920044,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.715567409992218,
            "answer": "onboard",
            "hit": false
          },
          {
            "score": 0.7097828984260559,
            "answer": "downstairs",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7999336123466492,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.8333840370178223,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.8269928097724915,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7748396396636963,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7695866823196411,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.7626163959503174,
            "answer": "interior",
            "hit": false
          },
          {
            "score": 0.7525026798248291,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8269928097724915,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7974299788475037,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.769279420375824,
            "answer": "mundane",
            "hit": false
          },
          {
            "score": 0.7615793943405151,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7579507827758789,
            "answer": "exquisite",
            "hit": false
          },
          {
            "score": 0.7572978138923645,
            "answer": "mystical",
            "hit": false
          },
          {
            "score": 0.7564594745635986,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7974299788475037,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.8709343075752258,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8694447875022888,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8503434658050537,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.8217841386795044,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.8019317984580994,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.7938753366470337,
            "answer": "occupants",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.744937926530838,
        "b in neighbourhood of b_prime": 428,
        "b_prime in neighbourhood of b": 53
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.7110823392868042,
            "answer": "around",
            "hit": false
          },
          {
            "score": 0.7067127227783203,
            "answer": "down",
            "hit": false
          },
          {
            "score": 0.6999303698539734,
            "answer": "out",
            "hit": false
          },
          {
            "score": 0.6964795589447021,
            "answer": "about",
            "hit": false
          },
          {
            "score": 0.6919729709625244,
            "answer": "under",
            "hit": true
          },
          {
            "score": 0.6899285912513733,
            "answer": "through",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6919729709625244,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.877004086971283,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.8108751177787781,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.8094415664672852,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.7919233441352844,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7856491804122925,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.7855561375617981,
            "answer": "initially",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7730764746665955,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8952521085739136,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.8788480758666992,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.8402968049049377,
            "answer": "progressing",
            "hit": false
          },
          {
            "score": 0.8359804749488831,
            "answer": "commence",
            "hit": false
          },
          {
            "score": 0.8312451839447021,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.8179497718811035,
            "answer": "progresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 8481,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7100841850042343,
        "b in neighbourhood of b_prime": 2237,
        "b_prime in neighbourhood of b": 8482
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.8404645919799805,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7962965369224548,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7954697012901306,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7772248387336731,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7660658359527588,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.764009952545166,
            "answer": "decline",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 1348,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6747203171253204,
        "b in neighbourhood of b_prime": 8425,
        "b_prime in neighbourhood of b": 1349
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.900760293006897,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.8497294187545776,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.8390741944313049,
            "answer": "west",
            "hit": false
          },
          {
            "score": 0.7825496196746826,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.7782738208770752,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7749252319335938,
            "answer": "southern",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.900760293006897,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.9127417802810669,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.9049690961837769,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.8518325686454773,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7882289886474609,
            "answer": "midwest",
            "hit": false
          },
          {
            "score": 0.784003734588623,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.7825496196746826,
            "answer": "south",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9127418100833893,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.8922731876373291,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.7282780408859253,
            "answer": "nearer",
            "hit": false
          },
          {
            "score": 0.726087749004364,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7223725914955139,
            "answer": "maximize",
            "hit": false
          },
          {
            "score": 0.7217535972595215,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.7202434539794922,
            "answer": "farther",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 5063,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6082758158445358,
        "b in neighbourhood of b_prime": 7674,
        "b_prime in neighbourhood of b": 5064
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7415412664413452,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7372317910194397,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7348021268844604,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.725244402885437,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.7199193239212036,
            "answer": "authentic",
            "hit": false
          },
          {
            "score": 0.7153843641281128,
            "answer": "truth",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7252443581819534,
        "b in neighbourhood of b_prime": 120,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.893383264541626,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.8435606360435486,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.8390741944313049,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.7748957872390747,
            "answer": "western",
            "hit": false
          },
          {
            "score": 0.7654262781143188,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.76397305727005,
            "answer": "northwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8933832049369812,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 23,
      "accuracy": 0.391304347826087
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "462d70ab-c653-44f6-8c4b-1f405a0ad075",
      "timestamp": "2025-05-18T12:23:26.854516"
    }
  }
]