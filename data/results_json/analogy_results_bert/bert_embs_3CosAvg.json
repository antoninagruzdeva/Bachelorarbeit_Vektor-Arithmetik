[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.9093379378318787,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.7725225687026978,
            "answer": "recordings",
            "hit": false
          },
          {
            "score": 0.7697669267654419,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.7658327221870422,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.761970043182373,
            "answer": "soundtrack",
            "hit": false
          },
          {
            "score": 0.7607556581497192,
            "answer": "releases",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.909337967634201
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.921829879283905,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.8363085985183716,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.829716145992279,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8160121440887451,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8149983286857605,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.8114727139472961,
            "answer": "applied",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.921829879283905
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.9085608124732971,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.8039144277572632,
            "answer": "region",
            "hit": false
          },
          {
            "score": 0.7783992290496826,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.7621084451675415,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.7535892724990845,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.7478519082069397,
            "answer": "zones",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9085609018802643
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.8609452247619629,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.8051113486289978,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.7986746430397034,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7983119487762451,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.7895742654800415,
            "answer": "automobiles",
            "hit": false
          },
          {
            "score": 0.7863278985023499,
            "answer": "truck",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8609452843666077
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.8780219554901123,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.7985855937004089,
            "answer": "university",
            "hit": false
          },
          {
            "score": 0.7778695821762085,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.7703932523727417,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.7512426376342773,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7463853359222412,
            "answer": "professors",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8780220448970795
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8875032663345337,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7571791410446167,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.754187822341919,
            "answer": "committee",
            "hit": false
          },
          {
            "score": 0.7411925196647644,
            "answer": "advisors",
            "hit": false
          },
          {
            "score": 0.7407921552658081,
            "answer": "forums",
            "hit": false
          },
          {
            "score": 0.7403831481933594,
            "answer": "commissions",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8875032663345337
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.914330005645752,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.8338598608970642,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.8270092010498047,
            "answer": "clients",
            "hit": false
          },
          {
            "score": 0.8227505087852478,
            "answer": "suppliers",
            "hit": false
          },
          {
            "score": 0.8207105398178101,
            "answer": "subscribers",
            "hit": false
          },
          {
            "score": 0.8178687691688538,
            "answer": "stakeholders",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9143300652503967
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.8117562532424927,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.7782443165779114,
            "answer": "night",
            "hit": false
          },
          {
            "score": 0.7644520998001099,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7640218734741211,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7573791146278381,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7563800811767578,
            "answer": "evening",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8117562532424927
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.8449870944023132,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7882630825042725,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.7687174081802368,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.765945315361023,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.760244607925415,
            "answer": "murder",
            "hit": false
          },
          {
            "score": 0.7597885727882385,
            "answer": "suicide",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8449871242046356
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.9137389063835144,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.8145609498023987,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.7537238597869873,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.7461366653442383,
            "answer": "suppliers",
            "hit": false
          },
          {
            "score": 0.7425236105918884,
            "answer": "disciplines",
            "hit": false
          },
          {
            "score": 0.7418133616447449,
            "answer": "bureaucracy",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9137389063835144
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.8471093773841858,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.8361050486564636,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.831753671169281,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8069300055503845,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8064938187599182,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8052295446395874,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8471093773841858
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.863784909248352,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7928857803344727,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7903414368629456,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.787571132183075,
            "answer": "distinguishes",
            "hit": false
          },
          {
            "score": 0.7871218919754028,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.7861786484718323,
            "answer": "distinguishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8637849390506744
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8909599184989929,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7995738387107849,
            "answer": "directing",
            "hit": false
          },
          {
            "score": 0.7935661673545837,
            "answer": "directs",
            "hit": false
          },
          {
            "score": 0.7909545302391052,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7884302735328674,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7760228514671326,
            "answer": "chairman",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8909598886966705
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.8784070611000061,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.775004506111145,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.7690253257751465,
            "answer": "gatherings",
            "hit": false
          },
          {
            "score": 0.7602248787879944,
            "answer": "incidents",
            "hit": false
          },
          {
            "score": 0.7591879367828369,
            "answer": "occurrences",
            "hit": false
          },
          {
            "score": 0.7580046653747559,
            "answer": "festivals",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8784070611000061
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8996498584747314,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.8749029040336609,
            "answer": "instance",
            "hit": false
          },
          {
            "score": 0.7829899787902832,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.7616336345672607,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.7552645802497864,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7544419169425964,
            "answer": "illustrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8996498584747314
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.8088369369506836,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.7607842683792114,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.7597607374191284,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.7514210939407349,
            "answer": "realities",
            "hit": false
          },
          {
            "score": 0.7506171464920044,
            "answer": "evidenced",
            "hit": false
          },
          {
            "score": 0.7452684640884399,
            "answer": "likelihood",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8088369071483612
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.8560715913772583,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.7989915609359741,
            "answer": "colleague",
            "hit": false
          },
          {
            "score": 0.7975730299949646,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7941356897354126,
            "answer": "comrades",
            "hit": false
          },
          {
            "score": 0.7872850894927979,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7868977785110474,
            "answer": "niece",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8560715913772583
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.8235083818435669,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.8039359450340271,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7859898805618286,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.7654513716697693,
            "answer": "heavens",
            "hit": false
          },
          {
            "score": 0.7640664577484131,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7597835659980774,
            "answer": "christ",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8235083818435669
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8729368448257446,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.8385883569717407,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.7799376249313354,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7749119997024536,
            "answer": "authorities",
            "hit": false
          },
          {
            "score": 0.76740562915802,
            "answer": "governance",
            "hit": false
          },
          {
            "score": 0.7603417634963989,
            "answer": "legislators",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8729369044303894
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.8526652455329895,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.7737101912498474,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.7715814709663391,
            "answer": "minutes",
            "hit": false
          },
          {
            "score": 0.7693429589271545,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7574617266654968,
            "answer": "moments",
            "hit": false
          },
          {
            "score": 0.7558496594429016,
            "answer": "weeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8526652455329895
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.8579062819480896,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.8308181762695312,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7993322014808655,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.7918915748596191,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.788325846195221,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7757753133773804,
            "answer": "envisioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8579063415527344
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.8896263241767883,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.8033116459846497,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7768934369087219,
            "answer": "dialect",
            "hit": false
          },
          {
            "score": 0.760148286819458,
            "answer": "interpreter",
            "hit": false
          },
          {
            "score": 0.757459282875061,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.7528626918792725,
            "answer": "translations",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8896263837814331
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.8494666814804077,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7632128000259399,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.7559952139854431,
            "answer": "statutes",
            "hit": false
          },
          {
            "score": 0.7505334615707397,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7486975193023682,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.7396752238273621,
            "answer": "lawyer",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8494667112827301
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.9001653790473938,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7740447521209717,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7694565057754517,
            "answer": "participant",
            "hit": false
          },
          {
            "score": 0.7592020034790039,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7536856532096863,
            "answer": "supporter",
            "hit": false
          },
          {
            "score": 0.751350998878479,
            "answer": "affiliates",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9001653790473938
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8658525943756104,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.8332065343856812,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.8308967351913452,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7919899821281433,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.775147557258606,
            "answer": "hospitalized",
            "hit": false
          },
          {
            "score": 0.7740329504013062,
            "answer": "evenings",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8658526539802551
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.8407770395278931,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.8375170826911926,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.799372136592865,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7849926352500916,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7719876170158386,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7637913227081299,
            "answer": "dusk",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8407770097255707
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.8928064107894897,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7561818361282349,
            "answer": "apartment",
            "hit": false
          },
          {
            "score": 0.7430695295333862,
            "answer": "apartments",
            "hit": false
          },
          {
            "score": 0.7426207065582275,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.7420947551727295,
            "answer": "factories",
            "hit": false
          },
          {
            "score": 0.7403093576431274,
            "answer": "desk",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8928064703941345
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8892560601234436,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7709396481513977,
            "answer": "era",
            "hit": false
          },
          {
            "score": 0.7542498707771301,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.752434492111206,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.7523359060287476,
            "answer": "phases",
            "hit": false
          },
          {
            "score": 0.7488574981689453,
            "answer": "interval",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8892560601234436
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.901618242263794,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7703306674957275,
            "answer": "footballer",
            "hit": false
          },
          {
            "score": 0.7690398097038269,
            "answer": "teammates",
            "hit": false
          },
          {
            "score": 0.7684515118598938,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.7682917714118958,
            "answer": "midfielder",
            "hit": false
          },
          {
            "score": 0.7653957605361938,
            "answer": "gameplay",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.901618242263794
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8964757919311523,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.8030327558517456,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.7914260625839233,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.790342390537262,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.7778352499008179,
            "answer": "residents",
            "hit": false
          },
          {
            "score": 0.7755597233772278,
            "answer": "communities",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8964757919311523
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.894729495048523,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.8206108808517456,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.807509183883667,
            "answer": "difficulties",
            "hit": false
          },
          {
            "score": 0.7983943223953247,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.7909996509552002,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7846134901046753,
            "answer": "crises",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8947295546531677
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.9166958332061768,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.771129310131073,
            "answer": "shipments",
            "hit": false
          },
          {
            "score": 0.7704910039901733,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7694401741027832,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.767963171005249,
            "answer": "commodities",
            "hit": false
          },
          {
            "score": 0.7638435363769531,
            "answer": "marketed",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9166958928108215
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.8912268280982971,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.8041359186172485,
            "answer": "fuels",
            "hit": false
          },
          {
            "score": 0.7950245141983032,
            "answer": "nutrient",
            "hit": false
          },
          {
            "score": 0.7943171858787537,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.7927865982055664,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.7890719175338745,
            "answer": "commodities",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8912268877029419
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.8358138799667358,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.7862095832824707,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7646808624267578,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7600590586662292,
            "answer": "streams",
            "hit": false
          },
          {
            "score": 0.7590093612670898,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7576220035552979,
            "answer": "mountains",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8358138799667358
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8513864874839783,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7959558963775635,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7898690700531006,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.774272084236145,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.7609077095985413,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.7588889598846436,
            "answer": "street",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.851386547088623
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.9115179777145386,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7896775603294373,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7764013409614563,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.7687423229217529,
            "answer": "capacities",
            "hit": false
          },
          {
            "score": 0.7565783262252808,
            "answer": "positions",
            "hit": false
          },
          {
            "score": 0.7562810778617859,
            "answer": "tasks",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9115179777145386
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8494483828544617,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.841781735420227,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.8097419738769531,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.8064954876899719,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.7837749123573303,
            "answer": "biology",
            "hit": false
          },
          {
            "score": 0.7806825041770935,
            "answer": "physics",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8417817950248718
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.9234871864318848,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.8115633726119995,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.8101420998573303,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.8076834678649902,
            "answer": "remedy",
            "hit": false
          },
          {
            "score": 0.8002673983573914,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.8000019192695618,
            "answer": "solving",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9234871864318848
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8914492130279541,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.776878833770752,
            "answer": "tunes",
            "hit": false
          },
          {
            "score": 0.7685811519622803,
            "answer": "sung",
            "hit": false
          },
          {
            "score": 0.7660175561904907,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.761967658996582,
            "answer": "anthem",
            "hit": false
          },
          {
            "score": 0.7608640789985657,
            "answer": "sings",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8914492130279541
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.8510829210281372,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.790683388710022,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.7721184492111206,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.758583128452301,
            "answer": "avenues",
            "hit": false
          },
          {
            "score": 0.7573698163032532,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.7529160976409912,
            "answer": "alley",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8510829508304596
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.893823504447937,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.8021008968353271,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.795184314250946,
            "answer": "classmates",
            "hit": false
          },
          {
            "score": 0.7906172871589661,
            "answer": "pupils",
            "hit": false
          },
          {
            "score": 0.7886763215065002,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.787874698638916,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.893823504447937
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.9049083590507507,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.7593616843223572,
            "answer": "networks",
            "hit": false
          },
          {
            "score": 0.7494518756866455,
            "answer": "systemic",
            "hit": false
          },
          {
            "score": 0.7476342916488647,
            "answer": "network",
            "hit": false
          },
          {
            "score": 0.747255802154541,
            "answer": "setup",
            "hit": false
          },
          {
            "score": 0.7370734810829163,
            "answer": "methods",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9049083590507507
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.8180869221687317,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.7455123066902161,
            "answer": "creatures",
            "hit": false
          },
          {
            "score": 0.7455106973648071,
            "answer": "creature",
            "hit": false
          },
          {
            "score": 0.7451701164245605,
            "answer": "stuff",
            "hit": false
          },
          {
            "score": 0.7412184476852417,
            "answer": "entities",
            "hit": false
          },
          {
            "score": 0.7361593246459961,
            "answer": "horrors",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8180869221687317
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8649348616600037,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.8070908784866333,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.8009441494941711,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7699849605560303,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7648621797561646,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.7474062442779541,
            "answer": "communities",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8649348616600037
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.9155490398406982,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.796374499797821,
            "answer": "stakeholders",
            "hit": false
          },
          {
            "score": 0.7961800694465637,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.795532763004303,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.7908879518508911,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7908235788345337,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9155490696430206
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.9349855780601501,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.8083372116088867,
            "answer": "variant",
            "hit": false
          },
          {
            "score": 0.8047170639038086,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.7948884963989258,
            "answer": "rendition",
            "hit": false
          },
          {
            "score": 0.7916858196258545,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.783656895160675,
            "answer": "edition",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9349856078624725
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.8818135857582092,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8328994512557983,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.7804425358772278,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7776947021484375,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.774297297000885,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.7709537148475647,
            "answer": "settlements",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8818135857582092
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.9213465452194214,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.827883780002594,
            "answer": "blog",
            "hit": false
          },
          {
            "score": 0.8134114742279053,
            "answer": "blogs",
            "hit": false
          },
          {
            "score": 0.8093648552894592,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.8008955121040344,
            "answer": "blogger",
            "hit": false
          },
          {
            "score": 0.7970311641693115,
            "answer": "podcast",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9213465452194214
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.8719654083251953,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.8465309143066406,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.8049004077911377,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.8005712032318115,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7942319512367249,
            "answer": "weekends",
            "hit": false
          },
          {
            "score": 0.7904191613197327,
            "answer": "semester",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8719654381275177
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.8421947956085205,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.8250937461853027,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.8089945316314697,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7971593737602234,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7919297814369202,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7801677584648132,
            "answer": "season",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8421947360038757
      }
    ],
    "result": {
      "cnt_questions_correct": 49,
      "cnt_questions_total": 50,
      "accuracy": 0.98
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5fd11055-a270-4859-90a4-591c209d1a2f",
      "timestamp": "2025-05-18T12:24:34.875671"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.9105966687202454,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.8613786101341248,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.8289475440979004,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.8274250030517578,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.818533182144165,
            "answer": "willingness",
            "hit": false
          },
          {
            "score": 0.8155595064163208,
            "answer": "capability",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9105966985225677
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8921862244606018,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.8037729859352112,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.8004384636878967,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.7910772562026978,
            "answer": "exercising",
            "hit": false
          },
          {
            "score": 0.7868643999099731,
            "answer": "activism",
            "hit": false
          },
          {
            "score": 0.7848479747772217,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8921862840652466
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.9132689237594604,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7887437343597412,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.7755324244499207,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.7748956680297852,
            "answer": "entities",
            "hit": false
          },
          {
            "score": 0.7714215517044067,
            "answer": "contractors",
            "hit": false
          },
          {
            "score": 0.77020263671875,
            "answer": "organizations",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9132689833641052
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.9185259342193604,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.8738348484039307,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.8651676177978516,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.8637018203735352,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.8515877723693848,
            "answer": "analysts",
            "hit": false
          },
          {
            "score": 0.8445672988891602,
            "answer": "analytical",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9185259640216827
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8707270622253418,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.8100987672805786,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.8012803792953491,
            "answer": "navy",
            "hit": false
          },
          {
            "score": 0.7939075827598572,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7819188237190247,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7702906727790833,
            "answer": "forces",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8707270622253418
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.8240909576416016,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.8081854581832886,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7828434705734253,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7791963815689087,
            "answer": "legitimacy",
            "hit": false
          },
          {
            "score": 0.7762392163276672,
            "answer": "jurisdictions",
            "hit": false
          },
          {
            "score": 0.7677447199821472,
            "answer": "empowered",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.824090987443924
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7808039784431458,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.7765297889709473,
            "answer": "incomes",
            "hit": false
          },
          {
            "score": 0.7731515765190125,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.7726061344146729,
            "answer": "illnesses",
            "hit": false
          },
          {
            "score": 0.7650555372238159,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7650070786476135,
            "answer": "bases",
            "hit": true
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7650071382522583
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.8360124826431274,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7601152658462524,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.7494201064109802,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7382858395576477,
            "answer": "merchants",
            "hit": false
          },
          {
            "score": 0.7372058629989624,
            "answer": "factories",
            "hit": false
          },
          {
            "score": 0.7350890636444092,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.836012452840805
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.9048340320587158,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.8084051012992859,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.8029998540878296,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.7788273096084595,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.7757755517959595,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.7754863500595093,
            "answer": "disciplines",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9048340916633606
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.8735829591751099,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.8127614259719849,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.8012483716011047,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7908406257629395,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.757169246673584,
            "answer": "generations",
            "hit": false
          },
          {
            "score": 0.7521767616271973,
            "answer": "psychologists",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8735829889774323
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.8226146101951599,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.7773869037628174,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7732510566711426,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.7729430198669434,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7683936357498169,
            "answer": "adolescents",
            "hit": false
          },
          {
            "score": 0.7682734727859497,
            "answer": "kids",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8226146101951599
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8571322560310364,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.8207305669784546,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7847383618354797,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.770391583442688,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7446680068969727,
            "answer": "municipal",
            "hit": false
          },
          {
            "score": 0.7445613145828247,
            "answer": "urban",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571322560310364
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.9091813564300537,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7728676795959473,
            "answer": "communal",
            "hit": false
          },
          {
            "score": 0.7708472609519958,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7687746286392212,
            "answer": "neighborhood",
            "hit": false
          },
          {
            "score": 0.7635841369628906,
            "answer": "neighbourhood",
            "hit": false
          },
          {
            "score": 0.7600977420806885,
            "answer": "ecosystems",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9091813266277313
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.803863525390625,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.7808613181114197,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.7544209957122803,
            "answer": "countryside",
            "hit": false
          },
          {
            "score": 0.7495334148406982,
            "answer": "valleys",
            "hit": false
          },
          {
            "score": 0.7430635094642639,
            "answer": "homeland",
            "hit": false
          },
          {
            "score": 0.7412957549095154,
            "answer": "regions",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8038635849952698
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8830763697624207,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7738692760467529,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7626672983169556,
            "answer": "jurisdictions",
            "hit": false
          },
          {
            "score": 0.7605620622634888,
            "answer": "valleys",
            "hit": false
          },
          {
            "score": 0.760395348072052,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7570174336433411,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8830763697624207
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.8556983470916748,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.8012338876724243,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.8003581166267395,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7981643080711365,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7773779630661011,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.7682510018348694,
            "answer": "contractual",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556983470916748
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.8929552435874939,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.8193600177764893,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.8178165555000305,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.8107378482818604,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.8091306686401367,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.8001813888549805,
            "answer": "economics",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8929552435874939
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8736656904220581,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.8046865463256836,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.7716046571731567,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.7659180164337158,
            "answer": "infused",
            "hit": false
          },
          {
            "score": 0.7643209099769592,
            "answer": "pulses",
            "hit": false
          },
          {
            "score": 0.763069748878479,
            "answer": "fuels",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8736656904220581
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.8881975412368774,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.8208579421043396,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.792904257774353,
            "answer": "enters",
            "hit": false
          },
          {
            "score": 0.7871469855308533,
            "answer": "entering",
            "hit": false
          },
          {
            "score": 0.7837327718734741,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.7803913354873657,
            "answer": "enter",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8881976008415222
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.8938969373703003,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.8094805479049683,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.805793285369873,
            "answer": "accommodations",
            "hit": false
          },
          {
            "score": 0.8041257262229919,
            "answer": "complexes",
            "hit": false
          },
          {
            "score": 0.8017493486404419,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8014246225357056,
            "answer": "upgrades",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8938969969749451
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.8493120074272156,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7733480930328369,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.7603738903999329,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.7470837831497192,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.743248701095581,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.7429702281951904,
            "answer": "brothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8493120670318604
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8499209880828857,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.8027669191360474,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.7878510355949402,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7877083420753479,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7519736289978027,
            "answer": "geography",
            "hit": false
          },
          {
            "score": 0.7461189031600952,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8499210476875305
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.8632983565330505,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.7913529872894287,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.7898377180099487,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.7896087765693665,
            "answer": "factories",
            "hit": false
          },
          {
            "score": 0.7791789174079895,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7790223360061646,
            "answer": "professions",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8632984161376953
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.9075191617012024,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.8022953867912292,
            "answer": "archives",
            "hit": false
          },
          {
            "score": 0.7863853573799133,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.785595178604126,
            "answer": "museums",
            "hit": false
          },
          {
            "score": 0.7830374240875244,
            "answer": "archive",
            "hit": false
          },
          {
            "score": 0.7777520418167114,
            "answer": "stacks",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9075191617012024
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.8137120008468628,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.7385382652282715,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.7332289218902588,
            "answer": "lifespan",
            "hit": false
          },
          {
            "score": 0.7318217754364014,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7292853593826294,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.7210915684700012,
            "answer": "lifelong",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.813711941242218
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8660980463027954,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.8281481266021729,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8073168992996216,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.807222306728363,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7835917472839355,
            "answer": "defeats",
            "hit": false
          },
          {
            "score": 0.7709815502166748,
            "answer": "destroys",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8660980463027954
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.8705717921257019,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.8017110824584961,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7946551442146301,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7837393283843994,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.7681164741516113,
            "answer": "forgetting",
            "hit": false
          },
          {
            "score": 0.7654732465744019,
            "answer": "cognition",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8705718219280243
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8966786861419678,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.7938020825386047,
            "answer": "initiatives",
            "hit": false
          },
          {
            "score": 0.7846850156784058,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.7764509916305542,
            "answer": "chance",
            "hit": false
          },
          {
            "score": 0.7759100794792175,
            "answer": "outset",
            "hit": false
          },
          {
            "score": 0.7755753397941589,
            "answer": "undertake",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8966787159442902
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.9222135543823242,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7995886206626892,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.7907417416572571,
            "answer": "initiatives",
            "hit": false
          },
          {
            "score": 0.7856121063232422,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7839049696922302,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.7837055921554565,
            "answer": "ideology",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.922213613986969
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.8703430891036987,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7715125679969788,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.7682414054870605,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.7641090750694275,
            "answer": "possessions",
            "hit": false
          },
          {
            "score": 0.7630957365036011,
            "answer": "premises",
            "hit": false
          },
          {
            "score": 0.7618997693061829,
            "answer": "belongings",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8703431785106659
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8806246519088745,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.8175641298294067,
            "answer": "accountable",
            "hit": false
          },
          {
            "score": 0.8047933578491211,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.8047091960906982,
            "answer": "liability",
            "hit": false
          },
          {
            "score": 0.8029489517211914,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.8023779392242432,
            "answer": "obligation",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8806247115135193
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7658030986785889,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7642810344696045,
            "answer": "verification",
            "hit": false
          },
          {
            "score": 0.7636699676513672,
            "answer": "authentication",
            "hit": false
          },
          {
            "score": 0.7603985071182251,
            "answer": "surveillance",
            "hit": false
          },
          {
            "score": 0.7586745023727417,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.7568719983100891,
            "answer": "reliability",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7396978884935379
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.7543396949768066,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.7455923557281494,
            "answer": "sequences",
            "hit": false
          },
          {
            "score": 0.7307642102241516,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.730507493019104,
            "answer": "programmes",
            "hit": false
          },
          {
            "score": 0.7303465604782104,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.7261931300163269,
            "answer": "programs",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9712208211421967
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8700987100601196,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.7927374839782715,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7528334259986877,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.7524582147598267,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.7488553524017334,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.7444421648979187,
            "answer": "institutions",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870098739862442
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.7882704138755798,
            "answer": "breeds",
            "hit": false
          },
          {
            "score": 0.7864402532577515,
            "answer": "specimens",
            "hit": false
          },
          {
            "score": 0.7856178283691406,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.7855225801467896,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.7854270935058594,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.7830299139022827,
            "answer": "populations",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9751645922660828
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.9019137024879456,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7963181734085083,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.789543092250824,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7838823199272156,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7799385786056519,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.7709625363349915,
            "answer": "storytelling",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9019137024879456
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.9178754687309265,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.8387399911880493,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.8162508010864258,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.8157151937484741,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.8073239326477051,
            "answer": "aggressively",
            "hit": false
          },
          {
            "score": 0.8066917657852173,
            "answer": "policies",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9178755283355713
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.8945138454437256,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.8239175081253052,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.8054332733154297,
            "answer": "victories",
            "hit": false
          },
          {
            "score": 0.8011692762374878,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7962008118629456,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7810519933700562,
            "answer": "succeed",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8945138454437256
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.9074528217315674,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8709850311279297,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7938804626464844,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.7930337190628052,
            "answer": "technicians",
            "hit": false
          },
          {
            "score": 0.7929630279541016,
            "answer": "techniques",
            "hit": false
          },
          {
            "score": 0.7920388579368591,
            "answer": "tech",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9074528515338898
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8999208211898804,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.8280776143074036,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.821540117263794,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7955002784729004,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.7931998372077942,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.7883663177490234,
            "answer": "ideology",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8999208807945251
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.8608559966087341,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7955180406570435,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7945691347122192,
            "answer": "college",
            "hit": false
          },
          {
            "score": 0.7654708623886108,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.7638760209083557,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.7585264444351196,
            "answer": "professors",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8608559966087341
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8610773682594299,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7885251045227051,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.7833596467971802,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.7749680876731873,
            "answer": "variability",
            "hit": false
          },
          {
            "score": 0.7711566686630249,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.7695844769477844,
            "answer": "variants",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8610774278640747
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.8631138801574707,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.8401154279708862,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.8271004557609558,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.8192760348320007,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.8042981624603271,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.8011130690574646,
            "answer": "widow",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631138801574707
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.8451944589614868,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.8301044702529907,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.8197211027145386,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.7874718904495239,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.7774122357368469,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7766373157501221,
            "answer": "ladies",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8451945185661316
      }
    ],
    "result": {
      "cnt_questions_correct": 40,
      "cnt_questions_total": 44,
      "accuracy": 0.9090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e11c6208-47d6-41c3-ae82-f684f3021e76",
      "timestamp": "2025-05-18T12:24:35.072535"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8774793148040771,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.8543821573257446,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.8070183992385864,
            "answer": "poorer",
            "hit": false
          },
          {
            "score": 0.8019759654998779,
            "answer": "thicker",
            "hit": false
          },
          {
            "score": 0.800909161567688,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.8003511428833008,
            "answer": "smarter",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8774793148040771
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.8531779050827026,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.821537435054779,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.8023418188095093,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7884261608123779,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.7860345840454102,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7851078510284424,
            "answer": "delighted",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8531779050827026
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.8736253976821899,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.8251043558120728,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.8054965734481812,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7848066687583923,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.7811639904975891,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.7798538208007812,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8736254572868347
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.8817623257637024,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.8585612773895264,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.8413488268852234,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.83906489610672,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.8162165880203247,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.8126223683357239,
            "answer": "weakening",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8817623257637024
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "cd2d1a7c-e730-4e04-bfdc-4e5d7cd6db43",
      "timestamp": "2025-05-18T12:24:35.251845"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.812778890132904,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7706691026687622,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7419068813323975,
            "answer": "heated",
            "hit": false
          },
          {
            "score": 0.7388370037078857,
            "answer": "richest",
            "hit": false
          },
          {
            "score": 0.7374981641769409,
            "answer": "easiest",
            "hit": false
          },
          {
            "score": 0.735743522644043,
            "answer": "fastest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8127789497375488
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.8206748962402344,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.8038774728775024,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7794839143753052,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.7625978589057922,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.7608562707901001,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7532798051834106,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8206748962402344
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 2,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c3fcb543-fd31-40b5-8202-75b4b2d53c2a",
      "timestamp": "2025-05-18T12:24:35.265666"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.9234368801116943,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.9057958126068115,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.876467764377594,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8310962915420532,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.8127188086509705,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.8106387257575989,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9234369099140167
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8885223865509033,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8592523336410522,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.8319207429885864,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7959039211273193,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7850539088249207,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.7698245048522949,
            "answer": "expands",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8885224163532257
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.9179573655128479,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8950050473213196,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8672022819519043,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.8445781469345093,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.833899736404419,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8068468570709229,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9179573655128479
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9409241676330566,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.9113622903823853,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8765349984169006,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8630882501602173,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8550228476524353,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8438385725021362,
            "answer": "enable",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.940924197435379
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9440295100212097,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.9095134139060974,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8986024856567383,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.8230595588684082,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8212630152702332,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.82041335105896,
            "answer": "seem",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9440295696258545
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9471078515052795,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.9225059151649475,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8852113485336304,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8286005854606628,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8094112873077393,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8062250018119812,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9471078217029572
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.9011303186416626,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8629329204559326,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8623651266098022,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7837505340576172,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7730339169502258,
            "answer": "requests",
            "hit": false
          },
          {
            "score": 0.7642119526863098,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9011303186416626
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.9138298630714417,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.9097222089767456,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.9064366817474365,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8320066928863525,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.830487847328186,
            "answer": "evade",
            "hit": false
          },
          {
            "score": 0.8240169286727905,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9138299226760864
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.9009412527084351,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8769011497497559,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8705061674118042,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7582864761352539,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.757144033908844,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7530025243759155,
            "answer": "emerges",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9009412527084351
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.9132381677627563,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8684024214744568,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.8670257925987244,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7931254506111145,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7919706702232361,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7894880175590515,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9132382869720459
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.9127553701400757,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8441669940948486,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.8247050046920776,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.8018637299537659,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.798444926738739,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7976070642471313,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9127554297447205
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9280991554260254,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8909673690795898,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8610039353370667,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8280988931655884,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8096119165420532,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8048593401908875,
            "answer": "utilizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9280991554260254
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.9169536828994751,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8923927545547485,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8821191787719727,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8206683397293091,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.820026159286499,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8180984258651733,
            "answer": "possesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9169537127017975
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9482232928276062,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.895047664642334,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8841084837913513,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8170025944709778,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.811908483505249,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.8100639581680298,
            "answer": "begins",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.948223352432251
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9328854084014893,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.9269148111343384,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8788694739341736,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8527324795722961,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8373346924781799,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8236156702041626,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9328854382038116
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9223084449768066,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.9048696160316467,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8557000756263733,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.8475639820098877,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.830314040184021,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8182726502418518,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9223084449768066
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.9397135972976685,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.907549262046814,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8857198357582092,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8280618786811829,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8275641202926636,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8252550363540649,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9397135972976685
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.9312318563461304,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.9018509387969971,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.896303653717041,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.870410680770874,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.866108775138855,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8599434494972229,
            "answer": "allows",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9312319159507751
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.9256664514541626,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.9128265380859375,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.9042572975158691,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8321952819824219,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8225070238113403,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8103870749473572,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9256665110588074
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.9363072514533997,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.9260692596435547,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.907856285572052,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.8447017669677734,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8419265747070312,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.8304739594459534,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9363072216510773
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.9452345371246338,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.8975812196731567,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.8090198040008545,
            "answer": "possesses",
            "hit": false
          },
          {
            "score": 0.8023867607116699,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8013500571250916,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.7953878045082092,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9452345371246338
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.9131907224655151,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8894882202148438,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8882840871810913,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8518571257591248,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.8457356095314026,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.8139970302581787,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9131907224655151
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.9010762572288513,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.88624107837677,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.8066723346710205,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7773628830909729,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7630925178527832,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7624019980430603,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9010762870311737
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9122003316879272,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8875725269317627,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8381174802780151,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.831052839756012,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8285477161407471,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8068501949310303,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.912200391292572
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8705136179924011,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.8647156357765198,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.829604983329773,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7838387489318848,
            "answer": "audible",
            "hit": false
          },
          {
            "score": 0.7799153327941895,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.7746904492378235,
            "answer": "understands",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8647156655788422
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.9435323476791382,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.9255455732345581,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8969721794128418,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8555985689163208,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8391101360321045,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.8298815488815308,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.943532407283783
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9335064888000488,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.9301560521125793,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8833352327346802,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8541395664215088,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8521128296852112,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.849777102470398,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9335064888000488
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.9158196449279785,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.8782334923744202,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.8047432899475098,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7916258573532104,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7911068201065063,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7896261215209961,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9158196449279785
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9386016130447388,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8896101713180542,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8427262306213379,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.840348482131958,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.838255763053894,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8307218551635742,
            "answer": "engages",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9386016130447388
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.9257210493087769,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.8755216598510742,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.869090735912323,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.8489402532577515,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.8208727836608887,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.8168432712554932,
            "answer": "teaches",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9257209897041321
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.935851514339447,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.9318904280662537,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.913708508014679,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8469467759132385,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.8318718671798706,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8284671306610107,
            "answer": "asserts",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9318904876708984
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9469847083091736,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.9089249968528748,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8847126364707947,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.837090253829956,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.8364130258560181,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8330457806587219,
            "answer": "occurrences",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9469847083091736
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.9446856379508972,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.9037647247314453,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.8638840913772583,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.831585168838501,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8254324197769165,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8208114504814148,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9446855783462524
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.9338469505310059,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.9280235767364502,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.9044592380523682,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8508272171020508,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.8449406027793884,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8443746566772461,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9338470101356506
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9514271020889282,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.9346587657928467,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8747210502624512,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8412402272224426,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8324671983718872,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8299106955528259,
            "answer": "promotion",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9514271318912506
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.9249931573867798,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.9115301370620728,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.8575466871261597,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.8334483504295349,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.8308098316192627,
            "answer": "defend",
            "hit": false
          },
          {
            "score": 0.8271898031234741,
            "answer": "safeguard",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9249932169914246
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9545065760612488,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.9252270460128784,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8909482955932617,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8384130001068115,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8163267374038696,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.8117090463638306,
            "answer": "furnished",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9545064568519592
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9351247549057007,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8982229232788086,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.891515851020813,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8151611089706421,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8119168877601624,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.8098433017730713,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9351247847080231
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9497001767158508,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.9216136932373047,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8855176568031311,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8708901405334473,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.8625533580780029,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.853193998336792,
            "answer": "reduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.949700117111206
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.9076424837112427,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8698024749755859,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8658009767532349,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8080484867095947,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8080219030380249,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.8071721792221069,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9076425731182098
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.9036560654640198,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8880434036254883,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8280102014541626,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.8205730319023132,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.8195080161094666,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.8164308667182922,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8880434632301331
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.8925263285636902,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.8638573884963989,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.8631564378738403,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.817161500453949,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.8135645389556885,
            "answer": "recalls",
            "hit": false
          },
          {
            "score": 0.8024990558624268,
            "answer": "recalling",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.892526388168335
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.9455305337905884,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.9107096791267395,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.9033792018890381,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8211075067520142,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.8163098096847534,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.8140174150466919,
            "answer": "representation",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9455305635929108
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9472543001174927,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.9142359495162964,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8647090196609497,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.835921049118042,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8342249393463135,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.829433262348175,
            "answer": "requirement",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9472543001174927
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.9214264154434204,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8951716423034668,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8400155305862427,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.8305449485778809,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8099786639213562,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7849771976470947,
            "answer": "emerges",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9214264154434204
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.9256434440612793,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.9054895043373108,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8727380037307739,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.8189432621002197,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7809358835220337,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.777626633644104,
            "answer": "brings",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9256434440612793
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.9125946760177612,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8792026042938232,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8668531775474548,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.8319131731987,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.8246576189994812,
            "answer": "recommends",
            "hit": false
          },
          {
            "score": 0.8210539221763611,
            "answer": "implies",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9125946760177612
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8832873702049255,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8503377437591553,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8437865376472473,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7757351994514465,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7543982863426208,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7475846409797668,
            "answer": "tel",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8832874000072479
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8943331241607666,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8920211791992188,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8259527683258057,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8122990727424622,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7922141551971436,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7910391688346863,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8943331241607666
      }
    ],
    "result": {
      "cnt_questions_correct": 46,
      "cnt_questions_total": 49,
      "accuracy": 0.9387755102040817
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2f68f43b-e33e-4bdd-8bdf-d9f15e7f67a5",
      "timestamp": "2025-05-18T12:24:35.273056"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9342910647392273,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.9026538729667664,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8541968464851379,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.8489378690719604,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.847010612487793,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.8337196707725525,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9342910647392273
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.8698675632476807,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.8547119498252869,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.8295047283172607,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.785237193107605,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7581984996795654,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.753094494342804,
            "answer": "enhancement",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8698675632476807
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.9291279911994934,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.9041958451271057,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8816403150558472,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.851790726184845,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8352530002593994,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.8343257904052734,
            "answer": "enable",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9291279911994934
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.9252917170524597,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.9098526239395142,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.9042582511901855,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8144676685333252,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.8075038194656372,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.8059000372886658,
            "answer": "seem",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9252917170524597
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.9348908066749573,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.9214533567428589,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8891783356666565,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8215778470039368,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8112335205078125,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.8044047951698303,
            "answer": "implementing",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9348908066749573
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.8786832094192505,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.86252361536026,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8600324392318726,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7633457779884338,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7613605260848999,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7552099227905273,
            "answer": "requests",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8786832690238953
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.9305993914604187,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8973492980003357,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.8006336688995361,
            "answer": "tending",
            "hit": false
          },
          {
            "score": 0.7999019026756287,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7917927503585815,
            "answer": "witnessing",
            "hit": false
          },
          {
            "score": 0.7840296030044556,
            "answer": "enroll",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9305993318557739
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.9170148372650146,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.9057847261428833,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.8932890892028809,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.8284740447998047,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8179193735122681,
            "answer": "evade",
            "hit": false
          },
          {
            "score": 0.8000827431678772,
            "answer": "discourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9170148074626923
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8997542858123779,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8610721826553345,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8536173105239868,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7639443278312683,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.736420750617981,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7337732315063477,
            "answer": "acquiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8997543454170227
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8820234537124634,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8776044845581055,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.8673390746116638,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7853364944458008,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7775996923446655,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7706496119499207,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8776044845581055
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.8865979909896851,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8559232950210571,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.8344895839691162,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.7964031100273132,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7947229743003845,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7895947694778442,
            "answer": "assessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8344895839691162
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8968995809555054,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8957730531692505,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8855257630348206,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8069955110549927,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8019517660140991,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7987169027328491,
            "answer": "incorporating",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8968995213508606
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.9168370366096497,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.9084786176681519,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.8995646238327026,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8151277303695679,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7971578240394592,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7945953011512756,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9084786772727966
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.9509327411651611,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.904631495475769,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8843938708305359,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8212426900863647,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.821221113204956,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8193303346633911,
            "answer": "generate",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9509327411651611
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.9319032430648804,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.9128758311271667,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8858844041824341,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8288178443908691,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8205715417861938,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.8177576661109924,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.931903213262558
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.9133944511413574,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8914295434951782,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8794161081314087,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8661608695983887,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8521910905838013,
            "answer": "stimulate",
            "hit": false
          },
          {
            "score": 0.8485984802246094,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8914295434951782
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.9205501079559326,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.9122495651245117,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.905229926109314,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8329827189445496,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8158327341079712,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8079268336296082,
            "answer": "experiencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.920550137758255
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.9402680397033691,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.9155107736587524,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.9026138782501221,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.8351986408233643,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.81632000207901,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.8153756856918335,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9402680397033691
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.9457924962043762,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.9099780321121216,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8778205513954163,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.8371742367744446,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8277405500411987,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.8219836950302124,
            "answer": "initiating",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9457924962043762
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.9198625683784485,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.8927589058876038,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7978739142417908,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7968185544013977,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.7857180833816528,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7833197116851807,
            "answer": "existent",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7968185245990753
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.8661047220230103,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8610005378723145,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.8279992341995239,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.7883261442184448,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7798886299133301,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7745629549026489,
            "answer": "predicting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8610005378723145
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.8830924034118652,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.869622528553009,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.8360005021095276,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.751384973526001,
            "answer": "trailing",
            "hit": false
          },
          {
            "score": 0.749424397945404,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7470206022262573,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8360005617141724
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8852778077125549,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8794345259666443,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8573974370956421,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.8181233406066895,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8133041858673096,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7900741100311279,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8573974370956421
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.9360383749008179,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.9210790395736694,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8974153995513916,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8573125600814819,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8398862481117249,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.816038966178894,
            "answer": "acknowledging",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9360383450984955
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.9463204741477966,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.9121152758598328,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8876926302909851,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8525098562240601,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8474860787391663,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8471300005912781,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.946320503950119
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.8837776780128479,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.8804032206535339,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.8327584266662598,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.7813591957092285,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7796080112457275,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7777005434036255,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8327584564685822
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.9051340818405151,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.895462155342102,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.8484395742416382,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.8345128893852234,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.8234078288078308,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.8137626051902771,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8954621851444244
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.8986263275146484,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.8772330284118652,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8751686811447144,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.863964319229126,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.8021620512008667,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7922115921974182,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8751687109470367
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.9001078009605408,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8988791704177856,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.8375712037086487,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.8011767864227295,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7897997498512268,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7740370035171509,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8988792300224304
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9487860798835754,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.9131942391395569,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.9067201018333435,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8244420289993286,
            "answer": "retaining",
            "hit": false
          },
          {
            "score": 0.8232153654098511,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.8230842351913452,
            "answer": "sustaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9487860798835754
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.908801794052124,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.9032674431800842,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.8983791470527649,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8100994229316711,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7971806526184082,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.7921485304832458,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9032673835754395
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.9165721535682678,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.9039780497550964,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.892204225063324,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.8172210454940796,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.8068205118179321,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8058435320854187,
            "answer": "utilizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8922042548656464
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.9279305934906006,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.9176552295684814,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.9068588018417358,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.818657398223877,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8173032999038696,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8100072741508484,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9279305934906006
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.9383386373519897,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.9086724519729614,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8969987630844116,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8408451676368713,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8238100409507751,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.819151759147644,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9383386373519897
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9516419172286987,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.9293150901794434,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8754665851593018,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8384959697723389,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.8304075598716736,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.8276233673095703,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9516419172286987
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.9235297441482544,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.9007012248039246,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.8606533408164978,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.824644148349762,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.8237966299057007,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.8214905261993408,
            "answer": "defend",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9235298037528992
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.9477874040603638,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.921230673789978,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8944836854934692,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8415780663490295,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8020482063293457,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8004591464996338,
            "answer": "furnished",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9477874636650085
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.9219995141029358,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.9094672799110413,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8944762945175171,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8057029843330383,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.8050965070724487,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.8034915924072266,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9219995141029358
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.9385901689529419,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.9274505376815796,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8898076415061951,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8594684600830078,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8532965183258057,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8483248353004456,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9385901987552643
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8801911473274231,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.8757540583610535,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.862459659576416,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8094436526298523,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.8010258078575134,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8008104562759399,
            "answer": "describing",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8801911473274231
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.9011145830154419,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8680130839347839,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8489122986793518,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.8114991784095764,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.8063943386077881,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.805754542350769,
            "answer": "stays",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489122986793518
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.8685280084609985,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.866432249546051,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.8607303500175476,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.8143154382705688,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.8042833805084229,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.7887808084487915,
            "answer": "recalls",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8685280680656433
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.9250389933586121,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.9183146357536316,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.9053218364715576,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8175411820411682,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.806930661201477,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.8045737743377686,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9250389337539673
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.9276032447814941,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.9213235974311829,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8727697730064392,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8348630666732788,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8238919973373413,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.8162064552307129,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9276033341884613
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8893493413925171,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8862358331680298,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8497801423072815,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.8034413456916809,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.792670488357544,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7913592457771301,
            "answer": "appearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8497801721096039
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.8493574261665344,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.8435038328170776,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.8150080442428589,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.7634688019752502,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.741938591003418,
            "answer": "standing",
            "hit": false
          },
          {
            "score": 0.7366460561752319,
            "answer": "suspend",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8493574559688568
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.9129098653793335,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.9074777960777283,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8854166269302368,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8014706373214722,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7937958836555481,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7865462303161621,
            "answer": "investing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9129098653793335
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8981600999832153,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8855434656143188,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8737825751304626,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8063114881515503,
            "answer": "instructors",
            "hit": false
          },
          {
            "score": 0.7976220846176147,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7944391965866089,
            "answer": "educators",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8737825751304626
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.8573572635650635,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.8417829871177673,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8350602984428406,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7466962933540344,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.742550790309906,
            "answer": "tel",
            "hit": false
          },
          {
            "score": 0.7380194664001465,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8573573231697083
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8870483636856079,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8704917430877686,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8265314698219299,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.8196328282356262,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7849206924438477,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7798672914505005,
            "answer": "misunderstood",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8265314698219299
      }
    ],
    "result": {
      "cnt_questions_correct": 32,
      "cnt_questions_total": 50,
      "accuracy": 0.64
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "27fb1318-257f-461e-b1af-bf91dbf46b62",
      "timestamp": "2025-05-18T12:24:35.461258"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.9003766179084778,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8832988739013672,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8746467232704163,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8139780759811401,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.780033528804779,
            "answer": "rejected",
            "hit": false
          },
          {
            "score": 0.7734330892562866,
            "answer": "reject",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9003766179084778
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.9231180548667908,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.903353214263916,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8533247709274292,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.8418946266174316,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.834822416305542,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.8113913536071777,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9231181144714355
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8566161394119263,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8368642330169678,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.8336636424064636,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7651903629302979,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7413274049758911,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.728496253490448,
            "answer": "elaborated",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8566161394119263
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8899103403091431,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8743782043457031,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8740406632423401,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8160890936851501,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8066133856773376,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7926965951919556,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8899104595184326
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9037550687789917,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8897667527198792,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8869070410728455,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8445720672607422,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8122497797012329,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8035545349121094,
            "answer": "enable",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9037551283836365
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9080832004547119,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8927574157714844,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.887287974357605,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8451998233795166,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8382563591003418,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8213122487068176,
            "answer": "disclosed",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8927574157714844
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9213809967041016,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.9041438698768616,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8849378824234009,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7966598272323608,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7898330092430115,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7680410146713257,
            "answer": "appearances",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9213809967041016
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9085291028022766,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.908380389213562,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.9033465385437012,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8060681819915771,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.8006303906440735,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7814557552337646,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9085290729999542
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8842823505401611,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8397740721702576,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8369647860527039,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7444890737533569,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7395241856575012,
            "answer": "questioned",
            "hit": false
          },
          {
            "score": 0.7276109457015991,
            "answer": "requested",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8842824101448059
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.9127070307731628,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.9031457304954529,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.7723087072372437,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7686692476272583,
            "answer": "visited",
            "hit": false
          },
          {
            "score": 0.7685170769691467,
            "answer": "tending",
            "hit": false
          },
          {
            "score": 0.7683162689208984,
            "answer": "participated",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9127070307731628
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8679280877113342,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8545026779174805,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8294327259063721,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7725650668144226,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.7346560955047607,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7093888521194458,
            "answer": "created",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.867928147315979
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8799088597297668,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8590939044952393,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8312697410583496,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7555360794067383,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7431960105895996,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.7366441488265991,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8799088597297668
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8778485059738159,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8634523153305054,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8020322918891907,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7761085033416748,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7698314785957336,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.7621856927871704,
            "answer": "consideration",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8778483867645264
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9231357574462891,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.9077959060668945,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8777421116828918,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7865406274795532,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7796807289123535,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.7730736136436462,
            "answer": "persisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9231358170509338
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.9192723631858826,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.9122279286384583,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8833152055740356,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.803156852722168,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7927084565162659,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7902730703353882,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.919272392988205
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.893069863319397,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8773652911186218,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8572986721992493,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8045766353607178,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8018045425415039,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7914086580276489,
            "answer": "determining",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8930698335170746
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8820558786392212,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8793106079101562,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8787880539894104,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8207405209541321,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8044960498809814,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.7872146368026733,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8793106079101562
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.9198343753814697,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.9068008661270142,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8992347121238708,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8168051242828369,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8024025559425354,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.8006985187530518,
            "answer": "evolving",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9198344349861145
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.8739343881607056,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.8665154576301575,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.842644214630127,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.807171106338501,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.8048586845397949,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.784885048866272,
            "answer": "uncover",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8739343881607056
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.9213637709617615,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.8856936693191528,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8843352198600769,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8085488677024841,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7866960763931274,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7741472721099854,
            "answer": "appreciated",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9213637709617615
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.9112577438354492,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.9000753164291382,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.8986167907714844,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8159067630767822,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.7969710826873779,
            "answer": "guarantee",
            "hit": false
          },
          {
            "score": 0.7948009967803955,
            "answer": "guarantees",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9000752866268158
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.9169001579284668,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.9136285185813904,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8914076089859009,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8154028654098511,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.8094375133514404,
            "answer": "asserted",
            "hit": false
          },
          {
            "score": 0.8088837265968323,
            "answer": "founded",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9136285185813904
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.850253701210022,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8425571322441101,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8295693397521973,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7662498354911804,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.7617597579956055,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7556101083755493,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.850253701210022
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.904219388961792,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8576823472976685,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.814981997013092,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7245702743530273,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7226489782333374,
            "answer": "pursued",
            "hit": false
          },
          {
            "score": 0.7131540775299072,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.904219388961792
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8965301513671875,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8160392642021179,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.815980076789856,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.757668137550354,
            "answer": "audible",
            "hit": false
          },
          {
            "score": 0.7405221462249756,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7266438007354736,
            "answer": "sounded",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8965302109718323
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.9160569906234741,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.9057837724685669,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.9031155705451965,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8436094522476196,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8228933215141296,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7932350635528564,
            "answer": "differentiated",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9160569906234741
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.9223678112030029,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.9021716117858887,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8984681367874146,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8467862606048584,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8401111364364624,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8318103551864624,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9021716117858887
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.9073854684829712,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.8649001717567444,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.807931661605835,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7436609268188477,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.742260217666626,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.74085533618927,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9073854684829712
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9285672307014465,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.9099704027175903,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.9083207845687866,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8453843593597412,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.7962386608123779,
            "answer": "implemented",
            "hit": false
          },
          {
            "score": 0.7946051359176636,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9285672605037689
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8975452184677124,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8775807023048401,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8712486624717712,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.8181071281433105,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.8107431530952454,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.7926293611526489,
            "answer": "utilized",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8712486326694489
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8979566097259521,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.8123317360877991,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7985883951187134,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.7978256940841675,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7944640517234802,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7935197353363037,
            "answer": "locations",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8123317658901215
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8803799748420715,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8696020841598511,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8661888241767883,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7839096784591675,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7774215340614319,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7483358383178711,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8661887645721436
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.9205952882766724,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8898206353187561,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8710207343101501,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.790626049041748,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7663224339485168,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7656551003456116,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9205952882766724
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8923547267913818,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8748154640197754,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8093318939208984,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7913468480110168,
            "answer": "wed",
            "hit": false
          },
          {
            "score": 0.7792063355445862,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.778532862663269,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8748154640197754
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9328847527503967,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8972980976104736,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8964494466781616,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7975261807441711,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7939431667327881,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7927166819572449,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9328847229480743
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9210145473480225,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.9119212031364441,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.9090847969055176,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8028287291526794,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7994087934494019,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.7872849702835083,
            "answer": "furnished",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9210146367549896
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.9155814051628113,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.8611646890640259,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8299058675765991,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8233423233032227,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8222029209136963,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.8133017420768738,
            "answer": "printed",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9155813753604889
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9267842173576355,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8880066275596619,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8868768215179443,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7795403003692627,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7716310024261475,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7647027969360352,
            "answer": "receipt",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9267842173576355
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.9102445840835571,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.9061566591262817,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.9000287055969238,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8472702503204346,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8365861177444458,
            "answer": "decreased",
            "hit": false
          },
          {
            "score": 0.8362613320350647,
            "answer": "decrease",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9000287055969238
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8697456121444702,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8689764142036438,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8461184501647949,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7783026099205017,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7735998034477234,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.770953357219696,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8689764142036438
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8846617937088013,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8503814935684204,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.8031067848205566,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7914297580718994,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7890219688415527,
            "answer": "summarized",
            "hit": false
          },
          {
            "score": 0.7889939546585083,
            "answer": "communicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7914298176765442
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.9168728590011597,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8586426377296448,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8226107954978943,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.8109359741210938,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7838083505630493,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.7757181525230408,
            "answer": "retained",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9168729186058044
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.9094042181968689,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8937489986419678,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.872319221496582,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8257917761802673,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.8001673221588135,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7884124517440796,
            "answer": "substituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9094042181968689
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.9100523591041565,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8938431143760681,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8905065059661865,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8094480633735657,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.8036589622497559,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7926822900772095,
            "answer": "needing",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8938430845737457
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8979454040527344,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8804619312286377,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.80792236328125,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.8012726902961731,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7911866307258606,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7860544919967651,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.897945374250412
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9023482203483582,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8844068050384521,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8773910999298096,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7933558225631714,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7546310424804688,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.7392251491546631,
            "answer": "transmitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9023481905460358
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.9066462516784668,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8870851993560791,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.8856992721557617,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.781242847442627,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7696532011032104,
            "answer": "wasted",
            "hit": false
          },
          {
            "score": 0.769484281539917,
            "answer": "expenditures",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9066462516784668
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8502784967422485,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8197985887527466,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8160882592201233,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.7244389057159424,
            "answer": "tel",
            "hit": false
          },
          {
            "score": 0.7049029469490051,
            "answer": "informed",
            "hit": false
          },
          {
            "score": 0.7002720832824707,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8502785265445709
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8962698578834534,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8392331600189209,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7941397428512573,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7883868217468262,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7591162323951721,
            "answer": "appreciated",
            "hit": false
          },
          {
            "score": 0.7546840906143188,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.896269828081131
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.7913960218429565,
            "answer": "merging",
            "hit": false
          },
          {
            "score": 0.7851473093032837,
            "answer": "empowered",
            "hit": false
          },
          {
            "score": 0.7846425175666809,
            "answer": "clustered",
            "hit": false
          },
          {
            "score": 0.7836931943893433,
            "answer": "united",
            "hit": true
          },
          {
            "score": 0.7833459973335266,
            "answer": "fused",
            "hit": false
          },
          {
            "score": 0.7832752466201782,
            "answer": "embracing",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.783693253993988
      }
    ],
    "result": {
      "cnt_questions_correct": 36,
      "cnt_questions_total": 50,
      "accuracy": 0.72
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "763df791-7921-4949-aa59-f9c977d6232c",
      "timestamp": "2025-05-18T12:24:35.655363"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.9187421202659607,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8611765503883362,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.8457012176513672,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.828993558883667,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.8258969187736511,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.8040276169776917,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9187421202659607
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9472923278808594,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8996063470840454,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8892430067062378,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.855696976184845,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8494526147842407,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8459011912345886,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9472924172878265
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9146044254302979,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.9006698131561279,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8961667418479919,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8165501952171326,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.8133425712585449,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.8118888139724731,
            "answer": "emerges",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9146043658256531
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9183352589607239,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.9143977761268616,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8755749464035034,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8284777998924255,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8245079517364502,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8167774677276611,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9183352589607239
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.9049944877624512,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8511075973510742,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8469952940940857,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.8062196969985962,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.8059167861938477,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7918754816055298,
            "answer": "invites",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9049944877624512
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.9039969444274902,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8734809756278992,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8696100115776062,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7715357542037964,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7711361646652222,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.7671123147010803,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9039969444274902
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.9080004692077637,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8526794910430908,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.8430840969085693,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.8256630301475525,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.8236109018325806,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.8199787735939026,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9080004692077637
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8517482876777649,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8230828046798706,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7861939072608948,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.781043529510498,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7808969020843506,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7802402973175049,
            "answer": "assessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8517483472824097
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9148794412612915,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8890657424926758,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8625710010528564,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8422375321388245,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8355941772460938,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.8353195190429688,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9148794412612915
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.9018439054489136,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8822181820869446,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8412883877754211,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8221684098243713,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8123711347579956,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7997065782546997,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9018439054489136
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9165558815002441,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8893386125564575,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8787606954574585,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8211115598678589,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.8131283521652222,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.806002676486969,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9165559113025665
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9328016638755798,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.9208154678344727,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.868400514125824,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8596077561378479,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8406389355659485,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8331544399261475,
            "answer": "generate",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9328016638755798
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8691117763519287,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.8159276247024536,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.8106652498245239,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.8093709945678711,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7997839450836182,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.7854273319244385,
            "answer": "focuses",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8691117763519287
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9386375546455383,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8900048136711121,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8641268014907837,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8556103110313416,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.8526730537414551,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8446369171142578,
            "answer": "defines",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9386375546455383
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.9147570133209229,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.9134259819984436,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8780248761177063,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8209108710289001,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.8147299885749817,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.8099133968353271,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9147570431232452
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.9204091429710388,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8799615502357483,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.8712456226348877,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.8708115816116333,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8499724268913269,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.8466703295707703,
            "answer": "uncover",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9204091429710388
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.913372278213501,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8968279361724854,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8867970108985901,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.8645963072776794,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.856853723526001,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8549872040748596,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.913372278213501
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.8104869723320007,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7978305816650391,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7974530458450317,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.780072033405304,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7704982757568359,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7684056162834167,
            "answer": "improves",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8104869723320007
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.9103031158447266,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8848912715911865,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8838872313499451,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.848090648651123,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.8457854390144348,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.8397661447525024,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9103031754493713
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8254325985908508,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.8146956562995911,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.8146687746047974,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7491400837898254,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7330207824707031,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.7309773564338684,
            "answer": "preceding",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8254325687885284
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8516672253608704,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8460915684700012,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8417257070541382,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8192130923271179,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8178144693374634,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8156928420066833,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8516672253608704
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8323285579681396,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8313336372375488,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.8061851263046265,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7955926656723022,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7699659466743469,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7645353078842163,
            "answer": "learns",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8323285579681396
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9295276403427124,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.9275091886520386,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8831958770751953,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8678058385848999,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8567068576812744,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8512483239173889,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9295276999473572
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8510195016860962,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.8277064561843872,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.794171929359436,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7834841012954712,
            "answer": "notably",
            "hit": false
          },
          {
            "score": 0.7615494728088379,
            "answer": "namely",
            "hit": false
          },
          {
            "score": 0.7526418566703796,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8510195016860962
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9026772975921631,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8813488483428955,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8181514739990234,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.8136972188949585,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8025473356246948,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.8019804954528809,
            "answer": "implicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9026773571968079
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8610738515853882,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.8584247827529907,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.8134970664978027,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.8134160041809082,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7896863222122192,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.778386652469635,
            "answer": "teaches",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8584247827529907
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.9039273858070374,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8777152895927429,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8120312690734863,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.8049147725105286,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7838301658630371,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.777696430683136,
            "answer": "destroys",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.903927356004715
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.9058653712272644,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.8841711282730103,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8546943068504333,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8183201551437378,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.8029070496559143,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7971388101577759,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9058653712272644
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9091026782989502,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8978925943374634,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8597484230995178,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8454124927520752,
            "answer": "occurrences",
            "hit": false
          },
          {
            "score": 0.8452219367027283,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.8305128812789917,
            "answer": "happens",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9091026484966278
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8872355818748474,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.881573498249054,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8553928136825562,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.8121634721755981,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7915820479393005,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.7840020060539246,
            "answer": "operations",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8872355222702026
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.921366810798645,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.9073547124862671,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8758020997047424,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8269705772399902,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8268444538116455,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8244497776031494,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9213668406009674
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9427574872970581,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.9326428174972534,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8682851791381836,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8591633439064026,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8405145406723022,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.838104248046875,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9427575469017029
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9562302231788635,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.9184372425079346,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8899588584899902,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8621675968170166,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8247621059417725,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.8233853578567505,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9562302231788635
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9110780358314514,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8996174335479736,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8609021306037903,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7976763248443604,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7969112396240234,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7946262359619141,
            "answer": "recipients",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9110780656337738
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9275456666946411,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.9197089672088623,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8738322854042053,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.8639500141143799,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8533383011817932,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8491000533103943,
            "answer": "reduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9275456666946411
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.9098705053329468,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8661772608757019,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8493354320526123,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8451560735702515,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.8226817846298218,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8226232528686523,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9098704755306244
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.9127938151359558,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8743738532066345,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8664547204971313,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8140549659729004,
            "answer": "compares",
            "hit": false
          },
          {
            "score": 0.8137156963348389,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8092866539955139,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9127938151359558
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8306231498718262,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8232078552246094,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8093200922012329,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7874981164932251,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.78396075963974,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.766930878162384,
            "answer": "stays",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8093201220035553
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.9279779195785522,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.9013317823410034,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.885945737361908,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8246899247169495,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.812158465385437,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.8019962310791016,
            "answer": "representation",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9279779195785522
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9227707982063293,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.9084856510162354,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.852107048034668,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.841171383857727,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8407703042030334,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.8376380205154419,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9227708280086517
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8636488914489746,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8459511995315552,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8330497145652771,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8294080495834351,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.8162439465522766,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8151235580444336,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8636488914489746
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8672724962234497,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.8319743871688843,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.8315576314926147,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.8066722750663757,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7737017869949341,
            "answer": "standing",
            "hit": false
          },
          {
            "score": 0.757156252861023,
            "answer": "rests",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8672724962234497
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8998887538909912,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.8978978991508484,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8310007452964783,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8280599117279053,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.8197286128997803,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7830653190612793,
            "answer": "utilizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8998887240886688
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.9115365743637085,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8865845203399658,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8706060647964478,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.8600937724113464,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.8533208966255188,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.8522147536277771,
            "answer": "implies",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9115366041660309
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8954429626464844,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8632622957229614,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8609568476676941,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8295403718948364,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.8024670481681824,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7981216907501221,
            "answer": "preaching",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8954429030418396
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.9053449034690857,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8443071842193604,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.8266164660453796,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8142847418785095,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.8119736313819885,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7921513319015503,
            "answer": "reminding",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9053449034690857
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8446028232574463,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8166547417640686,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8066043853759766,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.8000715970993042,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7817102074623108,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7768926620483398,
            "answer": "misunderstanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8446027934551239
      }
    ],
    "result": {
      "cnt_questions_correct": 45,
      "cnt_questions_total": 47,
      "accuracy": 0.9574468085106383
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8d13e983-40e4-4987-8ced-cc0ef3556730",
      "timestamp": "2025-05-18T12:24:35.847889"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.895869255065918,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8749833703041077,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.8371299505233765,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8087143301963806,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7710033655166626,
            "answer": "contributed",
            "hit": false
          },
          {
            "score": 0.7646154165267944,
            "answer": "elaborated",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8958692848682404
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8881078958511353,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8825621008872986,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8773847818374634,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8237086534500122,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8211908340454102,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.817952036857605,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8881079256534576
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9082025289535522,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8954274654388428,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8911965489387512,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8463599681854248,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.829603374004364,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8259702324867249,
            "answer": "enabling",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8911966383457184
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9085447192192078,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8953644633293152,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8805601596832275,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8448119163513184,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8427844047546387,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.817772626876831,
            "answer": "declares",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.89536452293396
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9145694971084595,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.884032130241394,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8728359937667847,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.798822283744812,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.784252405166626,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.7828363180160522,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9145694375038147
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9059799313545227,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.905591607093811,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8829714059829712,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8059936761856079,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7947854399681091,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7926088571548462,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9055916666984558
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8760354518890381,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8510760068893433,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8401123285293579,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7762467861175537,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7717920541763306,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7610920667648315,
            "answer": "questioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8760354816913605
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.905778706073761,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8947305083274841,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.7758750915527344,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.771359920501709,
            "answer": "enrolled",
            "hit": false
          },
          {
            "score": 0.7621411681175232,
            "answer": "tending",
            "hit": false
          },
          {
            "score": 0.7607899308204651,
            "answer": "attendance",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9057787656784058
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8785641193389893,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.876390814781189,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8439857959747314,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.734566867351532,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.7312933802604675,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7312427759170532,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.878564178943634
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8028420209884644,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.8016872406005859,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7935683727264404,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7562237977981567,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7452778220176697,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7425011992454529,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7935682833194733
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8630760908126831,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8605380058288574,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8538597226142883,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7916998863220215,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7581799626350403,
            "answer": "housed",
            "hit": false
          },
          {
            "score": 0.7561237812042236,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8538597226142883
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9017693400382996,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8703688979148865,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8686764240264893,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7983485460281372,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7799071073532104,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7662971019744873,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.901769369840622
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.9169090390205383,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.915875256061554,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8900336623191833,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8100178837776184,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.8058618307113647,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8032106757164001,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9169090688228607
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8691906332969666,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.865835428237915,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8492330312728882,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.83905428647995,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8005836009979248,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7992510795593262,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8691906332969666
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.911087155342102,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.890628457069397,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8836550712585449,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8517348170280457,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.8222244381904602,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.8095876574516296,
            "answer": "summarized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.890628457069397
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.9035414457321167,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.890906810760498,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8642050623893738,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8169177770614624,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7963062524795532,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.7871465086936951,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9035414457321167
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.9160162210464478,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8951883912086487,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8888916969299316,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8116415143013,
            "answer": "founded",
            "hit": false
          },
          {
            "score": 0.8091785907745361,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.807304322719574,
            "answer": "asserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8951883912086487
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7703090310096741,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.7586400508880615,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7534458041191101,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7475298643112183,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7449735403060913,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7314479947090149,
            "answer": "previous",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7703090012073517
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8358319401741028,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8350183367729187,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.831762433052063,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7823015451431274,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.754057765007019,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.747183084487915,
            "answer": "intending",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8358319103717804
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8649992346763611,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8207703828811646,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.8156248927116394,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8084388971328735,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.8031802177429199,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7700294852256775,
            "answer": "declining",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8649992346763611
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.816753089427948,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7866953611373901,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7649760246276855,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7558268904685974,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.6936514973640442,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.6841796040534973,
            "answer": "preceding",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8167531192302704
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8205883502960205,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8052423000335693,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7779946327209473,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7518360614776611,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7242187261581421,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7191104888916016,
            "answer": "audible",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8205884099006653
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.9085532426834106,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.9006685018539429,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8920656442642212,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8545069694519043,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8538758754730225,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.825998067855835,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9006685614585876
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8077223300933838,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7969285845756531,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7823289036750793,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7421104311943054,
            "answer": "notably",
            "hit": false
          },
          {
            "score": 0.7189422845840454,
            "answer": "namely",
            "hit": false
          },
          {
            "score": 0.7064619660377502,
            "answer": "especially",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8077223598957062
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9070176482200623,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.9067671298980713,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8920456767082214,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8410325646400452,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.7949768304824829,
            "answer": "introductory",
            "hit": false
          },
          {
            "score": 0.7881566286087036,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9067670702934265
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8589624762535095,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8533079624176025,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8040863275527954,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7913851737976074,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.7743121981620789,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.7732295989990234,
            "answer": "implicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8040863275527954
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8969829082489014,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.8190779685974121,
            "answer": "securely",
            "hit": false
          },
          {
            "score": 0.8190068006515503,
            "answer": "clustered",
            "hit": false
          },
          {
            "score": 0.8167555332183838,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.8159967660903931,
            "answer": "localized",
            "hit": false
          },
          {
            "score": 0.8159106969833374,
            "answer": "detecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8076875805854797
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8581852912902832,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8529379367828369,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8527481555938721,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7765422463417053,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7751070261001587,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7490973472595215,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8529379367828369
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8797787427902222,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8719662427902222,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8608068823814392,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7932759523391724,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7722152471542358,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7615913152694702,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8797787129878998
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.89501953125,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.8663918972015381,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.824791431427002,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7988280057907104,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.7961260080337524,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7915515899658203,
            "answer": "wed",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8663919568061829
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8489946126937866,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.8446031212806702,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8249835968017578,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7944815158843994,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7705693244934082,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7539007663726807,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489946722984314
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8938083648681641,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8879953622817993,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.866543173789978,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7960610389709473,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.795560896396637,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7953199148178101,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8938083648681641
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.9029437899589539,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.894638180732727,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8790132999420166,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8564897775650024,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8503009676933289,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8466181755065918,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8790133595466614
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9274168014526367,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.9192876815795898,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.9095253348350525,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8352833390235901,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8071696162223816,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.7901029586791992,
            "answer": "furnished",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9274168312549591
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8554927110671997,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.8405015468597412,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.8129788637161255,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8082284331321716,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8047850131988525,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.8040435910224915,
            "answer": "publisher",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8554928004741669
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8952556848526001,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8844552636146545,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8609269857406616,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7660137414932251,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7584093809127808,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7562530636787415,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8952556252479553
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.904634952545166,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8891243934631348,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8807807564735413,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8466897010803223,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8349795937538147,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8335570096969604,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8807807564735413
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8791002035140991,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8575883507728577,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8525748252868652,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8072113990783691,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7812310457229614,
            "answer": "detrimental",
            "hit": false
          },
          {
            "score": 0.7777862548828125,
            "answer": "correlated",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8072115182876587
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8181066513061523,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7997344732284546,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7630908489227295,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7535845637321472,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7484868764877319,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7439837455749512,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8181066513061523
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.9280487895011902,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8946940898895264,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.887715220451355,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7964088320732117,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.793205976486206,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.7774168848991394,
            "answer": "replacements",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9280487895011902
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.9089941382408142,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8947683572769165,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.8927488327026367,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7994110584259033,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7747942805290222,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.7679011225700378,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.908994197845459
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.9000421762466431,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8905714154243469,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8739044666290283,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8147569894790649,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8087520599365234,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.8051692247390747,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8739044070243835
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9079059958457947,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.9028846025466919,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.889397382736206,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8046571016311646,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7717599868774414,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.7588769197463989,
            "answer": "bringing",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9079060256481171
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8780784606933594,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8474653363227844,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8456101417541504,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.805557370185852,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7875547409057617,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7496970891952515,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8456101417541504
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8679020404815674,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8424952030181885,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8369128704071045,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.7729594707489014,
            "answer": "endured",
            "hit": false
          },
          {
            "score": 0.7673941850662231,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7596428394317627,
            "answer": "misery",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8679020404815674
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8527075052261353,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.8331706523895264,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8318442702293396,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7844928503036499,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7780466079711914,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7774282693862915,
            "answer": "teacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8527075052261353
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8695358633995056,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8624393939971924,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.827073872089386,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7760712504386902,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7537696361541748,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.750754714012146,
            "answer": "informed",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8695358633995056
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.811403751373291,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7873961925506592,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7802778482437134,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7668648958206177,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7425540685653687,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.7413809895515442,
            "answer": "appreciation",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8114037811756134
      }
    ],
    "result": {
      "cnt_questions_correct": 30,
      "cnt_questions_total": 48,
      "accuracy": 0.625
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "30eb0490-3852-461b-9cd9-ee16be6dfd3d",
      "timestamp": "2025-05-18T12:24:36.026489"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.9101722836494446,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8855860233306885,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.8496593832969666,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8272691369056702,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7855120897293091,
            "answer": "elaborated",
            "hit": false
          },
          {
            "score": 0.7834479808807373,
            "answer": "omitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9101722836494446
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.9037925004959106,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8826491236686707,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8748031854629517,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8193521499633789,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8037656545639038,
            "answer": "complied",
            "hit": false
          },
          {
            "score": 0.8035978078842163,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9037925004959106
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9047202467918396,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8983538746833801,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8976235389709473,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8491122722625732,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8426809310913086,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.813439130783081,
            "answer": "enabled",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9047203660011292
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8958604335784912,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8882696032524109,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8862425684928894,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8427603244781494,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8396643400192261,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8390034437179565,
            "answer": "announcement",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8958604037761688
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.913709282875061,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8926523923873901,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8577762842178345,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.793550968170166,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7747158408164978,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7649401426315308,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.913709282875061
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9089682698249817,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8922905325889587,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.87273108959198,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8095950484275818,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7824094295501709,
            "answer": "implemented",
            "hit": false
          },
          {
            "score": 0.7815529704093933,
            "answer": "application",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8922905921936035
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.9435206651687622,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8617230653762817,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8604809641838074,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8258203864097595,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.8006662130355835,
            "answer": "questioned",
            "hit": false
          },
          {
            "score": 0.786998450756073,
            "answer": "requested",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9435206949710846
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8942657709121704,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.877582311630249,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8637783527374268,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.752314567565918,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7489385604858398,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.739363431930542,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.894265741109848
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.9163899421691895,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8653097152709961,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.8594247698783875,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7982699871063232,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.795785665512085,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7880618572235107,
            "answer": "believers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9163899421691895
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8811855912208557,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.870448112487793,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.8099464178085327,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.8098753690719604,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.8020493984222412,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.799353301525116,
            "answer": "deemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8811855316162109
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9175557494163513,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.8823122978210449,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8614369630813599,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7799727916717529,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7777716517448425,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.760230302810669,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9175557494163513
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8677049875259399,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8632148504257202,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8464426398277283,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.788978636264801,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7613749504089355,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7593646049499512,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8677050471305847
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9238605499267578,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.902273416519165,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8743588924407959,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7808966636657715,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7778973579406738,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.7721071243286133,
            "answer": "persisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.923860639333725
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8959363698959351,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8910627365112305,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8846921324729919,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8095934391021729,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8048171997070312,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.8026788234710693,
            "answer": "crafted",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8846921622753143
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.9178251624107361,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8833642601966858,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8466818332672119,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8133713603019714,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8062224388122559,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.8019704818725586,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9178251624107361
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.9035128355026245,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.888165295124054,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8737620115280151,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8122354745864868,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7919033765792847,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.7890913486480713,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9035128653049469
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8974783420562744,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8947197198867798,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8797080516815186,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8160609006881714,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.809461236000061,
            "answer": "elaborated",
            "hit": false
          },
          {
            "score": 0.8069060444831848,
            "answer": "evolving",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8947197496891022
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.890824556350708,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8881468772888184,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8749422430992126,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8298011422157288,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8227336406707764,
            "answer": "asserted",
            "hit": false
          },
          {
            "score": 0.8223356604576111,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8749422132968903
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8783149719238281,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8404494524002075,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8356031179428101,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.8312320709228516,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.8265813589096069,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.807332456111908,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8783150017261505
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8850280046463013,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8651008605957031,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.839451789855957,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8249135613441467,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.8184630274772644,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7884365320205688,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8850280344486237
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.881492018699646,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8572219610214233,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7938061952590942,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.740303099155426,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7158937454223633,
            "answer": "pursued",
            "hit": false
          },
          {
            "score": 0.7110573053359985,
            "answer": "preceded",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.881492018699646
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.8990100622177124,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8653678894042969,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8037934899330139,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7779284119606018,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7733726501464844,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7729798555374146,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8990100920200348
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.854730486869812,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8142321109771729,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7899138927459717,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7600438594818115,
            "answer": "audible",
            "hit": false
          },
          {
            "score": 0.7498457431793213,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7475128173828125,
            "answer": "hearings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.854730486869812
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.9058154821395874,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.8736177682876587,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.8109056949615479,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7734577655792236,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7570918798446655,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7504599690437317,
            "answer": "featured",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9058155119419098
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8607537746429443,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.8530837297439575,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.8518463969230652,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.8237864971160889,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.8220288753509521,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.8173702955245972,
            "answer": "expects",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8607537150382996
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9070072770118713,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.9057766199111938,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8965847492218018,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.826796293258667,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.8049468994140625,
            "answer": "introductory",
            "hit": false
          },
          {
            "score": 0.7975329160690308,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9057765901088715
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8963429927825928,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8593224287033081,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8448717594146729,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7907392382621765,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.7791861295700073,
            "answer": "stakeholders",
            "hit": false
          },
          {
            "score": 0.7754374742507935,
            "answer": "involvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8448717594146729
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8879104256629944,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.879813015460968,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8735259771347046,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8231180310249329,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7885652184486389,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7848237752914429,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.879813015460968
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.9261791706085205,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8999683856964111,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8686615228652954,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7959727644920349,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7919596433639526,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.784365713596344,
            "answer": "administered",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9261791706085205
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.8987762331962585,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8958922028541565,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8620955348014832,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7863686680793762,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.7811511158943176,
            "answer": "occurrences",
            "hit": false
          },
          {
            "score": 0.7790146470069885,
            "answer": "happened",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8958922028541565
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.9085674285888672,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.8965480923652649,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.846264123916626,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7753182649612427,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.7731874585151672,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7727342844009399,
            "answer": "implemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9085675179958344
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9276902675628662,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.9068114161491394,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8865033984184265,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.813041090965271,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8103225231170654,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8074301481246948,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9276902973651886
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8920003175735474,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8914295434951782,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8855001926422119,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.835138201713562,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8289880752563477,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8164610862731934,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8920004069805145
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.924088716506958,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.9093683958053589,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.9048076868057251,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8028501868247986,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7969352006912231,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7947010397911072,
            "answer": "supplying",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.924088716506958
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9065626263618469,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8990578651428223,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8749555349349976,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7844222784042358,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7835021018981934,
            "answer": "obtained",
            "hit": false
          },
          {
            "score": 0.7819949984550476,
            "answer": "accepts",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9065626859664917
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8631822466850281,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.854283332824707,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.851963996887207,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7656722068786621,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7618019580841064,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7547789812088013,
            "answer": "referencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631822466850281
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8810062408447266,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8681289553642273,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.8169159293174744,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8074954748153687,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7955847382545471,
            "answer": "disclosed",
            "hit": false
          },
          {
            "score": 0.7930010557174683,
            "answer": "detrimental",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8074955344200134
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.851664662361145,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8335038423538208,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7694802284240723,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7427189350128174,
            "answer": "remnants",
            "hit": false
          },
          {
            "score": 0.7407917380332947,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7155498266220093,
            "answer": "stays",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8516646325588226
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.9079164862632751,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8912108540534973,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8741220235824585,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.827692985534668,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.822560727596283,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.8186753392219543,
            "answer": "replacement",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9079164862632751
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.9065104722976685,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.9051170349121094,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.8776346445083618,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7730923295021057,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.756759524345398,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.755645751953125,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9065105319023132
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.9046086072921753,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8991541862487793,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8708442449569702,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8112674951553345,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.8061826825141907,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7878432869911194,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8991541564464569
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.9120690226554871,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8745976686477661,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8079322576522827,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7942636013031006,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7843475937843323,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7690200209617615,
            "answer": "appear",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9120689928531647
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9038804769515991,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.9019231200218201,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8881023526191711,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8216715455055237,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7867134809494019,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.7752913236618042,
            "answer": "communicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9038804769515991
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8968953490257263,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8950028419494629,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8674298524856567,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.806383490562439,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7919958233833313,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.790287971496582,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8968953490257263
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.9090508222579956,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8623291254043579,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.8567729592323303,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8058153986930847,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.8022656440734863,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7897753715515137,
            "answer": "suggestions",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9090508222579956
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.9025784134864807,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8573340773582458,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.842179536819458,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8002767562866211,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.777623176574707,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7732280492782593,
            "answer": "informed",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9025783538818359
      }
    ],
    "result": {
      "cnt_questions_correct": 36,
      "cnt_questions_total": 46,
      "accuracy": 0.782608695652174
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7a61a883-7b64-44ad-bd26-64b44955cfc0",
      "timestamp": "2025-05-18T12:24:36.212512"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7613072395324707,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.6844599843025208,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.6768835783004761,
            "answer": "relentless",
            "hit": false
          },
          {
            "score": 0.6677932739257812,
            "answer": "brutal",
            "hit": false
          },
          {
            "score": 0.6671249866485596,
            "answer": "house",
            "hit": false
          },
          {
            "score": 0.6652964949607849,
            "answer": "aggressively",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 7531,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5943901389837265
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.8562542796134949,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.7636351585388184,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.763465940952301,
            "answer": "viruses",
            "hit": false
          },
          {
            "score": 0.7630320191383362,
            "answer": "detainees",
            "hit": false
          },
          {
            "score": 0.7560501098632812,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7500172853469849,
            "answer": "raped",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 937,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7190217673778534
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7f53346d-49d6-483e-a457-2ccc70f034c8",
      "timestamp": "2025-05-18T12:24:36.385738"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.861163318157196,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.8087323307991028,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.7944623231887817,
            "answer": "unwilling",
            "hit": false
          },
          {
            "score": 0.7935802936553955,
            "answer": "ability",
            "hit": false
          },
          {
            "score": 0.7893052697181702,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7874795794487,
            "answer": "enable",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.861163318157196
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.9097777605056763,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.8479689359664917,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.8299681544303894,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8282204270362854,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.8279014825820923,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.8243197202682495,
            "answer": "harmful",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.909777820110321
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8823547959327698,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.8637228012084961,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.8622455596923828,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.8557220697402954,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8497520685195923,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.8099699020385742,
            "answer": "susceptible",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8622456192970276
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8546002507209778,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.800084114074707,
            "answer": "availability",
            "hit": false
          },
          {
            "score": 0.7887400388717651,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.7832111716270447,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.7681193351745605,
            "answer": "unpublished",
            "hit": false
          },
          {
            "score": 0.7661064863204956,
            "answer": "inexpensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8546002507209778
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.8538757562637329,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.8058050870895386,
            "answer": "realizing",
            "hit": false
          },
          {
            "score": 0.8052192330360413,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.7976524829864502,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.7974520921707153,
            "answer": "acquainted",
            "hit": false
          },
          {
            "score": 0.7970444560050964,
            "answer": "realize",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8538757562637329
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7813819050788879,
            "answer": "sure",
            "hit": false
          },
          {
            "score": 0.7725546360015869,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.7640888690948486,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7612533569335938,
            "answer": "dubious",
            "hit": false
          },
          {
            "score": 0.7546281218528748,
            "answer": "questionable",
            "hit": false
          },
          {
            "score": 0.7535249590873718,
            "answer": "uncertain",
            "hit": true
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7535249888896942
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.8632761836051941,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.8536721467971802,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.8366823196411133,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.8341320753097534,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.812450647354126,
            "answer": "altering",
            "hit": false
          },
          {
            "score": 0.8033992648124695,
            "answer": "alteration",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7661758065223694
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8829865455627441,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.8433681130409241,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.8277899622917175,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.8250508308410645,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.809206485748291,
            "answer": "cozy",
            "hit": false
          },
          {
            "score": 0.808587908744812,
            "answer": "luxurious",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8829866051673889
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.838171660900116,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.8287987112998962,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.815476655960083,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.8103015422821045,
            "answer": "aware",
            "hit": false
          },
          {
            "score": 0.7984369397163391,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7972034215927124,
            "answer": "discomfort",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.815476655960083
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8941224217414856,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.8844653367996216,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.8795779347419739,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.8346939086914062,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.8316700458526611,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.8266584873199463,
            "answer": "utilizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8346938490867615
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.8613831400871277,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.843059778213501,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.8367932438850403,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8330086469650269,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.797359824180603,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7880805730819702,
            "answer": "expectation",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.782660186290741
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.8766250610351562,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.8580523729324341,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.8501714468002319,
            "answer": "finish",
            "hit": false
          },
          {
            "score": 0.821376621723175,
            "answer": "completed",
            "hit": false
          },
          {
            "score": 0.8011986017227173,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.7985678911209106,
            "answer": "completing",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8011985719203949
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8563613891601562,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.8260772228240967,
            "answer": "foolish",
            "hit": false
          },
          {
            "score": 0.8241353631019592,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.8211396336555481,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8192705512046814,
            "answer": "fortunately",
            "hit": false
          },
          {
            "score": 0.8182246685028076,
            "answer": "privileged",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.856361448764801
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.8629392981529236,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.8230677247047424,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.8050283193588257,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.794709324836731,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.7905429601669312,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7888097763061523,
            "answer": "delighted",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8629392683506012
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.9031946063041687,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8996967077255249,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.8945924639701843,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8436099886894226,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.8402213454246521,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8155245184898376,
            "answer": "implicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.815313994884491
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7649587392807007,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7616302967071533,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7578129172325134,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7561467289924622,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7555147409439087,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7554280757904053,
            "answer": "infamous",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7533513307571411
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8967688083648682,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.8413090109825134,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.8399710059165955,
            "answer": "illicit",
            "hit": false
          },
          {
            "score": 0.83732008934021,
            "answer": "harmful",
            "hit": false
          },
          {
            "score": 0.8362744450569153,
            "answer": "fraudulent",
            "hit": false
          },
          {
            "score": 0.8352116942405701,
            "answer": "unconstitutional",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8967688083648682
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.876416802406311,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.8456618189811707,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.8345226049423218,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.8341619372367859,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.801923394203186,
            "answer": "compensated",
            "hit": false
          },
          {
            "score": 0.7984218597412109,
            "answer": "payment",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8341619372367859
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.8682979345321655,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.8416908979415894,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8381139636039734,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8029364347457886,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.8019561767578125,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.8016484975814819,
            "answer": "pleasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8682979643344879
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.8310118913650513,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.8250036239624023,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7854015827178955,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.7829081416130066,
            "answer": "controversial",
            "hit": false
          },
          {
            "score": 0.7719501256942749,
            "answer": "prevalent",
            "hit": false
          },
          {
            "score": 0.7711312174797058,
            "answer": "iconic",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8310118615627289
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8810043334960938,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.8363345861434937,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.8331900238990784,
            "answer": "repetitive",
            "hit": false
          },
          {
            "score": 0.8287488222122192,
            "answer": "outdated",
            "hit": false
          },
          {
            "score": 0.8286218643188477,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.8272330164909363,
            "answer": "inevitably",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8810043931007385
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.8910007476806641,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.8464299440383911,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8424991965293884,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8369201421737671,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.8295910358428955,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8113091588020325,
            "answer": "reprinted",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8369201123714447
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8705958127975464,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.8492946624755859,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.8376243114471436,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.8252918720245361,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.8228546380996704,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.8203763365745544,
            "answer": "feasible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8705958127975464
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.8351395130157471,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.8202906250953674,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.8151914477348328,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8106876611709595,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7961068153381348,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7740383148193359,
            "answer": "associated",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8351395428180695
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.9062093496322632,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.8513051271438599,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.8448611497879028,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.8407081961631775,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.8400336503982544,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.8395043015480042,
            "answer": "inaccurate",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9062093198299408
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.8882508277893066,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8837018609046936,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.8534682989120483,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.8351595997810364,
            "answer": "specifications",
            "hit": false
          },
          {
            "score": 0.8343797326087952,
            "answer": "configured",
            "hit": false
          },
          {
            "score": 0.8339896202087402,
            "answer": "prescribed",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8534683287143707
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.9066336154937744,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.847601592540741,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.838654100894928,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.8073369860649109,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.8055594563484192,
            "answer": "disastrous",
            "hit": false
          },
          {
            "score": 0.8047741651535034,
            "answer": "success",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9066335558891296
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.8473566770553589,
            "answer": "use",
            "hit": false
          },
          {
            "score": 0.8369505405426025,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.8317703008651733,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.8189926743507385,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.8108040690422058,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.7989969849586487,
            "answer": "utilize",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7958821356296539
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.8230663537979126,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7701272964477539,
            "answer": "aforementioned",
            "hit": false
          },
          {
            "score": 0.7684053778648376,
            "answer": "commonplace",
            "hit": false
          },
          {
            "score": 0.7675199508666992,
            "answer": "predominant",
            "hit": false
          },
          {
            "score": 0.763780415058136,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7630519270896912,
            "answer": "prevalent",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 75,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7474539577960968
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.8717062473297119,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8446857333183289,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.8311527967453003,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.7970399856567383,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.7902066111564636,
            "answer": "desires",
            "hit": false
          },
          {
            "score": 0.7881168127059937,
            "answer": "desired",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7749099731445312
      }
    ],
    "result": {
      "cnt_questions_correct": 15,
      "cnt_questions_total": 30,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e9d038ec-7a14-4866-a0ee-338193db1844",
      "timestamp": "2025-05-18T12:24:36.396983"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7986599206924438,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.798507809638977,
            "answer": "pursuant",
            "hit": false
          },
          {
            "score": 0.7606725692749023,
            "answer": "adherence",
            "hit": false
          },
          {
            "score": 0.7586309909820557,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.7575536966323853,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7553669810295105,
            "answer": "adhere",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7494066953659058
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.8191030621528625,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.8005118370056152,
            "answer": "exceptionally",
            "hit": false
          },
          {
            "score": 0.7880865335464478,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.7856429219245911,
            "answer": "explicitly",
            "hit": false
          },
          {
            "score": 0.7831307053565979,
            "answer": "intentionally",
            "hit": false
          },
          {
            "score": 0.7825474739074707,
            "answer": "incredibly",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8191030621528625
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.8366838693618774,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.8011610507965088,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7975070476531982,
            "answer": "supplementary",
            "hit": false
          },
          {
            "score": 0.7919603586196899,
            "answer": "extra",
            "hit": false
          },
          {
            "score": 0.790866494178772,
            "answer": "alternatively",
            "hit": false
          },
          {
            "score": 0.7895334362983704,
            "answer": "adds",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8366839289665222
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.838681161403656,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8125270009040833,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.8044813275337219,
            "answer": "arguably",
            "hit": false
          },
          {
            "score": 0.8018108010292053,
            "answer": "allegedly",
            "hit": false
          },
          {
            "score": 0.80094313621521,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7994112968444824,
            "answer": "obvious",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7936263084411621
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.873102605342865,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8534201383590698,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.8371450304985046,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8179530501365662,
            "answer": "stunning",
            "hit": false
          },
          {
            "score": 0.8178226351737976,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.8112660646438599,
            "answer": "exquisite",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8534201979637146
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.8416281938552856,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.8066173791885376,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.7904296517372131,
            "answer": "criticisms",
            "hit": false
          },
          {
            "score": 0.779801070690155,
            "answer": "detrimental",
            "hit": false
          },
          {
            "score": 0.7747241258621216,
            "answer": "imperative",
            "hit": false
          },
          {
            "score": 0.7740734219551086,
            "answer": "criticism",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8416281938552856
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.8781446218490601,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.8260639309883118,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.803179144859314,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.8000937104225159,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7978746891021729,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7969071269035339,
            "answer": "culture",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8781447410583496
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8946388959884644,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8641715049743652,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8433657288551331,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7968855500221252,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.7927679419517517,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7909126281738281,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7642351686954498
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.8368607759475708,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.8039135932922363,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.7810617685317993,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.769124448299408,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7685728669166565,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.7677738666534424,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8368607461452484
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8745132684707642,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.8238763809204102,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.7832239270210266,
            "answer": "electronic",
            "hit": false
          },
          {
            "score": 0.778034508228302,
            "answer": "titanium",
            "hit": false
          },
          {
            "score": 0.7772797346115112,
            "answer": "analogue",
            "hit": false
          },
          {
            "score": 0.7771955728530884,
            "answer": "globally",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8745132684707642
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.8562257885932922,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.831291913986206,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.8276323080062866,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.8140009641647339,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.8128489851951599,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7924814224243164,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.856225848197937
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.864555299282074,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.8444327712059021,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.8231940865516663,
            "answer": "ecology",
            "hit": false
          },
          {
            "score": 0.8202847838401794,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.8193168044090271,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.8164552450180054,
            "answer": "ecosystems",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8645552694797516
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.8803110122680664,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.8457261323928833,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.8312993049621582,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.8233116865158081,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.8230659365653992,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.8212560415267944,
            "answer": "intricate",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8803109526634216
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.8575134873390198,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.8558582663536072,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.8484479188919067,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.8407107591629028,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.8170986175537109,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.8013530969619751,
            "answer": "iconic",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8484479188919067
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.8723479509353638,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.8383570909500122,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.8137162923812866,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.8060663342475891,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7957635521888733,
            "answer": "budgets",
            "hit": false
          },
          {
            "score": 0.7945744395256042,
            "answer": "financed",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8723479509353638
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8792609572410583,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.8251261711120605,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.8025418519973755,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.784942090511322,
            "answer": "universally",
            "hit": false
          },
          {
            "score": 0.7796404361724854,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.7776616215705872,
            "answer": "collectively",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8792610168457031
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.839372992515564,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.836419939994812,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.8129907846450806,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.8109265565872192,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.797249436378479,
            "answer": "histories",
            "hit": false
          },
          {
            "score": 0.7917322516441345,
            "answer": "culturally",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.839372992515564
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8815761804580688,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.8688421249389648,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.8486608862876892,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.8447641134262085,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.8408782482147217,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.8227102160453796,
            "answer": "tremendous",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.848660945892334
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.828171968460083,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.8108119964599609,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7975361347198486,
            "answer": "promptly",
            "hit": false
          },
          {
            "score": 0.7960797548294067,
            "answer": "urgently",
            "hit": false
          },
          {
            "score": 0.7881767749786377,
            "answer": "swiftly",
            "hit": false
          },
          {
            "score": 0.7856762409210205,
            "answer": "universally",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.828171968460083
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.8276543021202087,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.8149697184562683,
            "answer": "importance",
            "hit": false
          },
          {
            "score": 0.8015061616897583,
            "answer": "significant",
            "hit": false
          },
          {
            "score": 0.8010603785514832,
            "answer": "influential",
            "hit": false
          },
          {
            "score": 0.7889072895050049,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7867494225502014,
            "answer": "pivotal",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7844926714897156
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.8863455057144165,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8618230819702148,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.8558645844459534,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.8537126779556274,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.8498600721359253,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.84939044713974,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8498601317405701
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.8698351383209229,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.81827312707901,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.8167252540588379,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7816030383110046,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.7762171030044556,
            "answer": "inherently",
            "hit": false
          },
          {
            "score": 0.7724533081054688,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8698351085186005
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.8343114256858826,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7922672629356384,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.775215744972229,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7663778066635132,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.7537375688552856,
            "answer": "abroad",
            "hit": false
          },
          {
            "score": 0.747489333152771,
            "answer": "overseas",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.834311455488205
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.8463133573532104,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7972105741500854,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.784942626953125,
            "answer": "lawful",
            "hit": false
          },
          {
            "score": 0.7814054489135742,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7805973291397095,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.7789753079414368,
            "answer": "attorneys",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8463134467601776
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.8702283501625061,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.8128489255905151,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.7963003516197205,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.7881626486778259,
            "answer": "schizophrenia",
            "hit": false
          },
          {
            "score": 0.7874813675880432,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7873443365097046,
            "answer": "morally",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8702283799648285
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.8028093576431274,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.786159873008728,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.7807260155677795,
            "answer": "cute",
            "hit": false
          },
          {
            "score": 0.7771008014678955,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.763714075088501,
            "answer": "strangely",
            "hit": false
          },
          {
            "score": 0.7632119059562683,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8028094470500946
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.8373153209686279,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8261061310768127,
            "answer": "obviously",
            "hit": true
          },
          {
            "score": 0.8070502281188965,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.8019145727157593,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.797112226486206,
            "answer": "plainly",
            "hit": false
          },
          {
            "score": 0.7946250438690186,
            "answer": "evidently",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8261061310768127
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8933794498443604,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.7901187539100647,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.7869017124176025,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.775191605091095,
            "answer": "mechanically",
            "hit": false
          },
          {
            "score": 0.7733799815177917,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.7657647728919983,
            "answer": "forcibly",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8933793902397156
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.876907467842102,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.8353091478347778,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.8251160979270935,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.8202512264251709,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7989169359207153,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.7868931293487549,
            "answer": "ideology",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8769074976444244
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.8068386912345886,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.8053982853889465,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.7999966144561768,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.795462965965271,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.7954387068748474,
            "answer": "legally",
            "hit": false
          },
          {
            "score": 0.7949815988540649,
            "answer": "profoundly",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 999,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7490385472774506
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.848569393157959,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.8412569761276245,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.8234543800354004,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.8040057420730591,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.799593448638916,
            "answer": "predecessors",
            "hit": false
          },
          {
            "score": 0.7866013050079346,
            "answer": "beforehand",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8485693335533142
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.8274983763694763,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7995669841766357,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.787919819355011,
            "answer": "unusually",
            "hit": false
          },
          {
            "score": 0.7777643799781799,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.7727062106132507,
            "answer": "exceptionally",
            "hit": false
          },
          {
            "score": 0.7715306878089905,
            "answer": "commonplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7995669841766357
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.850319504737854,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.824529767036438,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7903625965118408,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.7883166670799255,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.7875927686691284,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7835503816604614,
            "answer": "sincere",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.850319504737854
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.9042075872421265,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.835627555847168,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.8287391066551208,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.8190518021583557,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.8162520527839661,
            "answer": "erotic",
            "hit": false
          },
          {
            "score": 0.8071720600128174,
            "answer": "emotionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9042075872421265
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.866936445236206,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.8612629175186157,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.843123197555542,
            "answer": "substantially",
            "hit": false
          },
          {
            "score": 0.8376086950302124,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.8332452178001404,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.8123509883880615,
            "answer": "noticeable",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.866936445236206
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.878659188747406,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.8558427095413208,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.8453242182731628,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.8096262812614441,
            "answer": "identical",
            "hit": false
          },
          {
            "score": 0.7960790395736694,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7850834131240845,
            "answer": "likewise",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8786592483520508
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.8366467952728271,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.8267055153846741,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.7979245185852051,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.7978241443634033,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7836087346076965,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7807542085647583,
            "answer": "strengthened",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8267055153846741
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8817126750946045,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.8618927001953125,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.8307139277458191,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.830159604549408,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.828942596912384,
            "answer": "consequently",
            "hit": false
          },
          {
            "score": 0.8208852410316467,
            "answer": "successive",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8817127048969269
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8732515573501587,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.8703964948654175,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.8351702690124512,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.8088086843490601,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.8033053278923035,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.8021668195724487,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8703964352607727
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.8656403422355652,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.8132693767547607,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7926278710365295,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7865909337997437,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.7827068567276001,
            "answer": "tradition",
            "hit": false
          },
          {
            "score": 0.7727459669113159,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8656403422355652
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.8361697196960449,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.8165401816368103,
            "answer": "characteristic",
            "hit": false
          },
          {
            "score": 0.7901595830917358,
            "answer": "reminiscent",
            "hit": false
          },
          {
            "score": 0.7877102494239807,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.7858811020851135,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.7844730615615845,
            "answer": "indicative",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8361697494983673
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.8593024611473083,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.8280291557312012,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.8046765327453613,
            "answer": "innovative",
            "hit": false
          },
          {
            "score": 0.7998620271682739,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.7966797351837158,
            "answer": "unprecedented",
            "hit": false
          },
          {
            "score": 0.7960869073867798,
            "answer": "exceptionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8593024909496307
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.8112773895263672,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.8093113899230957,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.7860318422317505,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7852085828781128,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.7850189805030823,
            "answer": "simulate",
            "hit": false
          },
          {
            "score": 0.7811154127120972,
            "answer": "electronically",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8093114197254181
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.854587197303772,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.7949494123458862,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.7720201015472412,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.770466148853302,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7687970399856567,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.7679856419563293,
            "answer": "presentations",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8545872271060944
      }
    ],
    "result": {
      "cnt_questions_correct": 30,
      "cnt_questions_total": 44,
      "accuracy": 0.6818181818181818
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "529c488e-e8b4-4d81-99c1-a7c3b630a6d0",
      "timestamp": "2025-05-18T12:24:36.502208"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.8216816186904907,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.8024437427520752,
            "answer": "realizing",
            "hit": false
          },
          {
            "score": 0.801238477230072,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.7980644106864929,
            "answer": "acquainted",
            "hit": false
          },
          {
            "score": 0.7913751006126404,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.7891040444374084,
            "answer": "realizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.801238477230072
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.8496072292327881,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.8381656408309937,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.8153314590454102,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7958484292030334,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.7892606258392334,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7835077047348022,
            "answer": "despair",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8496072292327881
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.8256071209907532,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.8148736953735352,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.8132246136665344,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.7939956784248352,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7831978797912598,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7802633047103882,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8256071507930756
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.8212553262710571,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.8179585337638855,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.8167107105255127,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.8067200183868408,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7984223365783691,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.7847734093666077,
            "answer": "delighted",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8167107105255127
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7617315053939819,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.7614196538925171,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.7569030523300171,
            "answer": "angered",
            "hit": false
          },
          {
            "score": 0.7528432607650757,
            "answer": "mania",
            "hit": false
          },
          {
            "score": 0.7486206293106079,
            "answer": "angry",
            "hit": false
          },
          {
            "score": 0.7468522787094116,
            "answer": "insanity",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7614196538925171
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.8271826505661011,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7979089021682739,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.7820436954498291,
            "answer": "sadly",
            "hit": false
          },
          {
            "score": 0.7793573141098022,
            "answer": "loneliness",
            "hit": false
          },
          {
            "score": 0.775585412979126,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7732855081558228,
            "answer": "optimism",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8271826505661011
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.8222061991691589,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.8025742769241333,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.786352813243866,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7709557414054871,
            "answer": "severity",
            "hit": false
          },
          {
            "score": 0.7663891315460205,
            "answer": "sincere",
            "hit": false
          },
          {
            "score": 0.7592886686325073,
            "answer": "solemn",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8222061991691589
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.8545991778373718,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.8410823941230774,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.8307402729988098,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.8287113308906555,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.8138960599899292,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.8096455335617065,
            "answer": "weaknesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8410823941230774
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 8,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9aa56908-d515-4a92-a5f3-ad46e6805a4f",
      "timestamp": "2025-05-18T12:24:36.668958"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8912323713302612,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8852766752243042,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.873404860496521,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8212360739707947,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.8040474653244019,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.798250675201416,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7676301598548889
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.9119738340377808,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8959736824035645,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.8513489961624146,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8483359217643738,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.8440675139427185,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.8357547521591187,
            "answer": "adapting",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8440675139427185
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.8322280049324036,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.7953138947486877,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7820982933044434,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7807204723358154,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7761943936347961,
            "answer": "cheaper",
            "hit": false
          },
          {
            "score": 0.7759910225868225,
            "answer": "furnished",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7953139245510101
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.8735470771789551,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8478800058364868,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.8075631856918335,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7879751920700073,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7845039963722229,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7830367088317871,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 1554,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7206464409828186
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.9040474891662598,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.8927768468856812,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8866159319877625,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8267783522605896,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.8238793015480042,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.8017189502716064,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8238792717456818
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.9110081791877747,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.9078899025917053,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8901393413543701,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8496032953262329,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.8410760164260864,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.8136909008026123,
            "answer": "recognizable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8496032953262329
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8833284378051758,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.8591793775558472,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.8535807728767395,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.8512782454490662,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.8208311796188354,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.8192054629325867,
            "answer": "predictable",
            "hit": true
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8192055225372314
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.9116977453231812,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.907180905342102,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8947162628173828,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8413782119750977,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.840264081954956,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.8390058279037476,
            "answer": "reliance",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 109,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7813836932182312
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8901310563087463,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.8652048110961914,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.8190693855285645,
            "answer": "repairing",
            "hit": false
          },
          {
            "score": 0.818253755569458,
            "answer": "revive",
            "hit": false
          },
          {
            "score": 0.8092164993286133,
            "answer": "vigorous",
            "hit": false
          },
          {
            "score": 0.8060235977172852,
            "answer": "markedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 515,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7752074003219604
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8904309272766113,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.8481982350349426,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.80791175365448,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8075466156005859,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8069101572036743,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.8045337200164795,
            "answer": "durable",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7935416400432587
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8795152306556702,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8352552652359009,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.8237527012825012,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8180392980575562,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.8174120187759399,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.8131915926933289,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7554580569267273
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "a8803835-9f8f-4ff6-83ac-e164f09300ea",
      "timestamp": "2025-05-18T12:24:36.694996"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.8706325888633728,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8539438247680664,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.8492729067802429,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.778919517993927,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7748797535896301,
            "answer": "believer",
            "hit": true
          },
          {
            "score": 0.770879328250885,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7748797535896301
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.9019508361816406,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.8618316054344177,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.83616703748703,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.8049749135971069,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.8044833540916443,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.8042481541633606,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.83616703748703
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.9002255201339722,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.8770999908447266,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.833275318145752,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.8306719064712524,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.8282840251922607,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.8217166662216187,
            "answer": "eats",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 107,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.794720470905304
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.8239543437957764,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8220556378364563,
            "answer": "assertion",
            "hit": false
          },
          {
            "score": 0.8142493963241577,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.8120284080505371,
            "answer": "adversary",
            "hit": false
          },
          {
            "score": 0.8088010549545288,
            "answer": "dismay",
            "hit": false
          },
          {
            "score": 0.8086141347885132,
            "answer": "asserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7953920960426331
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.889525294303894,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8834773302078247,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.8254245519638062,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.8192947506904602,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.813733696937561,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.8079825639724731,
            "answer": "defenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7963940501213074
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.9078859090805054,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.9041370749473572,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8776343464851379,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8381446599960327,
            "answer": "developer",
            "hit": true
          },
          {
            "score": 0.8201194405555725,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8127209544181824,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8381446301937103
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8874279856681824,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8774340152740479,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8771885633468628,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8407147526741028,
            "answer": "inspect",
            "hit": false
          },
          {
            "score": 0.8400089144706726,
            "answer": "inspected",
            "hit": false
          },
          {
            "score": 0.8284989595413208,
            "answer": "analyzing",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8055488467216492
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.9108531475067139,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.9069532752037048,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8803685307502747,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8543486595153809,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.8138206601142883,
            "answer": "textures",
            "hit": false
          },
          {
            "score": 0.8130447864532471,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 90,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7845093607902527
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.8742282390594482,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.86250901222229,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.8041027784347534,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7525014877319336,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.7425217628479004,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7310538291931152,
            "answer": "predictable",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7525014579296112
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8810986876487732,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.868118166923523,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.8659021854400635,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.8577888607978821,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.8414469957351685,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.7989410161972046,
            "answer": "translating",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8414469957351685
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.8706583976745605,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.8526185750961304,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.779849112033844,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.7593989968299866,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.744405210018158,
            "answer": "interpreter",
            "hit": false
          },
          {
            "score": 0.7374600768089294,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.779849112033844
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.893737256526947,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8736114501953125,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8301840424537659,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7948100566864014,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7894682884216309,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7538114786148071,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7526009678840637
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8927934169769287,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8865188360214233,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8702913522720337,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.8095946311950684,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.7890559434890747,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.7751825451850891,
            "answer": "administrator",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7890559732913971
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.9099169969558716,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8991888761520386,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8799558877944946,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8308766484260559,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.8240160346031189,
            "answer": "observers",
            "hit": false
          },
          {
            "score": 0.8177174925804138,
            "answer": "observation",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8119691610336304
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8959018588066101,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8738520741462708,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8692870140075684,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.8437041640281677,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.8419549465179443,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.8247374296188354,
            "answer": "arranging",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8692870140075684
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.9072695374488831,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8943869471549988,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8937950134277344,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8434544801712036,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.8292859792709351,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.8094407320022583,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8434544801712036
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8752334713935852,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.8328077793121338,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.815405011177063,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.810649573802948,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8075242042541504,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.806818425655365,
            "answer": "promoters",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8328078389167786
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.9238538146018982,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.9200865626335144,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8648380041122437,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8420438170433044,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.8251224756240845,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.8143022060394287,
            "answer": "promoters",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8136858940124512
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.9122705459594727,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.9095884561538696,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.881784975528717,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8208287358283997,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8088817596435547,
            "answer": "provider",
            "hit": true
          },
          {
            "score": 0.7943696975708008,
            "answer": "furnished",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8088817894458771
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8694436550140381,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.8623146414756775,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8622908592224121,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.8499603271484375,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8387274146080017,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.8327945470809937,
            "answer": "publications",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8622909188270569
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8957080841064453,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8905279040336609,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8824281692504883,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8158918619155884,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.8143699169158936,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7969282865524292,
            "answer": "receipt",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7761034369468689
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8809691667556763,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.8499535322189331,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.8340977430343628,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.8085581660270691,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.7767249345779419,
            "answer": "talk",
            "hit": false
          },
          {
            "score": 0.7718755602836609,
            "answer": "talked",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7582709193229675
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.885813295841217,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8694829344749451,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8464306592941284,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8135690093040466,
            "answer": "instructors",
            "hit": false
          },
          {
            "score": 0.8120039701461792,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.8094130158424377,
            "answer": "teacher",
            "hit": true
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8094130158424377
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8786266446113586,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.8674277663230896,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.8572178483009338,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.8370299935340881,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.8338388204574585,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.8121283650398254,
            "answer": "writers",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8370299935340881
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "76f553b0-d051-4074-87d3-6ab4e57360e9",
      "timestamp": "2025-05-18T12:24:36.731413"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8766111135482788,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8631770610809326,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.850752055644989,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.8488466143608093,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.8139356374740601,
            "answer": "assertion",
            "hit": false
          },
          {
            "score": 0.8095824718475342,
            "answer": "allegations",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.863177090883255
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8829492330551147,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.8486661911010742,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.7916820645332336,
            "answer": "appreciated",
            "hit": false
          },
          {
            "score": 0.7906078100204468,
            "answer": "appreciate",
            "hit": false
          },
          {
            "score": 0.7898669242858887,
            "answer": "appreciation",
            "hit": false
          },
          {
            "score": 0.7853484153747559,
            "answer": "dislike",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8486661911010742
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8355354070663452,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.8222847580909729,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.8176426887512207,
            "answer": "calculating",
            "hit": false
          },
          {
            "score": 0.8146160840988159,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8142670392990112,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.8083569407463074,
            "answer": "computing",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8355353474617004
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.9004628658294678,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.893370509147644,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8752688765525818,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8084542751312256,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7749795913696289,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7711402773857117,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8084542155265808
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.9010807275772095,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8900407552719116,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8683858513832092,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.8335593938827515,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.8104613423347473,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8102151155471802,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8335594534873962
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8833170533180237,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8744458556175232,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.820234477519989,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.8103514313697815,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8067958354949951,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8056355714797974,
            "answer": "deciding",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7986592352390289
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8889950513839722,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8807876110076904,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.879057765007019,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8438244462013245,
            "answer": "examination",
            "hit": true
          },
          {
            "score": 0.8380581140518188,
            "answer": "inspected",
            "hit": false
          },
          {
            "score": 0.8380389213562012,
            "answer": "inspect",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8438243865966797
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.9116191864013672,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.9079951047897339,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8739078044891357,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8709174394607544,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.81221604347229,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8097476363182068,
            "answer": "investigated",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8709174990653992
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.8215154409408569,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.8175985217094421,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.780964732170105,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.7650061845779419,
            "answer": "pictured",
            "hit": false
          },
          {
            "score": 0.7552070617675781,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7546722888946533,
            "answer": "suppose",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 248,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7112869322299957
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8665081262588501,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.8323724269866943,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.8174952268600464,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8101061582565308,
            "answer": "provoke",
            "hit": false
          },
          {
            "score": 0.8059923052787781,
            "answer": "stimulate",
            "hit": false
          },
          {
            "score": 0.8054840564727783,
            "answer": "inspiration",
            "hit": true
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8054840862751007
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.9126049280166626,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.897933840751648,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8798285126686096,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8382722735404968,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.8366540670394897,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.8122061491012573,
            "answer": "observers",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8382722437381744
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8619855642318726,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.851793110370636,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8341485261917114,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.7916203141212463,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.7806065678596497,
            "answer": "occupants",
            "hit": false
          },
          {
            "score": 0.7790195941925049,
            "answer": "occupations",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7916203141212463
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8905290365219116,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.874491810798645,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.841168999671936,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.8410727977752686,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.8219093084335327,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8199130296707153,
            "answer": "arrange",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7836147546768188
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.9029805064201355,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8883431553840637,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.8820405602455139,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.8622643351554871,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.8447568416595459,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7902953028678894,
            "answer": "readiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8820405304431915
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.9096680283546448,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8870492577552795,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.8733699321746826,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.8111492991447449,
            "answer": "revive",
            "hit": false
          },
          {
            "score": 0.80671626329422,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.8024631142616272,
            "answer": "rebuild",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8733699321746826
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8753573894500732,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.8668015003204346,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8419483304023743,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.819788932800293,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.819459080696106,
            "answer": "unstable",
            "hit": false
          },
          {
            "score": 0.8154332637786865,
            "answer": "instability",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8668015003204346
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 16,
      "accuracy": 0.0625
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b3ac5e16-5dd1-4564-9397-cf2a54a857ab",
      "timestamp": "2025-05-18T12:24:36.815219"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8776196241378784,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.8456531763076782,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.8315396308898926,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8304086923599243,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.8293973207473755,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.817306637763977,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8456532061100006
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.911549985408783,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.9014657735824585,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8508772850036621,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.8373637199401855,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.8326141834259033,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.8170122504234314,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8061195015907288
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.9151743054389954,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8915228843688965,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.8576017618179321,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.843295693397522,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.823400616645813,
            "answer": "adapting",
            "hit": false
          },
          {
            "score": 0.8170520067214966,
            "answer": "adjustable",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8576017916202545
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8808272480964661,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.87725830078125,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8657959699630737,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.817896842956543,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8170605897903442,
            "answer": "agreement",
            "hit": true
          },
          {
            "score": 0.7998344898223877,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8170606195926666
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.8685228824615479,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.8248565196990967,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.8072691559791565,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.8002162575721741,
            "answer": "positioned",
            "hit": false
          },
          {
            "score": 0.7970685958862305,
            "answer": "merging",
            "hit": false
          },
          {
            "score": 0.7959737777709961,
            "answer": "labeling",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8248565196990967
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8277702331542969,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.7982945442199707,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.7965847253799438,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7938508987426758,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7925189733505249,
            "answer": "modify",
            "hit": false
          },
          {
            "score": 0.7921857833862305,
            "answer": "altering",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 49,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7637855112552643
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.9110162258148193,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8873204588890076,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8657843470573425,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.862119197845459,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.8470930457115173,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8180978894233704,
            "answer": "declares",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8657843470573425
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8428003787994385,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.8209738731384277,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.8201920986175537,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.8157535791397095,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.8035061955451965,
            "answer": "granting",
            "hit": false
          },
          {
            "score": 0.8018834590911865,
            "answer": "install",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8201920390129089
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.9157424569129944,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.9016087651252747,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.844456672668457,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.8318862915039062,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.815919041633606,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.8088151216506958,
            "answer": "organize",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8318863213062286
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8874256610870361,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8656359910964966,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8651169538497925,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.8628965616226196,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.8542490601539612,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.8516361713409424,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8651170134544373
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8568216562271118,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.8516265153884888,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.821315348148346,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.8123096227645874,
            "answer": "attach",
            "hit": false
          },
          {
            "score": 0.8119938373565674,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.8078018426895142,
            "answer": "adjustment",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.821315348148346
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.8941793441772461,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.8779577612876892,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.8680732250213623,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.8351345062255859,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7683445811271667,
            "answer": "pledged",
            "hit": false
          },
          {
            "score": 0.7664593458175659,
            "answer": "commitments",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8351344466209412
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.908220112323761,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.9002693891525269,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8903555274009705,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8495230674743652,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.8123595714569092,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.8091869354248047,
            "answer": "evolving",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.84952312707901
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8694782257080078,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8528599143028259,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.8256084322929382,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8089467883110046,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8063367605209351,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8056029081344604,
            "answer": "skepticism",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8528599739074707
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8951393365859985,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8698970675468445,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8693745136260986,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.8490487933158875,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8393626809120178,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.8316476345062256,
            "answer": "stimulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8393626809120178
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8800209760665894,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.852912187576294,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.8332736492156982,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.809341549873352,
            "answer": "imposing",
            "hit": false
          },
          {
            "score": 0.8046894073486328,
            "answer": "implementing",
            "hit": false
          },
          {
            "score": 0.8010379076004028,
            "answer": "implemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8332736194133759
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.9051105380058289,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8979461193084717,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8633992671966553,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.8186558485031128,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.7790781855583191,
            "answer": "acknowledges",
            "hit": false
          },
          {
            "score": 0.7769051790237427,
            "answer": "involvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8186558187007904
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8903672099113464,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8768022656440735,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.8630950450897217,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.8417766690254211,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8403019309043884,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.83653724193573,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8768022656440735
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.8997359275817871,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.8817811012268066,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8791090846061707,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8211002945899963,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.7901658415794373,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7756853103637695,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8211003541946411
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8940138816833496,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.8692124485969543,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.8037065267562866,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7991446256637573,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7956348061561584,
            "answer": "amused",
            "hit": false
          },
          {
            "score": 0.7910850048065186,
            "answer": "exercising",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 267,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7679033875465393
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.9202072620391846,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8959149718284607,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.885304868221283,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.813200831413269,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.8085519671440125,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.8079348802566528,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.813200831413269
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.9021276831626892,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.8925380706787109,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.8637890815734863,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.8156024813652039,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.8105547428131104,
            "answer": "fills",
            "hit": false
          },
          {
            "score": 0.8100439310073853,
            "answer": "reiterated",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8637890815734863
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.9235410690307617,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8974160552024841,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8859198093414307,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8711195588111877,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.8501811623573303,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.830962598323822,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8711195886135101
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.8763856291770935,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.8585838675498962,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.8396360874176025,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.8161382675170898,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.8076489567756653,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.7940762639045715,
            "answer": "investors",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8161382675170898
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8927655220031738,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8676036596298218,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.852009654045105,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.8296394944190979,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.812965989112854,
            "answer": "implicated",
            "hit": false
          },
          {
            "score": 0.7874598503112793,
            "answer": "stakeholders",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8296394944190979
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8936988115310669,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8838819861412048,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8720245361328125,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7995059490203857,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.784893274307251,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.7743502259254456,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.784893274307251
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8645529747009277,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.8416807055473328,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.8102790117263794,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.8030050992965698,
            "answer": "torment",
            "hit": false
          },
          {
            "score": 0.7974728345870972,
            "answer": "offenses",
            "hit": false
          },
          {
            "score": 0.79688560962677,
            "answer": "disciplined",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8416807055473328
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.8651405572891235,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.8461761474609375,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.8429138660430908,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8427023887634277,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.8364492058753967,
            "answer": "reiterated",
            "hit": false
          },
          {
            "score": 0.8353435397148132,
            "answer": "strengthened",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8651405870914459
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.891744077205658,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8873398900032043,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.8726182579994202,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8476504683494568,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.8147990107536316,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7817361354827881,
            "answer": "substitution",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8476504683494568
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.9043937921524048,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8925365805625916,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.873063325881958,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8314676284790039,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.8126871585845947,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.8017305731773376,
            "answer": "needing",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8314676284790039
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 30,
      "accuracy": 0.03333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "730c0d98-5a20-4e99-971e-83f6fc8a530b",
      "timestamp": "2025-05-18T12:24:36.868430"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8621935844421387,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.8145445585250854,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.8060987591743469,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7995268702507019,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7961064577102661,
            "answer": "cyprus",
            "hit": false
          },
          {
            "score": 0.7945302724838257,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8621935248374939
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8632351756095886,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.8531962037086487,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8403918743133545,
            "answer": "kuwait",
            "hit": false
          },
          {
            "score": 0.8247758746147156,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8177527189254761,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.8121007084846497,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8632351756095886
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.8972104787826538,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8381021618843079,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.805979311466217,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8048474788665771,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8047485947608948,
            "answer": "myanmar",
            "hit": false
          },
          {
            "score": 0.804279088973999,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8972104489803314
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.8085874319076538,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.8043926358222961,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7988446950912476,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7971054911613464,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.7967263460159302,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7953280210494995,
            "answer": "shanghai",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8085874617099762
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.841107189655304,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7786018252372742,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7770475745201111,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7758254408836365,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7742867469787598,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7733860015869141,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.841107189655304
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7946416735649109,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.7667250037193298,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7605157494544983,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7604016065597534,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7523496747016907,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.751720666885376,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7946416735649109
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8766598701477051,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.8268880844116211,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.8019112348556519,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8016182780265808,
            "answer": "netherlands",
            "hit": false
          },
          {
            "score": 0.8014373779296875,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8010731935501099,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8766599297523499
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.8756390810012817,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.8482816815376282,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8434022068977356,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.818120002746582,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.8108120560646057,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.8092066049575806,
            "answer": "austria",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8756390511989594
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.8518791794776917,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8089122176170349,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8083000183105469,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.8028221726417542,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.801728367805481,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.8015984296798706,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8518791198730469
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8799715042114258,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8415473103523254,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8385603427886963,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8284129500389099,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.8172732591629028,
            "answer": "iceland",
            "hit": false
          },
          {
            "score": 0.8050215840339661,
            "answer": "bulgaria",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8799715042114258
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.8607131838798523,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8222637176513672,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8205795884132385,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.8179923295974731,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.8142303228378296,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8129322528839111,
            "answer": "bulgaria",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8607132434844971
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8443739414215088,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.8037573099136353,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7917946577072144,
            "answer": "scotland",
            "hit": false
          },
          {
            "score": 0.790280818939209,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.787527859210968,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.786544919013977,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.844373881816864
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8774643540382385,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.8427039980888367,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.8360942006111145,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8200563192367554,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8154314756393433,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.806957483291626,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8774643540382385
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7702316045761108,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7675914764404297,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.7607856392860413,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.7565618753433228,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7565011382102966,
            "answer": "astonishing",
            "hit": false
          },
          {
            "score": 0.7563683986663818,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7675914466381073
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8761903643608093,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.8405352830886841,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.8205875158309937,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8173722624778748,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.8136776685714722,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.8129227161407471,
            "answer": "brazil",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8761903643608093
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8530980348587036,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.8333830833435059,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.8164407014846802,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.8027525544166565,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.8018401861190796,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.801363468170166,
            "answer": "argentina",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8530980348587036
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8195757269859314,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.8097286820411682,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.7868835926055908,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7859792709350586,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7770925760269165,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7770266532897949,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8195757269859314
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.8560599684715271,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.8096203804016113,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8068259954452515,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8045873045921326,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.8043310046195984,
            "answer": "ussr",
            "hit": false
          },
          {
            "score": 0.7959644794464111,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8560599684715271
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8606517314910889,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8220794796943665,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8174864053726196,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8083085417747498,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7964999675750732,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7894634008407593,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8606517016887665
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.8059560060501099,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.7879301905632019,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.7866317629814148,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.7853004932403564,
            "answer": "toronto",
            "hit": false
          },
          {
            "score": 0.7771013975143433,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.7761932611465454,
            "answer": "montreal",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7879301905632019
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.8552581667900085,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.7863073348999023,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7765631675720215,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7736354470252991,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7668008804321289,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7648507952690125,
            "answer": "europe",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8552582263946533
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.8113581538200378,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.781494140625,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7796626687049866,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7730013132095337,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7663116455078125,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7576455473899841,
            "answer": "portugal",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8113581836223602
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.7920495271682739,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7842410802841187,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7786537408828735,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.771965742111206,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.7619713544845581,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7612247467041016,
            "answer": "guatemala",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7920495271682739
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8828792572021484,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8387125730514526,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.8378547430038452,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8364400863647461,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8262121677398682,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8140872120857239,
            "answer": "russia",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8828793168067932
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8722704648971558,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.85108482837677,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8173673152923584,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8141658902168274,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.8056675791740417,
            "answer": "kuwait",
            "hit": false
          },
          {
            "score": 0.8052403330802917,
            "answer": "diplomats",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8722704648971558
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.8266011476516724,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.7900591492652893,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7868911027908325,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7860362529754639,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7837119102478027,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7778075337409973,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8266011774539948
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8384842872619629,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.8350707292556763,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8271419405937195,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8269073963165283,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8236287236213684,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8128231763839722,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8384842872619629
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8634670972824097,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.8074226975440979,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8018139600753784,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.8008803725242615,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8004430532455444,
            "answer": "ukraine",
            "hit": false
          },
          {
            "score": 0.7972586154937744,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8634671568870544
      }
    ],
    "result": {
      "cnt_questions_correct": 26,
      "cnt_questions_total": 28,
      "accuracy": 0.9285714285714286
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "02a08caa-9843-43f9-9949-beae61ec2fb1",
      "timestamp": "2025-05-18T12:24:36.974372"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8564546704292297,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8450255393981934,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8046558499336243,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8030253052711487,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.8005253672599792,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7823070287704468,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8564546704292297
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.8524712324142456,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7885148525238037,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7811481356620789,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7768929600715637,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7707470655441284,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7454619407653809,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7707470953464508
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8543096780776978,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8192447423934937,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.779758870601654,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.778461217880249,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7739001512527466,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.773147463798523,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.779758870601654
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8411448001861572,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8366774916648865,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8229389190673828,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.7863916158676147,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7764186263084412,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7716619372367859,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8229389190673828
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.823525071144104,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7840075492858887,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7588220834732056,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7528843879699707,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7516618371009827,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7489478588104248,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7588220834732056
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.84834885597229,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7912611961364746,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7805829048156738,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7779802083969116,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7727288007736206,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7718391418457031,
            "answer": "argentine",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.84834885597229
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.852887749671936,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.822199285030365,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8047918081283569,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7807700634002686,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7792816162109375,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7767587304115295,
            "answer": "romanian",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.852887749671936
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8461353778839111,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.838123083114624,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7908253073692322,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7870031595230103,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7707765102386475,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.76399827003479,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8461353778839111
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8162720799446106,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8158678412437439,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8095671534538269,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7975084185600281,
            "answer": "turkish",
            "hit": true
          },
          {
            "score": 0.7802489995956421,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7738012671470642,
            "answer": "lebanese",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7802489995956421
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.854084849357605,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8184463977813721,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7942400574684143,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7837342023849487,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7836698293685913,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.7722737193107605,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8184463679790497
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8452030420303345,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.815308690071106,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8027350902557373,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7778643369674683,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7753432989120483,
            "answer": "kazakh",
            "hit": false
          },
          {
            "score": 0.7738877534866333,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8452030122280121
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8497105836868286,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8282942771911621,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.8029180765151978,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8026026487350464,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7878138422966003,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7581434845924377,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8282943367958069
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8273417949676514,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.822677493095398,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8082605600357056,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8019585609436035,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7746070623397827,
            "answer": "kurdish",
            "hit": true
          },
          {
            "score": 0.762450635433197,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.822677493095398
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8063924312591553,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7916321754455566,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7724381685256958,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.7723702192306519,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7685517072677612,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7575110197067261,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7724382281303406
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7690393924713135,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7546393871307373,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.738776445388794,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7350752353668213,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7341635823249817,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7165182828903198,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7546393871307373
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8273717761039734,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8227048516273499,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.795861005783081,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7896333932876587,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7873479723930359,
            "answer": "lebanese",
            "hit": false
          },
          {
            "score": 0.7857931852340698,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8273717761039734
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8135359287261963,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8048027753829956,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.799667477607727,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.7928777933120728,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7817790508270264,
            "answer": "arabs",
            "hit": false
          },
          {
            "score": 0.7731741666793823,
            "answer": "palestinians",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8135358691215515
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8332173824310303,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7723209857940674,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.770618200302124,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7531428337097168,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7510190010070801,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7495255470275879,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8332173824310303
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.839208722114563,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.8167467713356018,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7919490933418274,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7847782373428345,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7781652212142944,
            "answer": "italian",
            "hit": true
          },
          {
            "score": 0.775051474571228,
            "answer": "german",
            "hit": true
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.775051474571228
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8403229713439941,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8394314646720886,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8195717930793762,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8011898994445801,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.7957970499992371,
            "answer": "kurdish",
            "hit": false
          },
          {
            "score": 0.7836706638336182,
            "answer": "portuguese",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8394314646720886
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.8102284669876099,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7946158647537231,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7863854169845581,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7849570512771606,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.779833972454071,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7698032855987549,
            "answer": "chinese",
            "hit": true
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7698032557964325
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7902238368988037,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7574693560600281,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7499213814735413,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7455766797065735,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7304903864860535,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.727822482585907,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7574693858623505
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8442398309707642,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8346618413925171,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8173408508300781,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7828227281570435,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7788078784942627,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7770294547080994,
            "answer": "welsh",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8442398607730865
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 23,
      "accuracy": 0.391304347826087
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "983695f3-429d-466b-9f79-bd33e9cdab79",
      "timestamp": "2025-05-18T12:24:37.073083"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8134506344795227,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7812391519546509,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7724766731262207,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.7532093524932861,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.7505431175231934,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.7477387189865112,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7724767327308655
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8686283826828003,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.805139422416687,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7863364219665527,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7789579033851624,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.7739821672439575,
            "answer": "assaults",
            "hit": false
          },
          {
            "score": 0.7734597325325012,
            "answer": "pakistani",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8686284422874451
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8683518767356873,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8204451203346252,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7985082864761353,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7856407165527344,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.7750979661941528,
            "answer": "norfolk",
            "hit": false
          },
          {
            "score": 0.7732477188110352,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.82044517993927
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8268718123435974,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7774759531021118,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7568814754486084,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7409573197364807,
            "answer": "turbulent",
            "hit": false
          },
          {
            "score": 0.739928126335144,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7396708726882935,
            "answer": "decks",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8268718123435974
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8840693235397339,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7946934700012207,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7900606989860535,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7744616866111755,
            "answer": "steelers",
            "hit": false
          },
          {
            "score": 0.7681061029434204,
            "answer": "manchester",
            "hit": false
          },
          {
            "score": 0.7674582600593567,
            "answer": "outputs",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8840693235397339
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.8559026718139648,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8170642852783203,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7934343814849854,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7840234041213989,
            "answer": "norfolk",
            "hit": false
          },
          {
            "score": 0.7821820974349976,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.7766745686531067,
            "answer": "asserting",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7607938051223755
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8741937279701233,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7927225232124329,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7907072901725769,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7811964750289917,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7750176787376404,
            "answer": "manchester",
            "hit": false
          },
          {
            "score": 0.772686243057251,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8741936683654785
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8054927587509155,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7700022459030151,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.7445390224456787,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.743178129196167,
            "answer": "valleys",
            "hit": false
          },
          {
            "score": 0.7404690384864807,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.7400400638580322,
            "answer": "unconventional",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7700022757053375
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8139778971672058,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7556275725364685,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7298336029052734,
            "answer": "jersey",
            "hit": false
          },
          {
            "score": 0.7233251333236694,
            "answer": "orleans",
            "hit": false
          },
          {
            "score": 0.7224777936935425,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7217947244644165,
            "answer": "yorker",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8139779269695282
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "32a54e9f-0fef-4430-b711-682e1d71cf59",
      "timestamp": "2025-05-18T12:24:37.151431"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.800152063369751,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7746490240097046,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7648565769195557,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7646014094352722,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7619342803955078,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7581506967544556,
            "answer": "greeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.800152063369751
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7821707725524902,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7587608098983765,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7544570565223694,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7449861764907837,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7441394329071045,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.7393852472305298,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6903965026140213
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.8046256303787231,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7674968242645264,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7525054216384888,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.75006103515625,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7455887794494629,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7451477646827698,
            "answer": "english",
            "hit": true
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7451477944850922
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.793495774269104,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.764929473400116,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7603151798248291,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7535613179206848,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7505128979682922,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7484951019287109,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7603152394294739
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.8022438287734985,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7640548348426819,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7624683976173401,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7539821267127991,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7522000074386597,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7468879222869873,
            "answer": "russian",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7135011255741119
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8102924823760986,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.767549455165863,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7659628391265869,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.7475547790527344,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7465260028839111,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7431544065475464,
            "answer": "jewish",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8102924823760986
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7683200836181641,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7499130964279175,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7496052980422974,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7466021180152893,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7428607940673828,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7377042770385742,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7496053278446198
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7906740307807922,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.78879714012146,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7654050588607788,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7620470523834229,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7600480318069458,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7598541975021362,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7500073313713074
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7921857833862305,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7834522724151611,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7786996960639954,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7724074721336365,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7683181762695312,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7598018646240234,
            "answer": "dutch",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7921857833862305
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7731168270111084,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7582423686981201,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7580387592315674,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7553090453147888,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7545352578163147,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7535134553909302,
            "answer": "swedish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7731168270111084
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.7962745428085327,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7961141467094421,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.7703138589859009,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.7674218416213989,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7613050937652588,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.7610130906105042,
            "answer": "russians",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7613051235675812
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.770762026309967,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.753467321395874,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7487084865570068,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7246221303939819,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7226052284240723,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.7203412055969238,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7534673511981964
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7672584056854248,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7586200833320618,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7578423023223877,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7552046775817871,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7452771663665771,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7450244426727295,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7578423619270325
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7812386751174927,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7641279697418213,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7474263906478882,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7393831610679626,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7337876558303833,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7337613105773926,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7812386751174927
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7793119549751282,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7736481428146362,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7658796310424805,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7485389709472656,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7457224130630493,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.744610071182251,
            "answer": "british",
            "hit": true
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7219914197921753
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7774115800857544,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7435721158981323,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7435617446899414,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7276394367218018,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7273968458175659,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7216854095458984,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7435617446899414
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7990705966949463,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7829002141952515,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7722967863082886,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7559229135513306,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.752798855304718,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7513706684112549,
            "answer": "scottish",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7829002141952515
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7856490015983582,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7463148832321167,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7428715229034424,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7393074035644531,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7367232441902161,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7314721941947937,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7428715378046036
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8095132112503052,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7721297740936279,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7588454484939575,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7533349990844727,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.748602032661438,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7476770877838135,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8095132112503052
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 19,
      "accuracy": 0.3684210526315789
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "48527f01-1913-450e-be6d-62fb0402db8c",
      "timestamp": "2025-05-18T12:24:37.180994"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8540433645248413,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8396444320678711,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7935792207717896,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7895544171333313,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7880155444145203,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.783684492111206,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8540433645248413
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7989224791526794,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7865405082702637,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7821820974349976,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7642902135848999,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7522574663162231,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.7517470121383667,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7492674589157104
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8002577424049377,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7911844849586487,
            "answer": "migrating",
            "hit": false
          },
          {
            "score": 0.7830109596252441,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7799598574638367,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7798683643341064,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.7684360146522522,
            "answer": "modify",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 1288,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7315285354852676
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7876077890396118,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7623753547668457,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7609816789627075,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7594237327575684,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7547927498817444,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.7424554228782654,
            "answer": "creators",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 113,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7243959158658981
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.8068499565124512,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.8048727512359619,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7843204736709595,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7821211814880371,
            "answer": "astonished",
            "hit": false
          },
          {
            "score": 0.7793262004852295,
            "answer": "installing",
            "hit": false
          },
          {
            "score": 0.7787115573883057,
            "answer": "illnesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7779342830181122
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.8376348614692688,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.8063373565673828,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8030794858932495,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7798857688903809,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7789228558540344,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.7786784172058105,
            "answer": "intellectuals",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8030795454978943
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.8076205253601074,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7977778911590576,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.785008430480957,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7832551002502441,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.782339334487915,
            "answer": "terrorists",
            "hit": false
          },
          {
            "score": 0.7786215543746948,
            "answer": "stalin",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7777988314628601
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.8253071308135986,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8011805415153503,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7853910326957703,
            "answer": "intellect",
            "hit": false
          },
          {
            "score": 0.780016303062439,
            "answer": "intellectuals",
            "hit": false
          },
          {
            "score": 0.7775834798812866,
            "answer": "contradictory",
            "hit": false
          },
          {
            "score": 0.776695966720581,
            "answer": "cognition",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8253071010112762
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.834823727607727,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8047230243682861,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7964451313018799,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7937798500061035,
            "answer": "programmer",
            "hit": false
          },
          {
            "score": 0.7936627864837646,
            "answer": "constantin",
            "hit": false
          },
          {
            "score": 0.7877489328384399,
            "answer": "diplomats",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.834823727607727
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7817012667655945,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7463456392288208,
            "answer": "worcester",
            "hit": false
          },
          {
            "score": 0.7448006868362427,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7438690662384033,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.741163432598114,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.735642671585083,
            "answer": "usable",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 2069,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.694351851940155
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8139687776565552,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7854573726654053,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.783058762550354,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.7771613597869873,
            "answer": "thinkers",
            "hit": false
          },
          {
            "score": 0.7731385827064514,
            "answer": "accuse",
            "hit": false
          },
          {
            "score": 0.771845817565918,
            "answer": "cognition",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8139687478542328
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.8327285051345825,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7996467351913452,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.7991496920585632,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7964288592338562,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.7942099571228027,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7729070782661438,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8327284753322601
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.8274576663970947,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7903872728347778,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7732681632041931,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7684335112571716,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7622594237327576,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7587669491767883,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7732681930065155
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.798480749130249,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7825379967689514,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.7798011302947998,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7759361267089844,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7692329287528992,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7641114592552185,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7625226974487305
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.801722526550293,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7826002836227417,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.7783668041229248,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7761836647987366,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.776086688041687,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7684750556945801,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7826002538204193
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8522763252258301,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8295243382453918,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7903363704681396,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.7902891039848328,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7897915244102478,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7867540717124939,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8522763252258301
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.8061470985412598,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7846001386642456,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7831108570098877,
            "answer": "intellectuals",
            "hit": false
          },
          {
            "score": 0.7755625247955322,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.773714542388916,
            "answer": "mcconnell",
            "hit": false
          },
          {
            "score": 0.772571325302124,
            "answer": "economists",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 9394,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6814529299736023
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7936978340148926,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7818738222122192,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.7748926877975464,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7735579013824463,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.7734167575836182,
            "answer": "programmer",
            "hit": false
          },
          {
            "score": 0.7731450200080872,
            "answer": "dismay",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 51,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7627039551734924
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 18,
      "accuracy": 0.3333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "a1b45764-9ae4-404a-9903-1126bc553d7d",
      "timestamp": "2025-05-18T12:24:37.244196"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8146923780441284,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7786588668823242,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7774133086204529,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7604144215583801,
            "answer": "youths",
            "hit": false
          },
          {
            "score": 0.7588749527931213,
            "answer": "experimentation",
            "hit": false
          },
          {
            "score": 0.7581750750541687,
            "answer": "authoritarian",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6857925653457642
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8120246529579163,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7728002071380615,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7612419128417969,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7401432394981384,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7334437966346741,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7274358868598938,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7728002071380615
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7876701354980469,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7532146573066711,
            "answer": "newborn",
            "hit": false
          },
          {
            "score": 0.7514678239822388,
            "answer": "erie",
            "hit": false
          },
          {
            "score": 0.7464377880096436,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.7460252046585083,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7440093755722046,
            "answer": "infants",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7460252344608307
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8270262479782104,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.8134346008300781,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7732362747192383,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7721928954124451,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.761835515499115,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7614942789077759,
            "answer": "infants",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7721929550170898
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.8246238827705383,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.8155292868614197,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.8034438490867615,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7757165431976318,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7736622095108032,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7676026821136475,
            "answer": "infants",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 1290,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7186714559793472
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7926694750785828,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7879266142845154,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7860974669456482,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7547775506973267,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7547071576118469,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7539123296737671,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7879266738891602
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8374401330947876,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.8213173151016235,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7997603416442871,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7717908620834351,
            "answer": "antics",
            "hit": false
          },
          {
            "score": 0.7671496868133545,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7640094757080078,
            "answer": "babies",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 50,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7461245208978653
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8418202996253967,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.8124389052391052,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7844533920288086,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.7806340456008911,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7580750584602356,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7256584763526917,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7043541520833969
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8401755094528198,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.8029841184616089,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.8006798624992371,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7690408825874329,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7620445489883423,
            "answer": "adolescent",
            "hit": false
          },
          {
            "score": 0.762004554271698,
            "answer": "fishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8006798326969147
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7970893979072571,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.793373167514801,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7747348546981812,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7553136348724365,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.7517855167388916,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.735503613948822,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7970893979072571
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.840593159198761,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.8265466690063477,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7903705835342407,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7709154486656189,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.7644003629684448,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.7624214291572571,
            "answer": "radically",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7903706431388855
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 11,
      "accuracy": 0.09090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "884477b8-2269-4616-8f94-c7d5a2835e6d",
      "timestamp": "2025-05-18T12:24:37.311534"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7744634747505188,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.7712581157684326,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.7504794001579285,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.7344157099723816,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.7250173091888428,
            "answer": "ding",
            "hit": false
          },
          {
            "score": 0.7223201990127563,
            "answer": "bing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7712581157684326
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7834662795066833,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7494511604309082,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.74873286485672,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7427970170974731,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.7376621961593628,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7274717092514038,
            "answer": "buzz",
            "hit": true
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7274716794490814
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.8018622398376465,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.798116147518158,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7684231400489807,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7515831589698792,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.7069592475891113,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6995533108711243,
            "answer": "protections",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 2967,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6510547548532486
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.8238917589187622,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.816989004611969,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7716108560562134,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.7505894899368286,
            "answer": "reiterated",
            "hit": false
          },
          {
            "score": 0.7482779622077942,
            "answer": "sleek",
            "hit": false
          },
          {
            "score": 0.7477304339408875,
            "answer": "herds",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 11641,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6483137458562851
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fd676684-3bab-4826-ab02-b699b8728665",
      "timestamp": "2025-05-18T12:24:37.347504"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8064916133880615,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7795055508613586,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7616295218467712,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7598596811294556,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7517370581626892,
            "answer": "umar",
            "hit": false
          },
          {
            "score": 0.7455039024353027,
            "answer": "overcoming",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 2426,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6892886906862259
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7845098972320557,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7612223625183105,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.7383837103843689,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7162076234817505,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7118427157402039,
            "answer": "umar",
            "hit": false
          },
          {
            "score": 0.7056771516799927,
            "answer": "bert",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 846,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6611210405826569
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8060061931610107,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7706919312477112,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7346372008323669,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7331026792526245,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7260469198226929,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.7076908349990845,
            "answer": "bearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7260468751192093
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.8073522448539734,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7843267917633057,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7791665196418762,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7744482755661011,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7677409648895264,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7530626058578491,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 3206,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6855494976043701
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7577205300331116,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7481719851493835,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.7373090982437134,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7342391610145569,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7259098291397095,
            "answer": "tennis",
            "hit": false
          },
          {
            "score": 0.7194628715515137,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7577205300331116
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7919829487800598,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7447373867034912,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7446402311325073,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7400382161140442,
            "answer": "dismay",
            "hit": false
          },
          {
            "score": 0.7348847985267639,
            "answer": "sturdy",
            "hit": false
          },
          {
            "score": 0.7299090623855591,
            "answer": "lund",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7919829487800598
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8174723982810974,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.8021491169929504,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7485752105712891,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7387037873268127,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7316150665283203,
            "answer": "dod",
            "hit": false
          },
          {
            "score": 0.7297385334968567,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7026853561401367
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8011198043823242,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7740939855575562,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7725604772567749,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7628147602081299,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7506505250930786,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7138257622718811,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7725604176521301
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7683781981468201,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7373659610748291,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.7293211817741394,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.724615752696991,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.7210360765457153,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.7148727178573608,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7293211817741394
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.8295350670814514,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.8266570568084717,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.8054258823394775,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7774360179901123,
            "answer": "pest",
            "hit": false
          },
          {
            "score": 0.7756631374359131,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7739071249961853,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8266569972038269
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7966321110725403,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7669327259063721,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7519852519035339,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7372364401817322,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.7367540001869202,
            "answer": "kern",
            "hit": false
          },
          {
            "score": 0.7338511943817139,
            "answer": "distrust",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6996218115091324
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8242837190628052,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.8235116600990295,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7865522503852844,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7623233199119568,
            "answer": "noisy",
            "hit": false
          },
          {
            "score": 0.7617720365524292,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.7597549557685852,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 618,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6980567276477814
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.782559335231781,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7722288370132446,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7501361966133118,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7465837597846985,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.743407130241394,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7371430993080139,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.772228866815567
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7819865345954895,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.7648574113845825,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7371000051498413,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7351802587509155,
            "answer": "hut",
            "hit": false
          },
          {
            "score": 0.7311687469482422,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7282343506813049,
            "answer": "swap",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7648574113845825
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7894764542579651,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7492707967758179,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.733835756778717,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7313475608825684,
            "answer": "lund",
            "hit": false
          },
          {
            "score": 0.7297487258911133,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.7260053753852844,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7894764542579651
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8033148050308228,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7890740633010864,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7456167936325073,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7278457880020142,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7265611886978149,
            "answer": "shredded",
            "hit": false
          },
          {
            "score": 0.7259422540664673,
            "answer": "distressed",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7236648797988892
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8308237791061401,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.8169046640396118,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7781850099563599,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7556940317153931,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.752656877040863,
            "answer": "storing",
            "hit": false
          },
          {
            "score": 0.752227783203125,
            "answer": "crate",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 3733,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6991517692804337
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7921025156974792,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7766385078430176,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7277554869651794,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.7077329754829407,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7025324106216431,
            "answer": "cave",
            "hit": false
          },
          {
            "score": 0.7024409770965576,
            "answer": "owl",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7277554869651794
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 18,
      "accuracy": 0.2222222222222222
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e4f8fbb5-2a0c-401b-bfe9-5a1988036063",
      "timestamp": "2025-05-18T12:24:37.367330"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.8096230030059814,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.8041123151779175,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7930988669395447,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7522649765014648,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7374632358551025,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.7328159809112549,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8096229732036591
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.824321985244751,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8111246824264526,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.77476567029953,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7674196362495422,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7605660557746887,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7552554607391357,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7674196362495422
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.816381573677063,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8073432445526123,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7664715051651001,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7220713496208191,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.715580940246582,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.702517032623291,
            "answer": "dark",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7664714753627777
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.837506890296936,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8073747158050537,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7979856729507446,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7905380725860596,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7732291221618652,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7710272669792175,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7732291221618652
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.8128962516784668,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8038632869720459,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8017907738685608,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7894461154937744,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7749481201171875,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.758103609085083,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7234015166759491
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.819458544254303,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7959133386611938,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7880252599716187,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7701160907745361,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7696616649627686,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7527074217796326,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7880252599716187
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7962385416030884,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7944326400756836,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7824450731277466,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7672773003578186,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7631939053535461,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7626413106918335,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7944326996803284
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8034041523933411,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8025696873664856,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.76833575963974,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.743381142616272,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.731316089630127,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7286109924316406,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8025696873664856
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.798737645149231,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7889103889465332,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.778361439704895,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7454959154129028,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7358664274215698,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7311886548995972,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.798737645149231
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8049248456954956,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7841975092887878,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7546344995498657,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.753690242767334,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7371737957000732,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7243185043334961,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7841975390911102
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.8260790109634399,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8067104816436768,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7750220894813538,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7584394216537476,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7517542243003845,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7514261603355408,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8260789811611176
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.8282736539840698,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8146819472312927,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7723565697669983,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7581205368041992,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7396345138549805,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7359851598739624,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.814681887626648
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8174484968185425,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7916250824928284,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.762737512588501,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7452614903450012,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7452399134635925,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7388613820075989,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7916250824928284
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.8211820125579834,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7942838668823242,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7906430959701538,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7587960958480835,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7516529560089111,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7424169778823853,
            "answer": "pink",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7587961554527283
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.8172041177749634,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7801722884178162,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7714685797691345,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7584729194641113,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7579035758972168,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.7552851438522339,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7801722884178162
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.8081331253051758,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8037432432174683,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7791715860366821,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7727340459823608,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7463712692260742,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7453960180282593,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7791716456413269
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.8081822991371155,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7922012805938721,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7685269117355347,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.7670086622238159,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.7559230923652649,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.753438413143158,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7441736161708832
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.8154287338256836,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7942366600036621,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7709395885467529,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7341569662094116,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7287386655807495,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7282755374908447,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.815428763628006
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.7960411310195923,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7880785465240479,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7634619474411011,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7486346364021301,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7347114682197571,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.715248703956604,
            "answer": "papers",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7960411310195923
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7993094325065613,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7921976447105408,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7737276554107666,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7661116719245911,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7613847851753235,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7562386989593506,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7921976447105408
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8049548864364624,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7981216311454773,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7920637130737305,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7767336368560791,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7688894271850586,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7627952098846436,
            "answer": "potatoes",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7523331642150879
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.8161617517471313,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.8070686459541321,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7616212368011475,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7514852285385132,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7457861304283142,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7451351881027222,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8161617517471313
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.8217728137969971,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8074401617050171,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7804028987884521,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7601087093353271,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7382776737213135,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.7273614406585693,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7804028391838074
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.8267003297805786,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8245606422424316,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7834384441375732,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7620580196380615,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.74973064661026,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7414003610610962,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.783438503742218
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.8180729746818542,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8106757402420044,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7836568355560303,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7538481950759888,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7460960745811462,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7296377420425415,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.818073034286499
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7976300120353699,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7914021015167236,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7523506879806519,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7377312183380127,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7334515452384949,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.7113490700721741,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7334515601396561
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7927410006523132,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.789459228515625,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7728071808815002,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7504445910453796,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.7381370067596436,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7081366777420044,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7504445910453796
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.821140706539154,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8162343502044678,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7599347829818726,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7531729936599731,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7508019208908081,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7224820852279663,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8162343502044678
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.7916478514671326,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7867038249969482,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.764613151550293,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7506020069122314,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7359604239463806,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7250971794128418,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7867038249969482
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8205356001853943,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8029485940933228,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7886451482772827,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7472696900367737,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7454156875610352,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7307651042938232,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8205356299877167
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.8057759404182434,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7976605892181396,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7714235186576843,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7427458167076111,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7393906116485596,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7103517055511475,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055273205041885
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8169214129447937,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8001980781555176,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7768921852111816,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7570730447769165,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7501239776611328,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7484383583068848,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8169214725494385
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.8055359721183777,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7865099906921387,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7728739976882935,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7586565017700195,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7495443224906921,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7393709421157837,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7865099906921387
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.8345301151275635,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8202161192893982,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8123038411140442,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.782596230506897,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7817506790161133,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7763710618019104,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8123038411140442
      }
    ],
    "result": {
      "cnt_questions_correct": 12,
      "cnt_questions_total": 34,
      "accuracy": 0.35294117647058826
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4305500a-9ebf-4fb0-8c66-efa721cd1efc",
      "timestamp": "2025-05-18T12:24:37.432442"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.9418498277664185,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.8789246082305908,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.8486202359199524,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7896938323974609,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7883737683296204,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7815060615539551,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9418497979640961
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.8886514902114868,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.8058024644851685,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7937381267547607,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.7677375674247742,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.7387518882751465,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.7369334697723389,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8886515200138092
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.9077448844909668,
            "answer": "sister",
            "hit": true
          },
          {
            "score": 0.8233060836791992,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8185190558433533,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8048495054244995,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.8038177490234375,
            "answer": "sisters",
            "hit": false
          },
          {
            "score": 0.8021920919418335,
            "answer": "sibling",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.907744973897934
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.7557978630065918,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.7447701692581177,
            "answer": "accelerating",
            "hit": false
          },
          {
            "score": 0.7421187162399292,
            "answer": "feminism",
            "hit": false
          },
          {
            "score": 0.7401403188705444,
            "answer": "sock",
            "hit": false
          },
          {
            "score": 0.7399278283119202,
            "answer": "distrust",
            "hit": false
          },
          {
            "score": 0.7398442029953003,
            "answer": "weiss",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 976,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7085641026496887
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.8027598857879639,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.7344082593917847,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7311697006225586,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.7297633290290833,
            "answer": "cow",
            "hit": true
          },
          {
            "score": 0.7281290292739868,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7208032608032227,
            "answer": "chick",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7297633588314056
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.8768558502197266,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.8103054165840149,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7971285581588745,
            "answer": "mum",
            "hit": true
          },
          {
            "score": 0.7860950231552124,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.7774311304092407,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.7713107466697693,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8768559098243713
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.8654947876930237,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.7669543027877808,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.7630773782730103,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.7418075203895569,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.7305876016616821,
            "answer": "duc",
            "hit": false
          },
          {
            "score": 0.7298275828361511,
            "answer": "aunt",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654948472976685
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.8962498903274536,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.8286945819854736,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8075681924819946,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.8060822486877441,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.798560380935669,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7957813143730164,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8962498903274536
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.8112128973007202,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.7960496544837952,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7842084169387817,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7447277307510376,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.7420428991317749,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7385140657424927,
            "answer": "heaven",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8112128973007202
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.9028023481369019,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8716110587120056,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.817267894744873,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.8139728903770447,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8120698928833008,
            "answer": "ancestors",
            "hit": false
          },
          {
            "score": 0.8054105043411255,
            "answer": "niece",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9028024077415466
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.8019870519638062,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7925465106964111,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7807220220565796,
            "answer": "bathrooms",
            "hit": false
          },
          {
            "score": 0.7771031260490417,
            "answer": "dresses",
            "hit": false
          },
          {
            "score": 0.777014970779419,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7755471467971802,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7925465106964111
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8413139581680298,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8398207426071167,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.8353813886642456,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.8206206560134888,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.7768800854682922,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7758884429931641,
            "answer": "marrying",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8398208022117615
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.8633496761322021,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.7812172770500183,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.7729418873786926,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.7619530558586121,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.7534557580947876,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.7510111331939697,
            "answer": "ruler",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8633496165275574
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.8646852970123291,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.8020975589752197,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.758928656578064,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.7495781183242798,
            "answer": "person",
            "hit": false
          },
          {
            "score": 0.7336744666099548,
            "answer": "women",
            "hit": false
          },
          {
            "score": 0.7263175845146179,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8646852970123291
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9335925579071045,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8686911463737488,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.830365002155304,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8269660472869873,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.825762152671814,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.8229482173919678,
            "answer": "aunt",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9335925579071045
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.869938850402832,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.8117941617965698,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7897316217422485,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.7744781970977783,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.7443329095840454,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.7361636161804199,
            "answer": "rulers",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8699388802051544
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.9072941541671753,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.8310520648956299,
            "answer": "sons",
            "hit": false
          },
          {
            "score": 0.8125717043876648,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.8035102486610413,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7953143119812012,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7893577814102173,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9072941541671753
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8863431215286255,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.8327356576919556,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.814459502696991,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.8124167919158936,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7974559664726257,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7924612760543823,
            "answer": "grandparents",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8863431215286255
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 18,
      "accuracy": 0.7777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "85d57113-55fa-4d2f-ac09-f4122686978a",
      "timestamp": "2025-05-18T12:24:37.554178"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.783800482749939,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.7803704738616943,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.763331413269043,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.7482407093048096,
            "answer": "occupants",
            "hit": false
          },
          {
            "score": 0.7481988668441772,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.7474228143692017,
            "answer": "disturbances",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6935094147920609
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.833503246307373,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.7556447982788086,
            "answer": "backpack",
            "hit": false
          },
          {
            "score": 0.7399013042449951,
            "answer": "sack",
            "hit": false
          },
          {
            "score": 0.7378989458084106,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.7360378503799438,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.7275171279907227,
            "answer": "pouch",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 287,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6906325221061707
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.751925528049469,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7495579719543457,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7483683824539185,
            "answer": "onions",
            "hit": false
          },
          {
            "score": 0.7471480965614319,
            "answer": "disclose",
            "hit": false
          },
          {
            "score": 0.7443501353263855,
            "answer": "hardness",
            "hit": false
          },
          {
            "score": 0.7439006567001343,
            "answer": "youths",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7358274757862091
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.8399306535720825,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.7110390663146973,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.707747757434845,
            "answer": "flesh",
            "hit": true
          },
          {
            "score": 0.7014216780662537,
            "answer": "head",
            "hit": false
          },
          {
            "score": 0.696991503238678,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6935220956802368,
            "answer": "frame",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7077477723360062
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.8173356652259827,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7673113942146301,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.755533754825592,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7484606504440308,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.74309241771698,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7428376078605652,
            "answer": "socks",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7305054664611816
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.860467791557312,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7575283050537109,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.744795024394989,
            "answer": "brewery",
            "hit": false
          },
          {
            "score": 0.7445342540740967,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.7444913387298584,
            "answer": "formulated",
            "hit": false
          },
          {
            "score": 0.7443327903747559,
            "answer": "crate",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7575283050537109
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8261281251907349,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7284159064292908,
            "answer": "lobe",
            "hit": false
          },
          {
            "score": 0.7282502055168152,
            "answer": "pitcher",
            "hit": false
          },
          {
            "score": 0.7249006032943726,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.7233984470367432,
            "answer": "vikings",
            "hit": false
          },
          {
            "score": 0.7228703498840332,
            "answer": "glass",
            "hit": true
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7228703796863556
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.7979817390441895,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7851293087005615,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7818880081176758,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.7818593978881836,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.7805061340332031,
            "answer": "toxin",
            "hit": false
          },
          {
            "score": 0.7748270034790039,
            "answer": "provocative",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 368,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7280565053224564
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7852344512939453,
            "answer": "desktop",
            "hit": false
          },
          {
            "score": 0.7355560064315796,
            "answer": "keyboard",
            "hit": false
          },
          {
            "score": 0.733881950378418,
            "answer": "laptop",
            "hit": false
          },
          {
            "score": 0.7319698333740234,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.731184184551239,
            "answer": "shelves",
            "hit": false
          },
          {
            "score": 0.7309194803237915,
            "answer": "frustrating",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 3049,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6504545956850052
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.8234623074531555,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7476699352264404,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.7452283501625061,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.7447505593299866,
            "answer": "titanium",
            "hit": false
          },
          {
            "score": 0.7388408780097961,
            "answer": "silver",
            "hit": false
          },
          {
            "score": 0.7360835671424866,
            "answer": "jewels",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 1520,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6731240153312683
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.8187231421470642,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.7247463464736938,
            "answer": "banner",
            "hit": false
          },
          {
            "score": 0.7066012620925903,
            "answer": "lamps",
            "hit": false
          },
          {
            "score": 0.7055974006652832,
            "answer": "colours",
            "hit": false
          },
          {
            "score": 0.7007700800895691,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.6988782286643982,
            "answer": "peas",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 2683,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6561139225959778
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8040053248405457,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7187603116035461,
            "answer": "building",
            "hit": false
          },
          {
            "score": 0.7120518684387207,
            "answer": "home",
            "hit": false
          },
          {
            "score": 0.7106114625930786,
            "answer": "wood",
            "hit": true
          },
          {
            "score": 0.7050957679748535,
            "answer": "room",
            "hit": false
          },
          {
            "score": 0.7025914192199707,
            "answer": "hall",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.606768287718296
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.731263279914856,
            "answer": "agra",
            "hit": false
          },
          {
            "score": 0.7298056483268738,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.727042019367218,
            "answer": "essen",
            "hit": false
          },
          {
            "score": 0.724484920501709,
            "answer": "lund",
            "hit": false
          },
          {
            "score": 0.7237518429756165,
            "answer": "rum",
            "hit": false
          },
          {
            "score": 0.7225246429443359,
            "answer": "jul",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 450,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.662927120923996
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7735403180122375,
            "answer": "backyard",
            "hit": false
          },
          {
            "score": 0.770403265953064,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.765242874622345,
            "answer": "gardening",
            "hit": false
          },
          {
            "score": 0.7539999485015869,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.7524551153182983,
            "answer": "grass",
            "hit": true
          },
          {
            "score": 0.7501598000526428,
            "answer": "weeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7524551153182983
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8620550036430359,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.7625734806060791,
            "answer": "photographers",
            "hit": false
          },
          {
            "score": 0.7615389823913574,
            "answer": "optics",
            "hit": false
          },
          {
            "score": 0.7609922289848328,
            "answer": "bulbs",
            "hit": false
          },
          {
            "score": 0.7598957419395447,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.7591445446014404,
            "answer": "opaque",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 95,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7363068908452988
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.8538194894790649,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7464776039123535,
            "answer": "reflection",
            "hit": false
          },
          {
            "score": 0.7365081906318665,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.7351727485656738,
            "answer": "reflections",
            "hit": false
          },
          {
            "score": 0.7268637418746948,
            "answer": "reflecting",
            "hit": false
          },
          {
            "score": 0.7249536514282227,
            "answer": "aluminium",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7365081906318665
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7641059160232544,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7561661005020142,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.7289854288101196,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.7200132608413696,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.7187371850013733,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7091183662414551,
            "answer": "wealth",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6677839607000351
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8278380036354065,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7494093179702759,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.7389094829559326,
            "answer": "atlantic",
            "hit": false
          },
          {
            "score": 0.7335512042045593,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7316330671310425,
            "answer": "sediment",
            "hit": false
          },
          {
            "score": 0.7316242456436157,
            "answer": "aluminum",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7123723179101944
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.807997465133667,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.804376482963562,
            "answer": "cakes",
            "hit": false
          },
          {
            "score": 0.8024797439575195,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.7941068410873413,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7930082082748413,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.7927440404891968,
            "answer": "sausage",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7787137031555176
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7452214956283569,
            "answer": "commodity",
            "hit": false
          },
          {
            "score": 0.7438182830810547,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.7402129769325256,
            "answer": "commodities",
            "hit": false
          },
          {
            "score": 0.7401714324951172,
            "answer": "unpaid",
            "hit": false
          },
          {
            "score": 0.7395174503326416,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7379497289657593,
            "answer": "regulating",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6939598023891449
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.8014487624168396,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7630711197853088,
            "answer": "medication",
            "hit": false
          },
          {
            "score": 0.7560193538665771,
            "answer": "medications",
            "hit": false
          },
          {
            "score": 0.7516093254089355,
            "answer": "magnesium",
            "hit": false
          },
          {
            "score": 0.7485443949699402,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.7470687627792358,
            "answer": "cosmetic",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 1625,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055453062057495
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.8023692965507507,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7781389951705933,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.7779462337493896,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7756528854370117,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.7714567184448242,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.7588280439376831,
            "answer": "leather",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7407652586698532
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7585486173629761,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7521910667419434,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7328301668167114,
            "answer": "water",
            "hit": true
          },
          {
            "score": 0.7233200669288635,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7152796387672424,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7079595327377319,
            "answer": "marine",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7328301668167114
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7717266082763672,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.7635066509246826,
            "answer": "collapsing",
            "hit": false
          },
          {
            "score": 0.7582563161849976,
            "answer": "sweetness",
            "hit": false
          },
          {
            "score": 0.7582422494888306,
            "answer": "unconventional",
            "hit": false
          },
          {
            "score": 0.7574080228805542,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.7569292783737183,
            "answer": "salts",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 83,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7452703416347504
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8295280933380127,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.7079945206642151,
            "answer": "discussion",
            "hit": false
          },
          {
            "score": 0.7025312781333923,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.700541079044342,
            "answer": "counter",
            "hit": false
          },
          {
            "score": 0.6990852952003479,
            "answer": "couch",
            "hit": false
          },
          {
            "score": 0.6942777633666992,
            "answer": "sofa",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817967444658279
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.763015866279602,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7593520283699036,
            "answer": "textile",
            "hit": false
          },
          {
            "score": 0.758002519607544,
            "answer": "astonishing",
            "hit": false
          },
          {
            "score": 0.7565745115280151,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7546072006225586,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7542742490768433,
            "answer": "vinegar",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 3588,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7075172066688538
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.810205340385437,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7567921876907349,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7516949772834778,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7405225038528442,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7383294105529785,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.7347764372825623,
            "answer": "alcohol",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7275155931711197
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.8097829222679138,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.7667487859725952,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.7588299512863159,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7433921098709106,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.7293345332145691,
            "answer": "cables",
            "hit": false
          },
          {
            "score": 0.7255082726478577,
            "answer": "fibers",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 106,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7005630731582642
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 28,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b68b218b-8bf2-4041-94b0-77c981e7f6c7",
      "timestamp": "2025-05-18T12:24:37.614821"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.8297408223152161,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.7340563535690308,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7221739292144775,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7188919186592102,
            "answer": "flower",
            "hit": false
          },
          {
            "score": 0.7168734669685364,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.7163807153701782,
            "answer": "fragmented",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7093393206596375
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8760514259338379,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.8090713024139404,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.7995328903198242,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.7913734912872314,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7888113260269165,
            "answer": "forearm",
            "hit": false
          },
          {
            "score": 0.7882882356643677,
            "answer": "ankle",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7225749045610428
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.8092547655105591,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.7748822569847107,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.7587898969650269,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7491870522499084,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7388024926185608,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.7184023857116699,
            "answer": "automobiles",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6883157342672348
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8346691131591797,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7991098165512085,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7988439202308655,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7801562547683716,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7731248736381531,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7673195004463196,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7731248736381531
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.7852312922477722,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.7662532329559326,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.7434949278831482,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.7401167154312134,
            "answer": "pagan",
            "hit": false
          },
          {
            "score": 0.7358616590499878,
            "answer": "muslim",
            "hit": false
          },
          {
            "score": 0.734192430973053,
            "answer": "religious",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6546181589365005
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.8048549890518188,
            "answer": "university",
            "hit": true
          },
          {
            "score": 0.8035836219787598,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7992192506790161,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7303445339202881,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.7285547852516174,
            "answer": "academy",
            "hit": false
          },
          {
            "score": 0.7169785499572754,
            "answer": "campus",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8048549294471741
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.8084591031074524,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7443865537643433,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7426803112030029,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.728565514087677,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.7241698503494263,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.723226010799408,
            "answer": "province",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.693082720041275
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7971791625022888,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7418367862701416,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.741631031036377,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7399047017097473,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.737463116645813,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.737270712852478,
            "answer": "cattle",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7374631464481354
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7310084104537964,
            "answer": "dismay",
            "hit": false
          },
          {
            "score": 0.7303252220153809,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.7296937108039856,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.728485643863678,
            "answer": "agra",
            "hit": false
          },
          {
            "score": 0.7276498079299927,
            "answer": "sturdy",
            "hit": false
          },
          {
            "score": 0.7268469333648682,
            "answer": "hawks",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 7712,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.659350574016571
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8565413951873779,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.754368782043457,
            "answer": "oppressive",
            "hit": false
          },
          {
            "score": 0.7536702752113342,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7529772520065308,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.750831663608551,
            "answer": "ubiquitous",
            "hit": false
          },
          {
            "score": 0.7488993406295776,
            "answer": "unreasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 170,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7294273376464844
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.9008702635765076,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.8067363500595093,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7927083969116211,
            "answer": "workforce",
            "hit": false
          },
          {
            "score": 0.7916429042816162,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.7888057231903076,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.7833013534545898,
            "answer": "inmate",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 1190,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.736802875995636
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.8001431822776794,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7488721609115601,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.7433862686157227,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.7410176396369934,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.7363651990890503,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7350423336029053,
            "answer": "trout",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 6252,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.634021446108818
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8336324691772461,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.7817078232765198,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.75859135389328,
            "answer": "universe",
            "hit": true
          },
          {
            "score": 0.7463730573654175,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7414804697036743,
            "answer": "planetary",
            "hit": false
          },
          {
            "score": 0.7380074858665466,
            "answer": "cozy",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.75859135389328
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.8429914116859436,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.720827579498291,
            "answer": "email",
            "hit": false
          },
          {
            "score": 0.7183300256729126,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7175682783126831,
            "answer": "paragraph",
            "hit": false
          },
          {
            "score": 0.7149412631988525,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.7121788859367371,
            "answer": "message",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6882883459329605
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.8139740228652954,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7505761981010437,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7387734651565552,
            "answer": "safari",
            "hit": false
          },
          {
            "score": 0.7374441623687744,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7361069917678833,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7340942621231079,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 3236,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6813580244779587
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8749511241912842,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.8219232559204102,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.8006947636604309,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.8000537157058716,
            "answer": "viewers",
            "hit": false
          },
          {
            "score": 0.7911681532859802,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7901738882064819,
            "answer": "npr",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 117,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.771875262260437
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.8859190940856934,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7581757307052612,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7307673692703247,
            "answer": "participant",
            "hit": false
          },
          {
            "score": 0.7232375144958496,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.71002197265625,
            "answer": "leader",
            "hit": false
          },
          {
            "score": 0.7017842531204224,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6408779323101044
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8691290616989136,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8122655153274536,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.8101447820663452,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.8003415465354919,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.7992820143699646,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7934401035308838,
            "answer": "singers",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7643911242485046
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7854665517807007,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7651863098144531,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.740871012210846,
            "answer": "individual",
            "hit": false
          },
          {
            "score": 0.7369171380996704,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.7354053258895874,
            "answer": "individuals",
            "hit": false
          },
          {
            "score": 0.7222521901130676,
            "answer": "man",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 176,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6368615180253983
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.8599711656570435,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.8426419496536255,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.8203456997871399,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7914887070655823,
            "answer": "photography",
            "hit": false
          },
          {
            "score": 0.7909198999404907,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.785411536693573,
            "answer": "pictures",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 7645,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6263881772756577
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.879815399646759,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.763260006904602,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7396012544631958,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.7223742008209229,
            "answer": "plays",
            "hit": false
          },
          {
            "score": 0.7208067178726196,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.7177696824073792,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7077613770961761
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8163591027259827,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.8009275197982788,
            "answer": "detectives",
            "hit": false
          },
          {
            "score": 0.8002178072929382,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7966502904891968,
            "answer": "respectable",
            "hit": false
          },
          {
            "score": 0.7963637113571167,
            "answer": "psychiatrist",
            "hit": false
          },
          {
            "score": 0.7945555448532104,
            "answer": "disturbances",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 171,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7726688385009766
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7418462038040161,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.7382450103759766,
            "answer": "ministers",
            "hit": false
          },
          {
            "score": 0.7372153997421265,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7360352873802185,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.7342923879623413,
            "answer": "auditor",
            "hit": false
          },
          {
            "score": 0.731407642364502,
            "answer": "conferences",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 9382,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6459896415472031
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8498772382736206,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8303098678588867,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.8201519250869751,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7863278388977051,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.7728803157806396,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7576035857200623,
            "answer": "governor",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8201518952846527
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7988508939743042,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7815192937850952,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7741287350654602,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7671093940734863,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7646800875663757,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.7574573755264282,
            "answer": "cows",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7646800875663757
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8681406378746033,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7645995616912842,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7564646005630493,
            "answer": "armies",
            "hit": false
          },
          {
            "score": 0.7510855197906494,
            "answer": "commanders",
            "hit": false
          },
          {
            "score": 0.7492257952690125,
            "answer": "diplomats",
            "hit": false
          },
          {
            "score": 0.7491350173950195,
            "answer": "army",
            "hit": true
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7491350173950195
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.8238233327865601,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8145699501037598,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7983254194259644,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7970086336135864,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7954574823379517,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.7920640707015991,
            "answer": "invariably",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 6749,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7146848142147064
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7549964785575867,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.7309929132461548,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7230639457702637,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7070021629333496,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.693739652633667,
            "answer": "country",
            "hit": true
          },
          {
            "score": 0.6906512379646301,
            "answer": "county",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.693739652633667
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.871423602104187,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7730672955513,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7513512969017029,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.7452050447463989,
            "answer": "pupils",
            "hit": false
          },
          {
            "score": 0.743712306022644,
            "answer": "school",
            "hit": true
          },
          {
            "score": 0.740187406539917,
            "answer": "classroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6711277514696121
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.8405920267105103,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7077935934066772,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.7056364417076111,
            "answer": "bushes",
            "hit": false
          },
          {
            "score": 0.7024576663970947,
            "answer": "vine",
            "hit": false
          },
          {
            "score": 0.6988043785095215,
            "answer": "queue",
            "hit": false
          },
          {
            "score": 0.6976741552352905,
            "answer": "node",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6975919604301453
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.8070114850997925,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7137197852134705,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7108798027038574,
            "answer": "packs",
            "hit": false
          },
          {
            "score": 0.7104068398475647,
            "answer": "beast",
            "hit": false
          },
          {
            "score": 0.7102958559989929,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7054703235626221,
            "answer": "pack",
            "hit": true
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7054703533649445
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7631994485855103,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7185356616973877,
            "answer": "term",
            "hit": false
          },
          {
            "score": 0.7141696214675903,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.6885073184967041,
            "answer": "name",
            "hit": false
          },
          {
            "score": 0.6850127577781677,
            "answer": "sentence",
            "hit": true
          },
          {
            "score": 0.6776344776153564,
            "answer": "language",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.649027094244957
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f87a3e8c-b6cc-4c95-9570-64968c76ebfd",
      "timestamp": "2025-05-18T12:24:37.719975"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.768319845199585,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.7051823139190674,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6975194215774536,
            "answer": "train",
            "hit": false
          },
          {
            "score": 0.6963826417922974,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.6860806345939636,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6794416904449463,
            "answer": "cent",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 603,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6154170781373978
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.8238173723220825,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.787070095539093,
            "answer": "pixels",
            "hit": false
          },
          {
            "score": 0.7717355489730835,
            "answer": "programmers",
            "hit": false
          },
          {
            "score": 0.7651069760322571,
            "answer": "ieee",
            "hit": false
          },
          {
            "score": 0.7647841572761536,
            "answer": "pixel",
            "hit": false
          },
          {
            "score": 0.7631149888038635,
            "answer": "abnormalities",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 10161,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6673241406679153
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.7219409942626953,
            "answer": "brushes",
            "hit": false
          },
          {
            "score": 0.7206264734268188,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.7164896726608276,
            "answer": "splendid",
            "hit": false
          },
          {
            "score": 0.7109889388084412,
            "answer": "scrape",
            "hit": false
          },
          {
            "score": 0.7109798789024353,
            "answer": "brushing",
            "hit": false
          },
          {
            "score": 0.7076075673103333,
            "answer": "constantin",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 3126,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6427768170833588
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.763588547706604,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7327466011047363,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.7289321422576904,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.7111194729804993,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7016048431396484,
            "answer": "nickel",
            "hit": false
          },
          {
            "score": 0.6982486248016357,
            "answer": "gallon",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 544,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6578948795795441
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6c35924e-5cee-403d-b1e2-460ca9124119",
      "timestamp": "2025-05-18T12:24:37.852275"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.8338710069656372,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.8275079727172852,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8219518065452576,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.8205881118774414,
            "answer": "anxious",
            "hit": false
          },
          {
            "score": 0.8201778531074524,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.8060287833213806,
            "answer": "delighted",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8037727177143097
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8178620934486389,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7225028872489929,
            "answer": "building",
            "hit": false
          },
          {
            "score": 0.7144479155540466,
            "answer": "room",
            "hit": false
          },
          {
            "score": 0.7092758417129517,
            "answer": "home",
            "hit": false
          },
          {
            "score": 0.7072442770004272,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.7042897939682007,
            "answer": "castle",
            "hit": true
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6932232081890106
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.805008053779602,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7680174708366394,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.761705219745636,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7525452375411987,
            "answer": "reservoir",
            "hit": false
          },
          {
            "score": 0.7328569889068604,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7240961790084839,
            "answer": "ocean",
            "hit": true
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6684335619211197
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.8019098043441772,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.7759439945220947,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7731890678405762,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7728189826011658,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.7618933916091919,
            "answer": "pains",
            "hit": false
          },
          {
            "score": 0.751099705696106,
            "answer": "hurting",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.74288409948349
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.7882214784622192,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7816528677940369,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7752430438995361,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7739772796630859,
            "answer": "rabbits",
            "hit": false
          },
          {
            "score": 0.773837149143219,
            "answer": "compiling",
            "hit": false
          },
          {
            "score": 0.7735153436660767,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 2612,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7305412739515305
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7619032859802246,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.7579625844955444,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7185565233230591,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7093771696090698,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7075520157814026,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7016671895980835,
            "answer": "gulf",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7619032263755798
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8722593784332275,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.8284564018249512,
            "answer": "beverages",
            "hit": false
          },
          {
            "score": 0.8241977095603943,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.8169468641281128,
            "answer": "antics",
            "hit": false
          },
          {
            "score": 0.813004732131958,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.8123350143432617,
            "answer": "sandwiches",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 344,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7824300527572632
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.8523596525192261,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8112236261367798,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.7930644750595093,
            "answer": "exhaustion",
            "hit": false
          },
          {
            "score": 0.7760761976242065,
            "answer": "fatigue",
            "hit": false
          },
          {
            "score": 0.776069164276123,
            "answer": "impatient",
            "hit": false
          },
          {
            "score": 0.7720949649810791,
            "answer": "restless",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8112236857414246
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 8,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "07462799-b06c-4eee-9ec5-c5394f6cd4d6",
      "timestamp": "2025-05-18T12:24:37.872415"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8605129718780518,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.8396294116973877,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.83860182762146,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.8288911581039429,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.8276316523551941,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.8148118257522583,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8605129718780518
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7917787432670593,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.7833361625671387,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.7805359959602356,
            "answer": "fabric",
            "hit": true
          },
          {
            "score": 0.7791619300842285,
            "answer": "textile",
            "hit": true
          },
          {
            "score": 0.7756267786026001,
            "answer": "yarn",
            "hit": false
          },
          {
            "score": 0.7704955339431763,
            "answer": "garments",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7805359959602356
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8290004730224609,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7951260209083557,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.777403712272644,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.7759511470794678,
            "answer": "gallons",
            "hit": false
          },
          {
            "score": 0.7748576998710632,
            "answer": "pounds",
            "hit": false
          },
          {
            "score": 0.7714213132858276,
            "answer": "financed",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7774037718772888
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.8625136613845825,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8144196271896362,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.810922384262085,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8102761507034302,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.79680997133255,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7878643274307251,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8144196569919586
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.8352776765823364,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.833250880241394,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.81847083568573,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.8006560206413269,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7715337872505188,
            "answer": "assist",
            "hit": true
          },
          {
            "score": 0.7704527378082275,
            "answer": "aid",
            "hit": true
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7704527676105499
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.8052325248718262,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7906286716461182,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.7852342128753662,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.784751296043396,
            "answer": "cynical",
            "hit": false
          },
          {
            "score": 0.7846477031707764,
            "answer": "cunning",
            "hit": false
          },
          {
            "score": 0.7844845056533813,
            "answer": "intellect",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7906287312507629
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8258919715881348,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7782788872718811,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7719910144805908,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7626250386238098,
            "answer": "glitter",
            "hit": false
          },
          {
            "score": 0.7619339823722839,
            "answer": "treasures",
            "hit": false
          },
          {
            "score": 0.7616978287696838,
            "answer": "locating",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7530859112739563
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.8728536367416382,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.7846056222915649,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7703019380569458,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.7608028650283813,
            "answer": "statues",
            "hit": false
          },
          {
            "score": 0.7573806047439575,
            "answer": "tomb",
            "hit": false
          },
          {
            "score": 0.7543567419052124,
            "answer": "sculptures",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7846056520938873
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7527895569801331,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.740136444568634,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.738862931728363,
            "answer": "old",
            "hit": false
          },
          {
            "score": 0.7202367186546326,
            "answer": "fresh",
            "hit": false
          },
          {
            "score": 0.7123676538467407,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.7116532921791077,
            "answer": "other",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7041447907686234
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.9024695754051208,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.8004904389381409,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.7837194800376892,
            "answer": "bundle",
            "hit": true
          },
          {
            "score": 0.7812954187393188,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7779158353805542,
            "answer": "bundles",
            "hit": false
          },
          {
            "score": 0.7745774388313293,
            "answer": "bundled",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7489619553089142
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.849783182144165,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.764462411403656,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.7533155083656311,
            "answer": "subway",
            "hit": false
          },
          {
            "score": 0.7519282102584839,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7487921118736267,
            "answer": "rails",
            "hit": false
          },
          {
            "score": 0.7388280034065247,
            "answer": "airports",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8497832119464874
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.8357177972793579,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.810624361038208,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.8004502654075623,
            "answer": "logical",
            "hit": true
          },
          {
            "score": 0.7943239808082581,
            "answer": "coherent",
            "hit": true
          },
          {
            "score": 0.7917624711990356,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.7878278493881226,
            "answer": "analytical",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8004502654075623
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.8478842973709106,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.847253680229187,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.8322534561157227,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.8133382201194763,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.8082759976387024,
            "answer": "sensible",
            "hit": true
          },
          {
            "score": 0.8070220947265625,
            "answer": "logical",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8082759976387024
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8009665012359619,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.7482128143310547,
            "answer": "stone",
            "hit": true
          },
          {
            "score": 0.7236021757125854,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.7096579074859619,
            "answer": "pop",
            "hit": false
          },
          {
            "score": 0.7016516923904419,
            "answer": "funk",
            "hit": false
          },
          {
            "score": 0.7013579607009888,
            "answer": "rocking",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7482128143310547
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.8643393516540527,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.8008249998092651,
            "answer": "bedrooms",
            "hit": false
          },
          {
            "score": 0.7882862091064453,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7880434989929199,
            "answer": "fridge",
            "hit": false
          },
          {
            "score": 0.7871053218841553,
            "answer": "sweater",
            "hit": false
          },
          {
            "score": 0.7860399484634399,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8643393516540527
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.8223440647125244,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7770835161209106,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7444817423820496,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.736362636089325,
            "answer": "type",
            "hit": false
          },
          {
            "score": 0.7268836498260498,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.7195121049880981,
            "answer": "fashion",
            "hit": true
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7054551839828491
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "07b0345d-318e-4358-8d7e-6656a3e69a22",
      "timestamp": "2025-05-18T12:24:37.900434"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7592252492904663,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7540159225463867,
            "answer": "before",
            "hit": true
          },
          {
            "score": 0.7357082962989807,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.7132673859596252,
            "answer": "with",
            "hit": false
          },
          {
            "score": 0.7087893486022949,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.7042387127876282,
            "answer": "afterwards",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7540159523487091
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.7267432808876038,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.7195369005203247,
            "answer": "overhead",
            "hit": false
          },
          {
            "score": 0.7189322113990784,
            "answer": "looming",
            "hit": false
          },
          {
            "score": 0.7105633616447449,
            "answer": "outlined",
            "hit": false
          },
          {
            "score": 0.710159182548523,
            "answer": "downstream",
            "hit": false
          },
          {
            "score": 0.7100805640220642,
            "answer": "optimistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.702472984790802
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.9068841934204102,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8210278749465942,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.8185155391693115,
            "answer": "authoritarian",
            "hit": false
          },
          {
            "score": 0.8176419138908386,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.8160690069198608,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.8138090372085571,
            "answer": "spacious",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9068842828273773
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.7585749626159668,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.7306786775588989,
            "answer": "until",
            "hit": false
          },
          {
            "score": 0.71954745054245,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7155435085296631,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.7047201991081238,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7029626965522766,
            "answer": "beforehand",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7585750222206116
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8806121349334717,
            "answer": "starting",
            "hit": false
          },
          {
            "score": 0.8107572197914124,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.8101953268051147,
            "answer": "start",
            "hit": false
          },
          {
            "score": 0.8005781769752502,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.7971984148025513,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.7957885265350342,
            "answer": "began",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7169962972402573
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7676752209663391,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.738543689250946,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.737895131111145,
            "answer": "slain",
            "hit": false
          },
          {
            "score": 0.7324036359786987,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.7322948575019836,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.7304947972297668,
            "answer": "lifeless",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6923816800117493
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8336725234985352,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7781023979187012,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.7660565972328186,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7588063478469849,
            "answer": "diver",
            "hit": false
          },
          {
            "score": 0.754217803478241,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7529959082603455,
            "answer": "sinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 1440,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7083302140235901
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.8233765363693237,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.8157992959022522,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.8136909008026123,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.7770150899887085,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7534787654876709,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7517815828323364,
            "answer": "autumn",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 353,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6603785157203674
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8325532674789429,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.7784491777420044,
            "answer": "third",
            "hit": false
          },
          {
            "score": 0.7759852409362793,
            "answer": "last",
            "hit": true
          },
          {
            "score": 0.7427413463592529,
            "answer": "fourth",
            "hit": false
          },
          {
            "score": 0.7406713366508484,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7324658036231995,
            "answer": "only",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7759852409362793
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.88813716173172,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.822908878326416,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.8096626400947571,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.7813408374786377,
            "answer": "feedback",
            "hit": false
          },
          {
            "score": 0.7700352668762207,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.7689034938812256,
            "answer": "influx",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8229088187217712
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.8042957186698914,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7737173438072205,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7351219654083252,
            "answer": "upstairs",
            "hit": false
          },
          {
            "score": 0.734346866607666,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.717830240726471,
            "answer": "onboard",
            "hit": false
          },
          {
            "score": 0.7131094932556152,
            "answer": "downstairs",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042957186698914
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.8289788961410522,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.8277872800827026,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7776507139205933,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7660313248634338,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.7573350667953491,
            "answer": "interior",
            "hit": false
          },
          {
            "score": 0.7538501620292664,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8277872800827026
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7976250052452087,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.7674775123596191,
            "answer": "mundane",
            "hit": false
          },
          {
            "score": 0.761480450630188,
            "answer": "astonished",
            "hit": false
          },
          {
            "score": 0.7590038776397705,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7589384317398071,
            "answer": "metaphysical",
            "hit": false
          },
          {
            "score": 0.7589038610458374,
            "answer": "mystical",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7976250052452087
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.8671313524246216,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8653348088264465,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8484967947006226,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.8164020776748657,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.8050302267074585,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.7954752445220947,
            "answer": "occupants",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7440219521522522
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.7159379720687866,
            "answer": "around",
            "hit": false
          },
          {
            "score": 0.7106826305389404,
            "answer": "out",
            "hit": false
          },
          {
            "score": 0.7100695371627808,
            "answer": "down",
            "hit": false
          },
          {
            "score": 0.7004227638244629,
            "answer": "under",
            "hit": true
          },
          {
            "score": 0.6949019432067871,
            "answer": "about",
            "hit": false
          },
          {
            "score": 0.6938830614089966,
            "answer": "back",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7004227936267853
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.8728901147842407,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.8032428026199341,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.7986771464347839,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.7911384701728821,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7878923416137695,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.7745832204818726,
            "answer": "subsequently",
            "hit": true
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7745832204818726
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8893990516662598,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.8728476762771606,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.8388111591339111,
            "answer": "progressing",
            "hit": false
          },
          {
            "score": 0.8297574520111084,
            "answer": "commence",
            "hit": false
          },
          {
            "score": 0.8287743330001831,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.815754771232605,
            "answer": "progresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 8209,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7126364856958389
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.8307175040245056,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7879047393798828,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7875866293907166,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7805931568145752,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7613449096679688,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.7589419484138489,
            "answer": "decline",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 1589,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.671769991517067
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.8893114924430847,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.8493257164955139,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.8270836472511292,
            "answer": "west",
            "hit": false
          },
          {
            "score": 0.774996817111969,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7715713977813721,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.7694761753082275,
            "answer": "southern",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8893114924430847
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.9041880369186401,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.9018807411193848,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.8490812182426453,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7885104417800903,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.7848870754241943,
            "answer": "midwest",
            "hit": false
          },
          {
            "score": 0.7755201458930969,
            "answer": "south",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9041879773139954
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.886782705783844,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.7339414358139038,
            "answer": "nearer",
            "hit": false
          },
          {
            "score": 0.7287611365318298,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7274155616760254,
            "answer": "maximize",
            "hit": false
          },
          {
            "score": 0.7261996269226074,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.7241817116737366,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 5377,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6100137457251549
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7389364242553711,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7350647449493408,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.73505699634552,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.7290735840797424,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.7220063209533691,
            "answer": "authentic",
            "hit": false
          },
          {
            "score": 0.714070200920105,
            "answer": "truth",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7290736138820648
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.8881992101669312,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.838028073310852,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.8284721970558167,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.7716369032859802,
            "answer": "western",
            "hit": false
          },
          {
            "score": 0.7632838487625122,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7616543769836426,
            "answer": "southwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8881992101669312
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 23,
      "accuracy": 0.34782608695652173
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "73520e83-71b9-4c46-a6b7-50fb1d277b5a",
      "timestamp": "2025-05-18T12:24:37.953664"
    }
  }
]