[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.8496351838111877,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.7415701150894165,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.7104177474975586,
            "answer": "artists",
            "hit": false
          },
          {
            "score": 0.6913647651672363,
            "answer": "cds",
            "hit": false
          },
          {
            "score": 0.691159725189209,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.6905007362365723,
            "answer": "proteins",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.849635124206543
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.7695690393447876,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7464570999145508,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7391359806060791,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.7232272624969482,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.7108833193778992,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7016116976737976,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7391360551118851
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.9083148837089539,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.6672030687332153,
            "answer": "zones",
            "hit": false
          },
          {
            "score": 0.6589301824569702,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.6344623565673828,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6310614347457886,
            "answer": "perimeter",
            "hit": false
          },
          {
            "score": 0.6303049921989441,
            "answer": "neighborhood",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9083148241043091
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.6984363794326782,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.6547520160675049,
            "answer": "automobiles",
            "hit": false
          },
          {
            "score": 0.6510277390480042,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.6483893394470215,
            "answer": "carp",
            "hit": false
          },
          {
            "score": 0.6477625370025635,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.6433389186859131,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6984364092350006
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.7953999042510986,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.6993740200996399,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.6972699165344238,
            "answer": "university",
            "hit": false
          },
          {
            "score": 0.6765085458755493,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.6761987209320068,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6669220328330994,
            "answer": "schools",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7953999042510986
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8551889657974243,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.6833337545394897,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.6687777042388916,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.655734658241272,
            "answer": "committee",
            "hit": false
          },
          {
            "score": 0.6473526358604431,
            "answer": "counselor",
            "hit": false
          },
          {
            "score": 0.6467947959899902,
            "answer": "chiefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8551889955997467
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8433927297592163,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.7334280014038086,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7135323882102966,
            "answer": "patients",
            "hit": false
          },
          {
            "score": 0.7133361101150513,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.7116596698760986,
            "answer": "buyer",
            "hit": false
          },
          {
            "score": 0.7085861563682556,
            "answer": "buyers",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8433927893638611
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7271456718444824,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.7258973717689514,
            "answer": "night",
            "hit": false
          },
          {
            "score": 0.7223235964775085,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7169708609580994,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7108526825904846,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7085025310516357,
            "answer": "morrow",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7271456569433212
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.8402033448219299,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7669469118118286,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.7298905849456787,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.7139389514923096,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.7106723189353943,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.7099268436431885,
            "answer": "dies",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8402033746242523
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8316351175308228,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.7971467971801758,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.6762770414352417,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.6760456562042236,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.6340094208717346,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.6084628105163574,
            "answer": "institutions",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7971468269824982
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7583568692207336,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7428359985351562,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.7420656681060791,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7414105534553528,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7371053695678711,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7303909063339233,
            "answer": "develops",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7428360283374786
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.8194764256477356,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7052947282791138,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.7012737989425659,
            "answer": "comparing",
            "hit": false
          },
          {
            "score": 0.6935160160064697,
            "answer": "comparison",
            "hit": false
          },
          {
            "score": 0.6933205127716064,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.6873226165771484,
            "answer": "different",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8194764256477356
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.79742431640625,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7146920561790466,
            "answer": "direct",
            "hit": false
          },
          {
            "score": 0.7011692523956299,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.688316285610199,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.6863985061645508,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6860699653625488,
            "answer": "president",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.79742431640625
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.8099901676177979,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.6551491618156433,
            "answer": "incidents",
            "hit": false
          },
          {
            "score": 0.6391658782958984,
            "answer": "festivals",
            "hit": false
          },
          {
            "score": 0.6389025449752808,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.6340415477752686,
            "answer": "gatherings",
            "hit": false
          },
          {
            "score": 0.6329337358474731,
            "answer": "rallies",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8099901676177979
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.7931272387504578,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.6949877738952637,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.6720423698425293,
            "answer": "demo",
            "hit": false
          },
          {
            "score": 0.6642144918441772,
            "answer": "illustrates",
            "hit": false
          },
          {
            "score": 0.6636883616447449,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.6630578637123108,
            "answer": "illustrating",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7931272983551025
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.6814076900482178,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.6583129167556763,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.6525055170059204,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.6445841193199158,
            "answer": "reality",
            "hit": false
          },
          {
            "score": 0.6415704488754272,
            "answer": "facto",
            "hit": false
          },
          {
            "score": 0.6062448024749756,
            "answer": "circumstance",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6814076602458954
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.7464114427566528,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7303751707077026,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.7269045114517212,
            "answer": "friendly",
            "hit": false
          },
          {
            "score": 0.7020031213760376,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.6758325099945068,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.6624223589897156,
            "answer": "comrades",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7020030915737152
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7695141434669495,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.7208294868469238,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7113159894943237,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.7055562734603882,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.6933335065841675,
            "answer": "lord",
            "hit": false
          },
          {
            "score": 0.6894875764846802,
            "answer": "divine",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7695140838623047
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.7914031744003296,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.7134909629821777,
            "answer": "govern",
            "hit": false
          },
          {
            "score": 0.7080574631690979,
            "answer": "gov",
            "hit": false
          },
          {
            "score": 0.7048942446708679,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.6693200469017029,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.656166672706604,
            "answer": "politicians",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7914031744003296
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.8350565433502197,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.709257960319519,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.7018682956695557,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.6836312413215637,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.6751540899276733,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.6643658876419067,
            "answer": "seconds",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8350566029548645
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.8001410961151123,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7440065741539001,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.7369891405105591,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7122547626495361,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.6945896744728088,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.688000500202179,
            "answer": "suggestion",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7440065890550613
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.8376586437225342,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.7218465209007263,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.6971210241317749,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.6635603904724121,
            "answer": "dialect",
            "hit": false
          },
          {
            "score": 0.6624226570129395,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.6621823310852051,
            "answer": "terminology",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8376586437225342
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.7518749833106995,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7138791084289551,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6804258823394775,
            "answer": "lawful",
            "hit": false
          },
          {
            "score": 0.6753711700439453,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.6687909364700317,
            "answer": "statutes",
            "hit": false
          },
          {
            "score": 0.6614970564842224,
            "answer": "legal",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7518749833106995
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.7701352834701538,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7129274010658264,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.6493899822235107,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.6474514007568359,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.642441987991333,
            "answer": "mps",
            "hit": false
          },
          {
            "score": 0.6375269293785095,
            "answer": "gatherings",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7701352834701538
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8538334369659424,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.7941809296607971,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7384333610534668,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.7363146543502808,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.7198964357376099,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.7190924882888794,
            "answer": "year",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8538334369659424
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.792865514755249,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.7299486398696899,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7180620431900024,
            "answer": "morrow",
            "hit": false
          },
          {
            "score": 0.7109271287918091,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.707872748374939,
            "answer": "dusk",
            "hit": false
          },
          {
            "score": 0.704161524772644,
            "answer": "afternoon",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7928654551506042
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7838116884231567,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.6731796264648438,
            "answer": "classrooms",
            "hit": false
          },
          {
            "score": 0.6622087955474854,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.6607462763786316,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.659902811050415,
            "answer": "salaries",
            "hit": false
          },
          {
            "score": 0.6584906578063965,
            "answer": "campuses",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7838116884231567
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8414673805236816,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7376106977462769,
            "answer": "periodic",
            "hit": false
          },
          {
            "score": 0.664532482624054,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.6621319055557251,
            "answer": "duration",
            "hit": false
          },
          {
            "score": 0.6582554578781128,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.6572210788726807,
            "answer": "interval",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8414673805236816
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.8003595471382141,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7277960181236267,
            "answer": "play",
            "hit": false
          },
          {
            "score": 0.708230197429657,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7059266567230225,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.6999524831771851,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.6942996978759766,
            "answer": "gameplay",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8003595471382141
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8887832164764404,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.6934983134269714,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.6836240291595459,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.6787749528884888,
            "answer": "pop",
            "hit": false
          },
          {
            "score": 0.6766350269317627,
            "answer": "workforce",
            "hit": false
          },
          {
            "score": 0.6755553483963013,
            "answer": "demographic",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.888783186674118
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.8625973463058472,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7240002155303955,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.7099756002426147,
            "answer": "issue",
            "hit": false
          },
          {
            "score": 0.7095299959182739,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.6858278512954712,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.6848311424255371,
            "answer": "difficulties",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8625974059104919
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.7670122385025024,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.6518054008483887,
            "answer": "merchandise",
            "hit": false
          },
          {
            "score": 0.6410114765167236,
            "answer": "goods",
            "hit": false
          },
          {
            "score": 0.6385847330093384,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6327324509620667,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.6224210858345032,
            "answer": "brands",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7670122385025024
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.76900315284729,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.6367725133895874,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.6258617639541626,
            "answer": "sources",
            "hit": false
          },
          {
            "score": 0.6211754083633423,
            "answer": "commodity",
            "hit": false
          },
          {
            "score": 0.6194056868553162,
            "answer": "facilities",
            "hit": false
          },
          {
            "score": 0.6165810823440552,
            "answer": "scarce",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7690030932426453
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.6711253523826599,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.6547756195068359,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.6544569730758667,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.6525610685348511,
            "answer": "rift",
            "hit": false
          },
          {
            "score": 0.6492986679077148,
            "answer": "ridges",
            "hit": false
          },
          {
            "score": 0.6469020843505859,
            "answer": "roadway",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.640258252620697
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.7196600437164307,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7067093849182129,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.6961343288421631,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.6936624050140381,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.684002161026001,
            "answer": "drive",
            "hit": false
          },
          {
            "score": 0.6818944215774536,
            "answer": "avenue",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6936623901128769
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.7999126315116882,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.6688809394836426,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6560549139976501,
            "answer": "proteins",
            "hit": false
          },
          {
            "score": 0.6528147459030151,
            "answer": "functions",
            "hit": false
          },
          {
            "score": 0.6495016813278198,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.6453161239624023,
            "answer": "involvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7999126613140106
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.7962146997451782,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.7730520963668823,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.7535959482192993,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.7376117706298828,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.721937894821167,
            "answer": "biology",
            "hit": false
          },
          {
            "score": 0.6907626390457153,
            "answer": "astronomy",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7730521559715271
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.7955211997032166,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7419256567955017,
            "answer": "solving",
            "hit": false
          },
          {
            "score": 0.7401232123374939,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.6938257813453674,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.6812089085578918,
            "answer": "problems",
            "hit": false
          },
          {
            "score": 0.6703632473945618,
            "answer": "answer",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7955211997032166
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.7581691741943359,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7381281852722168,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7277169823646545,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.7252734899520874,
            "answer": "melody",
            "hit": false
          },
          {
            "score": 0.7175288200378418,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.7037481069564819,
            "answer": "musical",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7581692337989807
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.7438734769821167,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.686887264251709,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.6868000030517578,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.676619827747345,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.6711012721061707,
            "answer": "alley",
            "hit": false
          },
          {
            "score": 0.6703129410743713,
            "answer": "cities",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7438734769821167
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8755048513412476,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7346648573875427,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7156482934951782,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7086879014968872,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7071185111999512,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7059439420700073,
            "answer": "classroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8755048215389252
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.9161564111709595,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.6706798076629639,
            "answer": "systemic",
            "hit": false
          },
          {
            "score": 0.6332787275314331,
            "answer": "systematic",
            "hit": false
          },
          {
            "score": 0.6268261075019836,
            "answer": "apparatus",
            "hit": false
          },
          {
            "score": 0.5961901545524597,
            "answer": "mechanism",
            "hit": false
          },
          {
            "score": 0.5942687392234802,
            "answer": "regime",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9161564111709595
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.8347167372703552,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.6725128889083862,
            "answer": "anything",
            "hit": false
          },
          {
            "score": 0.6659674644470215,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.6591359376907349,
            "answer": "everything",
            "hit": false
          },
          {
            "score": 0.6376581192016602,
            "answer": "stuff",
            "hit": false
          },
          {
            "score": 0.6370633840560913,
            "answer": "people",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.834716796875
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.7741107940673828,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.7129794359207153,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7053091526031494,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.7041932344436646,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.6997170448303223,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6966549158096313,
            "answer": "villages",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7741108238697052
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7663805484771729,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.6874350905418396,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6628491878509521,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.6599301099777222,
            "answer": "hacker",
            "hit": false
          },
          {
            "score": 0.6561883687973022,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.6541860103607178,
            "answer": "players",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7663806080818176
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.7618213295936584,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.690687894821167,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.6820530891418457,
            "answer": "revision",
            "hit": false
          },
          {
            "score": 0.6665504574775696,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.6521543860435486,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.6517554521560669,
            "answer": "adaptations",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7618213295936584
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.8834664821624756,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8086603879928589,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.7392064332962036,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.7264816761016846,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6731867790222168,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.6705193519592285,
            "answer": "municipalities",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8834664523601532
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.8012444376945496,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.6902862787246704,
            "answer": "youtube",
            "hit": false
          },
          {
            "score": 0.6865898370742798,
            "answer": "videos",
            "hit": false
          },
          {
            "score": 0.6851831078529358,
            "answer": "sites",
            "hit": false
          },
          {
            "score": 0.6845851540565491,
            "answer": "links",
            "hit": false
          },
          {
            "score": 0.6796144247055054,
            "answer": "blog",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8012444078922272
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7945221066474915,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7931089401245117,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.7557839751243591,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7436268925666809,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7336413860321045,
            "answer": "weekends",
            "hit": false
          },
          {
            "score": 0.7155390381813049,
            "answer": "day",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7931089401245117
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7978106141090393,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7208613157272339,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7083703279495239,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.704465925693512,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7044291496276855,
            "answer": "yearly",
            "hit": false
          },
          {
            "score": 0.6779698133468628,
            "answer": "annually",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7978106141090393
      }
    ],
    "result": {
      "cnt_questions_correct": 41,
      "cnt_questions_total": 50,
      "accuracy": 0.82
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2ab3ea86-e24d-4a70-8bb5-e68750d77f0c",
      "timestamp": "2025-05-18T10:35:32.999939"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.8685033917427063,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.8194131851196289,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7835364937782288,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.7721964716911316,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.7249397039413452,
            "answer": "capacity",
            "hit": false
          },
          {
            "score": 0.7122056484222412,
            "answer": "capacities",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8685033917427063
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8031446933746338,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.6809175610542297,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.674353301525116,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.6697897911071777,
            "answer": "act",
            "hit": false
          },
          {
            "score": 0.6608996987342834,
            "answer": "gatherings",
            "hit": false
          },
          {
            "score": 0.6560038328170776,
            "answer": "activation",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8031447231769562
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.7984206676483154,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.6595070362091064,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.6583430171012878,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.6572067141532898,
            "answer": "organisation",
            "hit": false
          },
          {
            "score": 0.6555651426315308,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.6505980491638184,
            "answer": "ngo",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7984206676483154
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.7798207998275757,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.7791010737419128,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7764312028884888,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.7556889057159424,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.7047207355499268,
            "answer": "evaluation",
            "hit": false
          },
          {
            "score": 0.7032487392425537,
            "answer": "assessment",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7764312624931335
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8571627736091614,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.7581055164337158,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7490204572677612,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7140820622444153,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.7092859745025635,
            "answer": "soldier",
            "hit": false
          },
          {
            "score": 0.7059586048126221,
            "answer": "cavalry",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571628034114838
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7626309990882874,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.7252739667892456,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7173537611961365,
            "answer": "author",
            "hit": false
          },
          {
            "score": 0.6842888593673706,
            "answer": "authorization",
            "hit": false
          },
          {
            "score": 0.6555964946746826,
            "answer": "legitimacy",
            "hit": false
          },
          {
            "score": 0.654043436050415,
            "answer": "jurisdiction",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7626309990882874
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7649074196815491,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.6730570793151855,
            "answer": "foundations",
            "hit": false
          },
          {
            "score": 0.6411063075065613,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.6297375559806824,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.6261571645736694,
            "answer": "footing",
            "hit": false
          },
          {
            "score": 0.6255466341972351,
            "answer": "justification",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7649073600769043
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.818161129951477,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7146804332733154,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.7029700875282288,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.6765224933624268,
            "answer": "entrepreneur",
            "hit": false
          },
          {
            "score": 0.67372727394104,
            "answer": "enterprises",
            "hit": false
          },
          {
            "score": 0.672487735748291,
            "answer": "merchants",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8181611895561218
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.7317214012145996,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7312811017036438,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.6782084703445435,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.6751121878623962,
            "answer": "classification",
            "hit": false
          },
          {
            "score": 0.66339510679245,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.6606585383415222,
            "answer": "classify",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.731721431016922
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.7425156831741333,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.7134454846382141,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.701746940612793,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.6987035274505615,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6782286763191223,
            "answer": "hundred",
            "hit": false
          },
          {
            "score": 0.6772205233573914,
            "answer": "decades",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7425156533718109
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.7671062350273132,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.7088516354560852,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.7029314041137695,
            "answer": "pediatric",
            "hit": false
          },
          {
            "score": 0.6975030899047852,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.6974661350250244,
            "answer": "childhood",
            "hit": false
          },
          {
            "score": 0.6957042217254639,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7671062350273132
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.7554718255996704,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7383177280426025,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.7083148956298828,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.704391360282898,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.6844855546951294,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.6839669942855835,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.755471795797348
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.784957230091095,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.6952649354934692,
            "answer": "communal",
            "hit": false
          },
          {
            "score": 0.6784431338310242,
            "answer": "partnerships",
            "hit": false
          },
          {
            "score": 0.6781421899795532,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.6718170642852783,
            "answer": "populations",
            "hit": false
          },
          {
            "score": 0.6688519716262817,
            "answer": "villages",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.784957230091095
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.7534018158912659,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.6985205411911011,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.6983206272125244,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.6919032335281372,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6852246522903442,
            "answer": "countryside",
            "hit": false
          },
          {
            "score": 0.6788015365600586,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7534018456935883
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.80764240026474,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7135012149810791,
            "answer": "pradesh",
            "hit": false
          },
          {
            "score": 0.7032783031463623,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7023186087608337,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.695838451385498,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6893771886825562,
            "answer": "country",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8076424300670624
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.8420512080192566,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7414435744285583,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7284202575683594,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7063222527503967,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.6891905069351196,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.6492553353309631,
            "answer": "tasks",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8420512080192566
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.859171986579895,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.7334946393966675,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7027559280395508,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6986232399940491,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.6966259479522705,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6929280161857605,
            "answer": "economists",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8591719567775726
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8653804063796997,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7306930422782898,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.7068114280700684,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.6420631408691406,
            "answer": "fuel",
            "hit": false
          },
          {
            "score": 0.641432523727417,
            "answer": "power",
            "hit": false
          },
          {
            "score": 0.6205227375030518,
            "answer": "fuels",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653804063796997
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.8122320771217346,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.710503101348877,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.6823210120201111,
            "answer": "entering",
            "hit": false
          },
          {
            "score": 0.6778162121772766,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.6582756042480469,
            "answer": "enters",
            "hit": false
          },
          {
            "score": 0.6366673707962036,
            "answer": "enter",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8122320771217346
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.9000651240348816,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.6502242088317871,
            "answer": "infrastructure",
            "hit": false
          },
          {
            "score": 0.6495123505592346,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.6463069319725037,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.6425164341926575,
            "answer": "amenities",
            "hit": false
          },
          {
            "score": 0.6364565491676331,
            "answer": "venues",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9000651240348816
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.813879132270813,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7049232125282288,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.6738266944885254,
            "answer": "clan",
            "hit": false
          },
          {
            "score": 0.6660191416740417,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.6641082167625427,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.6500685214996338,
            "answer": "household",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.813879132270813
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8421972990036011,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7695023417472839,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7500409483909607,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.7248300313949585,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6799455285072327,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.6486028432846069,
            "answer": "philosophy",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8421973884105682
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.7163265347480774,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.6983582973480225,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.6867611408233643,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.6766989231109619,
            "answer": "firms",
            "hit": false
          },
          {
            "score": 0.6740071773529053,
            "answer": "enterprises",
            "hit": false
          },
          {
            "score": 0.6674728989601135,
            "answer": "factories",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6673217564821243
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.8091023564338684,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.6647071242332458,
            "answer": "museums",
            "hit": false
          },
          {
            "score": 0.6560192704200745,
            "answer": "textbooks",
            "hit": false
          },
          {
            "score": 0.6548052430152893,
            "answer": "intellectuals",
            "hit": false
          },
          {
            "score": 0.6518592238426208,
            "answer": "populations",
            "hit": false
          },
          {
            "score": 0.651293158531189,
            "answer": "dictionary",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8091023564338684
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7273409962654114,
            "answer": "lifespan",
            "hit": false
          },
          {
            "score": 0.7126402854919434,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.6909417510032654,
            "answer": "linear",
            "hit": false
          },
          {
            "score": 0.6878582835197449,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.6837338209152222,
            "answer": "love",
            "hit": false
          },
          {
            "score": 0.6807094216346741,
            "answer": "proteins",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7126403301954269
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.7636071443557739,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7364241480827332,
            "answer": "damages",
            "hit": false
          },
          {
            "score": 0.7291380167007446,
            "answer": "profits",
            "hit": false
          },
          {
            "score": 0.7123316526412964,
            "answer": "linear",
            "hit": false
          },
          {
            "score": 0.7080065011978149,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7075278759002686,
            "answer": "software",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7636071443557739
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.834907054901123,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.6980289816856384,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.6864445209503174,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6757441759109497,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.6246243715286255,
            "answer": "dementia",
            "hit": false
          },
          {
            "score": 0.6234893202781677,
            "answer": "recalling",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8349070847034454
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8935766816139221,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.6992731690406799,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.6991099119186401,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.6949061751365662,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.6628793478012085,
            "answer": "avenues",
            "hit": false
          },
          {
            "score": 0.6585350036621094,
            "answer": "chance",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8935766816139221
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8932551145553589,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.6507352590560913,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.6363307237625122,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.6321662664413452,
            "answer": "laws",
            "hit": false
          },
          {
            "score": 0.6306704878807068,
            "answer": "governance",
            "hit": false
          },
          {
            "score": 0.6238166689872742,
            "answer": "politics",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8932551145553589
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.7857863903045654,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7218042612075806,
            "answer": "prop",
            "hit": false
          },
          {
            "score": 0.6908726692199707,
            "answer": "possessions",
            "hit": false
          },
          {
            "score": 0.6840325593948364,
            "answer": "belongings",
            "hit": false
          },
          {
            "score": 0.6752767562866211,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.6743767261505127,
            "answer": "props",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7857863306999207
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8753370046615601,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7289589643478394,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.7224564552307129,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.7175381183624268,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7171070575714111,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.706364095211029,
            "answer": "accountability",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8753370940685272
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.6893885135650635,
            "answer": "secured",
            "hit": false
          },
          {
            "score": 0.6830002069473267,
            "answer": "safety",
            "hit": false
          },
          {
            "score": 0.6702195405960083,
            "answer": "encryption",
            "hit": false
          },
          {
            "score": 0.6671562194824219,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.6667077541351318,
            "answer": "terrorists",
            "hit": false
          },
          {
            "score": 0.6595238447189331,
            "answer": "thieves",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6430521309375763
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.672059178352356,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.6193280816078186,
            "answer": "succession",
            "hit": false
          },
          {
            "score": 0.6174395084381104,
            "answer": "serial",
            "hit": false
          },
          {
            "score": 0.6070857048034668,
            "answer": "sets",
            "hit": false
          },
          {
            "score": 0.6051957607269287,
            "answer": "pairs",
            "hit": false
          },
          {
            "score": 0.6036652326583862,
            "answer": "sequence",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9760398268699646
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8751814365386963,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.7628606557846069,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7143654823303223,
            "answer": "civilization",
            "hit": false
          },
          {
            "score": 0.6831265091896057,
            "answer": "mankind",
            "hit": false
          },
          {
            "score": 0.6823284029960632,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.6654418110847473,
            "answer": "soc",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8751814961433411
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.6901669502258301,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.676437258720398,
            "answer": "breeds",
            "hit": false
          },
          {
            "score": 0.6643345355987549,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.6591746211051941,
            "answer": "breed",
            "hit": false
          },
          {
            "score": 0.6565693020820618,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.6545514464378357,
            "answer": "creatures",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9773723483085632
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.8976467847824097,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.8031345009803772,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.747550368309021,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7470089197158813,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.7374066710472107,
            "answer": "storyline",
            "hit": false
          },
          {
            "score": 0.7323163151741028,
            "answer": "narratives",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8976467847824097
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.768662691116333,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.7104557752609253,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.7076525688171387,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.6841788291931152,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.6760404109954834,
            "answer": "analyses",
            "hit": false
          },
          {
            "score": 0.6646832227706909,
            "answer": "algorithm",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686627507209778
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7977153658866882,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.772284984588623,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7676764130592346,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7350588440895081,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7250264883041382,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.7235832810401917,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7977153956890106
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.8143765926361084,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7920473217964172,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.7480442523956299,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.723806619644165,
            "answer": "techniques",
            "hit": false
          },
          {
            "score": 0.6934870481491089,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.669769287109375,
            "answer": "inventions",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7480443269014359
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8837847709655762,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.7271519899368286,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7014589905738831,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.6754293441772461,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.6742810606956482,
            "answer": "doctrine",
            "hit": false
          },
          {
            "score": 0.6587956547737122,
            "answer": "doctrines",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8837848603725433
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.8671308755874634,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7815739512443542,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7448786497116089,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7435545921325684,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.7258504629135132,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.7190669775009155,
            "answer": "academic",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8671308755874634
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8346107602119446,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7104674577713013,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.6984960436820984,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.6942644119262695,
            "answer": "myriad",
            "hit": false
          },
          {
            "score": 0.68613600730896,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.6859720945358276,
            "answer": "diverse",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8346107602119446
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.7926836013793945,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.7142725586891174,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7121827602386475,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7011779546737671,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6966320872306824,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6925432682037354,
            "answer": "husband",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7926836013793945
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.7877057194709778,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.7275562286376953,
            "answer": "females",
            "hit": false
          },
          {
            "score": 0.7057942152023315,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.700317919254303,
            "answer": "feminine",
            "hit": false
          },
          {
            "score": 0.6803749799728394,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.6730574369430542,
            "answer": "actress",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7877057194709778
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 44,
      "accuracy": 0.8409090909090909
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5982fa70-98f9-4cd8-b0af-2abacc2436c1",
      "timestamp": "2025-05-18T10:35:33.221931"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8525819182395935,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.7898879051208496,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7088155150413513,
            "answer": "easier",
            "hit": false
          },
          {
            "score": 0.7062857151031494,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.705304741859436,
            "answer": "simpler",
            "hit": false
          },
          {
            "score": 0.6973546147346497,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8525819480419159
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.7628544569015503,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.6738699674606323,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6695995926856995,
            "answer": "brighter",
            "hit": false
          },
          {
            "score": 0.6678484082221985,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.6651142835617065,
            "answer": "quicker",
            "hit": false
          },
          {
            "score": 0.6643805503845215,
            "answer": "softer",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7628544569015503
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.841988742351532,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.7867066860198975,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7428560853004456,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6905763149261475,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6846573948860168,
            "answer": "brighter",
            "hit": false
          },
          {
            "score": 0.679591953754425,
            "answer": "strongly",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8419888019561768
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.8359466791152954,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.783047080039978,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7457613945007324,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.743683934211731,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.7426192760467529,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.733549177646637,
            "answer": "weaknesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8359467387199402
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0fb905f6-6fd8-49bf-a1e5-b332fcb34c67",
      "timestamp": "2025-05-18T10:35:33.422046"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7553751468658447,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7169625163078308,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6828556060791016,
            "answer": "brightest",
            "hit": false
          },
          {
            "score": 0.6799731254577637,
            "answer": "greatest",
            "hit": false
          },
          {
            "score": 0.666358470916748,
            "answer": "biggest",
            "hit": false
          },
          {
            "score": 0.6645148992538452,
            "answer": "richest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7553751468658447
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.778262734413147,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7417191863059998,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.7038267254829407,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.679826021194458,
            "answer": "brightest",
            "hit": false
          },
          {
            "score": 0.6613292694091797,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6593239307403564,
            "answer": "fastest",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.778262734413147
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 2,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fb56c4b5-353a-444c-a34d-9bcb71cf5346",
      "timestamp": "2025-05-18T10:35:33.437852"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.814828634262085,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.7862331867218018,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7580311894416809,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7509475946426392,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.6942031383514404,
            "answer": "rejects",
            "hit": false
          },
          {
            "score": 0.6896622180938721,
            "answer": "acknowledges",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8148286640644073
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.870106041431427,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.801169753074646,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6864331960678101,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6529240012168884,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6522406339645386,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6429045796394348,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870106041431427
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8986390233039856,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.7946807146072388,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7768968939781189,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7429874539375305,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.6907682418823242,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.6820986270904541,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8986390233039856
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8029281497001648,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.7210357189178467,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7173541188240051,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6943140625953674,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.692155122756958,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6801396608352661,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8029281497001648
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9529485106468201,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8503515720367432,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7966300845146179,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7851971387863159,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7759482860565186,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7080565690994263,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9529485106468201
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9303820133209229,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8159637451171875,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7685783505439758,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7356412410736084,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6710758209228516,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6599115133285522,
            "answer": "applicable",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9303820729255676
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7163196206092834,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.674822211265564,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.6724668145179749,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.6701792478561401,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.668976902961731,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.6668038368225098,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6724667847156525
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8322256803512573,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.7781514525413513,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.7742252349853516,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7674750089645386,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.7246873378753662,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.691878080368042,
            "answer": "protects",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8322256505489349
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.928131103515625,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8247908353805542,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7971620559692383,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7035604119300842,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6677577495574951,
            "answer": "comes",
            "hit": false
          },
          {
            "score": 0.6519296169281006,
            "answer": "grows",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9281312227249146
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.7728269696235657,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.6920117139816284,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.6919591426849365,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6896722316741943,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6847125887870789,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6843119263648987,
            "answer": "hates",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7728269994258881
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8026292324066162,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7525856494903564,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.7431322336196899,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6856722831726074,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.668864369392395,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6633870005607605,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8026292324066162
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.7536918520927429,
            "answer": "consistency",
            "hit": false
          },
          {
            "score": 0.6975890398025513,
            "answer": "consistently",
            "hit": false
          },
          {
            "score": 0.6703695058822632,
            "answer": "inconsistent",
            "hit": false
          },
          {
            "score": 0.6630261540412903,
            "answer": "derives",
            "hit": false
          },
          {
            "score": 0.6604876518249512,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.6592869758605957,
            "answer": "promotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6497745215892792
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.9471259713172913,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8014184236526489,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.7486857771873474,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.741848349571228,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7210197448730469,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7174883484840393,
            "answer": "possesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9471259713172913
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8155547976493835,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.7109999060630798,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6985454559326172,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6971745491027832,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6694692969322205,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.6667054891586304,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8155547678470612
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.7445587515830994,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.7221595048904419,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7160609364509583,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7029991745948792,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7019827365875244,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6829718947410583,
            "answer": "creations",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.744558721780777
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9345019459724426,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.801327109336853,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7561825513839722,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7433439493179321,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.726103663444519,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7254013419151306,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9345019459724426
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8310897946357727,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7748718857765198,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7712176442146301,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7140859365463257,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7100943326950073,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6998702883720398,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8310897946357727
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.7710831165313721,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.7142335176467896,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.6988992691040039,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.6826019883155823,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.6812041997909546,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.6799808740615845,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7710831463336945
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.7690276503562927,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.6955434083938599,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6921234130859375,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6913331151008606,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6879472732543945,
            "answer": "boasts",
            "hit": false
          },
          {
            "score": 0.6860758066177368,
            "answer": "celebrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7690276503562927
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.9120616912841797,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.8246546387672424,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7960662245750427,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7595231533050537,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.7438108921051025,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.739820122718811,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9120616912841797
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.8101939558982849,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7695806622505188,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7516618967056274,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6934034824371338,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.6831141114234924,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.6754238605499268,
            "answer": "resides",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8101938962936401
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.9176711440086365,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.819553017616272,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8041393160820007,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7889842987060547,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7697684168815613,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.7307007312774658,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9176711440086365
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7944968938827515,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7153811454772949,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.707940936088562,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6880247592926025,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.674870491027832,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6421734094619751,
            "answer": "subsequent",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7944968938827515
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9159452319145203,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8493037223815918,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8105524182319641,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8017337322235107,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7635395526885986,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.731412947177887,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9159452319145203
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8850411176681519,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7019258737564087,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.6931796073913574,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.6869149208068848,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6826574802398682,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.6714721918106079,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8850411474704742
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.9189209342002869,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8369871377944946,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7522203326225281,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7361500263214111,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.6978783011436462,
            "answer": "recognizes",
            "hit": false
          },
          {
            "score": 0.6893551349639893,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9189209342002869
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8497768640518188,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.829981803894043,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7713369131088257,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7708607912063599,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7335693836212158,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7066366076469421,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8497769236564636
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7050571441650391,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6885756850242615,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.6828873157501221,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6671478748321533,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.665120005607605,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.6589903831481934,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7050571441650391
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9386290311813354,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7765982151031494,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7568823099136353,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7294350266456604,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.725000262260437,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7194340229034424,
            "answer": "involvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9386290907859802
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.785293698310852,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.7114087343215942,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7071428298950195,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.6878527402877808,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.6833041310310364,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6821069121360779,
            "answer": "explores",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.785293698310852
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.9098877310752869,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8354849219322205,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8298094272613525,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7450444102287292,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7319296598434448,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.6778101921081543,
            "answer": "kept",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9098877906799316
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9584677219390869,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8635043501853943,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8175501823425293,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8103634119033813,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7600299119949341,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.752737283706665,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9584677219390869
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.9373582601547241,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7710548639297485,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7519783973693848,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7218259572982788,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7162286043167114,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.7036056518554688,
            "answer": "performs",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9373582601547241
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.7822282314300537,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.7438997626304626,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.7315035462379456,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7201496362686157,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7193748354911804,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7032464742660522,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7822282314300537
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.920831561088562,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8209382891654968,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7841665148735046,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7552455067634583,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7495632171630859,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7490519881248474,
            "answer": "promotion",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9208316802978516
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.8288248777389526,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.7586541175842285,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7360215187072754,
            "answer": "protective",
            "hit": false
          },
          {
            "score": 0.7131887674331665,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7016376852989197,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.6981480121612549,
            "answer": "protections",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8288248181343079
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9552756547927856,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8133956789970398,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7726154327392578,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7415822744369507,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7119231224060059,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7023724317550659,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9552756547927856
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.7737558484077454,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.6976184248924255,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.691226601600647,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6819413304328918,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6813095211982727,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.6688261032104492,
            "answer": "learns",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7737558484077454
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9169398546218872,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8099263906478882,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7666482925415039,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.740967333316803,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.740325927734375,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7401504516601562,
            "answer": "reduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.916939914226532
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8939181566238403,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8017709851264954,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7928651571273804,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6999213695526123,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6989262104034424,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.6778324842453003,
            "answer": "corresponds",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8939181268215179
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.912979006767273,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8465971350669861,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7631234526634216,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7454003095626831,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.7343599200248718,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7301114797592163,
            "answer": "retains",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9129790365695953
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.7861018776893616,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7273911237716675,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7193523645401001,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.7103475332260132,
            "answer": "recalls",
            "hit": false
          },
          {
            "score": 0.6973491907119751,
            "answer": "reminds",
            "hit": false
          },
          {
            "score": 0.69638991355896,
            "answer": "remembered",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7861018776893616
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8021031618118286,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.8000101447105408,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7849493622779846,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7402671575546265,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7339685559272766,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7087213397026062,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.784949392080307
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8173097968101501,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7972813248634338,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7413554191589355,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.7076330780982971,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7020207047462463,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.7000306844711304,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7413554340600967
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.9423544406890869,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8428542613983154,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8237560987472534,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.772453248500824,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7321276068687439,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7038424611091614,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9423545300960541
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.8248913884162903,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.7426263093948364,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.66868656873703,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6642379760742188,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.6590074300765991,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6518031358718872,
            "answer": "sent",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8248913884162903
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8284249305725098,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7657163143157959,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.7565549612045288,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.7483675479888916,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7402717471122742,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7080765962600708,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8284249603748322
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.778246283531189,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7198729515075684,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6835265159606934,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6807126998901367,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6678541898727417,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6651310324668884,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7782463133335114
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8717614412307739,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8082696795463562,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.8037998676300049,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.754359781742096,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.715509831905365,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.6898367404937744,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8717614412307739
      }
    ],
    "result": {
      "cnt_questions_correct": 45,
      "cnt_questions_total": 49,
      "accuracy": 0.9183673469387755
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2af7657c-ebf5-400c-9ef1-efa3ace150a2",
      "timestamp": "2025-05-18T10:35:33.446467"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9105609655380249,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.8278942108154297,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8044968843460083,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7726126909255981,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7275489568710327,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7121123671531677,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9105609655380249
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.8692253232002258,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.7902644872665405,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6837446689605713,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6410731673240662,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.6282029151916504,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.625990629196167,
            "answer": "making",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8692253232002258
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.7838963270187378,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.7577925324440002,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7160203456878662,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.6870736479759216,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6779787540435791,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.6673256754875183,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7838963270187378
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8859105110168457,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8473162055015564,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8433068990707397,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.7730005383491516,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7251197099685669,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7224228382110596,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8433068990707397
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.9010424613952637,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.8588265180587769,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7861553430557251,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7556567192077637,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6668722629547119,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6588470935821533,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9010424017906189
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.7784549593925476,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7084122896194458,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.6797084212303162,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6742368936538696,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.6738520264625549,
            "answer": "interviewing",
            "hit": false
          },
          {
            "score": 0.6698663830757141,
            "answer": "questioning",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7784549295902252
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.869033932685852,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8141686320304871,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.7490833401679993,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7035350799560547,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6855900287628174,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.656143069267273,
            "answer": "visiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8690339028835297
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.831592321395874,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.7832537293434143,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.7716060876846313,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7455718517303467,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7107712626457214,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6869663000106812,
            "answer": "keeping",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.831592321395874
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8667840361595154,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8542188405990601,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8070864677429199,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.6674058437347412,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.6592727899551392,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.6350918412208557,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.866784006357193
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.744706928730011,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7050838470458984,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6973450183868408,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.6830387115478516,
            "answer": "imagine",
            "hit": false
          },
          {
            "score": 0.6772719621658325,
            "answer": "doing",
            "hit": false
          },
          {
            "score": 0.6747124195098877,
            "answer": "finding",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.744706928730011
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.7573081254959106,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7525705099105835,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.7213988304138184,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6942522525787354,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.6874774098396301,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6443902850151062,
            "answer": "having",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6942522823810577
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8785715103149414,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8675817251205444,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.7293652296066284,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6922264099121094,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.6756263971328735,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6715133786201477,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8675817847251892
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.7579706311225891,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.7377634048461914,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7140182852745056,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7033936977386475,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6551885604858398,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.6439753174781799,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7579706311225891
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.8005765080451965,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.7184472680091858,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7055695056915283,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7024964094161987,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6840000152587891,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.6753352284431458,
            "answer": "creations",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8005764782428741
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8238471746444702,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.7768150568008423,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7518888115882874,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7162997722625732,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.708511233329773,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7003872394561768,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8238471746444702
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8423727750778198,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8165233135223389,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8112947940826416,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7689071893692017,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.7405552268028259,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.7119680047035217,
            "answer": "promoting",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8165233433246613
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.749170184135437,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.6993786692619324,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6930193901062012,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6915947794914246,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6679274439811707,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6641213893890381,
            "answer": "excellent",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.749170184135437
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.9066047668457031,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.8334539532661438,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7934472560882568,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7506738901138306,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.71934574842453,
            "answer": "guarantee",
            "hit": false
          },
          {
            "score": 0.7016193866729736,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9066047668457031
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.91044020652771,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8352559804916382,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8282219171524048,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7313524484634399,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6804439425468445,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6714524030685425,
            "answer": "demonstrating",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9104402363300323
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.7711013555526733,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.74446040391922,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.740186333656311,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7096703052520752,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.6449731588363647,
            "answer": "adapting",
            "hit": false
          },
          {
            "score": 0.6396697759628296,
            "answer": "extant",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6263424009084702
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.7858590483665466,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.7702902555465698,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7500997185707092,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7463966012001038,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7020288705825806,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.694129467010498,
            "answer": "expected",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7858590483665466
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.7504959106445312,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7214301824569702,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.708545446395874,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6899292469024658,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.6870889663696289,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6420003771781921,
            "answer": "pursuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6899292469024658
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8585611581802368,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.8460327386856079,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8325675129890442,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7535483837127686,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.747774600982666,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7188168168067932,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8585611581802368
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.9122762680053711,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8415676951408386,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7556970715522766,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.748571515083313,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.6991989612579346,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.671371579170227,
            "answer": "recognizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9122762680053711
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.8355731964111328,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.8306432962417603,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7824916839599609,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.767642617225647,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7392828464508057,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7206175327301025,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8355731666088104
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.6605848073959351,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6544725894927979,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.6515011191368103,
            "answer": "mentioning",
            "hit": false
          },
          {
            "score": 0.6481426954269409,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6451367735862732,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.6429166793823242,
            "answer": "insisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6451367735862732
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.8631170988082886,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8289393782615662,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7793390154838562,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.734089732170105,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6513310074806213,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.6502628922462463,
            "answer": "implicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8289393782615662
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.7209938764572144,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.7183281183242798,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.6807567477226257,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.6781991720199585,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6732380390167236,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6650676131248474,
            "answer": "studying",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7209939062595367
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.8770014643669128,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.8533568382263184,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.736673891544342,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7081734538078308,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6841086149215698,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6705473065376282,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8770014643669128
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9091030359268188,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8432089686393738,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.825757622718811,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.699216902256012,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.6946744918823242,
            "answer": "retaining",
            "hit": false
          },
          {
            "score": 0.6845995187759399,
            "answer": "sustaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9091030359268188
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8321803212165833,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8158684968948364,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7200608253479004,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.6874619126319885,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6735547780990601,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.6718473434448242,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7200608551502228
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8680514097213745,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8243701457977295,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.7728555202484131,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.738059401512146,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7317622900009155,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.703339159488678,
            "answer": "operative",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8243700861930847
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.7884881496429443,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.74156254529953,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7365700006484985,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7356448173522949,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7263425588607788,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7151404619216919,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7884881794452667
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.7885981202125549,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.7447054386138916,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.7070613503456116,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7060731649398804,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.6904110908508301,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.6882208585739136,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7885981202125549
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9070461988449097,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8387603163719177,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8003157377243042,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.771037220954895,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7145808935165405,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7025917768478394,
            "answer": "encourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9070461988449097
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.8171729445457458,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.7461692094802856,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7340930700302124,
            "answer": "protective",
            "hit": false
          },
          {
            "score": 0.7080069780349731,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7042328119277954,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.692459225654602,
            "answer": "protections",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8171729445457458
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.9145634174346924,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.8724352121353149,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7231806516647339,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7080882787704468,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7070192098617554,
            "answer": "giving",
            "hit": false
          },
          {
            "score": 0.6868944764137268,
            "answer": "offers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9145634174346924
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.7272593975067139,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.6961102485656738,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6948975324630737,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6727770566940308,
            "answer": "withdrawing",
            "hit": false
          },
          {
            "score": 0.6658072471618652,
            "answer": "exchanging",
            "hit": false
          },
          {
            "score": 0.6656290292739868,
            "answer": "sending",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7272593677043915
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.8935315608978271,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.832467794418335,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7688934206962585,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7543982863426208,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7481546401977539,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.7371584177017212,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8935315608978271
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8583274483680725,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.813565194606781,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8013565540313721,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7079831957817078,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6712135076522827,
            "answer": "reference",
            "hit": false
          },
          {
            "score": 0.6689090728759766,
            "answer": "referenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8583274185657501
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8653470277786255,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8474429845809937,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.780232310295105,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.7206556797027588,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.7172236442565918,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.6939859986305237,
            "answer": "stays",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7802322506904602
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.7693781852722168,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.7204389572143555,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7109445929527283,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.7092501521110535,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.6984148621559143,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6888535022735596,
            "answer": "forgetting",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7693782150745392
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.8017542362213135,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7982054352760315,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7841318845748901,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7398627400398254,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7025067806243896,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.694514811038971,
            "answer": "represents",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7841318845748901
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.8237802386283875,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.8057559728622437,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7627689838409424,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.71555495262146,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6941646337509155,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6864251494407654,
            "answer": "prohibiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7627689838409424
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8832541704177856,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8393602967262268,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7807130217552185,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7722377777099609,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7548441886901855,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7243848443031311,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7807130813598633
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.7929470539093018,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.7664595246315002,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.6615114212036133,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6459989547729492,
            "answer": "standing",
            "hit": false
          },
          {
            "score": 0.6456719636917114,
            "answer": "stand",
            "hit": false
          },
          {
            "score": 0.6171639561653137,
            "answer": "laying",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7929470539093018
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.858657717704773,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.8413026332855225,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8220738172531128,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.6847533583641052,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6832239031791687,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6533612012863159,
            "answer": "wasting",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8586577475070953
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8670364618301392,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8506056070327759,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8302552700042725,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7343422174453735,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7249053120613098,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7214421033859253,
            "answer": "teachers",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8670365512371063
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.7165252566337585,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7056785821914673,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.6920328140258789,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6779130101203918,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6670103073120117,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.6666862964630127,
            "answer": "ask",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7056785970926285
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8441303968429565,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.810901939868927,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8038638830184937,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7438907623291016,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6658775806427002,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.6549533605575562,
            "answer": "know",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8441303968429565
      }
    ],
    "result": {
      "cnt_questions_correct": 35,
      "cnt_questions_total": 50,
      "accuracy": 0.7
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "27a713c0-d49f-43b8-a017-4e06c44f9b47",
      "timestamp": "2025-05-18T10:35:33.656764"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.7925485968589783,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.7910885810852051,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7576426267623901,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7405528426170349,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.6761903762817383,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.6732969284057617,
            "answer": "acknowledged",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7925486266613007
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.8813583254814148,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.8474604487419128,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8072763085365295,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7782943248748779,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7641423344612122,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7399802803993225,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8813583254814148
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8100888133049011,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7888450622558594,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6813595294952393,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.645858108997345,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.644214391708374,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.6273106336593628,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.645858108997345
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8414466381072998,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.836100697517395,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7822197079658508,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.746587872505188,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.6947802305221558,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6923102140426636,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.841446578502655
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.7661079168319702,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7294495701789856,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7223896384239197,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6888875961303711,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6730872392654419,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.6526151895523071,
            "answer": "allowance",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.729449599981308
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8643556833267212,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8441972136497498,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8343740701675415,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.798456072807312,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7747260332107544,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.691632091999054,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8643556833267212
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8994661569595337,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.891816258430481,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8014687299728394,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.787187933921814,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7363439202308655,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.733305811882019,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.891816258430481
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8685181140899658,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.84151291847229,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8073702454566956,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7630032896995544,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.659404993057251,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6542218923568726,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8073702454566956
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7243448495864868,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6958951354026794,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.684910774230957,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.6619855761528015,
            "answer": "questioned",
            "hit": false
          },
          {
            "score": 0.6578834652900696,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6545395255088806,
            "answer": "tell",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6849108040332794
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8438265323638916,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.829118549823761,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.7439653873443604,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6998031139373779,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6864408254623413,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6525328159332275,
            "answer": "participated",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8438264727592468
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8555977940559387,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8392942547798157,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8130784630775452,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6659239530563354,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6481970548629761,
            "answer": "gotten",
            "hit": false
          },
          {
            "score": 0.6284355521202087,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8392943143844604
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.7074968814849854,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7019516229629517,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.6930747628211975,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6790149211883545,
            "answer": "imagine",
            "hit": false
          },
          {
            "score": 0.6642052531242371,
            "answer": "everybody",
            "hit": false
          },
          {
            "score": 0.6634715795516968,
            "answer": "knowing",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7019515931606293
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7535829544067383,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7480002641677856,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.7251318693161011,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7209836840629578,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.6704686284065247,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.645499587059021,
            "answer": "regarded",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7209837138652802
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7481598258018494,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7332318425178528,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.7255982756614685,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6969854235649109,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6564806699752808,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6502852439880371,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7332317978143692
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7471171021461487,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7329478859901428,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7068862318992615,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7021198868751526,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6740520000457764,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.6536287069320679,
            "answer": "crafted",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7471170872449875
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8690317869186401,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8481025695800781,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8181113004684448,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.733195960521698,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7136157751083374,
            "answer": "choose",
            "hit": false
          },
          {
            "score": 0.7091343998908997,
            "answer": "decisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8481025397777557
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8754280805587769,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8227221369743347,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8037280440330505,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7680192589759827,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7058718800544739,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.6805064678192139,
            "answer": "explain",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8037280440330505
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8000986576080322,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7878963351249695,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7576407194137573,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7250779867172241,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7129216194152832,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7032585144042969,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8000986874103546
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.7427054643630981,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.7271002531051636,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7179925441741943,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.7177019715309143,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.6959758996963501,
            "answer": "finding",
            "hit": false
          },
          {
            "score": 0.6922134160995483,
            "answer": "discovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7179925441741943
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.7272369861602783,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.6932604908943176,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6918691396713257,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6876727938652039,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6662070155143738,
            "answer": "excellent",
            "hit": false
          },
          {
            "score": 0.657189130783081,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7272370159626007
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8413436412811279,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.8413097858428955,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8368881344795227,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.757282018661499,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.7117702960968018,
            "answer": "guarantee",
            "hit": false
          },
          {
            "score": 0.6811515092849731,
            "answer": "guarantees",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8368881344795227
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8639880418777466,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8470858335494995,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8386874198913574,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7356594800949097,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6610506772994995,
            "answer": "demonstrate",
            "hit": false
          },
          {
            "score": 0.6522088050842285,
            "answer": "establishments",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8639881014823914
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7710352540016174,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7556337118148804,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7504926919937134,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7499496936798096,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.710780143737793,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6924745440483093,
            "answer": "hoped",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7107801139354706
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7540493011474609,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7412338256835938,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.6994933485984802,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6835747957229614,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6765658855438232,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6418650150299072,
            "answer": "ensued",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7412338107824326
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8366425037384033,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7313508987426758,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.6948474049568176,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6767897009849548,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6739983558654785,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.6665787696838379,
            "answer": "listening",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7313509583473206
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8626747131347656,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8492458462715149,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7730923891067505,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.7597103118896484,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6980944275856018,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.6687535047531128,
            "answer": "identities",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7730923891067505
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8363935351371765,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7850286960601807,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7819503545761108,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7697139382362366,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7589094042778015,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7182719707489014,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7589093744754791
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.6770078539848328,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6617041826248169,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6272612810134888,
            "answer": "iteration",
            "hit": false
          },
          {
            "score": 0.6271735429763794,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.622880220413208,
            "answer": "leaned",
            "hit": false
          },
          {
            "score": 0.6220914721488953,
            "answer": "provided",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6770078390836716
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8836515545845032,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8580305576324463,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8547234535217285,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7295546531677246,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.6427359580993652,
            "answer": "inserted",
            "hit": false
          },
          {
            "score": 0.6425679922103882,
            "answer": "introductory",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8836515843868256
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8687052726745605,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8078680038452148,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.8008686900138855,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7331315279006958,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6773457527160645,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6682549715042114,
            "answer": "implicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8078680038452148
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8625245094299316,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7630672454833984,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7005494832992554,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6877764463424683,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.6739906072616577,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.6738168597221375,
            "answer": "location",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7630672454833984
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8569124937057495,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8330760598182678,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7378396391868591,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7146621346473694,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6774499416351318,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6657893657684326,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7146621197462082
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8556931614875793,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8418633937835693,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7020128965377808,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6931790113449097,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.670553982257843,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.669497013092041,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556931912899017
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8434510827064514,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.77940833568573,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7679120898246765,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7632348537445068,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7092101573944092,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.6941505670547485,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7679120898246765
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7495489120483398,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.745549201965332,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7411787509918213,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.740506649017334,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7311062812805176,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7212687134742737,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7495488673448563
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8852709531784058,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8406236171722412,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.698728084564209,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.6983926296234131,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.6951912641525269,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6834125518798828,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6079394146800041
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8332905173301697,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7894134521484375,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7718632817268372,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7484452724456787,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.7251603007316589,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.689495325088501,
            "answer": "unpublished",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7718632519245148
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.7247691750526428,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.6985366344451904,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6799868941307068,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6537903547286987,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6529573798179626,
            "answer": "receiver",
            "hit": false
          },
          {
            "score": 0.6471999287605286,
            "answer": "receipt",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7247691750526428
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8398455381393433,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8335415124893188,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7697142958641052,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7663214206695557,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.7530996799468994,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.7359325885772705,
            "answer": "decreased",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.766321450471878
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8366320729255676,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8276834487915039,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8171341419219971,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.6928938031196594,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.6677191257476807,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6657789945602417,
            "answer": "reference",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8366320729255676
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8666070699691772,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7804620265960693,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7384734749794006,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6785930395126343,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.6758348941802979,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6583981513977051,
            "answer": "unrelated",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7384734600782394
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8878920078277588,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8753010034561157,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7664936184883118,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7225720882415771,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.7208530306816101,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.6928379535675049,
            "answer": "stays",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8878920078277588
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.7750790119171143,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7682675719261169,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7541613578796387,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.7412211894989014,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7075833082199097,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.6818290948867798,
            "answer": "changing",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7541613280773163
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8284835815429688,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.8109787106513977,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7099523544311523,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7048916816711426,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6923799514770508,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6888827681541443,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7048916965723038
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8927342295646667,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8754610419273376,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.7818810939788818,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7683632373809814,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7425894737243652,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7270097732543945,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8754610419273376
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.7509530782699585,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7432218194007874,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.6662585139274597,
            "answer": "communicated",
            "hit": false
          },
          {
            "score": 0.6561788320541382,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6525743007659912,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6519702672958374,
            "answer": "receive",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6561788618564606
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8570854663848877,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8416810035705566,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8277000188827515,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6807920932769775,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6776846051216125,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6345618963241577,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8570854365825653
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7180463671684265,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.6997910737991333,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6860841512680054,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6655809283256531,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6609920859336853,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.6379228830337524,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7180463969707489
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8473020792007446,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.819107711315155,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.8026316165924072,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7361288070678711,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6636666059494019,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.652563214302063,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8473020195960999
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.7049703598022461,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.666839599609375,
            "answer": "collaborated",
            "hit": false
          },
          {
            "score": 0.6568320989608765,
            "answer": "merged",
            "hit": false
          },
          {
            "score": 0.6452953815460205,
            "answer": "joins",
            "hit": false
          },
          {
            "score": 0.6429053544998169,
            "answer": "converge",
            "hit": false
          },
          {
            "score": 0.6418168544769287,
            "answer": "embraced",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 83,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6138625219464302
      }
    ],
    "result": {
      "cnt_questions_correct": 19,
      "cnt_questions_total": 50,
      "accuracy": 0.38
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7205fe30-380a-47fe-8bc9-ec625ba677bf",
      "timestamp": "2025-05-18T10:35:33.872622"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8866878747940063,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8090401291847229,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.7480953931808472,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6945737600326538,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6884787678718567,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6687278151512146,
            "answer": "introduces",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8866878151893616
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.7976219058036804,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7950071692466736,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7628738880157471,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.7564885020256042,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.7487989664077759,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.7389153838157654,
            "answer": "enabling",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7154895663261414
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8389649987220764,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.7976238131523132,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.790068507194519,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7424830198287964,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.7274872064590454,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.6933478116989136,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8389650285243988
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8654776215553284,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8414263725280762,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7782557010650635,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7567496299743652,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6808896064758301,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.6796323657035828,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654776811599731
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7515730857849121,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7321126461029053,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6955022811889648,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.6912084221839905,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6899475455284119,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6749548316001892,
            "answer": "questioning",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6594464033842087
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8465259075164795,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8166408538818359,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.7801962494850159,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.6768428683280945,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.6768062710762024,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.6752902865409851,
            "answer": "gets",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8465259671211243
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8363949060440063,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7409706115722656,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.72330641746521,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7168224453926086,
            "answer": "trusting",
            "hit": false
          },
          {
            "score": 0.7157586812973022,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7112407684326172,
            "answer": "believe",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8363949060440063
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7644625902175903,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7015870213508606,
            "answer": "regardless",
            "hit": false
          },
          {
            "score": 0.7002959251403809,
            "answer": "though",
            "hit": false
          },
          {
            "score": 0.6925882697105408,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.6917120218276978,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.6878337860107422,
            "answer": "although",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7644625902175903
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8829266428947449,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.819553554058075,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8096004128456116,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8018894195556641,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7963971495628357,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7692621946334839,
            "answer": "composed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8829266726970673
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8862083554267883,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8207904100418091,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7160648703575134,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.6933445930480957,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6906570196151733,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.675116240978241,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8862084150314331
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8674560785293579,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8093418478965759,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7380424737930298,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7249168157577515,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7190345525741577,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7148376107215881,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8674560785293579
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.7395410537719727,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7324477434158325,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7169620394706726,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.71632981300354,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7095178365707397,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.706157922744751,
            "answer": "generating",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7095178365707397
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.739260733127594,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.7312998175621033,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.7305775284767151,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.7052428722381592,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.6972556710243225,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6963703036308289,
            "answer": "ideally",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7392607182264328
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8988511562347412,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8265362977981567,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.775206446647644,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7352645993232727,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.7247523665428162,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7228167057037354,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8988511562347412
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8771705031394958,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7874798774719238,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7500234842300415,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7385306358337402,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6916784048080444,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6725175976753235,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8771705627441406
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8927532434463501,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8019922971725464,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.7815038561820984,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.7691582441329956,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.7491852045059204,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7426855564117432,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8927531838417053
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8714287281036377,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.7645082473754883,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7547194957733154,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.7265937924385071,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7223964929580688,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.72086101770401,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8714287579059601
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7312090992927551,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7004673480987549,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6761255264282227,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6726155281066895,
            "answer": "already",
            "hit": false
          },
          {
            "score": 0.667158305644989,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6600240468978882,
            "answer": "current",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7312090545892715
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.885395884513855,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8231152296066284,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7803215384483337,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7756877541542053,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.7688191533088684,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.736016035079956,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8853958249092102
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7345258593559265,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.6871936321258545,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.6721122860908508,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6687003970146179,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.6640922427177429,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.6604688763618469,
            "answer": "though",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7345258295536041
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8606220483779907,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8130608201026917,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8110517263412476,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.7938404083251953,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7738599181175232,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7299647927284241,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8606220483779907
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.7732095718383789,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7652132511138916,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7067391872406006,
            "answer": "deaf",
            "hit": false
          },
          {
            "score": 0.6963324546813965,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6898729205131531,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6804460883140564,
            "answer": "heard",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7732095718383789
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9027387499809265,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8092426061630249,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8069117665290833,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8043434619903564,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7848607301712036,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7331646084785461,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9027388095855713
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7160842418670654,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7144064903259277,
            "answer": "whether",
            "hit": false
          },
          {
            "score": 0.713716983795166,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7027816772460938,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6914005875587463,
            "answer": "strict",
            "hit": false
          },
          {
            "score": 0.6895262598991394,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7027816772460938
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8486697673797607,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7868269681930542,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.6836305856704712,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6833058595657349,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.682998776435852,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.6815620064735413,
            "answer": "involved",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8486698269844055
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8209038972854614,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.7259621620178223,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7235699892044067,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.7159930467605591,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7129136323928833,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7041507959365845,
            "answer": "discovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8209039270877838
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8580881357192993,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8170864582061768,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7372235059738159,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6997376680374146,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.6891582608222961,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.6828881502151489,
            "answer": "lost",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8580881655216217
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.7649025917053223,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7027440667152405,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.6997935175895691,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6932421922683716,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6902801990509033,
            "answer": "regulates",
            "hit": false
          },
          {
            "score": 0.6842330694198608,
            "answer": "examines",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7649025917053223
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8811816573143005,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8290254473686218,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8101364374160767,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7816325426101685,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7736779451370239,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.752674400806427,
            "answer": "occurrence",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8811816573143005
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8209450244903564,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7867029309272766,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7293252944946289,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7090860605239868,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7022442817687988,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.6900213360786438,
            "answer": "operations",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8209450244903564
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8955996632575989,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.7747800350189209,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7385069131851196,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.725649893283844,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7183135151863098,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7002431154251099,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8955997228622437
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8942359089851379,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8460354804992676,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.7748719453811646,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7691858410835266,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7334483861923218,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.730398416519165,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8942359685897827
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9152113795280457,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8481853008270264,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7507240772247314,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7254035472869873,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7203985452651978,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7102636098861694,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9152113795280457
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8897137641906738,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.7408261299133301,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7286192178726196,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6772171854972839,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6693058013916016,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.6682292819023132,
            "answer": "recipient",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8897137641906738
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8786010146141052,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.826626718044281,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.7871463298797607,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.746586799621582,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.7440062761306763,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7389943599700928,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8786010444164276
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8645203709602356,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8045379519462585,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7667346000671387,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7408213019371033,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7111486196517944,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6984182000160217,
            "answer": "denotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8645203709602356
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8374173641204834,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8090119957923889,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7786834239959717,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7231338620185852,
            "answer": "related",
            "hit": false
          },
          {
            "score": 0.7205822467803955,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7193220257759094,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8374173641204834
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7711346745491028,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.76052325963974,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7427530884742737,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7317673563957214,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6968839764595032,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6762078404426575,
            "answer": "surviving",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7711346745491028
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8888217210769653,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7342395186424255,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7234994173049927,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7127910852432251,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.7075728178024292,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7069580554962158,
            "answer": "corresponds",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8888217210769653
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7752211093902588,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.74592524766922,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.739830732345581,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7188736200332642,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7147936820983887,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7093204855918884,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7752211391925812
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.7810817956924438,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.7720052599906921,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7612621188163757,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7535549402236938,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7433091402053833,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7070874571800232,
            "answer": "resembles",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7810817360877991
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8302420377731323,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7460554838180542,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.7363351583480835,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7028271555900574,
            "answer": "standing",
            "hit": false
          },
          {
            "score": 0.640210747718811,
            "answer": "hanging",
            "hit": false
          },
          {
            "score": 0.633497953414917,
            "answer": "resides",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8302420675754547
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8204208612442017,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.8152083158493042,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.7470265626907349,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7339133024215698,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7114483714103699,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.6687349081039429,
            "answer": "buys",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8204209208488464
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8803731799125671,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8048778176307678,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8027271032333374,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.779190182685852,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.749287486076355,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.7250843048095703,
            "answer": "implies",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8803731799125671
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8517084121704102,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8261110186576843,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7814761400222778,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7596338987350464,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7403936982154846,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7348289489746094,
            "answer": "teachers",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8517084419727325
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.7457573413848877,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.69834965467453,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6860388517379761,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.6784220337867737,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6764837503433228,
            "answer": "warns",
            "hit": false
          },
          {
            "score": 0.6659988164901733,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7457573115825653
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8108888268470764,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.8048669099807739,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7493694424629211,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7072910070419312,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7004798054695129,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6837142705917358,
            "answer": "insight",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8048669099807739
      }
    ],
    "result": {
      "cnt_questions_correct": 42,
      "cnt_questions_total": 47,
      "accuracy": 0.8936170212765957
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8bd2df42-d00a-490d-a9c4-8cd8af5b94ff",
      "timestamp": "2025-05-18T10:35:34.089788"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8314787745475769,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8149858117103577,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7514699697494507,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7185021042823792,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.700459897518158,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6556428670883179,
            "answer": "additive",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7185020744800568
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8294934034347534,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8156499862670898,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8035863637924194,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7656593322753906,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.7440273761749268,
            "answer": "agreements",
            "hit": false
          },
          {
            "score": 0.7395985722541809,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8294933438301086
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8109573721885681,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8054819703102112,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7551827430725098,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7534119486808777,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.7427811026573181,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7348244190216064,
            "answer": "allow",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8109573721885681
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8406968116760254,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8301299810409546,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.813176155090332,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8091531991958618,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7999066710472107,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6969253420829773,
            "answer": "signaled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131761848926544
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8293042182922363,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.7960661053657532,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7730063796043396,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7318363785743713,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7303252220153809,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.6834641695022583,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8293042778968811
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8435011506080627,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8140447735786438,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7911158800125122,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7778719663619995,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6816301345825195,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.6737267971038818,
            "answer": "applicant",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8140448033809662
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7563807964324951,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7362391948699951,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7212228775024414,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6826237440109253,
            "answer": "questioned",
            "hit": false
          },
          {
            "score": 0.6812559366226196,
            "answer": "questioning",
            "hit": false
          },
          {
            "score": 0.6751338243484497,
            "answer": "requested",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6602413356304169
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8339790105819702,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.804573655128479,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7413081526756287,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.702770471572876,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6772922873497009,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6759774684906006,
            "answer": "enrolled",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8045735955238342
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8310070633888245,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.7941802144050598,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7699174284934998,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7068454027175903,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.6749279499053955,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.657461404800415,
            "answer": "getting",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7941802144050598
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7084652185440063,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7018284797668457,
            "answer": "though",
            "hit": false
          },
          {
            "score": 0.6945583820343018,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.692987322807312,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.69270920753479,
            "answer": "actually",
            "hit": false
          },
          {
            "score": 0.692696750164032,
            "answer": "regardless",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.708465188741684
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.809138298034668,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8075382113456726,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7234627604484558,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.6968653202056885,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6939166784286499,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.681032657623291,
            "answer": "composed",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6939167082309723
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8433176875114441,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8005224466323853,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7456567287445068,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7379804253578186,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7241136431694031,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7125915288925171,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8433177471160889
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7612253427505493,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7475781440734863,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7080981731414795,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.6985762119293213,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.6899063587188721,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.6886122226715088,
            "answer": "creations",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7612253725528717
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8227208256721497,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8028732538223267,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7880418300628662,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.7663384079933167,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7187438011169434,
            "answer": "decisions",
            "hit": false
          },
          {
            "score": 0.7086496353149414,
            "answer": "decision",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7880418598651886
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8275884985923767,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8267006874084473,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7831083536148071,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7489505410194397,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7373133897781372,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7249476909637451,
            "answer": "description",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7489505261182785
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8068264126777649,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.793569803237915,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.782572865486145,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.752188503742218,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6945480704307556,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6794608235359192,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.782572865486145
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8560928702354431,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8209229707717896,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7936418056488037,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7479238510131836,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.679205060005188,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.6647763252258301,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7936418056488037
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7086657881736755,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7059206962585449,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6982859969139099,
            "answer": "already",
            "hit": false
          },
          {
            "score": 0.6860879063606262,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.677405595779419,
            "answer": "current",
            "hit": false
          },
          {
            "score": 0.6692430377006531,
            "answer": "exists",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6860878765583038
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.777664303779602,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7578968405723572,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7445155382156372,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.7178229093551636,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7165492177009583,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7103713750839233,
            "answer": "expected",
            "hit": true
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7103713899850845
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.7950832843780518,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7838234901428223,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.7619749307632446,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7358918190002441,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.7329661846160889,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.6766310930252075,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7329661548137665
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7018181681632996,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6862510442733765,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.6843908429145813,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6730297207832336,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.6587031483650208,
            "answer": "though",
            "hit": false
          },
          {
            "score": 0.6579718589782715,
            "answer": "although",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6464840173721313
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7639725208282471,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7217352986335754,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7055689692497253,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7001272439956665,
            "answer": "deaf",
            "hit": false
          },
          {
            "score": 0.696237325668335,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6950648427009583,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055689990520477
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.841642439365387,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8316167593002319,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8256341218948364,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8115246295928955,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7943702340126038,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7396258115768433,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8416424691677094
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7163617014884949,
            "answer": "whether",
            "hit": false
          },
          {
            "score": 0.6952837705612183,
            "answer": "strict",
            "hit": false
          },
          {
            "score": 0.6923365592956543,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6858718395233154,
            "answer": "such",
            "hit": false
          },
          {
            "score": 0.6844896078109741,
            "answer": "otherwise",
            "hit": false
          },
          {
            "score": 0.6771910786628723,
            "answer": "damages",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6660313308238983
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8647353649139404,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8574222326278687,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.841133713722229,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.7612133622169495,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.6700706481933594,
            "answer": "introductory",
            "hit": false
          },
          {
            "score": 0.6504485607147217,
            "answer": "adopting",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8574222326278687
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.7819236516952515,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7627465128898621,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7169631123542786,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6886084675788879,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.680948793888092,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.6744927167892456,
            "answer": "consisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7169630825519562
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8665433526039124,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7145519852638245,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7011944055557251,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.7000940442085266,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.6975576877593994,
            "answer": "finding",
            "hit": false
          },
          {
            "score": 0.6951748132705688,
            "answer": "relocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7145519852638245
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8234878182411194,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8004807233810425,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7305587530136108,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.704025149345398,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.7013798952102661,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6751317977905273,
            "answer": "loss",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7013798654079437
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7051985263824463,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7011802196502686,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.696681022644043,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6836832761764526,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.674518883228302,
            "answer": "marketing",
            "hit": false
          },
          {
            "score": 0.6627414226531982,
            "answer": "managed",
            "hit": true
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.662741482257843
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8550537824630737,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7718132138252258,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7641525268554688,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7520084977149963,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7251282930374146,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.708455502986908,
            "answer": "bride",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7520084977149963
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7777431011199951,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7451061010360718,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7437624335289001,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7216614484786987,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7159532308578491,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.6942676305770874,
            "answer": "operations",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6733936071395874
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8264289498329163,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.824974775314331,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7418534159660339,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7213594913482666,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7184885740280151,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6991479992866516,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8264289498329163
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8490396738052368,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8474197387695312,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7952432632446289,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7842626571655273,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.7757717370986938,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.7330957651138306,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7757717967033386
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8479775190353394,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8305290937423706,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7478184700012207,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.72154700756073,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7133958339691162,
            "answer": "giving",
            "hit": false
          },
          {
            "score": 0.6842692494392395,
            "answer": "supplied",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6135693565011024
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.830159604549408,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7817516326904297,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7756490707397461,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7586286067962646,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.7388540506362915,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7182034254074097,
            "answer": "printing",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7388540655374527
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.817024290561676,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7778118252754211,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7294315099716187,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6734322905540466,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.669106125831604,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.6658797264099121,
            "answer": "reception",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7778118252754211
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8299384117126465,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.7946962714195251,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7873252034187317,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7610400915145874,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.7534552216529846,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7529840469360352,
            "answer": "reduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7610400915145874
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8261077404022217,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.775824248790741,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7714228630065918,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7513701319694519,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7362743616104126,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7347879409790039,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7513701319694519
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.7629302740097046,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7550120949745178,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7426140308380127,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7161117196083069,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6778244376182556,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.657351553440094,
            "answer": "other",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7550120949745178
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.86628258228302,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8373687863349915,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8009816408157349,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7940640449523926,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7747457027435303,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.7316871881484985,
            "answer": "substitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8662826120853424
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.812828779220581,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7440560460090637,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7390639185905457,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7056408524513245,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7021424770355225,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.6972260475158691,
            "answer": "representation",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7440560758113861
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7580994367599487,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7546007633209229,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7326364517211914,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7324974536895752,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.7207322120666504,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7201865911483765,
            "answer": "require",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.73249751329422
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8428627252578735,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7636143565177917,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6732332706451416,
            "answer": "transmitting",
            "hit": false
          },
          {
            "score": 0.6546120047569275,
            "answer": "transmitted",
            "hit": false
          },
          {
            "score": 0.652922511100769,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6475012898445129,
            "answer": "dispatched",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6529225707054138
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8312171101570129,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.764872670173645,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7520906329154968,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7500160336494446,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7416120767593384,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6627304553985596,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.752090573310852
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.7896618843078613,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.7815248966217041,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.738929271697998,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.6931940317153931,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.6672936081886292,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.6645779609680176,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7815248668193817
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8256514072418213,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8158972859382629,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.7853533029556274,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7628416419029236,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7469937801361084,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7417582273483276,
            "answer": "teachers",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8158972859382629
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.6809784173965454,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.6797235012054443,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6739509105682373,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6582061648368835,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.6508493423461914,
            "answer": "yelled",
            "hit": false
          },
          {
            "score": 0.6472243070602417,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6809784173965454
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8237317800521851,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7883826494216919,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7409443259239197,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7097162008285522,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.6905275583267212,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.683906078338623,
            "answer": "insight",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7883826792240143
      }
    ],
    "result": {
      "cnt_questions_correct": 10,
      "cnt_questions_total": 48,
      "accuracy": 0.20833333333333334
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "29756c63-8998-4eef-bcfe-93e91d3a0209",
      "timestamp": "2025-05-18T10:35:34.290061"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8315230011940002,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.8284485936164856,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.745523989200592,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7365992069244385,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6929577589035034,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6502435207366943,
            "answer": "additive",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7365991473197937
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8592454195022583,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8452531099319458,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8093982338905334,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7338426113128662,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7188830971717834,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.6990383863449097,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.845253050327301
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.7764120697975159,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.6925932168960571,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.691558837890625,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.658004641532898,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6456677913665771,
            "answer": "tolerated",
            "hit": false
          },
          {
            "score": 0.6441446542739868,
            "answer": "permitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.691558837890625
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8577877879142761,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8548088073730469,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8253346085548401,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7810745239257812,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.770749032497406,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.7171259522438049,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8577877879142761
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8977506160736084,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8862115740776062,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.7870558500289917,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7775402069091797,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7578932046890259,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7569674849510193,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8862116038799286
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8688735961914062,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.793644905090332,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7904766201972961,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7012941837310791,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6886610388755798,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6406306624412537,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7904766201972961
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.6541522145271301,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6411857008934021,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6401283740997314,
            "answer": "tasks",
            "hit": false
          },
          {
            "score": 0.6390222907066345,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.6328403353691101,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6292234063148499,
            "answer": "begged",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6390222758054733
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.891764223575592,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8624353408813477,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7883509397506714,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6541200876235962,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6448716521263123,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6241629719734192,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8624353408813477
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.844925582408905,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7749367952346802,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7697941660881042,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7453489899635315,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7201907634735107,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.708709716796875,
            "answer": "believe",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.844925582408905
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.791086733341217,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7375770807266235,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7272148132324219,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.7222063541412354,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6988246440887451,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6840366125106812,
            "answer": "deemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.791086733341217
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9166834354400635,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.8286283016204834,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7911779284477234,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7785876393318176,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7219101786613464,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7213119268417358,
            "answer": "composed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9166834056377411
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8892067074775696,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8345595002174377,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.7316833734512329,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.6954643726348877,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.6926933526992798,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6681019067764282,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7316833734512329
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8773956298828125,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8189796209335327,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7526440024375916,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7168418169021606,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7159286737442017,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.707667887210846,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8773956298828125
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7200385332107544,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7123964428901672,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.6726157665252686,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6637170314788818,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6572917699813843,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.6518488526344299,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7123964130878448
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8731778860092163,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8653936982154846,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8097836375236511,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7209680080413818,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7135541439056396,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.7080022096633911,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653936684131622
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8758095502853394,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8262581825256348,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8017710447311401,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7536448836326599,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6948644518852234,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.6849703788757324,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8017711043357849
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8315660953521729,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8031221628189087,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7889460325241089,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7475470900535583,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.696933388710022,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6799810528755188,
            "answer": "progressed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8031222224235535
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8574873805046082,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8325808644294739,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8046173453330994,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.6995119452476501,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6714403629302979,
            "answer": "demonstrates",
            "hit": false
          },
          {
            "score": 0.6692187786102295,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.804617315530777
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7843112945556641,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7752629518508911,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7487735748291016,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7478548288345337,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7425647377967834,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.7358828186988831,
            "answer": "hoped",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7239506840705872
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.807540774345398,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.783654510974884,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7727051973342896,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.767861008644104,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7633852362632751,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.6823561191558838,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7727052569389343
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7888175249099731,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7506219148635864,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7011006474494934,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6326664686203003,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.6193215847015381,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.6129818558692932,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888174951076508
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.890903890132904,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8719016313552856,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8122767806053162,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7723511457443237,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7701070308685303,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7492174506187439,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.890903890132904
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8502637147903442,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7801883220672607,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7387031316757202,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7227067351341248,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6967738270759583,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.6811552047729492,
            "answer": "listening",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7801883220672607
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7819758057594299,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6936410665512085,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6644315719604492,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.6634646654129028,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.6542494297027588,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.6495152711868286,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7819758057594299
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8497306704521179,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.785685658454895,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.7850345373153687,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7553324103355408,
            "answer": "intention",
            "hit": false
          },
          {
            "score": 0.7482744455337524,
            "answer": "intentions",
            "hit": false
          },
          {
            "score": 0.7284102439880371,
            "answer": "planned",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.785685658454895
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8674864768981934,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8471649885177612,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8386775851249695,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7225314378738403,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.6561787724494934,
            "answer": "introductory",
            "hit": false
          },
          {
            "score": 0.647409200668335,
            "answer": "debuted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.847165048122406
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8862058520317078,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7918184995651245,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7917678356170654,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7014794945716858,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6926597952842712,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6913285255432129,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7917678356170654
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8594266176223755,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.817668080329895,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7787804007530212,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7286845445632935,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6999348402023315,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6896503567695618,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7286845296621323
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8514076471328735,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8500152826309204,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7068085670471191,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6781483888626099,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6670800447463989,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6670769453048706,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8500152826309204
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9168159365653992,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.9090222120285034,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8337832093238831,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7793959379196167,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7774729132652283,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7420408129692078,
            "answer": "happen",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9168159663677216
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8788361549377441,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.776363730430603,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7578819394111633,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.7395548820495605,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7082396745681763,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6922163963317871,
            "answer": "operative",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7578819692134857
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8448646664619446,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8383204936981201,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7628066539764404,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7311777472496033,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7237582206726074,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7214556932449341,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8448646664619446
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8632799386978149,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8388026356697083,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8090164661407471,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.7770760655403137,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7688466310501099,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.71053147315979,
            "answer": "advocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8090164363384247
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8890351057052612,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8306177854537964,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7252702713012695,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.714436948299408,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.700745701789856,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.6829099655151367,
            "answer": "supplied",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 54,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5916668921709061
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8427541255950928,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8113423585891724,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7147446870803833,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.7060564160346985,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.662801206111908,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6609189510345459,
            "answer": "underwent",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8113423585891724
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.838882565498352,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8110144734382629,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8010731935501099,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7026525735855103,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.689408540725708,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6872026324272156,
            "answer": "denotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8110144138336182
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8618506789207458,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7762196660041809,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7270731925964355,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6883654594421387,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6648445129394531,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.6547209620475769,
            "answer": "unrelated",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7270732223987579
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8613098859786987,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8553116321563721,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7423771619796753,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6705487370491028,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6699349880218506,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6598575115203857,
            "answer": "stay",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8553115725517273
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8629123568534851,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8342092037200928,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7803801894187927,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.7789061665534973,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7592078447341919,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7280164957046509,
            "answer": "substitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8629123568534851
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8210934996604919,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7497272491455078,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7149415016174316,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6875697374343872,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6829220056533813,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.6812352538108826,
            "answer": "constitutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7497272342443466
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7180985808372498,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6955862045288086,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.692118763923645,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6844441294670105,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6764699220657349,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.6725653409957886,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6921187341213226
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8896741271018982,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8856269121170044,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.7829087376594543,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7305854558944702,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7188727855682373,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7125059366226196,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8856269121170044
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8572041988372803,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7773159742355347,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.680687665939331,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6765146255493164,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6641440987586975,
            "answer": "communicated",
            "hit": false
          },
          {
            "score": 0.6631163358688354,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6765146404504776
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8635828495025635,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8277746438980103,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7788116335868835,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.712291955947876,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6940066814422607,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6651877760887146,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8277745842933655
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8589450120925903,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8127275705337524,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7888806462287903,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.779969334602356,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7432824969291687,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.7361242771148682,
            "answer": "suggestion",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8589450716972351
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8594280481338501,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7131186723709106,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6820239424705505,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6762557029724121,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.6729072332382202,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6550642848014832,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8594280183315277
      }
    ],
    "result": {
      "cnt_questions_correct": 13,
      "cnt_questions_total": 46,
      "accuracy": 0.2826086956521739
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "cb2bbadd-de57-4c1d-8356-14dc55004458",
      "timestamp": "2025-05-18T10:35:34.497734"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7988637089729309,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.6801892518997192,
            "answer": "relentless",
            "hit": false
          },
          {
            "score": 0.6682692766189575,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.6512599587440491,
            "answer": "savage",
            "hit": false
          },
          {
            "score": 0.6468828320503235,
            "answer": "arrogant",
            "hit": false
          },
          {
            "score": 0.6422097682952881,
            "answer": "fierce",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 2453,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5697558298707008
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7776500582695007,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.6324584484100342,
            "answer": "rachel",
            "hit": false
          },
          {
            "score": 0.6221252679824829,
            "answer": "unemployed",
            "hit": false
          },
          {
            "score": 0.6184166669845581,
            "answer": "refugee",
            "hit": false
          },
          {
            "score": 0.616780698299408,
            "answer": "refugees",
            "hit": false
          },
          {
            "score": 0.6007946729660034,
            "answer": "rita",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 2464,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5395822301506996
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "357c8c6a-edb7-4176-af38-8e658feb68dd",
      "timestamp": "2025-05-18T10:35:34.694379"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.6030656099319458,
            "answer": "impossible",
            "hit": false
          },
          {
            "score": 0.5967855453491211,
            "answer": "abel",
            "hit": false
          },
          {
            "score": 0.5894848108291626,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.5889464616775513,
            "answer": "unavailable",
            "hit": false
          },
          {
            "score": 0.5887066721916199,
            "answer": "unwanted",
            "hit": false
          },
          {
            "score": 0.5882267355918884,
            "answer": "unrelated",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5894847959280014
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8119652271270752,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.6852225661277771,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.6847327947616577,
            "answer": "accept",
            "hit": false
          },
          {
            "score": 0.6833192110061646,
            "answer": "tolerated",
            "hit": false
          },
          {
            "score": 0.6744370460510254,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.6734334230422974,
            "answer": "applicable",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8119651973247528
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8225606679916382,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.7779251337051392,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7489091157913208,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.7484018802642822,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.7289785742759705,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.7101802825927734,
            "answer": "influenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7779251933097839
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8239890933036804,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.7455439567565918,
            "answer": "availability",
            "hit": false
          },
          {
            "score": 0.6860643625259399,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.6782638430595398,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.676432728767395,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6654310822486877,
            "answer": "unreliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.823989063501358
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.7968525886535645,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.7255324125289917,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6945103406906128,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.6926403641700745,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.688835859298706,
            "answer": "unable",
            "hit": false
          },
          {
            "score": 0.6756584048271179,
            "answer": "acquainted",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7968525886535645
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.6650577783584595,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.6615700721740723,
            "answer": "unidentified",
            "hit": false
          },
          {
            "score": 0.6615017056465149,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.656438410282135,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.6538925170898438,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.6507490873336792,
            "answer": "pursuant",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6318880021572113
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.7476644515991211,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.7319552898406982,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.7071569561958313,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.6844752430915833,
            "answer": "unchanged",
            "hit": true
          },
          {
            "score": 0.6804366707801819,
            "answer": "altering",
            "hit": false
          },
          {
            "score": 0.6776853799819946,
            "answer": "alteration",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6844752430915833
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8226296305656433,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.7684919238090515,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7492775917053223,
            "answer": "comfort",
            "hit": false
          },
          {
            "score": 0.7138406038284302,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7131832838058472,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.7062708139419556,
            "answer": "cozy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8226296007633209
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.7543760538101196,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.754086971282959,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7515663504600525,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7033743858337402,
            "answer": "aware",
            "hit": false
          },
          {
            "score": 0.6857507228851318,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.6781579256057739,
            "answer": "intentional",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7543760240077972
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.761420726776123,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.7319197654724121,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7080721855163574,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.7076115012168884,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7071166634559631,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.6916363835334778,
            "answer": "unemployment",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7614206671714783
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.70350581407547,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7005505561828613,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.700021505355835,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.6955958604812622,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6899642944335938,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.684609591960907,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6813638806343079
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.7839926481246948,
            "answer": "completed",
            "hit": false
          },
          {
            "score": 0.7789901494979858,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.7563420534133911,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.7248129844665527,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.6807264685630798,
            "answer": "completing",
            "hit": false
          },
          {
            "score": 0.6755068898200989,
            "answer": "finish",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7248129844665527
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8674606084823608,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7862337827682495,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.7066059112548828,
            "answer": "luck",
            "hit": false
          },
          {
            "score": 0.6916701197624207,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.6882467269897461,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.6828534603118896,
            "answer": "grateful",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7862337231636047
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7432095408439636,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.6887511014938354,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6729124784469604,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6587415933609009,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.6536880731582642,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.6512421369552612,
            "answer": "happily",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7432095408439636
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.761296272277832,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.7510175704956055,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7440802454948425,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7386199831962585,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.729914665222168,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7236928343772888,
            "answer": "identifying",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7612962126731873
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.6960555911064148,
            "answer": "unknown",
            "hit": true
          },
          {
            "score": 0.671987771987915,
            "answer": "unidentified",
            "hit": false
          },
          {
            "score": 0.6670202016830444,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.6652064323425293,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6622582674026489,
            "answer": "unnamed",
            "hit": false
          },
          {
            "score": 0.660407543182373,
            "answer": "unpopular",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6960555911064148
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8154234886169434,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7101448774337769,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.6918247938156128,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.6915862560272217,
            "answer": "unauthorized",
            "hit": false
          },
          {
            "score": 0.6905235052108765,
            "answer": "unconstitutional",
            "hit": false
          },
          {
            "score": 0.6844733953475952,
            "answer": "improper",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8154234290122986
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.7518090009689331,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7480890154838562,
            "answer": "payment",
            "hit": false
          },
          {
            "score": 0.7152023315429688,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.7035682797431946,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.6913723945617676,
            "answer": "funded",
            "hit": false
          },
          {
            "score": 0.6722460985183716,
            "answer": "financed",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7518090307712555
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.7944015264511108,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.779435932636261,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7697559595108032,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7183336615562439,
            "answer": "pleasing",
            "hit": false
          },
          {
            "score": 0.7132483720779419,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.6981081962585449,
            "answer": "lovely",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7944014668464661
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.7399048805236816,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7068121433258057,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.6549642086029053,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.6540079712867737,
            "answer": "invalid",
            "hit": false
          },
          {
            "score": 0.6500897407531738,
            "answer": "unidentified",
            "hit": false
          },
          {
            "score": 0.650002658367157,
            "answer": "inaccessible",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7399048656225204
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8087339401245117,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7197458744049072,
            "answer": "predict",
            "hit": false
          },
          {
            "score": 0.716235876083374,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.6909826397895813,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.6791872382164001,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.6779155135154724,
            "answer": "disappointing",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8087340295314789
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.7633602619171143,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.7453980445861816,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7131729125976562,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7129595279693604,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.70252925157547,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6855063438415527,
            "answer": "manuscripts",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7633602023124695
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.7911323308944702,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7221162915229797,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7145979404449463,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.710352897644043,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.6827490329742432,
            "answer": "decent",
            "hit": false
          },
          {
            "score": 0.6809346675872803,
            "answer": "respectable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7911323308944702
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.7694027423858643,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.7606481909751892,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.735739529132843,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7012424468994141,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.69179767370224,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.6658698916435242,
            "answer": "corresponding",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7694027423858643
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8307417631149292,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.7192195057868958,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.7042719721794128,
            "answer": "inaccurate",
            "hit": false
          },
          {
            "score": 0.679731547832489,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.6722162961959839,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.6649726629257202,
            "answer": "unstable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8307417631149292
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.7532715797424316,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7394275069236755,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.7302122116088867,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7077160477638245,
            "answer": "designated",
            "hit": false
          },
          {
            "score": 0.6967158913612366,
            "answer": "stated",
            "hit": false
          },
          {
            "score": 0.6860940456390381,
            "answer": "indicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7394275218248367
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8610222339630127,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.7787485122680664,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.7639927268028259,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7498586177825928,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7233260869979858,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6960974931716919,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8610222637653351
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.7424468398094177,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.7217289209365845,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.6929268836975098,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.6702741384506226,
            "answer": "exploited",
            "hit": false
          },
          {
            "score": 0.6690822243690491,
            "answer": "utilization",
            "hit": false
          },
          {
            "score": 0.6651788353919983,
            "answer": "unreliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7217289507389069
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7845802307128906,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7267270684242249,
            "answer": "ordinary",
            "hit": false
          },
          {
            "score": 0.6993399858474731,
            "answer": "normal",
            "hit": false
          },
          {
            "score": 0.6857677698135376,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.66804039478302,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.6653300523757935,
            "answer": "unusual",
            "hit": true
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6653299927711487
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.8081001043319702,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.7941004037857056,
            "answer": "wished",
            "hit": false
          },
          {
            "score": 0.783444881439209,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.7265779376029968,
            "answer": "desired",
            "hit": false
          },
          {
            "score": 0.7216634750366211,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.6920819282531738,
            "answer": "sought",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6776344478130341
      }
    ],
    "result": {
      "cnt_questions_correct": 19,
      "cnt_questions_total": 30,
      "accuracy": 0.6333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "54660c73-dbca-4d40-9999-08c3be15ddc6",
      "timestamp": "2025-05-18T10:35:34.705243"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7184322476387024,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.6827692985534668,
            "answer": "therefore",
            "hit": false
          },
          {
            "score": 0.6576724648475647,
            "answer": "respectively",
            "hit": false
          },
          {
            "score": 0.6542438268661499,
            "answer": "reportedly",
            "hit": false
          },
          {
            "score": 0.6534591913223267,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.6517225503921509,
            "answer": "appropriately",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6489828824996948
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.6920161247253418,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.6819702982902527,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.6642061471939087,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.6626260876655579,
            "answer": "act",
            "hit": false
          },
          {
            "score": 0.6546316146850586,
            "answer": "literally",
            "hit": false
          },
          {
            "score": 0.6531132459640503,
            "answer": "honestly",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6920161098241806
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.6966685056686401,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.670741856098175,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.6435984373092651,
            "answer": "alternatively",
            "hit": false
          },
          {
            "score": 0.6323091387748718,
            "answer": "farther",
            "hit": false
          },
          {
            "score": 0.6318343281745911,
            "answer": "importantly",
            "hit": false
          },
          {
            "score": 0.629060685634613,
            "answer": "added",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6966685056686401
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.7967785596847534,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7294856905937195,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.6939630508422852,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.6921646595001221,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.6858149766921997,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6722568273544312,
            "answer": "obviously",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6239782646298409
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.7345763444900513,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.7275332808494568,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.6978020668029785,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.6965442895889282,
            "answer": "awesome",
            "hit": false
          },
          {
            "score": 0.6767147779464722,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.6710097193717957,
            "answer": "adorable",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7345763742923737
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7487403154373169,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.6846964359283447,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6653012037277222,
            "answer": "essential",
            "hit": false
          },
          {
            "score": 0.6568732857704163,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.6451373100280762,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.6415397524833679,
            "answer": "fiercely",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7487403601408005
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.8236377239227295,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.7383201122283936,
            "answer": "cult",
            "hit": false
          },
          {
            "score": 0.7210845351219177,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.6948993802070618,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.6695886850357056,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.6665651202201843,
            "answer": "linguistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8236377239227295
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.7896103858947754,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7767881751060486,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7245979309082031,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7038909196853638,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.6941287517547607,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.658416211605072,
            "answer": "decisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6132760643959045
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7604634761810303,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7274423837661743,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.714339017868042,
            "answer": "differential",
            "hit": false
          },
          {
            "score": 0.7112594246864319,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7075499892234802,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.7020127773284912,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7604634761810303
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8138386607170105,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7129734754562378,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6913743019104004,
            "answer": "digit",
            "hit": false
          },
          {
            "score": 0.6523057222366333,
            "answer": "smartphone",
            "hit": false
          },
          {
            "score": 0.6487088203430176,
            "answer": "multimedia",
            "hit": false
          },
          {
            "score": 0.6451882123947144,
            "answer": "culturally",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8138387203216553
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7668333053588867,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.7373604774475098,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.7290257811546326,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6752741932868958,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.6734501719474792,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.6727769374847412,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7373604625463486
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.7865821719169617,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.7392646670341492,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.6904889345169067,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.6868457794189453,
            "answer": "epa",
            "hit": false
          },
          {
            "score": 0.6724222302436829,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6698750853538513,
            "answer": "eco",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7865821719169617
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.7916425466537476,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.7274628281593323,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.7186230421066284,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7125428915023804,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.7013944387435913,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6986486315727234,
            "answer": "numerous",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7916425466537476
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.8265926241874695,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.8246563076972961,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.8027303218841553,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7835113406181335,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7505425810813904,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7343169450759888,
            "answer": "celebrated",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7505426108837128
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.8131878972053528,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.7489902377128601,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7423099279403687,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7314625978469849,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.701850950717926,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6927245855331421,
            "answer": "fiscal",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131879568099976
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8023374080657959,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.7060984373092651,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6671874523162842,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.6506896615028381,
            "answer": "globe",
            "hit": false
          },
          {
            "score": 0.639628529548645,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.6346795558929443,
            "answer": "nationally",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8023373782634735
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.7470137476921082,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.7450518012046814,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7347583174705505,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7258843183517456,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.7219310998916626,
            "answer": "history",
            "hit": false
          },
          {
            "score": 0.7034507989883423,
            "answer": "archaeological",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.725884348154068
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8748799562454224,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.8377093076705933,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.8161717653274536,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.7890596389770508,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.7717840671539307,
            "answer": "tremendous",
            "hit": false
          },
          {
            "score": 0.77086341381073,
            "answer": "hugely",
            "hit": true
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.77086341381073
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.7338771224021912,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7334439754486084,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.6835834980010986,
            "answer": "quickly",
            "hit": false
          },
          {
            "score": 0.6776849627494812,
            "answer": "promptly",
            "hit": false
          },
          {
            "score": 0.6739633679389954,
            "answer": "directly",
            "hit": false
          },
          {
            "score": 0.6612593531608582,
            "answer": "swiftly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7334439754486084
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.8119251132011414,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.7267581224441528,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.7106113433837891,
            "answer": "valuable",
            "hit": false
          },
          {
            "score": 0.7104621529579163,
            "answer": "interesting",
            "hit": false
          },
          {
            "score": 0.6953848600387573,
            "answer": "relevant",
            "hit": false
          },
          {
            "score": 0.693061888217926,
            "answer": "importance",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6115685850381851
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.771161675453186,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7485688328742981,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.7244921922683716,
            "answer": "progressively",
            "hit": false
          },
          {
            "score": 0.7237548232078552,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7049874067306519,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.6998006105422974,
            "answer": "steadily",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7485688626766205
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7611862421035767,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.7253255248069763,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6808793544769287,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.656838059425354,
            "answer": "intern",
            "hit": false
          },
          {
            "score": 0.6476571559906006,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.6437420845031738,
            "answer": "indirectly",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7611861824989319
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.7453674077987671,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.6900647878646851,
            "answer": "intern",
            "hit": false
          },
          {
            "score": 0.6777641773223877,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.6648552417755127,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.651405930519104,
            "answer": "nationally",
            "hit": false
          },
          {
            "score": 0.6427189111709595,
            "answer": "overseas",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7453673928976059
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.7539263367652893,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7118335366249084,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.678139865398407,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.6762856841087341,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.6751120090484619,
            "answer": "morally",
            "hit": false
          },
          {
            "score": 0.6742434501647949,
            "answer": "lawyer",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7539263665676117
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.7989774942398071,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.735579252243042,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.6816508769989014,
            "answer": "psychic",
            "hit": false
          },
          {
            "score": 0.6790973544120789,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.6739739179611206,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.6687033176422119,
            "answer": "emotional",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7989774942398071
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.6995551586151123,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.6631063222885132,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.6577274203300476,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.6511813402175903,
            "answer": "mildly",
            "hit": false
          },
          {
            "score": 0.6510059833526611,
            "answer": "politely",
            "hit": false
          },
          {
            "score": 0.649675190448761,
            "answer": "comfortably",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6995551586151123
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.7923744916915894,
            "answer": "obviously",
            "hit": true
          },
          {
            "score": 0.7562599182128906,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7213999032974243,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.7008082270622253,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6978040933609009,
            "answer": "plainly",
            "hit": false
          },
          {
            "score": 0.6809483766555786,
            "answer": "noticeable",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7923745214939117
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8605626821517944,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.6542441844940186,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.6459583044052124,
            "answer": "mechanical",
            "hit": false
          },
          {
            "score": 0.6414936184883118,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.6236642599105835,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.6163123846054077,
            "answer": "tangible",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8605626225471497
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.8404748439788818,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.7871170043945312,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.7134622931480408,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6972894072532654,
            "answer": "partisan",
            "hit": false
          },
          {
            "score": 0.6963150501251221,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.6925584077835083,
            "answer": "ideological",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8404749035835266
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.6905657649040222,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.6890154480934143,
            "answer": "practically",
            "hit": true
          },
          {
            "score": 0.6579758524894714,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.6541789770126343,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.646763265132904,
            "answer": "commercially",
            "hit": false
          },
          {
            "score": 0.6464395523071289,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6890154480934143
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7766866683959961,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.7330255508422852,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7005466818809509,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.6961707472801208,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6861960291862488,
            "answer": "predecessors",
            "hit": false
          },
          {
            "score": 0.6794964075088501,
            "answer": "predecessor",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7766866981983185
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7839263677597046,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7360762357711792,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.6968544721603394,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.6852760314941406,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.6686891317367554,
            "answer": "scarce",
            "hit": false
          },
          {
            "score": 0.6587344408035278,
            "answer": "frequently",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7360762655735016
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.7523062229156494,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.748022198677063,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.6969481706619263,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.6790407299995422,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.6754643321037292,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.6644240617752075,
            "answer": "significant",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7480221688747406
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.7552542686462402,
            "answer": "sex",
            "hit": false
          },
          {
            "score": 0.7500710487365723,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.7396750450134277,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7130053043365479,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.7091557383537292,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7032610177993774,
            "answer": "erotic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7500710487365723
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.7576193809509277,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.7286301851272583,
            "answer": "importantly",
            "hit": false
          },
          {
            "score": 0.7278050780296326,
            "answer": "notably",
            "hit": false
          },
          {
            "score": 0.7117138504981995,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7080605030059814,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7030633687973022,
            "answer": "drastically",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7576194405555725
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.784116268157959,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7563585042953491,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.7360211610794067,
            "answer": "similarities",
            "hit": false
          },
          {
            "score": 0.732718825340271,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.732178807258606,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7215976715087891,
            "answer": "reminiscent",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7327188551425934
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.7704421281814575,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.7439877986907959,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7277841567993164,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6838542222976685,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6825228929519653,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6712310314178467,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7704420983791351
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.7764230966567993,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7476582527160645,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.7436361908912659,
            "answer": "afterward",
            "hit": false
          },
          {
            "score": 0.7383804321289062,
            "answer": "afterwards",
            "hit": false
          },
          {
            "score": 0.722564697265625,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.718359112739563,
            "answer": "notably",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7764230966567993
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8403316140174866,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.7958859205245972,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7716004848480225,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7407789826393127,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7370368242263794,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6993353366851807,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8403316140174866
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.7595059871673584,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.7523851990699768,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.6837625503540039,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.6760885715484619,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6723214387893677,
            "answer": "naturally",
            "hit": false
          },
          {
            "score": 0.6696727275848389,
            "answer": "culturally",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7595059275627136
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.8038932681083679,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.7118226289749146,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.7001925110816956,
            "answer": "basically",
            "hit": false
          },
          {
            "score": 0.6912195682525635,
            "answer": "naturally",
            "hit": false
          },
          {
            "score": 0.6873710751533508,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.6861748695373535,
            "answer": "essentially",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8038932681083679
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.7821657657623291,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.6975005269050598,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.6499844193458557,
            "answer": "distinctly",
            "hit": false
          },
          {
            "score": 0.6375623345375061,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.6359187364578247,
            "answer": "universally",
            "hit": false
          },
          {
            "score": 0.6331439018249512,
            "answer": "strangely",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7821657359600067
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.6442006230354309,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.633467972278595,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.6194823980331421,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6155615448951721,
            "answer": "fictional",
            "hit": false
          },
          {
            "score": 0.6155158877372742,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6126556992530823,
            "answer": "temporarily",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.633467972278595
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.7633084058761597,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.6588926315307617,
            "answer": "visibly",
            "hit": false
          },
          {
            "score": 0.6522073149681091,
            "answer": "vis",
            "hit": false
          },
          {
            "score": 0.6514166593551636,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.6463394165039062,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.6425976753234863,
            "answer": "graphical",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7633084058761597
      }
    ],
    "result": {
      "cnt_questions_correct": 28,
      "cnt_questions_total": 44,
      "accuracy": 0.6363636363636364
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ee31dbfe-f45a-49ef-9808-59f9b7642131",
      "timestamp": "2025-05-18T10:35:34.826594"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7559245824813843,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.7414889335632324,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.6788156032562256,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6767391562461853,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.6767001152038574,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.6719245910644531,
            "answer": "acquainted",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7559245526790619
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.7917025685310364,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7549686431884766,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7115256786346436,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7079058289527893,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.6674560904502869,
            "answer": "conscience",
            "hit": false
          },
          {
            "score": 0.6564068794250488,
            "answer": "intentional",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.791702538728714
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7762694358825684,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7226872444152832,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.687038779258728,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.6526583433151245,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6470077633857727,
            "answer": "effect",
            "hit": false
          },
          {
            "score": 0.6434047818183899,
            "answer": "efficient",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7762694954872131
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.7268821001052856,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.688278317451477,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6839887499809265,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6762620210647583,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.6602064371109009,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.6597684621810913,
            "answer": "merry",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7268820852041245
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7216267585754395,
            "answer": "madison",
            "hit": false
          },
          {
            "score": 0.6976279020309448,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.6975499391555786,
            "answer": "madame",
            "hit": false
          },
          {
            "score": 0.661660373210907,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.6430008411407471,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6423883438110352,
            "answer": "insanity",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6976278871297836
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7362297177314758,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.6904111504554749,
            "answer": "sadly",
            "hit": false
          },
          {
            "score": 0.6809256076812744,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.6736446619033813,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.6639882326126099,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6589720249176025,
            "answer": "unfortunately",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7362297177314758
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.7805478572845459,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.6811050176620483,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6681973338127136,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.6662974953651428,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.6654532551765442,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.6641674041748047,
            "answer": "insanity",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7805478572845459
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.779315710067749,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.7471333146095276,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7371020913124084,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7357261180877686,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7315670251846313,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7144114971160889,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7793156802654266
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 8,
      "accuracy": 0.875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c08fb70a-8502-4670-8837-47302bc09f93",
      "timestamp": "2025-05-18T10:35:35.014494"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.7823670506477356,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7631849050521851,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7597447037696838,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7454952001571655,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.7088128328323364,
            "answer": "acceptable",
            "hit": true
          },
          {
            "score": 0.6792898178100586,
            "answer": "unacceptable",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7088128477334976
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.8249400854110718,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8022595047950745,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.8004641532897949,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.7689650058746338,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7375656366348267,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.679694414138794,
            "answer": "adapt",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7375656068325043
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.739246666431427,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7214080095291138,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.6927794814109802,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.6564395427703857,
            "answer": "cheaper",
            "hit": false
          },
          {
            "score": 0.6437951922416687,
            "answer": "accessibility",
            "hit": false
          },
          {
            "score": 0.639415979385376,
            "answer": "adjustable",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7392467260360718
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.746267557144165,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7446275949478149,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.7108281254768372,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6911102533340454,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6715734601020813,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6437805891036987,
            "answer": "suppose",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 312,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5850156024098396
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.7014179229736328,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6975245475769043,
            "answer": "excellent",
            "hit": false
          },
          {
            "score": 0.695104718208313,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.6931519508361816,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6930211186408997,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6908520460128784,
            "answer": "enjoying",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6951047033071518
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8401098847389221,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8311794996261597,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7435699105262756,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.740270733833313,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7173293232917786,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.6783645153045654,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7173292934894562
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.7640586495399475,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.7588276863098145,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.7277425527572632,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.7063711881637573,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.6871392130851746,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.6855109333992004,
            "answer": "predicted",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7588276863098145
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.6407107710838318,
            "answer": "reliable",
            "hit": true
          },
          {
            "score": 0.6365284323692322,
            "answer": "linear",
            "hit": false
          },
          {
            "score": 0.6344337463378906,
            "answer": "predictable",
            "hit": false
          },
          {
            "score": 0.6301906704902649,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.6297410130500793,
            "answer": "rallies",
            "hit": false
          },
          {
            "score": 0.628943920135498,
            "answer": "expensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6407107710838318
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.7707452774047852,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.7626121044158936,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.7206953167915344,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.6705870628356934,
            "answer": "ren",
            "hit": false
          },
          {
            "score": 0.6587018966674805,
            "answer": "revival",
            "hit": false
          },
          {
            "score": 0.6518524885177612,
            "answer": "sustainable",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7707452774047852
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8150553107261658,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.772668719291687,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7339608073234558,
            "answer": "sustainable",
            "hit": true
          },
          {
            "score": 0.6849610209465027,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.6719410419464111,
            "answer": "uphold",
            "hit": false
          },
          {
            "score": 0.6621884107589722,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7339608073234558
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.7288631200790405,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7003189325332642,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.692194938659668,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.6761647462844849,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.6559855937957764,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.6435224413871765,
            "answer": "variability",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6260214596986771
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 11,
      "accuracy": 0.2727272727272727
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9e05a735-59b6-441e-9662-4009a0cc5ebf",
      "timestamp": "2025-05-18T10:35:35.043838"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.7013380527496338,
            "answer": "believer",
            "hit": true
          },
          {
            "score": 0.6931948065757751,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6918596625328064,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6859642267227173,
            "answer": "imagine",
            "hit": false
          },
          {
            "score": 0.6841689348220825,
            "answer": "everybody",
            "hit": false
          },
          {
            "score": 0.6823942065238953,
            "answer": "knowing",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7013380229473114
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8202147483825684,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.7309300899505615,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.7231457233428955,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6936427354812622,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.693452775478363,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.6628881692886353,
            "answer": "counselor",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7309300899505615
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8304609060287476,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.7736941576004028,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.7588329315185547,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.7258574962615967,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.7027528285980225,
            "answer": "eaten",
            "hit": false
          },
          {
            "score": 0.6994824409484863,
            "answer": "drank",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6805288791656494
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7362911701202393,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.706944465637207,
            "answer": "contender",
            "hit": true
          },
          {
            "score": 0.7004056572914124,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.686255693435669,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.674376904964447,
            "answer": "asserting",
            "hit": false
          },
          {
            "score": 0.6724821329116821,
            "answer": "asserts",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7069444805383682
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8310412168502808,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.8280928730964661,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.7504354119300842,
            "answer": "defence",
            "hit": false
          },
          {
            "score": 0.7386161684989929,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.7322533130645752,
            "answer": "defense",
            "hit": false
          },
          {
            "score": 0.7257480621337891,
            "answer": "defenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7102405726909637
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.7837985157966614,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7666666507720947,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7464091181755066,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7337750196456909,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7213058471679688,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7194593548774719,
            "answer": "developer",
            "hit": true
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7194593399763107
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8427364826202393,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8279032707214355,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.814781665802002,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.7854059934616089,
            "answer": "examination",
            "hit": false
          },
          {
            "score": 0.7376435399055481,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.731009840965271,
            "answer": "examinations",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7272334694862366
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8421294093132019,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8075461387634277,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8057572841644287,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.7978130578994751,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.69706130027771,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6822055578231812,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6656860560178757
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7360732555389404,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.7340923547744751,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7000031471252441,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6937227249145508,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6786827445030212,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6450625658035278,
            "answer": "subsequent",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.736073225736618
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.7959494590759277,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.7848652005195618,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.782612681388855,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.765887975692749,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.7084635496139526,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.6254072785377502,
            "answer": "commentator",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7084635496139526
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.8533200025558472,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.8452441692352295,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7492007613182068,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6871793866157532,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.6757910847663879,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6731542348861694,
            "answer": "microphone",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6871793568134308
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.8622462749481201,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8292205333709717,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7447466850280762,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7205541729927063,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6972750425338745,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6868577599525452,
            "answer": "loser",
            "hit": true
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6868577897548676
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.834055483341217,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7997056841850281,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7312829494476318,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7086557149887085,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6965175867080688,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.6857463121414185,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6965175569057465
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.7255986928939819,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7100218534469604,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7096549868583679,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.7065391540527344,
            "answer": "observer",
            "hit": true
          },
          {
            "score": 0.6944957971572876,
            "answer": "noticing",
            "hit": false
          },
          {
            "score": 0.6773849725723267,
            "answer": "witnessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7065392136573792
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8256054520606995,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8060430884361267,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.7826388478279114,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7562790513038635,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7321592569351196,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.7280964851379395,
            "answer": "organised",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8060430884361267
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.7729958891868591,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.753433108329773,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7365922927856445,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7270039916038513,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7263658046722412,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7145265936851501,
            "answer": "performing",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7729959189891815
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8514413833618164,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.7864227294921875,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7531843185424805,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.7066360712051392,
            "answer": "missionary",
            "hit": false
          },
          {
            "score": 0.6943399906158447,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.6925222873687744,
            "answer": "missionaries",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7864227294921875
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8457794785499573,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8407649993896484,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8013583421707153,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7704009413719177,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7137652635574341,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7129237651824951,
            "answer": "promotions",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.694351002573967
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.8665635585784912,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8298482894897461,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6927933096885681,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6850322484970093,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6725727319717407,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.671637773513794,
            "answer": "provider",
            "hit": true
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.671637773513794
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8339910507202148,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.793071985244751,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7756349444389343,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.7581056356430054,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.7445827722549438,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.7089486122131348,
            "answer": "publishers",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7756350040435791
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.693677544593811,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6903345584869385,
            "answer": "receiver",
            "hit": true
          },
          {
            "score": 0.6817749738693237,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6661615371704102,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6547738313674927,
            "answer": "defender",
            "hit": false
          },
          {
            "score": 0.6525450944900513,
            "answer": "receiving",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6903345584869385
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8385130167007446,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.8029111623764038,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.7420839667320251,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.727308988571167,
            "answer": "talk",
            "hit": false
          },
          {
            "score": 0.70243239402771,
            "answer": "talking",
            "hit": false
          },
          {
            "score": 0.6833207607269287,
            "answer": "talked",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6532578319311142
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8508252501487732,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8327422738075256,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8317259550094604,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.7728517651557922,
            "answer": "teacher",
            "hit": true
          },
          {
            "score": 0.748702883720398,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.7375149726867676,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7728517651557922
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8308310508728027,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7601485252380371,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.7423899173736572,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.7281063795089722,
            "answer": "writers",
            "hit": false
          },
          {
            "score": 0.7173553705215454,
            "answer": "writ",
            "hit": false
          },
          {
            "score": 0.711349368095398,
            "answer": "writer",
            "hit": true
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.711349368095398
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 24,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f9bfda52-2f25-4d7d-bc68-435ca16a7d0e",
      "timestamp": "2025-05-18T10:35:35.084587"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.816420316696167,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.7969249486923218,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.7703903913497925,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.7443783283233643,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.7122780084609985,
            "answer": "blaming",
            "hit": false
          },
          {
            "score": 0.7050092816352844,
            "answer": "alleging",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7969249784946442
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.7811700105667114,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.7780355215072632,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.6883684992790222,
            "answer": "appreciation",
            "hit": false
          },
          {
            "score": 0.6828362941741943,
            "answer": "enthusiasts",
            "hit": false
          },
          {
            "score": 0.6636761426925659,
            "answer": "praise",
            "hit": false
          },
          {
            "score": 0.6620214581489563,
            "answer": "lovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7811700105667114
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.7380098700523376,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.7255350351333618,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.6835307478904724,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.6796038746833801,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.6615386009216309,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.6582845449447632,
            "answer": "measurement",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7380098700523376
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.7310768961906433,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7187305688858032,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7163195610046387,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7116315960884094,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6565337181091309,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.6306713819503784,
            "answer": "further",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7163195610046387
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.6189653873443604,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.6108068823814392,
            "answer": "imagination",
            "hit": false
          },
          {
            "score": 0.6101810336112976,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6099160313606262,
            "answer": "willingness",
            "hit": false
          },
          {
            "score": 0.6097650527954102,
            "answer": "depiction",
            "hit": false
          },
          {
            "score": 0.6079893708229065,
            "answer": "dissemination",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5992008671164513
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8447001576423645,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8427166938781738,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8047173619270325,
            "answer": "determination",
            "hit": true
          },
          {
            "score": 0.7368724942207336,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7293151617050171,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.694368839263916,
            "answer": "deciding",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8047173619270325
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8385481834411621,
            "answer": "examination",
            "hit": true
          },
          {
            "score": 0.8361681699752808,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8248650431632996,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8157179355621338,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7556845545768738,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.7437347173690796,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8385481834411621
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8439503908157349,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.8384158611297607,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8042142391204834,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.7782604694366455,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.701371431350708,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6830207109451294,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8439504504203796
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.6909987926483154,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.6725967526435852,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.6714925765991211,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.6600508689880371,
            "answer": "suppose",
            "hit": false
          },
          {
            "score": 0.6446617245674133,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.6443756222724915,
            "answer": "knowing",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6401325911283493
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.7977280616760254,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7638834714889526,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7361394762992859,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.6892415285110474,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6673736572265625,
            "answer": "provoke",
            "hit": false
          },
          {
            "score": 0.6666173338890076,
            "answer": "motivation",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7638834714889526
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.7226526141166687,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7192249298095703,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.7083715200424194,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.6999421715736389,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.6935730576515198,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6820086240768433,
            "answer": "noticing",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6999421864748001
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.848505973815918,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8234143257141113,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7840186953544617,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.715173602104187,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.6733492016792297,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.6642233729362488,
            "answer": "inhabit",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.715173602104187
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8351723551750183,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.781846284866333,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7562451362609863,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7324548363685608,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.725235104560852,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.7200669050216675,
            "answer": "organizers",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6956181228160858
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.837314784526825,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8144201040267944,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.7906564474105835,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.7650229334831238,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.7519258260726929,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.740259051322937,
            "answer": "prep",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7906564772129059
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.86516273021698,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.8444372415542603,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8391937613487244,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.6999021172523499,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.6865965723991394,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.6771459579467773,
            "answer": "rebuild",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.86516273021698
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8655490875244141,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8358932733535767,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.7401386499404907,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6927591562271118,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.6865478754043579,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.6861015558242798,
            "answer": "unstable",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8655491471290588
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 16,
      "accuracy": 0.375
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2da66e58-553a-4b41-854f-a31a90534c5b",
      "timestamp": "2025-05-18T10:35:35.178543"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.799480676651001,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7865642309188843,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7781080007553101,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.7224487662315369,
            "answer": "achievement",
            "hit": false
          },
          {
            "score": 0.7167381048202515,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7018999457359314,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7781080007553101
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.8414645195007324,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8357214331626892,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8048074245452881,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7705637812614441,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7524299621582031,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7277411222457886,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7524299323558807
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.8546119928359985,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.8377499580383301,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8134186863899231,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.788523256778717,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.6996031999588013,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.6718028783798218,
            "answer": "adapt",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8546119332313538
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8311667442321777,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.808860182762146,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7822772264480591,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7349346876144409,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7160412073135376,
            "answer": "agreement",
            "hit": true
          },
          {
            "score": 0.6937333345413208,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.71604123711586
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.7030012607574463,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.6981264352798462,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.625974714756012,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.6067081689834595,
            "answer": "intersect",
            "hit": false
          },
          {
            "score": 0.601009726524353,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.6001404523849487,
            "answer": "affiliation",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7030012160539627
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8021701574325562,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.7746113538742065,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7648470401763916,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.673141360282898,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.668691098690033,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.6432058811187744,
            "answer": "modification",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8021701574325562
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8380622863769531,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8343796133995056,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8330905437469482,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.8210521340370178,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.7913285493850708,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6659983396530151,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8330905437469482
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.7770810723304749,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7730643153190613,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.7180805206298828,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.6931303143501282,
            "answer": "hiring",
            "hit": false
          },
          {
            "score": 0.6627964973449707,
            "answer": "awarding",
            "hit": false
          },
          {
            "score": 0.6528918743133545,
            "answer": "dismissing",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7770810723304749
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8323401808738708,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8090757131576538,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.777507483959198,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.7492528557777405,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7153090834617615,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.6826273798942566,
            "answer": "organised",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7775075435638428
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8493590354919434,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.8138182163238525,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8111481666564941,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.7824399471282959,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.7325595617294312,
            "answer": "evaluation",
            "hit": false
          },
          {
            "score": 0.7079482674598694,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8493590354919434
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.7603771686553955,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7529066801071167,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.7131727933883667,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.6841924786567688,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.6206066012382507,
            "answer": "allocation",
            "hit": false
          },
          {
            "score": 0.619231104850769,
            "answer": "assessments",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7603772282600403
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.7678056955337524,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7091756463050842,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.7043810486793518,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.7002978920936584,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.6899102926254272,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.665278971195221,
            "answer": "committees",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7678056955337524
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.7864336371421814,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7846720218658447,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7525539398193359,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7435941100120544,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.717731237411499,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.7159944772720337,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7435941100120544
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8062711954116821,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7805569171905518,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7275454998016357,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.684867799282074,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.6796173453330994,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.6591104865074158,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7805569469928741
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8409504294395447,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8129122257232666,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7829352021217346,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.7765021920204163,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.7716935873031616,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.6977377533912659,
            "answer": "stimulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7716936469078064
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8396588563919067,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.824797511100769,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.7920292615890503,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.6629614233970642,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6626045107841492,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.6579979062080383,
            "answer": "uphold",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8247974514961243
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.8510487675666809,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8406715393066406,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.822192907333374,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.8022503852844238,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.6712258458137512,
            "answer": "undertake",
            "hit": false
          },
          {
            "score": 0.655907154083252,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8022503852844238
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8461282253265381,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8426169753074646,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.8186854720115662,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.7209521532058716,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7149044275283813,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7106078267097473,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8426170349121094
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.7167738676071167,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.6860957145690918,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6836746335029602,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6831939220428467,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6660828590393066,
            "answer": "excellent",
            "hit": false
          },
          {
            "score": 0.6546841859817505,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7167738527059555
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.7965773344039917,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7812419533729553,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.6782807111740112,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.6753458976745605,
            "answer": "amusement",
            "hit": false
          },
          {
            "score": 0.6502798199653625,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6482753157615662,
            "answer": "pleasures",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6782806664705276
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8466527462005615,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8334929943084717,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8265409469604492,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7681536078453064,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.6622194051742554,
            "answer": "demonstrate",
            "hit": false
          },
          {
            "score": 0.6613615155220032,
            "answer": "establishments",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7681535482406616
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8238121271133423,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.816144585609436,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.8156547546386719,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.754761815071106,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.6878747940063477,
            "answer": "satisfying",
            "hit": false
          },
          {
            "score": 0.6856876015663147,
            "answer": "accomplishment",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8238121271133423
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8475164771080017,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8206065893173218,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.770148754119873,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7645578384399414,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7388342022895813,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7128421664237976,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8206065893173218
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.7634392976760864,
            "answer": "investigation",
            "hit": false
          },
          {
            "score": 0.732575535774231,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.7267172336578369,
            "answer": "investigations",
            "hit": false
          },
          {
            "score": 0.71012943983078,
            "answer": "investigator",
            "hit": false
          },
          {
            "score": 0.700743556022644,
            "answer": "investigative",
            "hit": false
          },
          {
            "score": 0.7002437114715576,
            "answer": "investments",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7325755208730698
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8629366159439087,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7810708284378052,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.764708399772644,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7604602575302124,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.6509828567504883,
            "answer": "participation",
            "hit": false
          },
          {
            "score": 0.6438469886779785,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7604602575302124
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8293126821517944,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8168894052505493,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7050455808639526,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.7025589942932129,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6727777719497681,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6696776151657104,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7050455510616302
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8202641010284424,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.803364634513855,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.6899556517601013,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.6724241375923157,
            "answer": "revenge",
            "hit": false
          },
          {
            "score": 0.6615651845932007,
            "answer": "penal",
            "hit": false
          },
          {
            "score": 0.6571910977363586,
            "answer": "pun",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8202641010284424
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.8209877014160156,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.7717787623405457,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.669452428817749,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.6683064699172974,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6681210398674011,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.6676652431488037,
            "answer": "encouragement",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8209876716136932
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.7652782201766968,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7569323182106018,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7481151819229126,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7322747111320496,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.7146143317222595,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.6986443996429443,
            "answer": "substitution",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7322747111320496
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.8339711427688599,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.8310977816581726,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.6998113989830017,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6948598623275757,
            "answer": "necessity",
            "hit": false
          },
          {
            "score": 0.6912868618965149,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6832065582275391,
            "answer": "criteria",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8310977816581726
      }
    ],
    "result": {
      "cnt_questions_correct": 11,
      "cnt_questions_total": 30,
      "accuracy": 0.36666666666666664
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9fdbbf71-e984-4ce3-aa2e-286136cc8126",
      "timestamp": "2025-05-18T10:35:35.240820"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8405752778053284,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7563060522079468,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7291395664215088,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.724197268486023,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7239898443222046,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7233927249908447,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8405752778053284
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8167386054992676,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.7810360789299011,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7466079592704773,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7408921718597412,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.7351169586181641,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7290324568748474,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.81673863530159
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.8957622051239014,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.7868750095367432,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.7779093980789185,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.7731157541275024,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.766017735004425,
            "answer": "nepal",
            "hit": false
          },
          {
            "score": 0.761524498462677,
            "answer": "indonesia",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.895762175321579
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.833728551864624,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.7404679656028748,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.7374707460403442,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.735335111618042,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7334322929382324,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.7295488119125366,
            "answer": "russia",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8337284922599792
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.8352265954017639,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7388967871665955,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7362087965011597,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.732611894607544,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7252993583679199,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7236080169677734,
            "answer": "poland",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8352265954017639
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7228902578353882,
            "answer": "bernard",
            "hit": false
          },
          {
            "score": 0.7007085084915161,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.6797963380813599,
            "answer": "bernstein",
            "hit": false
          },
          {
            "score": 0.6717635989189148,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.6647272109985352,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.6568343639373779,
            "answer": "switzerland",
            "hit": true
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6568343788385391
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.819642961025238,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.7615528106689453,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7523689270019531,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7514644265174866,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.7482715845108032,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7411186695098877,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8196429908275604
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.877447783946991,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.7841817736625671,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7810255289077759,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7735258340835571,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7673617601394653,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7644879817962646,
            "answer": "poland",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.877447783946991
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.8053668737411499,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.7448687553405762,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.736840546131134,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7315365076065063,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7290270924568176,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7160047888755798,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8053668737411499
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8407860994338989,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.7751879096031189,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7713199853897095,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7691160440444946,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.732384443283081,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.731651782989502,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8407860994338989
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.7897326946258545,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.7303731441497803,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.72989821434021,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7196104526519775,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.7185412049293518,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7179677486419678,
            "answer": "serbia",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7897327542304993
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8394981622695923,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.7526462078094482,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7314014434814453,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7277782559394836,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.723585307598114,
            "answer": "scotland",
            "hit": false
          },
          {
            "score": 0.7201523780822754,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8394981622695923
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8295534253120422,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.7494300603866577,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7439333200454712,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.7282673716545105,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7247831225395203,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7233114838600159,
            "answer": "croatia",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.829553484916687
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7247210741043091,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.6733981966972351,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.6724553108215332,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6705273389816284,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.6649949550628662,
            "answer": "king",
            "hit": false
          },
          {
            "score": 0.6535922288894653,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7247210890054703
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8384209275245667,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.7698558568954468,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7482317686080933,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7439067363739014,
            "answer": "ireland",
            "hit": false
          },
          {
            "score": 0.7420444488525391,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7397168874740601,
            "answer": "greece",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8384209275245667
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8630751371383667,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.7850735783576965,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7650285959243774,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7541460990905762,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7475168704986572,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7443185448646545,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8630751967430115
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8151625990867615,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.797014057636261,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.7542591094970703,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7529224157333374,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7489234805107117,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.7435972690582275,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8151625990867615
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.8137800097465515,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.7687066793441772,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7545521259307861,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7450442314147949,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.732724666595459,
            "answer": "ukraine",
            "hit": false
          },
          {
            "score": 0.7315350770950317,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8137800097465515
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8307405710220337,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.7647406458854675,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.7490934729576111,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7468320727348328,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7306849956512451,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7200244665145874,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8307406008243561
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.7939925789833069,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.7651015520095825,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.7427371144294739,
            "answer": "quebec",
            "hit": false
          },
          {
            "score": 0.740269124507904,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.7369295358657837,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7350608706474304,
            "answer": "alberta",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7939925789833069
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.7659668922424316,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.7399480938911438,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7204394936561584,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7187259197235107,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7101644277572632,
            "answer": "europe",
            "hit": false
          },
          {
            "score": 0.7058449983596802,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7659668922424316
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.8042027950286865,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7439109683036804,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7436096668243408,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7394403219223022,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7054524421691895,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7012489438056946,
            "answer": "romania",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042028546333313
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.7506914734840393,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7488709092140198,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7132697701454163,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7093234062194824,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.7028635144233704,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.6979100704193115,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7488708794116974
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8731208443641663,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.7787737250328064,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7669755220413208,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7626951336860657,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7597299814224243,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7487736344337463,
            "answer": "switzerland",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8731208443641663
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8162975311279297,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.7869844436645508,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.7486034035682678,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7424635887145996,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7346737384796143,
            "answer": "pakistan",
            "hit": false
          },
          {
            "score": 0.732959508895874,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8162975907325745
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.869468629360199,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.7620871067047119,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7576165795326233,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7490781545639038,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7423046231269836,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.7422248125076294,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.869468629360199
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.834503173828125,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.7588663697242737,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7586351633071899,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7574306726455688,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.743937611579895,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7426689863204956,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.834503173828125
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.839297890663147,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.7460811734199524,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7411519885063171,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7345829010009766,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.729783296585083,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7240291833877563,
            "answer": "bulgaria",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8392978310585022
      }
    ],
    "result": {
      "cnt_questions_correct": 26,
      "cnt_questions_total": 28,
      "accuracy": 0.9285714285714286
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "a3114935-27a9-4dc7-8716-01572d5de44b",
      "timestamp": "2025-05-18T10:35:35.361167"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.843205988407135,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8072731494903564,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7663235664367676,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7570972442626953,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.754015326499939,
            "answer": "argent",
            "hit": false
          },
          {
            "score": 0.7385821342468262,
            "answer": "brazilian",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8072731494903564
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.849780261516571,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7414351105690002,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7361920475959778,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7100446820259094,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7087640762329102,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.7017927169799805,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6908172070980072
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8438131213188171,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7765237092971802,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7541872262954712,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7523065805435181,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7504268884658813,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7252199649810791,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7541872262954712
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8502888679504395,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8051413297653198,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7944076061248779,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.7554291486740112,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7545278072357178,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7510097026824951,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7944076657295227
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8292778730392456,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7318519949913025,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.721060574054718,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7180452942848206,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.7017887830734253,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.7012652158737183,
            "answer": "quebec",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6563395857810974
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8242587447166443,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7440993189811707,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.741656482219696,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7380213141441345,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7122564911842346,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.711876630783081,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242587447166443
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7997370958328247,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7576708793640137,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7158671617507935,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7148606181144714,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.704904317855835,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7031294107437134,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7997370958328247
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8252447843551636,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7923427224159241,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7362152338027954,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6978423595428467,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6950995326042175,
            "answer": "castro",
            "hit": false
          },
          {
            "score": 0.6905765533447266,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7923426926136017
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.7592949271202087,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7567599415779114,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7562751770019531,
            "answer": "turkish",
            "hit": true
          },
          {
            "score": 0.7324432134628296,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7099799513816833,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7041071653366089,
            "answer": "romanian",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7324432283639908
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8529219031333923,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7822697162628174,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.738585889339447,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7353323698043823,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7149051427841187,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.695647120475769,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7822696566581726
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7828220129013062,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7536191940307617,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.729426383972168,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7122138738632202,
            "answer": "indonesian",
            "hit": false
          },
          {
            "score": 0.7110590934753418,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7095355987548828,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7828219830989838
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8493775725364685,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.7910300493240356,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7686659693717957,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.7373178601264954,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7309778928756714,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.7277957797050476,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686659693717957
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8160957098007202,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7754237651824951,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7312261462211609,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7102700471878052,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.6865915656089783,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.6837825775146484,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7754237353801727
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8090735077857971,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7756825685501099,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.7248390316963196,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.7207769155502319,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7137857675552368,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6997730135917664,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7756825089454651
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7391715049743652,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6933157444000244,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6908090710639954,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6906138062477112,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6818257570266724,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6711148023605347,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7391715347766876
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7878655791282654,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7503851056098938,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7331908345222473,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7307799458503723,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7302951812744141,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.7198925018310547,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7878655791282654
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7761253714561462,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.7701367139816284,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7224661707878113,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7155124545097351,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.70097815990448,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.6888459920883179,
            "answer": "syrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7701367139816284
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7852495908737183,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.73577880859375,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7084354162216187,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7047619223594666,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7045928835868835,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.702033519744873,
            "answer": "brazilian",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7852495908737183
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8107209205627441,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.7793072462081909,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7375748753547668,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.733572244644165,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7295193076133728,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7214017510414124,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7335722148418427
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8437802791595459,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.7862541675567627,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.740648627281189,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7028921842575073,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.7023001313209534,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6963706016540527,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7862541675567627
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.7763298749923706,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7563615441322327,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.75509113073349,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7403953075408936,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.7327785491943359,
            "answer": "vietnamese",
            "hit": false
          },
          {
            "score": 0.7207731008529663,
            "answer": "tibetan",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7403953671455383
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7187265753746033,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.703713059425354,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6866922974586487,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6536333560943604,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6494330167770386,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6488195061683655,
            "answer": "english",
            "hit": true
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6488195210695267
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7946498394012451,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7584814429283142,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7189375162124634,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7087540626525879,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7063124775886536,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7045043706893921,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7946498692035675
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 23,
      "accuracy": 0.30434782608695654
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0a9439ee-452f-4292-b9c3-de87eb1366d8",
      "timestamp": "2025-05-18T10:35:35.473840"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7501517534255981,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7055209875106812,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.6851948499679565,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.6583775877952576,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6532878875732422,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.6502021551132202,
            "answer": "bathroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6851948648691177
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7891567349433899,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7147308588027954,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6992605924606323,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6898248195648193,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.6818345785140991,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.6659625768661499,
            "answer": "devon",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7891567945480347
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8149138689041138,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7562952041625977,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7283436059951782,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7049659490585327,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7007585167884827,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.7001914978027344,
            "answer": "devon",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.75629523396492
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.6886996030807495,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6514542102813721,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6384389400482178,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6248319149017334,
            "answer": "chassis",
            "hit": false
          },
          {
            "score": 0.6239857077598572,
            "answer": "yacht",
            "hit": false
          },
          {
            "score": 0.6230090856552124,
            "answer": "cockpit",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6886996328830719
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8740155696868896,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7463505268096924,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7358791828155518,
            "answer": "leicester",
            "hit": false
          },
          {
            "score": 0.7264965772628784,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7184469103813171,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.7157412767410278,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8740155696868896
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.7981439828872681,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7497403621673584,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7206360101699829,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.7064172625541687,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6981105208396912,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.690416693687439,
            "answer": "cornwall",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7206359803676605
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8381573557853699,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7438533306121826,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7276599407196045,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.725711464881897,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7225279211997986,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.699445903301239,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8381573557853699
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.722825288772583,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6716626882553101,
            "answer": "well",
            "hit": false
          },
          {
            "score": 0.6520137786865234,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.6429013013839722,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6346402168273926,
            "answer": "valleys",
            "hit": false
          },
          {
            "score": 0.6296364068984985,
            "answer": "villages",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6238843128085136
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8159003257751465,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7365968227386475,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7128838300704956,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.6950736045837402,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.673617959022522,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.6728007793426514,
            "answer": "zealand",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8159003555774689
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9e3cdcd4-5ff6-4796-8441-c107cd8d01fb",
      "timestamp": "2025-05-18T10:35:35.563829"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7411019802093506,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7121098637580872,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7037854194641113,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7010026574134827,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7006720304489136,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6906278729438782,
            "answer": "norwegian",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.741101935505867
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.736497700214386,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7247492074966431,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6922279596328735,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6801595687866211,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.679597020149231,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6747854351997375,
            "answer": "egyptian",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6801595687866211
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7279767990112305,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6889771223068237,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.674233078956604,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6704868078231812,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6585099101066589,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6575509309768677,
            "answer": "european",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5941888988018036
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7125399112701416,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6713076829910278,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6665785312652588,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6632120609283447,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6558048725128174,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6546827554702759,
            "answer": "russian",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6427655071020126
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7377026081085205,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7010783553123474,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6911617517471313,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6909085512161255,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.6893677711486816,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6866205334663391,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.637820690870285
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.794277548789978,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.783953070640564,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.7283634543418884,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7239820957183838,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.700099527835846,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.680145263671875,
            "answer": "japanese",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.794277548789978
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7225387692451477,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7178323268890381,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.6692932844161987,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.6685129404067993,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6635156273841858,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6586105823516846,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7178323268890381
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7090741395950317,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7051860094070435,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.6948806047439575,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6803463697433472,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6765363812446594,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6751017570495605,
            "answer": "british",
            "hit": true
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7051860094070435
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7530257701873779,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6830794215202332,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.6803919076919556,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6750943660736084,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6695630550384521,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.6688575148582458,
            "answer": "belgian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7530257403850555
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.6947803497314453,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6794583201408386,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6669569611549377,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6655963063240051,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6650201082229614,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.664064884185791,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6947803497314453
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.7427922487258911,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.7345128655433655,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7213533520698547,
            "answer": "ukrainian",
            "hit": false
          },
          {
            "score": 0.7066836357116699,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.6977726817131042,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6960430145263672,
            "answer": "romanian",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7066836655139923
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7255481481552124,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6894130706787109,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6706360578536987,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6633810997009277,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6574863791465759,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.6573991775512695,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6894130408763885
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7012057304382324,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6971861124038696,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6850686073303223,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6825369000434875,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.673802375793457,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6711605787277222,
            "answer": "belgian",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6630629897117615
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.739902138710022,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7085863947868347,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6938551664352417,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.6684035062789917,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6556564569473267,
            "answer": "soviet",
            "hit": false
          },
          {
            "score": 0.6529994010925293,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7085863947868347
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7133036851882935,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6765116453170776,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6544424891471863,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.6521698832511902,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.6504815816879272,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.6494107246398926,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6504816114902496
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7252009510993958,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6966869831085205,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6876786947250366,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6840506792068481,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.682709276676178,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6760396957397461,
            "answer": "british",
            "hit": true
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.649780198931694
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7357091307640076,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7184258103370667,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6873400807380676,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6793956756591797,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6765539050102234,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6706011891365051,
            "answer": "polish",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7357091307640076
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7131590843200684,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6731298565864563,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6715824604034424,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.6677416563034058,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6672092080116272,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6621921062469482,
            "answer": "korean",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6731298565864563
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7545906901359558,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.671371340751648,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6646387577056885,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6630654335021973,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6590895652770996,
            "answer": "welsh",
            "hit": false
          },
          {
            "score": 0.6589455604553223,
            "answer": "polish",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7545906603336334
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 19,
      "accuracy": 0.42105263157894735
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e49716b6-ea67-4a78-991c-d1af054c1df6",
      "timestamp": "2025-05-18T10:35:35.597889"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8044143915176392,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7564942836761475,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7309539318084717,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7048224210739136,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6954036951065063,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.6938504576683044,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8044143915176392
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7415250539779663,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6846118569374084,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6718897819519043,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6653391122817993,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6605575084686279,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6524295210838318,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6483154147863388
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7168089151382446,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6765261888504028,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.665756344795227,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.6606734991073608,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.6600298881530762,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.6583966016769409,
            "answer": "scholar",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 256,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5926737040281296
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7257882952690125,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7063276767730713,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.6964569091796875,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6932126879692078,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6849469542503357,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6825821399688721,
            "answer": "philosophers",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7063276916742325
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7355325222015381,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7021998763084412,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6841415166854858,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6819367408752441,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6766217947006226,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.675949215888977,
            "answer": "philosophers",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6710056066513062
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7560205459594727,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.744837760925293,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7082298398017883,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.703030526638031,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6837433576583862,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6819251775741577,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7448378205299377
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.7553819417953491,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.7443133592605591,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7343360781669617,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7128257751464844,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7035797834396362,
            "answer": "dictator",
            "hit": true
          },
          {
            "score": 0.7033288478851318,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7035797238349915
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7600832581520081,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7105113863945007,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6945904493331909,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6800867915153503,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6739530563354492,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.672498345375061,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7600832283496857
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.750946044921875,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6953823566436768,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6912740468978882,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6586288213729858,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6554379463195801,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6495226621627808,
            "answer": "scholar",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7509460747241974
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.6940299272537231,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6513217091560364,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6384038925170898,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.6351441144943237,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6343841552734375,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6251653432846069,
            "answer": "scholar",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6009191572666168
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7574883103370667,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7055399417877197,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6919976472854614,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6769843101501465,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6717391014099121,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6556892395019531,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7574882805347443
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.799080491065979,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7265834212303162,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6875278949737549,
            "answer": "socialist",
            "hit": false
          },
          {
            "score": 0.6841184496879578,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6840181946754456,
            "answer": "socialism",
            "hit": false
          },
          {
            "score": 0.6830729246139526,
            "answer": "communism",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7265834212303162
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.703649640083313,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.661400318145752,
            "answer": "max",
            "hit": false
          },
          {
            "score": 0.6605824828147888,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6449180841445923,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6433863639831543,
            "answer": "columnist",
            "hit": false
          },
          {
            "score": 0.6432800889015198,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6605824679136276
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7266272306442261,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.679985761642456,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.6776377558708191,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6645640730857849,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.6638838648796082,
            "answer": "psychiatrist",
            "hit": false
          },
          {
            "score": 0.6598296165466309,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6799857169389725
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7625572085380554,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6993738412857056,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6984822750091553,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6907845139503479,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6864248514175415,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6844469308853149,
            "answer": "emperor",
            "hit": true
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6844468712806702
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8042610883712769,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7584366202354431,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7246624827384949,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7242319583892822,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6979531645774841,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6885409355163574,
            "answer": "philosophy",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042610585689545
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7416871190071106,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7143834829330444,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6830731630325317,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6803308129310608,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6721474528312683,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.6709970235824585,
            "answer": "psychiatrist",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6569153964519501
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7238199710845947,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6692288517951965,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6667184829711914,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.6643755435943604,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6472145318984985,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6464369297027588,
            "answer": "guitarist",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6643755733966827
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 18,
      "accuracy": 0.3333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f0d56402-7e0e-4459-8770-f510cf4d3325",
      "timestamp": "2025-05-18T10:35:35.670320"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.6915647983551025,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6704345941543579,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.631890058517456,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.6293684244155884,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6279089450836182,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.6248447299003601,
            "answer": "calf",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 70,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5404149144887924
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.801593542098999,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6747956275939941,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.673404335975647,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.6600307822227478,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6518489718437195,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6479371786117554,
            "answer": "borne",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6518489718437195
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7031364440917969,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6516214609146118,
            "answer": "buff",
            "hit": false
          },
          {
            "score": 0.6506673693656921,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.6494840979576111,
            "answer": "pittsburgh",
            "hit": false
          },
          {
            "score": 0.6490938067436218,
            "answer": "calgary",
            "hit": false
          },
          {
            "score": 0.648171067237854,
            "answer": "cleveland",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5998278856277466
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7811694741249084,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.699600338935852,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6901934146881104,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6593385338783264,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6368074417114258,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6316041350364685,
            "answer": "camel",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6901934146881104
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.7844970226287842,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7437859177589417,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.691133975982666,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6894187927246094,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6727095246315002,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6519216299057007,
            "answer": "cows",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 72,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5886646062135696
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6633686423301697,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.658840537071228,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6527073383331299,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.6254463195800781,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.615694522857666,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6135909557342529,
            "answer": "kid",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6633686125278473
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7840326428413391,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.6873660683631897,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6868360638618469,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6551879048347473,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6390211582183838,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.6310030221939087,
            "answer": "canine",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6180303543806076
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.805490255355835,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7589241862297058,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7165709733963013,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6613095998764038,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6422614455223083,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.5968935489654541,
            "answer": "lock",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 101,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5580188259482384
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8295130133628845,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6896750926971436,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6864281892776489,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6749613285064697,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.6591615676879883,
            "answer": "yacht",
            "hit": false
          },
          {
            "score": 0.6549736261367798,
            "answer": "coral",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6864281892776489
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7258530855178833,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6954673528671265,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6437375545501709,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6336102485656738,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.6247708201408386,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.6180203557014465,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6954673230648041
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8087999224662781,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7020972967147827,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6899551153182983,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6524816155433655,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6491597294807434,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6437920928001404,
            "answer": "yacht",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6899551004171371
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 11,
      "accuracy": 0.09090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "53d468fd-de6d-4dd5-b55d-30585d346881",
      "timestamp": "2025-05-18T10:35:35.739288"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7381651401519775,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.6916263699531555,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.6792510151863098,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.636742353439331,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6246052980422974,
            "answer": "honey",
            "hit": false
          },
          {
            "score": 0.6047409176826477,
            "answer": "bard",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6916263401508331
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.6868172883987427,
            "answer": "flynn",
            "hit": false
          },
          {
            "score": 0.6808305978775024,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.6795002222061157,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.675561785697937,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6644365787506104,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6548330187797546,
            "answer": "buzz",
            "hit": true
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6548330038785934
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7482882738113403,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7208867073059082,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7134212255477905,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6796599626541138,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6287750005722046,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.5928959846496582,
            "answer": "lock",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 2545,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5155738489702344
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7788395881652832,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7680168747901917,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6557033061981201,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6553865075111389,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6502140760421753,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6223112940788269,
            "answer": "wolves",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 11926,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5156089011579752
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0e2eca13-b21a-4fe6-ac69-b7ab310be92b",
      "timestamp": "2025-05-18T10:35:35.780579"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7145357131958008,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6888366937637329,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6770874261856079,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6281459331512451,
            "answer": "pee",
            "hit": false
          },
          {
            "score": 0.6276916861534119,
            "answer": "damages",
            "hit": false
          },
          {
            "score": 0.6263409852981567,
            "answer": "linear",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 7024,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5475320667028427
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7306162118911743,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.631352424621582,
            "answer": "batch",
            "hit": false
          },
          {
            "score": 0.6306450366973877,
            "answer": "bal",
            "hit": false
          },
          {
            "score": 0.6292510032653809,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6226828098297119,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.6188873648643494,
            "answer": "bathing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 709,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5603943355381489
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8142029643058777,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6991071701049805,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.6735396385192871,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6708269119262695,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.654490053653717,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.629304051399231,
            "answer": "carry",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5967401638627052
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.7881752252578735,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7620073556900024,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7025994062423706,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6864678859710693,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6824182271957397,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.681907594203949,
            "answer": "dairy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 61,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6039441078901291
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7604827880859375,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7325006723403931,
            "answer": "tennis",
            "hit": false
          },
          {
            "score": 0.7262810468673706,
            "answer": "football",
            "hit": false
          },
          {
            "score": 0.7260463237762451,
            "answer": "hockey",
            "hit": false
          },
          {
            "score": 0.7054107189178467,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.6968080997467041,
            "answer": "nest",
            "hit": true
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6968080997467041
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7253177762031555,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.718176007270813,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7173186540603638,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.7082924842834473,
            "answer": "crowds",
            "hit": false
          },
          {
            "score": 0.6601776480674744,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.638994574546814,
            "answer": "densely",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7181760370731354
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7199215888977051,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7084239721298218,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.6417566537857056,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6239575147628784,
            "answer": "drake",
            "hit": false
          },
          {
            "score": 0.6227982044219971,
            "answer": "dunn",
            "hit": false
          },
          {
            "score": 0.6221689581871033,
            "answer": "doll",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5760700404644012
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7121884226799011,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7073767185211182,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7007321119308472,
            "answer": "flynn",
            "hit": false
          },
          {
            "score": 0.6960358619689941,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.6858571767807007,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6647486090660095,
            "answer": "flights",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7121884524822235
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7179341316223145,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6431987881660461,
            "answer": "forest",
            "hit": false
          },
          {
            "score": 0.6248924732208252,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6210812926292419,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.6194169521331787,
            "answer": "vast",
            "hit": false
          },
          {
            "score": 0.6191175580024719,
            "answer": "shirt",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6248924732208252
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.793886125087738,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.713413417339325,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.6943793892860413,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6560477614402771,
            "answer": "herb",
            "hit": false
          },
          {
            "score": 0.6533645987510681,
            "answer": "pest",
            "hit": false
          },
          {
            "score": 0.6409459710121155,
            "answer": "den",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6943793892860413
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7024972438812256,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6605176329612732,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.64862459897995,
            "answer": "mound",
            "hit": false
          },
          {
            "score": 0.6380392909049988,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.616453230381012,
            "answer": "molecules",
            "hit": false
          },
          {
            "score": 0.6134251952171326,
            "answer": "driveway",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5682694464921951
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8009515404701233,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.69786536693573,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.639499306678772,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6309161186218262,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6301757097244263,
            "answer": "monk",
            "hit": false
          },
          {
            "score": 0.6299002170562744,
            "answer": "puppy",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 65,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5275751706212759
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7316973805427551,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7311514019966125,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.6739322543144226,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.6435589790344238,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6425291299819946,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.6296771764755249,
            "answer": "mammalian",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7316973507404327
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6834572553634644,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.667553186416626,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6576888561248779,
            "answer": "ratings",
            "hit": false
          },
          {
            "score": 0.6372706294059753,
            "answer": "ratios",
            "hit": false
          },
          {
            "score": 0.6292924880981445,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6159687638282776,
            "answer": "rating",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6834572851657867
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7086030840873718,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.6910059452056885,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6304193139076233,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6233129501342773,
            "answer": "raiders",
            "hit": false
          },
          {
            "score": 0.6193272471427917,
            "answer": "aurora",
            "hit": false
          },
          {
            "score": 0.6113669872283936,
            "answer": "rosen",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6910059750080109
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7318435907363892,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.717565655708313,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6469639539718628,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.6221821308135986,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6219040751457214,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6185587644577026,
            "answer": "giant",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6221821010112762
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8265831470489502,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.727327287197113,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6778182983398438,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6620336771011353,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6584002375602722,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6561993360519409,
            "answer": "reef",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 217,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.594809427857399
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.728293240070343,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6650036573410034,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6553613543510437,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.6471010446548462,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6402552723884583,
            "answer": "snow",
            "hit": false
          },
          {
            "score": 0.6342470645904541,
            "answer": "wind",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6471010595560074
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e769b5cf-e91a-446f-b279-dd1a5b566db1",
      "timestamp": "2025-05-18T10:35:35.801309"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7319343090057373,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7287909984588623,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7275453805923462,
            "answer": "anti",
            "hit": false
          },
          {
            "score": 0.6827874183654785,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6440918445587158,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6351333856582642,
            "answer": "for",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6827873736619949
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7270583510398865,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7060657739639282,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6756734848022461,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.657772421836853,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6512711644172668,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6309774518013,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6756734549999237
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7464268207550049,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.717370331287384,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6844996213912964,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6753408908843994,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.655920684337616,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6351103186607361,
            "answer": "bloody",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.684499591588974
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7208781242370605,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6979140639305115,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6920371651649475,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6774823665618896,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6717787384986877,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6539307832717896,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6293333172798157
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7330185174942017,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.710354208946228,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6995052099227905,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6934150457382202,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6817874312400818,
            "answer": "orange",
            "hit": true
          },
          {
            "score": 0.6659960746765137,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817874312400818
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7575839757919312,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7243345975875854,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.709041178226471,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7004190683364868,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6734068989753723,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6551206111907959,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7004191130399704
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7520924210548401,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7164883613586426,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6950536966323853,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6838418245315552,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6682910919189453,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6477450132369995,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7164883315563202
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7148967981338501,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7131435871124268,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6911761164665222,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.6828392148017883,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6696905493736267,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6522724628448486,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7131436169147491
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7308809757232666,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7004588842391968,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6960839033126831,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.66010981798172,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6429176926612854,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6119808554649353,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7004588842391968
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7132874727249146,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7047877907752991,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6751009225845337,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6729373931884766,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6637638807296753,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6330751180648804,
            "answer": "whites",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7047878056764603
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7375578880310059,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7233967185020447,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6917873024940491,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6696515083312988,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6671434044837952,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6522431373596191,
            "answer": "creamy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7233967185020447
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7364209890365601,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6949102282524109,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.685630738735199,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.6843584775924683,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6835212707519531,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.681089460849762,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6949102282524109
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8060755729675293,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7125823497772217,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6968379020690918,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6737399697303772,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6643555164337158,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.633225679397583,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7125823348760605
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.7174670100212097,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6989734172821045,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6981039047241211,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6818675994873047,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.643649697303772,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.620353102684021,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6140313297510147
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.7289916276931763,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.7187818288803101,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6874966621398926,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6820415258407593,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6722553968429565,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6624350547790527,
            "answer": "blacks",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.687496691942215
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7262067794799805,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6991187334060669,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6815094947814941,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6710634231567383,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6455711126327515,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6294216513633728,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6294216513633728
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7394652366638184,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7087060213088989,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6919795870780945,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6809971332550049,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.6495952606201172,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6288934350013733,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5702908635139465
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7304086089134216,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7175306081771851,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.670354425907135,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6635048985481262,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.657141923904419,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6252270936965942,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7175306677818298
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.7274714708328247,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.697070837020874,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6825495958328247,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6623730063438416,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6523500680923462,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6180474758148193,
            "answer": "papers",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7274714708328247
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7529160976409912,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7161825895309448,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7040852308273315,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6906222105026245,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.6882287859916687,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6482528448104858,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7161826193332672
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7368789911270142,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7308108806610107,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.6966831088066101,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6916100978851318,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6890574097633362,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6595446467399597,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5724514350295067
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7233397960662842,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7214000225067139,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6938327550888062,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6409876346588135,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6365228891372681,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.6336686611175537,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7233397960662842
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7472303509712219,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7315292954444885,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7004694938659668,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6896977424621582,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6751468777656555,
            "answer": "rise",
            "hit": false
          },
          {
            "score": 0.6749103665351868,
            "answer": "rises",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7315292656421661
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7269943952560425,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7091957926750183,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6754336357116699,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.667593240737915,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6659886240959167,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.640911877155304,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6659886240959167
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7290176153182983,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7277838587760925,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6668901443481445,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6659194231033325,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6651568412780762,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6347103118896484,
            "answer": "silver",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7277838736772537
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7379888296127319,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.719207227230072,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6912967562675476,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6670529842376709,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6533289551734924,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6294986009597778,
            "answer": "ocean",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6670529395341873
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7168132066726685,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7109086513519287,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.696743369102478,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6896646022796631,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.663429856300354,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6507652401924133,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.663429856300354
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7341593503952026,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7212487459182739,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.680586040019989,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.669487714767456,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.661018431186676,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6590384840965271,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7212487757205963
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.7393594980239868,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7207585573196411,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7069296836853027,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6945440769195557,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6591968536376953,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6378618478775024,
            "answer": "earth",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7069296836853027
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.764603853225708,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7098387479782104,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7030292749404907,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6746432185173035,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6249730587005615,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6190299391746521,
            "answer": "whites",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.764603853225708
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7223586440086365,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7079997062683105,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6850637197494507,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6622868776321411,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6582525968551636,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6272184252738953,
            "answer": "solar",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6622868776321411
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7225347757339478,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7133593559265137,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6927176117897034,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6594608426094055,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6495922803878784,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6116633415222168,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7225348204374313
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7591056823730469,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7033321857452393,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6982707381248474,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.689741313457489,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6538437008857727,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6296165585517883,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.703332245349884
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7390074729919434,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7328323721885681,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7079370021820068,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7071489691734314,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7007098197937012,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6840742826461792,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7071489691734314
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 34,
      "accuracy": 0.2647058823529412
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3dc21bc8-5338-47c7-816a-f4b0102ea36f",
      "timestamp": "2025-05-18T10:35:35.875944"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.824275553226471,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.7713074684143066,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7382128238677979,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.6802652478218079,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6728833913803101,
            "answer": "dancer",
            "hit": false
          },
          {
            "score": 0.664171576499939,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242755830287933
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.7741877436637878,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7450960874557495,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.7014793753623962,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.6763193607330322,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.6713619828224182,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6691232919692993,
            "answer": "child",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7014793753623962
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.7958471179008484,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7572134137153625,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7535354495048523,
            "answer": "sibling",
            "hit": false
          },
          {
            "score": 0.75336754322052,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7379755973815918,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7346789240837097,
            "answer": "siblings",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7054023742675781
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.668348491191864,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6544274091720581,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6480145454406738,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.6457776427268982,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6448341608047485,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6438745856285095,
            "answer": "actress",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 10782,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5314422324299812
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.6764639616012573,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.6748538017272949,
            "answer": "bullshit",
            "hit": false
          },
          {
            "score": 0.6574167013168335,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6526268720626831,
            "answer": "bitch",
            "hit": false
          },
          {
            "score": 0.6484629511833191,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.6474270820617676,
            "answer": "princess",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 1862,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.576294519007206
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.7329651117324829,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.7273299694061279,
            "answer": "mum",
            "hit": true
          },
          {
            "score": 0.7166333198547363,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.7147374749183655,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.7093982696533203,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7029571533203125,
            "answer": "girl",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6963739097118378
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7834489941596985,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.6646568775177002,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.66148841381073,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.6614253520965576,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.636771559715271,
            "answer": "durham",
            "hit": false
          },
          {
            "score": 0.6353628039360046,
            "answer": "dame",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7834489345550537
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.7539664506912231,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7275785207748413,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.7268950939178467,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.7232451438903809,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.6971189975738525,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6872259378433228,
            "answer": "daddy",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7232451736927032
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7535478472709656,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.7340478897094727,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7201281189918518,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7008144855499268,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.6758297085762024,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6740964651107788,
            "answer": "divine",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7535479068756104
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8905990719795227,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8263493776321411,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.7923941612243652,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.738160252571106,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.735486626625061,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.733202338218689,
            "answer": "mothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8905990719795227
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.6973208785057068,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.6510785818099976,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6441690921783447,
            "answer": "mistress",
            "hit": false
          },
          {
            "score": 0.6412545442581177,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6402987837791443,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6368530988693237,
            "answer": "salon",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6973208785057068
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.7872298359870911,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7337185144424438,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7280167937278748,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.7060402631759644,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7005857825279236,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.6924872398376465,
            "answer": "feminism",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7280167937278748
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7413336038589478,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.721927285194397,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.7208398580551147,
            "answer": "kingdom",
            "hit": false
          },
          {
            "score": 0.7086098194122314,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6851649284362793,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.665035605430603,
            "answer": "duchess",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7413335740566254
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.7213557362556458,
            "answer": "mans",
            "hit": false
          },
          {
            "score": 0.6974917650222778,
            "answer": "mania",
            "hit": false
          },
          {
            "score": 0.6957785487174988,
            "answer": "mann",
            "hit": false
          },
          {
            "score": 0.6650102138519287,
            "answer": "maid",
            "hit": false
          },
          {
            "score": 0.6599093675613403,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.6511416435241699,
            "answer": "girl",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6599093973636627
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9178600311279297,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8147581815719604,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8091816902160645,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.7776214480400085,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7736462354660034,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7491441369056702,
            "answer": "uncle",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9178600609302521
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.7266529202461243,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.7059997320175171,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.691235363483429,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.679882287979126,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6406742930412292,
            "answer": "duke",
            "hit": false
          },
          {
            "score": 0.6386032700538635,
            "answer": "royal",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7266529202461243
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.6735116243362427,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6674546003341675,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.630354106426239,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.6294195055961609,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6279028654098511,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6224387884140015,
            "answer": "sons",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6674546301364899
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8762771487236023,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.7888675332069397,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7693102359771729,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7583470344543457,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7477867603302002,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.72746342420578,
            "answer": "grandfather",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8762771785259247
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 18,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "39485d6a-5fc0-40e1-aea7-ce965f4697a9",
      "timestamp": "2025-05-18T10:35:36.012964"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7375508546829224,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.6744955778121948,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6567530632019043,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.6560510993003845,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.6504543423652649,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.6478904485702515,
            "answer": "ambient",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5624426826834679
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7023516297340393,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.6391563415527344,
            "answer": "baggage",
            "hit": false
          },
          {
            "score": 0.6244105100631714,
            "answer": "gas",
            "hit": false
          },
          {
            "score": 0.6183308959007263,
            "answer": "sacks",
            "hit": false
          },
          {
            "score": 0.617612361907959,
            "answer": "pouch",
            "hit": false
          },
          {
            "score": 0.6133087277412415,
            "answer": "bin",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5877259075641632
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6658049821853638,
            "answer": "hairs",
            "hit": false
          },
          {
            "score": 0.6617205142974854,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.6491082310676575,
            "answer": "robes",
            "hit": false
          },
          {
            "score": 0.6471390724182129,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.6442145109176636,
            "answer": "eyebrows",
            "hit": false
          },
          {
            "score": 0.6384733319282532,
            "answer": "trousers",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6617205142974854
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.762367844581604,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.628061056137085,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.6224932670593262,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.6205938458442688,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.5969095230102539,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.589846670627594,
            "answer": "bones",
            "hit": true
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5838937014341354
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7738726735115051,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7021825313568115,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.7016745209693909,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.682672381401062,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.6768828630447388,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.6570332050323486,
            "answer": "shoe",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6373785436153412
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8539845943450928,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.6586514711380005,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.6527307629585266,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6513134241104126,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.6450611352920532,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.6444330215454102,
            "answer": "liquor",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6326121985912323
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8469610214233398,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7061323523521423,
            "answer": "bow",
            "hit": false
          },
          {
            "score": 0.6433892250061035,
            "answer": "basin",
            "hit": false
          },
          {
            "score": 0.6398806571960449,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.6298038959503174,
            "answer": "dish",
            "hit": false
          },
          {
            "score": 0.6264933347702026,
            "answer": "bucket",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6017419397830963
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.652140200138092,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.6494960784912109,
            "answer": "cock",
            "hit": false
          },
          {
            "score": 0.6455833315849304,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.6411723494529724,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.640884518623352,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.6406164169311523,
            "answer": "vodka",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5931244865059853
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6394011378288269,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.6242818832397461,
            "answer": "drawer",
            "hit": false
          },
          {
            "score": 0.6217164397239685,
            "answer": "laptop",
            "hit": false
          },
          {
            "score": 0.6216980218887329,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.6202890872955322,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.6185485124588013,
            "answer": "desktop",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 89,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5733240023255348
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7383034229278564,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.656980037689209,
            "answer": "silver",
            "hit": false
          },
          {
            "score": 0.64527428150177,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.6325936913490295,
            "answer": "pearl",
            "hit": false
          },
          {
            "score": 0.6306803822517395,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.6258041858673096,
            "answer": "gems",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 645,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5484984070062637
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.8148353099822998,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.5995875000953674,
            "answer": "banner",
            "hit": false
          },
          {
            "score": 0.5822654962539673,
            "answer": "signal",
            "hit": false
          },
          {
            "score": 0.5816384553909302,
            "answer": "marker",
            "hit": false
          },
          {
            "score": 0.5812931060791016,
            "answer": "fruit",
            "hit": false
          },
          {
            "score": 0.5797367691993713,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 836,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5203993674367666
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8482930660247803,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6467865705490112,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.6163512468338013,
            "answer": "housing",
            "hit": false
          },
          {
            "score": 0.6155543923377991,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6113348007202148,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.6089763641357422,
            "answer": "cottage",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5446573942899704
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.6571401357650757,
            "answer": "jem",
            "hit": false
          },
          {
            "score": 0.6306318044662476,
            "answer": "jane",
            "hit": false
          },
          {
            "score": 0.623427152633667,
            "answer": "jamie",
            "hit": false
          },
          {
            "score": 0.6160581707954407,
            "answer": "joy",
            "hit": false
          },
          {
            "score": 0.6072970628738403,
            "answer": "grass",
            "hit": false
          },
          {
            "score": 0.607240617275238,
            "answer": "jamaica",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 3908,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5259931739419699
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.657394528388977,
            "answer": "gardening",
            "hit": false
          },
          {
            "score": 0.6543561816215515,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.6480318307876587,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.6470316648483276,
            "answer": "backyard",
            "hit": false
          },
          {
            "score": 0.6381882429122925,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.6364903450012207,
            "answer": "turf",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6130410581827164
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7389492392539978,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.6309605240821838,
            "answer": "optics",
            "hit": false
          },
          {
            "score": 0.6299923658370972,
            "answer": "lash",
            "hit": false
          },
          {
            "score": 0.6276597380638123,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6259443163871765,
            "answer": "lac",
            "hit": false
          },
          {
            "score": 0.624504566192627,
            "answer": "litres",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6276597380638123
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.710749626159668,
            "answer": "mir",
            "hit": false
          },
          {
            "score": 0.7106834053993225,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.6490697860717773,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6418551802635193,
            "answer": "magic",
            "hit": false
          },
          {
            "score": 0.6350502967834473,
            "answer": "gradient",
            "hit": false
          },
          {
            "score": 0.6328272819519043,
            "answer": "sky",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6490697860717773
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6965945959091187,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.6846514344215393,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6782660484313965,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.6633355617523193,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.6623582243919373,
            "answer": "payment",
            "hit": false
          },
          {
            "score": 0.6617000699043274,
            "answer": "currency",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.573549896478653
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7994660139083862,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6917320489883423,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6730870008468628,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.6713525056838989,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.67038893699646,
            "answer": "aquatic",
            "hit": false
          },
          {
            "score": 0.6583910584449768,
            "answer": "underwater",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6258534044027328
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.6972355246543884,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.6805863976478577,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.6795984506607056,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.6769770979881287,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.6701115965843201,
            "answer": "cakes",
            "hit": false
          },
          {
            "score": 0.6579318046569824,
            "answer": "cake",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 611,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5874680578708649
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6634935140609741,
            "answer": "nickel",
            "hit": true
          },
          {
            "score": 0.6611821055412292,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.651036262512207,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6353464126586914,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.6334021091461182,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.6318085789680481,
            "answer": "monetary",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5910582318902016
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.6809676885604858,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.6648544073104858,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.6542103290557861,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.6290549635887146,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6210944652557373,
            "answer": "pillar",
            "hit": false
          },
          {
            "score": 0.6179436445236206,
            "answer": "lilly",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.551532294601202
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.7557613849639893,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.6601964831352234,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.6537692546844482,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.6439782381057739,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.6392765045166016,
            "answer": "steel",
            "hit": false
          },
          {
            "score": 0.6391820907592773,
            "answer": "aluminum",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6008901447057724
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.6925646066665649,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6701230406761169,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.640740692615509,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.6293874382972717,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.6285344362258911,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.6282597780227661,
            "answer": "naval",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 77,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5778380632400513
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6653968691825867,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.6342625021934509,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6293495893478394,
            "answer": "syrup",
            "hit": false
          },
          {
            "score": 0.6291177868843079,
            "answer": "sip",
            "hit": false
          },
          {
            "score": 0.6290009021759033,
            "answer": "scoop",
            "hit": false
          },
          {
            "score": 0.6169848442077637,
            "answer": "sugar",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5653418824076653
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7313997149467468,
            "answer": "figure",
            "hit": false
          },
          {
            "score": 0.7156316637992859,
            "answer": "fig",
            "hit": false
          },
          {
            "score": 0.6995021104812622,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6279692649841309,
            "answer": "row",
            "hit": false
          },
          {
            "score": 0.6218815445899963,
            "answer": "tab",
            "hit": false
          },
          {
            "score": 0.6207824945449829,
            "answer": "column",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 55,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5508422777056694
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6229375600814819,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.6209516525268555,
            "answer": "worm",
            "hit": false
          },
          {
            "score": 0.6182400584220886,
            "answer": "wizard",
            "hit": false
          },
          {
            "score": 0.6161245703697205,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6161242127418518,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.6137405633926392,
            "answer": "linear",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 1217,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5742897763848305
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.7718870639801025,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7150546312332153,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.6878501176834106,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6873803734779358,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6844044923782349,
            "answer": "vine",
            "hit": false
          },
          {
            "score": 0.6823559403419495,
            "answer": "meat",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6759990453720093
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.7425887584686279,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.693801760673523,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.6656904220581055,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.6614775657653809,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.6414942741394043,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6393882036209106,
            "answer": "wood",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6151491478085518
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 28,
      "accuracy": 0.03571428571428571
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "32047948-371a-48b4-9f31-5e8c9d6aca0f",
      "timestamp": "2025-05-18T10:35:36.087520"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.718339204788208,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.6690036654472351,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.663274884223938,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.65694260597229,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.6528253555297852,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.6498295664787292,
            "answer": "feathers",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6290429830551147
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8244803547859192,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6768486499786377,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.6730318665504456,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6653422713279724,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.6417674422264099,
            "answer": "thighs",
            "hit": false
          },
          {
            "score": 0.6400109529495239,
            "answer": "forearm",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6018067970871925
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.6648187637329102,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.6436495780944824,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.6412864923477173,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.6362252235412598,
            "answer": "caroline",
            "hit": false
          },
          {
            "score": 0.6343404054641724,
            "answer": "carter",
            "hit": false
          },
          {
            "score": 0.6337053775787354,
            "answer": "can",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 639,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.555182620882988
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8227982521057129,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7815802693367004,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7159043550491333,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7110059261322021,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7077625393867493,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.6985098123550415,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.68196702003479
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.7912307977676392,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.7492547631263733,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.7269903421401978,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.6705779433250427,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.6678516864776611,
            "answer": "protestant",
            "hit": false
          },
          {
            "score": 0.6659553050994873,
            "answer": "church",
            "hit": true
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5755733996629715
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.7563028335571289,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.6966656446456909,
            "answer": "university",
            "hit": true
          },
          {
            "score": 0.6632249355316162,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6598368883132935,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6595603227615356,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.6510576009750366,
            "answer": "campus",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6966656446456909
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.7689241170883179,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7093289494514465,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7049473524093628,
            "answer": "country",
            "hit": true
          },
          {
            "score": 0.7037512063980103,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6829383969306946,
            "answer": "pradesh",
            "hit": false
          },
          {
            "score": 0.6773340702056885,
            "answer": "statewide",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6546684801578522
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7567081451416016,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6937159299850464,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.656699538230896,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6313392519950867,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6295818090438843,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6259345412254333,
            "answer": "goat",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.656699538230896
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7581809163093567,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.7402610182762146,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.735727846622467,
            "answer": "crowds",
            "hit": false
          },
          {
            "score": 0.6709784269332886,
            "answer": "swarm",
            "hit": false
          },
          {
            "score": 0.6449791789054871,
            "answer": "population",
            "hit": false
          },
          {
            "score": 0.6440852880477905,
            "answer": "populations",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 3098,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5671133026480675
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8471015095710754,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6690242290496826,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.6644830703735352,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.6595984697341919,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.6530168652534485,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6521584391593933,
            "answer": "circus",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6494516730308533
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.7899392247200012,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.7270363569259644,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.7218447923660278,
            "answer": "workforce",
            "hit": false
          },
          {
            "score": 0.7182105779647827,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.7035689353942871,
            "answer": "employed",
            "hit": false
          },
          {
            "score": 0.7032442092895508,
            "answer": "employer",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 101,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6265047788619995
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.7620412707328796,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7099697589874268,
            "answer": "trout",
            "hit": false
          },
          {
            "score": 0.7093781232833862,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7042632102966309,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.6824012398719788,
            "answer": "fisher",
            "hit": false
          },
          {
            "score": 0.6770690679550171,
            "answer": "salmon",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 1202,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5314801782369614
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8145626187324524,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.6900362372398376,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.6836533546447754,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.6730945706367493,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.6652091145515442,
            "answer": "planets",
            "hit": false
          },
          {
            "score": 0.6503527760505676,
            "answer": "universe",
            "hit": true
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.65035280585289
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.7639871835708618,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7036851644515991,
            "answer": "software",
            "hit": false
          },
          {
            "score": 0.6939813494682312,
            "answer": "linear",
            "hit": false
          },
          {
            "score": 0.6907446980476379,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6899478435516357,
            "answer": "america",
            "hit": false
          },
          {
            "score": 0.6826112866401672,
            "answer": "profits",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 178,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6334634125232697
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.713112473487854,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.669818103313446,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.6149792075157166,
            "answer": "legion",
            "hit": false
          },
          {
            "score": 0.6125701069831848,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.6120972633361816,
            "answer": "lyon",
            "hit": false
          },
          {
            "score": 0.6084856390953064,
            "answer": "lil",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5993220508098602
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.731808066368103,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6837815046310425,
            "answer": "observer",
            "hit": false
          },
          {
            "score": 0.649290919303894,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6465160846710205,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.6406667232513428,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.6392555832862854,
            "answer": "orchestra",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6175451651215553
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.7601252198219299,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.719620943069458,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.6278232336044312,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.6258299350738525,
            "answer": "speaker",
            "hit": false
          },
          {
            "score": 0.6254306435585022,
            "answer": "group",
            "hit": true
          },
          {
            "score": 0.6237480640411377,
            "answer": "mps",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.564680278301239
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8622704744338989,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.7802442312240601,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.7625991106033325,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.7490081787109375,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.7483640909194946,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.7478625774383545,
            "answer": "musical",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.731100931763649
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7407056093215942,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.6971354484558105,
            "answer": "personnel",
            "hit": false
          },
          {
            "score": 0.692013680934906,
            "answer": "personality",
            "hit": false
          },
          {
            "score": 0.6839205026626587,
            "answer": "persona",
            "hit": false
          },
          {
            "score": 0.6546376347541809,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.6535215377807617,
            "answer": "personalities",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 50,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5380888544023037
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.7962024211883545,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.7593981027603149,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7324997186660767,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.7207570672035217,
            "answer": "picture",
            "hit": false
          },
          {
            "score": 0.7098286151885986,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.696090579032898,
            "answer": "photographers",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 82,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5662087947130203
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.7882943749427795,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7249836921691895,
            "answer": "play",
            "hit": false
          },
          {
            "score": 0.7060936689376831,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.694021999835968,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.688133716583252,
            "answer": "gameplay",
            "hit": false
          },
          {
            "score": 0.6787757277488708,
            "answer": "tournaments",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 127,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5437203645706177
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.767540454864502,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.7616572380065918,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7255287766456604,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6977633237838745,
            "answer": "detectives",
            "hit": false
          },
          {
            "score": 0.6852695345878601,
            "answer": "detective",
            "hit": false
          },
          {
            "score": 0.682960569858551,
            "answer": "sheriff",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7675405144691467
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.6867377161979675,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.6633013486862183,
            "answer": "assistant",
            "hit": false
          },
          {
            "score": 0.6592683792114258,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6545432806015015,
            "answer": "secret",
            "hit": false
          },
          {
            "score": 0.6502447128295898,
            "answer": "assistants",
            "hit": false
          },
          {
            "score": 0.6494929790496826,
            "answer": "commissioner",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 2385,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5616916194558144
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.7691673040390015,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.7218630313873291,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.720115065574646,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7155401706695557,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.7035355567932129,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.6845237016677856,
            "answer": "politicians",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7201150059700012
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7176898717880249,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7170277833938599,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.705717921257019,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.682401716709137,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6814702749252319,
            "answer": "pigs",
            "hit": false
          },
          {
            "score": 0.679402768611908,
            "answer": "flock",
            "hit": true
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6794027835130692
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8654711246490479,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7440751791000366,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7387719750404358,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.7210652828216553,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.6992590427398682,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.6952002048492432,
            "answer": "armies",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.738771989941597
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.7422696352005005,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7405767440795898,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7137196063995361,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7110531330108643,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.7099635601043701,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.6969003081321716,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 56,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.568389281630516
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.727698802947998,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.7101001739501953,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.6782993078231812,
            "answer": "united",
            "hit": false
          },
          {
            "score": 0.6766315698623657,
            "answer": "software",
            "hit": false
          },
          {
            "score": 0.676349937915802,
            "answer": "contract",
            "hit": false
          },
          {
            "score": 0.6644601225852966,
            "answer": "people",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6110067591071129
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8576377630233765,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7248576879501343,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7076844573020935,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7060214281082153,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6975640058517456,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.6960744261741638,
            "answer": "university",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5632779449224472
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.8572951555252075,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.6268770694732666,
            "answer": "forests",
            "hit": false
          },
          {
            "score": 0.6234543919563293,
            "answer": "branches",
            "hit": false
          },
          {
            "score": 0.6205509305000305,
            "answer": "trunk",
            "hit": false
          },
          {
            "score": 0.6156629323959351,
            "answer": "bushes",
            "hit": false
          },
          {
            "score": 0.6155635714530945,
            "answer": "forest",
            "hit": true
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6155635565519333
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.7027299404144287,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6644437313079834,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.6533979177474976,
            "answer": "snow",
            "hit": false
          },
          {
            "score": 0.6522665619850159,
            "answer": "wind",
            "hit": false
          },
          {
            "score": 0.6395332217216492,
            "answer": "pierre",
            "hit": false
          },
          {
            "score": 0.6393401622772217,
            "answer": "wilson",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6211496591567993
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7339738011360168,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.7020217180252075,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.6534841656684875,
            "answer": "language",
            "hit": false
          },
          {
            "score": 0.6354411840438843,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.626981258392334,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.6209920048713684,
            "answer": "noun",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5709195137023926
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "df4ba30a-6031-484b-bff9-7baaa06b10b7",
      "timestamp": "2025-05-18T10:35:36.202521"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.716985285282135,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.6479302644729614,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6259216070175171,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6155067682266235,
            "answer": "busy",
            "hit": false
          },
          {
            "score": 0.5943552851676941,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.5918324589729309,
            "answer": "cent",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5408577471971512
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.698555588722229,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.6577855944633484,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6557546854019165,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6539052128791809,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6389836072921753,
            "answer": "bits",
            "hit": false
          },
          {
            "score": 0.6312223672866821,
            "answer": "angle",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 13361,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5034176725894213
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.6407334208488464,
            "answer": "combo",
            "hit": false
          },
          {
            "score": 0.6297677755355835,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6162175536155701,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6155396699905396,
            "answer": "combat",
            "hit": false
          },
          {
            "score": 0.6076643466949463,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6072911620140076,
            "answer": "combination",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 163,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5306434109807014
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.7350969314575195,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6717991828918457,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6600769758224487,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.657513439655304,
            "answer": "pound",
            "hit": false
          },
          {
            "score": 0.656585693359375,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6505780220031738,
            "answer": "money",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 2731,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5665248259902
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3bbf387e-3fa7-4dcc-adbb-b1cb47025aae",
      "timestamp": "2025-05-18T10:35:36.339051"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.728513240814209,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.7243189215660095,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7103542685508728,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.6959009170532227,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.682070791721344,
            "answer": "intrigued",
            "hit": false
          },
          {
            "score": 0.6739683151245117,
            "answer": "agitated",
            "hit": true
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6739683151245117
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8492447137832642,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6580702662467957,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.647953987121582,
            "answer": "horse",
            "hit": false
          },
          {
            "score": 0.6261721849441528,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6260923147201538,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.6221309900283813,
            "answer": "boat",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5574522539973259
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7327189445495605,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.6335167288780212,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.622530996799469,
            "answer": "rivers",
            "hit": false
          },
          {
            "score": 0.6219168901443481,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6210941076278687,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.6209337115287781,
            "answer": "oceans",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5834706872701645
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.7018449306488037,
            "answer": "painter",
            "hit": false
          },
          {
            "score": 0.6910637617111206,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.6845851540565491,
            "answer": "painting",
            "hit": false
          },
          {
            "score": 0.6680663824081421,
            "answer": "paints",
            "hit": false
          },
          {
            "score": 0.6674782037734985,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.6673939228057861,
            "answer": "paintings",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.621777817606926
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.6850414276123047,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6843324899673462,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6623925566673279,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.6596677899360657,
            "answer": "pokemon",
            "hit": false
          },
          {
            "score": 0.6559914350509644,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.6496609449386597,
            "answer": "puppet",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6559914648532867
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.6891804933547974,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.682138979434967,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6421043276786804,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.6397347450256348,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.6348578929901123,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6343201994895935,
            "answer": "marine",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6821390241384506
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8481073975563049,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.6994972229003906,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.6894981265068054,
            "answer": "meal",
            "hit": true
          },
          {
            "score": 0.6821233034133911,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.6803873777389526,
            "answer": "meals",
            "hit": false
          },
          {
            "score": 0.6784688234329224,
            "answer": "pizza",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6894981265068054
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.7911969423294067,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.7248317003250122,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.6981972455978394,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.6847909688949585,
            "answer": "sleepy",
            "hit": false
          },
          {
            "score": 0.6820505857467651,
            "answer": "fatigue",
            "hit": false
          },
          {
            "score": 0.6695353984832764,
            "answer": "annoyed",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7248317301273346
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 8,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "64f84cee-8779-46dc-abfc-a0e45d4f3a3d",
      "timestamp": "2025-05-18T10:35:36.361514"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8520665168762207,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.7717129588127136,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.757709264755249,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7511883974075317,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.7177855968475342,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.7136267423629761,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8520665466785431
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.6929174661636353,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.6710717678070068,
            "answer": "fabric",
            "hit": true
          },
          {
            "score": 0.6650991439819336,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.6614862084388733,
            "answer": "clothes",
            "hit": false
          },
          {
            "score": 0.6611119508743286,
            "answer": "clothing",
            "hit": false
          },
          {
            "score": 0.659602701663971,
            "answer": "leather",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6710717380046844
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.7696918249130249,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7463365793228149,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.7198060750961304,
            "answer": "doll",
            "hit": false
          },
          {
            "score": 0.7067151069641113,
            "answer": "pounds",
            "hit": false
          },
          {
            "score": 0.7062055468559265,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7030608654022217,
            "answer": "money",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7463365197181702
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.7612736225128174,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.6974980235099792,
            "answer": "daddy",
            "hit": true
          },
          {
            "score": 0.6886263489723206,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.6733288764953613,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.6659218072891235,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6636148691177368,
            "answer": "grandfather",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6886263340711594
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7143231630325317,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.7127889394760132,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7082787752151489,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7017388343811035,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.6853439211845398,
            "answer": "assisting",
            "hit": false
          },
          {
            "score": 0.6815930604934692,
            "answer": "assist",
            "hit": true
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6769095659255981
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.7052959203720093,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.677996039390564,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.6778172254562378,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.6765918731689453,
            "answer": "smart",
            "hit": true
          },
          {
            "score": 0.6706616282463074,
            "answer": "intelligence",
            "hit": false
          },
          {
            "score": 0.660567581653595,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6778172254562378
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7999187707901001,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7324162721633911,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7102420926094055,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.6883682012557983,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.6778634786605835,
            "answer": "necklace",
            "hit": false
          },
          {
            "score": 0.674229085445404,
            "answer": "treasures",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 47,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6195215806365013
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.7983375787734985,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.711569607257843,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.6588148474693298,
            "answer": "landmark",
            "hit": false
          },
          {
            "score": 0.6585971117019653,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.6580396890640259,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.6451846361160278,
            "answer": "sculpture",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7115696221590042
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7134539484977722,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.6968667507171631,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.6941196918487549,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.6593532562255859,
            "answer": "nyc",
            "hit": false
          },
          {
            "score": 0.6366288661956787,
            "answer": "same",
            "hit": false
          },
          {
            "score": 0.6365063786506653,
            "answer": "novel",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 152,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5771505683660507
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.7280623912811279,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.7095034718513489,
            "answer": "pack",
            "hit": true
          },
          {
            "score": 0.7072405219078064,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.6963691711425781,
            "answer": "packet",
            "hit": true
          },
          {
            "score": 0.684148371219635,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.6544506549835205,
            "answer": "packs",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6230578050017357
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8187046051025391,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.7179700136184692,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.6948813796043396,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.6702753901481628,
            "answer": "subway",
            "hit": false
          },
          {
            "score": 0.6618211269378662,
            "answer": "airport",
            "hit": false
          },
          {
            "score": 0.6585568785667419,
            "answer": "roadway",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8187046349048615
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.7485737800598145,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.6763117909431458,
            "answer": "reasoned",
            "hit": false
          },
          {
            "score": 0.6704005002975464,
            "answer": "logical",
            "hit": true
          },
          {
            "score": 0.6466941237449646,
            "answer": "reasoning",
            "hit": false
          },
          {
            "score": 0.6461629867553711,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.6447185277938843,
            "answer": "reasonable",
            "hit": true
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6704005002975464
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.7360070943832397,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7315447926521301,
            "answer": "sensible",
            "hit": true
          },
          {
            "score": 0.722145676612854,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7129822969436646,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7026434540748596,
            "answer": "decent",
            "hit": false
          },
          {
            "score": 0.6807364225387573,
            "answer": "realistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7315448075532913
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7885851860046387,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.682735800743103,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6678821444511414,
            "answer": "stone",
            "hit": true
          },
          {
            "score": 0.6319171786308289,
            "answer": "rocky",
            "hit": false
          },
          {
            "score": 0.6268520355224609,
            "answer": "rocket",
            "hit": false
          },
          {
            "score": 0.6207521557807922,
            "answer": "punk",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6678821444511414
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.833655595779419,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.6966745853424072,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.6788902878761292,
            "answer": "fireplace",
            "hit": false
          },
          {
            "score": 0.677962064743042,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.6712253093719482,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.6678645610809326,
            "answer": "bedroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.833655595779419
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.7547559142112732,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.6906064748764038,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.6852150559425354,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.6434734463691711,
            "answer": "fashion",
            "hit": true
          },
          {
            "score": 0.6272764205932617,
            "answer": "fashioned",
            "hit": false
          },
          {
            "score": 0.619485080242157,
            "answer": "lifestyle",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5983819141983986
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "23c4b4cd-a04b-45f6-8cc1-8b9b206a0d8c",
      "timestamp": "2025-05-18T10:35:36.391022"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7339482307434082,
            "answer": "afterwards",
            "hit": false
          },
          {
            "score": 0.7243005037307739,
            "answer": "afterward",
            "hit": false
          },
          {
            "score": 0.6672120690345764,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.6507706642150879,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6491760015487671,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.6395126581192017,
            "answer": "aftermath",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6059139668941498
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.6533777713775635,
            "answer": "away",
            "hit": false
          },
          {
            "score": 0.642766535282135,
            "answer": "beyond",
            "hit": false
          },
          {
            "score": 0.6391876935958862,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.6349521279335022,
            "answer": "vance",
            "hit": false
          },
          {
            "score": 0.6315807104110718,
            "answer": "outside",
            "hit": false
          },
          {
            "score": 0.6309692859649658,
            "answer": "onwards",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.581816554069519
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8041799068450928,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.6701705455780029,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.6413975954055786,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.6384947896003723,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.6146194338798523,
            "answer": "inferior",
            "hit": false
          },
          {
            "score": 0.6139216423034668,
            "answer": "abdominal",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8041799068450928
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.7381309270858765,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.696161150932312,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.6837300062179565,
            "answer": "without",
            "hit": false
          },
          {
            "score": 0.670872151851654,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.6706387996673584,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6686619520187378,
            "answer": "previously",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6407829523086548
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7955255508422852,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.7515296339988708,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.7216363549232483,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.7213364839553833,
            "answer": "starts",
            "hit": false
          },
          {
            "score": 0.7176546454429626,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.7135843634605408,
            "answer": "begun",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6396726965904236
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7087321281433105,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7080599069595337,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.6925646066665649,
            "answer": "lifeless",
            "hit": false
          },
          {
            "score": 0.6649024486541748,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6608970165252686,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.6592242121696472,
            "answer": "slain",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6466853022575378
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8208642601966858,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.6944202184677124,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.6659154891967773,
            "answer": "jump",
            "hit": false
          },
          {
            "score": 0.6546675562858582,
            "answer": "leap",
            "hit": false
          },
          {
            "score": 0.653511643409729,
            "answer": "climb",
            "hit": false
          },
          {
            "score": 0.6509632468223572,
            "answer": "dove",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 925,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5736622735857964
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.7290416955947876,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.714958131313324,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.6953430771827698,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.69060879945755,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.674689769744873,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.6728107929229736,
            "answer": "spring",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 1399,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5643246620893478
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7425364255905151,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.6951342821121216,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.6764547824859619,
            "answer": "fourth",
            "hit": false
          },
          {
            "score": 0.6346519589424133,
            "answer": "fifth",
            "hit": false
          },
          {
            "score": 0.6279881000518799,
            "answer": "one",
            "hit": false
          },
          {
            "score": 0.6028150320053101,
            "answer": "last",
            "hit": true
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6028150618076324
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.7677813768386841,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.7015284299850464,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.6762787103652954,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.645106315612793,
            "answer": "feed",
            "hit": false
          },
          {
            "score": 0.6336727142333984,
            "answer": "attribute",
            "hit": false
          },
          {
            "score": 0.6322239637374878,
            "answer": "sensitivity",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7015284448862076
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7915465235710144,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7354403138160706,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.6901976466178894,
            "answer": "indoors",
            "hit": false
          },
          {
            "score": 0.6841217875480652,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.6657987236976624,
            "answer": "upstairs",
            "hit": false
          },
          {
            "score": 0.647951602935791,
            "answer": "insider",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7915465235710144
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.7169104814529419,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.6984163522720337,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.6798442602157593,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6492491960525513,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.6477148532867432,
            "answer": "intern",
            "hit": false
          },
          {
            "score": 0.610811173915863,
            "answer": "domestic",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6984163373708725
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.703982949256897,
            "answer": "mort",
            "hit": false
          },
          {
            "score": 0.6680091619491577,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.6545192003250122,
            "answer": "lethal",
            "hit": false
          },
          {
            "score": 0.6438570022583008,
            "answer": "eternal",
            "hit": false
          },
          {
            "score": 0.6436856985092163,
            "answer": "deadly",
            "hit": false
          },
          {
            "score": 0.6428521871566772,
            "answer": "mortality",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6680091917514801
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.7731409072875977,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.7497209310531616,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7379406094551086,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7333086133003235,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7193558216094971,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.6710650324821472,
            "answer": "invaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6597989797592163
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.7751694321632385,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.632692277431488,
            "answer": "overall",
            "hit": false
          },
          {
            "score": 0.6196752190589905,
            "answer": "overtime",
            "hit": false
          },
          {
            "score": 0.6171731948852539,
            "answer": "oven",
            "hit": false
          },
          {
            "score": 0.6167126297950745,
            "answer": "overlapping",
            "hit": false
          },
          {
            "score": 0.613234281539917,
            "answer": "overlap",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 2016,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.564531072974205
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.7890889644622803,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7468419671058655,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.7116965055465698,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.7108892202377319,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.696986198425293,
            "answer": "currently",
            "hit": false
          },
          {
            "score": 0.6746536493301392,
            "answer": "before",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5730088651180267
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8224976658821106,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7611866593360901,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.7566813230514526,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.6955666542053223,
            "answer": "commence",
            "hit": false
          },
          {
            "score": 0.6883571147918701,
            "answer": "pursue",
            "hit": false
          },
          {
            "score": 0.686450719833374,
            "answer": "progresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 3166,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5430897511541843
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.819431483745575,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.774101734161377,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.745826244354248,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.713238000869751,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.7020814418792725,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.693922758102417,
            "answer": "raise",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 207,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5565657280385494
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.9109043478965759,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.8200392127037048,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.8037340044975281,
            "answer": "southern",
            "hit": false
          },
          {
            "score": 0.8017193078994751,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8009706735610962,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.7533546686172485,
            "answer": "northern",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9109044075012207
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.9184741377830505,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.9084049463272095,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8405838012695312,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.8078150749206543,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.761257529258728,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.746062159538269,
            "answer": "southern",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7239016145467758
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.9230513572692871,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.6803266406059265,
            "answer": "tow",
            "hit": false
          },
          {
            "score": 0.642720639705658,
            "answer": "into",
            "hit": false
          },
          {
            "score": 0.6382838487625122,
            "answer": "nearer",
            "hit": false
          },
          {
            "score": 0.6272438168525696,
            "answer": "farther",
            "hit": false
          },
          {
            "score": 0.6260512471199036,
            "answer": "closer",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 88,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5658843442797661
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.6530941724777222,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.6447193622589111,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.6389985084533691,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.6129453182220459,
            "answer": "falsely",
            "hit": false
          },
          {
            "score": 0.6066126227378845,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.600225567817688,
            "answer": "accurate",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6530941426753998
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.7108266353607178,
            "answer": "western",
            "hit": false
          },
          {
            "score": 0.645796000957489,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.6294347643852234,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.6278952360153198,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.6156001091003418,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.6042342185974121,
            "answer": "eastern",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6156000718474388
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 23,
      "accuracy": 0.21739130434782608
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8a3fda06-9b98-42a9-a92a-20ac1fee08c0",
      "timestamp": "2025-05-18T10:35:36.453107"
    }
  }
]