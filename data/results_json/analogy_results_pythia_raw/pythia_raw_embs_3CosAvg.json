[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.8445147275924683,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.6402600407600403,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.6393750905990601,
            "answer": "vocals",
            "hit": false
          },
          {
            "score": 0.6343991160392761,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.6323590278625488,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.6310364007949829,
            "answer": "guitarist",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8445147573947906
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.7148686647415161,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.6424143314361572,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6089854836463928,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6055986285209656,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.6040226221084595,
            "answer": "app",
            "hit": false
          },
          {
            "score": 0.5999224185943604,
            "answer": "applicant",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7148686498403549
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7407176494598389,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.6324817538261414,
            "answer": "zones",
            "hit": false
          },
          {
            "score": 0.6275445222854614,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6220054030418396,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.6139919757843018,
            "answer": "sectors",
            "hit": false
          },
          {
            "score": 0.6136824488639832,
            "answer": "regions",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7407176494598389
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.6197341680526733,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.6028487086296082,
            "answer": "drivers",
            "hit": false
          },
          {
            "score": 0.5944697856903076,
            "answer": "automobiles",
            "hit": false
          },
          {
            "score": 0.589530885219574,
            "answer": "cas",
            "hit": false
          },
          {
            "score": 0.5857806205749512,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.5855546593666077,
            "answer": "storms",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6197341457009315
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.7475883960723877,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.6963539123535156,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6686532497406006,
            "answer": "university",
            "hit": false
          },
          {
            "score": 0.6603473424911499,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.644495964050293,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.6175304651260376,
            "answer": "students",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7475884258747101
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8154003620147705,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.6208663582801819,
            "answer": "board",
            "hit": false
          },
          {
            "score": 0.6183145046234131,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.6180008053779602,
            "answer": "advisers",
            "hit": false
          },
          {
            "score": 0.6142472624778748,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.6140998005867004,
            "answer": "chiefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8154003322124481
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.7270129919052124,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.6307696104049683,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.6264603137969971,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.625704288482666,
            "answer": "patient",
            "hit": false
          },
          {
            "score": 0.6223443150520325,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.6181880831718445,
            "answer": "clients",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7270130217075348
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.6825176477432251,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.6245468258857727,
            "answer": "nights",
            "hit": false
          },
          {
            "score": 0.6220605373382568,
            "answer": "mornings",
            "hit": false
          },
          {
            "score": 0.6188541650772095,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.604278564453125,
            "answer": "daytime",
            "hit": false
          },
          {
            "score": 0.6019955277442932,
            "answer": "today",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6825176775455475
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.7907742857933044,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7051481604576111,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6625725030899048,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.6542502045631409,
            "answer": "killing",
            "hit": false
          },
          {
            "score": 0.6541994214057922,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.6486932039260864,
            "answer": "dying",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7907742261886597
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.7490918040275574,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.7345367670059204,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.6331173777580261,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.6182825565338135,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.6171004772186279,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.6157330274581909,
            "answer": "institute",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7490918040275574
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7045097351074219,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6954161524772644,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.6864949464797974,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.6787856817245483,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6753557920455933,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6729650497436523,
            "answer": "develop",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.686494916677475
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7792032957077026,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.6536366939544678,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.6525811553001404,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.6413630843162537,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.634480893611908,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.6298726797103882,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7792032957077026
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8117043375968933,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.703902006149292,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.672663688659668,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.646737813949585,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.6396653652191162,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.635278046131134,
            "answer": "directs",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8117043972015381
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.6979874968528748,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.6032636165618896,
            "answer": "vents",
            "hit": false
          },
          {
            "score": 0.5942744612693787,
            "answer": "participants",
            "hit": false
          },
          {
            "score": 0.5922567248344421,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.5905090570449829,
            "answer": "reactions",
            "hit": false
          },
          {
            "score": 0.5904677510261536,
            "answer": "sessions",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.697987511754036
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.7547977566719055,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.612293004989624,
            "answer": "sample",
            "hit": false
          },
          {
            "score": 0.612144947052002,
            "answer": "illustrate",
            "hit": false
          },
          {
            "score": 0.6067247986793518,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.606529176235199,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.6063883900642395,
            "answer": "exemplary",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7547977566719055
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7055078744888306,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.6601714491844177,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.592767059803009,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.5906848907470703,
            "answer": "actually",
            "hit": false
          },
          {
            "score": 0.5901921987533569,
            "answer": "indeed",
            "hit": false
          },
          {
            "score": 0.5809025168418884,
            "answer": "effect",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055078595876694
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.685675859451294,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.6346635222434998,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.629830539226532,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.6280417442321777,
            "answer": "friendly",
            "hit": false
          },
          {
            "score": 0.6039888262748718,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.60345059633255,
            "answer": "buddy",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6856758296489716
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.6818123459815979,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.6671476364135742,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.6670827865600586,
            "answer": "heaven",
            "hit": false
          },
          {
            "score": 0.6571061015129089,
            "answer": "lord",
            "hit": false
          },
          {
            "score": 0.6490930318832397,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.6423168182373047,
            "answer": "allah",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6818123906850815
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.7623598575592041,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.6546008586883545,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.6452476978302002,
            "answer": "authorities",
            "hit": false
          },
          {
            "score": 0.6376523375511169,
            "answer": "govern",
            "hit": false
          },
          {
            "score": 0.6267011165618896,
            "answer": "commonwealth",
            "hit": false
          },
          {
            "score": 0.6250081062316895,
            "answer": "officials",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7623598277568817
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.77117919921875,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.6939677000045776,
            "answer": "minutes",
            "hit": false
          },
          {
            "score": 0.665797233581543,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.6481597423553467,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6431739926338196,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.6335660815238953,
            "answer": "evenings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.77117919921875
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.7317922115325928,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.6920945644378662,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.6756764650344849,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.6622776985168457,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.6431096792221069,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.6400948762893677,
            "answer": "suggestions",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6920945942401886
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.7527194023132324,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.652673065662384,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.6187777519226074,
            "answer": "lang",
            "hit": false
          },
          {
            "score": 0.6134189367294312,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.6110162138938904,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.6100165247917175,
            "answer": "terminology",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7527194023132324
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.7284643054008484,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.6399512887001038,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.6361072063446045,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.6340970396995544,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6295619010925293,
            "answer": "legally",
            "hit": false
          },
          {
            "score": 0.6227781176567078,
            "answer": "statute",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7284643352031708
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.7011203765869141,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.6281480193138123,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.5855242609977722,
            "answer": "directors",
            "hit": false
          },
          {
            "score": 0.585318922996521,
            "answer": "participants",
            "hit": false
          },
          {
            "score": 0.5848612785339355,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.5846387147903442,
            "answer": "mps",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7011203318834305
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.6752814054489136,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.6344231963157654,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.6270120143890381,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.6198363304138184,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6169992685317993,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.6142914891242981,
            "answer": "semester",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6752813756465912
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.7252345085144043,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.6731489896774292,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.6506134271621704,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.6292166709899902,
            "answer": "tonight",
            "hit": false
          },
          {
            "score": 0.6250894069671631,
            "answer": "midnight",
            "hit": false
          },
          {
            "score": 0.6235026121139526,
            "answer": "afternoon",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7252345234155655
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7549641132354736,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.6458867788314819,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.6178004741668701,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.610116720199585,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.6077688932418823,
            "answer": "headquarters",
            "hit": false
          },
          {
            "score": 0.6077491044998169,
            "answer": "agency",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7549641132354736
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8851681351661682,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.6262862682342529,
            "answer": "intervals",
            "hit": false
          },
          {
            "score": 0.6249068379402161,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6243958473205566,
            "answer": "duration",
            "hit": false
          },
          {
            "score": 0.6161766052246094,
            "answer": "dates",
            "hit": false
          },
          {
            "score": 0.6158022284507751,
            "answer": "interval",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8851680755615234
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.6965086460113525,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.6203306317329407,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.6076491475105286,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.6044647693634033,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.6005609035491943,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.5971340537071228,
            "answer": "gameplay",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6965086460113525
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8182249665260315,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.6260513663291931,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.6231058239936829,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.6177387237548828,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.6115053296089172,
            "answer": "individuals",
            "hit": false
          },
          {
            "score": 0.6094288229942322,
            "answer": "electorate",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8182249367237091
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.7292526364326477,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.6458873152732849,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.6457473039627075,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.6268219947814941,
            "answer": "trouble",
            "hit": false
          },
          {
            "score": 0.6190202832221985,
            "answer": "worries",
            "hit": false
          },
          {
            "score": 0.6175466775894165,
            "answer": "difficulties",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7292526215314865
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.7500622272491455,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.6115440130233765,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.6079627275466919,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6045765280723572,
            "answer": "medicines",
            "hit": false
          },
          {
            "score": 0.6038051843643188,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.5989022850990295,
            "answer": "productivity",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7500622272491455
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.7423726320266724,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.6024545431137085,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.5970121026039124,
            "answer": "service",
            "hit": false
          },
          {
            "score": 0.5875697135925293,
            "answer": "reserves",
            "hit": false
          },
          {
            "score": 0.5842706561088562,
            "answer": "environmental",
            "hit": false
          },
          {
            "score": 0.5839645862579346,
            "answer": "materials",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7423726171255112
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7117671966552734,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.6701589822769165,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.6417953372001648,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.6368321180343628,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.630855143070221,
            "answer": "streams",
            "hit": false
          },
          {
            "score": 0.6276394128799438,
            "answer": "pond",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 554,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5482311174273491
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8153079152107239,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7316757440567017,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.6818403005599976,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.6695335507392883,
            "answer": "streets",
            "hit": false
          },
          {
            "score": 0.6563361883163452,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.6308634281158447,
            "answer": "towns",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8153079152107239
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.757644772529602,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.5951282382011414,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.5933895111083984,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.5899304151535034,
            "answer": "effects",
            "hit": false
          },
          {
            "score": 0.5881933569908142,
            "answer": "importance",
            "hit": false
          },
          {
            "score": 0.586266815662384,
            "answer": "participation",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.757644772529602
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.696756899356842,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.663470447063446,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.6531230211257935,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6504952907562256,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.6279268264770508,
            "answer": "biology",
            "hit": false
          },
          {
            "score": 0.627636194229126,
            "answer": "astronomy",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.696756899356842
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.909024715423584,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7063230276107788,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.7034827470779419,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.6943767070770264,
            "answer": "solving",
            "hit": false
          },
          {
            "score": 0.6271694898605347,
            "answer": "dissolved",
            "hit": false
          },
          {
            "score": 0.6238104104995728,
            "answer": "alternatives",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.909024715423584
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.6917340755462646,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.6458261013031006,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.6318975687026978,
            "answer": "sung",
            "hit": false
          },
          {
            "score": 0.6285903453826904,
            "answer": "sang",
            "hit": false
          },
          {
            "score": 0.6223801970481873,
            "answer": "melody",
            "hit": false
          },
          {
            "score": 0.6188700795173645,
            "answer": "sings",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6917340904474258
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.6961578130722046,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.6198861002922058,
            "answer": "roads",
            "hit": false
          },
          {
            "score": 0.6186572909355164,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.6088558435440063,
            "answer": "road",
            "hit": false
          },
          {
            "score": 0.6046281456947327,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.6001616716384888,
            "answer": "roadway",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.696157842874527
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.7616506814956665,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.6474401950836182,
            "answer": "classmates",
            "hit": false
          },
          {
            "score": 0.6278278827667236,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.6242859363555908,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.6191555261611938,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.6180626153945923,
            "answer": "scholars",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7616506814956665
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.6365934610366821,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.585773766040802,
            "answer": "windows",
            "hit": false
          },
          {
            "score": 0.5811368227005005,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.5810767412185669,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.5798150897026062,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.5783138275146484,
            "answer": "platforms",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6365934610366821
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.7185744047164917,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.665328860282898,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.6289090514183044,
            "answer": "anything",
            "hit": false
          },
          {
            "score": 0.627835750579834,
            "answer": "everything",
            "hit": false
          },
          {
            "score": 0.6219980120658875,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.6119436025619507,
            "answer": "nothing",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7185744047164917
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.7100952863693237,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.6441262364387512,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.6409845352172852,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.6291232705116272,
            "answer": "borough",
            "hit": false
          },
          {
            "score": 0.6253080368041992,
            "answer": "downtown",
            "hit": false
          },
          {
            "score": 0.6102990508079529,
            "answer": "township",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7100953161716461
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7114474773406982,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.6355488300323486,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.6044021248817444,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.5972527861595154,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.5893698930740356,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.5889012813568115,
            "answer": "client",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7114474773406982
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.8787096738815308,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.6446696519851685,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.6406624913215637,
            "answer": "variant",
            "hit": false
          },
          {
            "score": 0.6332538723945618,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.6217359900474548,
            "answer": "copies",
            "hit": false
          },
          {
            "score": 0.609939455986023,
            "answer": "edition",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.878709614276886
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.835743248462677,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.7315671443939209,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.6857816576957703,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.636196494102478,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.6360234022140503,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.6324748396873474,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.835743248462677
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.8240661025047302,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.6748156547546387,
            "answer": "sites",
            "hit": false
          },
          {
            "score": 0.6579097509384155,
            "answer": "site",
            "hit": false
          },
          {
            "score": 0.6450265645980835,
            "answer": "blogs",
            "hit": false
          },
          {
            "score": 0.6409574151039124,
            "answer": "blog",
            "hit": false
          },
          {
            "score": 0.6301475763320923,
            "answer": "online",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8240661323070526
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7582110166549683,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.7006950378417969,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.677154004573822,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6617137789726257,
            "answer": "weekly",
            "hit": false
          },
          {
            "score": 0.658368706703186,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.6453118324279785,
            "answer": "weekends",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7582110166549683
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7475861310958862,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.6862069368362427,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.6678456664085388,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6602697372436523,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.6577751636505127,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.6466358304023743,
            "answer": "week",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7475861012935638
      }
    ],
    "result": {
      "cnt_questions_correct": 47,
      "cnt_questions_total": 50,
      "accuracy": 0.94
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "bfbb5a6c-c031-407b-adfa-3ee5644dc96a",
      "timestamp": "2025-05-18T10:34:18.777469"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.752595841884613,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.7199185490608215,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.6960811614990234,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.668177604675293,
            "answer": "capacities",
            "hit": false
          },
          {
            "score": 0.6549006700515747,
            "answer": "willingness",
            "hit": false
          },
          {
            "score": 0.6487303376197815,
            "answer": "unable",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6118156388401985
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.7719604969024658,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.6247947216033936,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.6241423487663269,
            "answer": "active",
            "hit": false
          },
          {
            "score": 0.6100696921348572,
            "answer": "installations",
            "hit": false
          },
          {
            "score": 0.6061270833015442,
            "answer": "activation",
            "hit": false
          },
          {
            "score": 0.6032332181930542,
            "answer": "behaviors",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7719605565071106
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.7532402276992798,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.6086127758026123,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.6059380769729614,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.6042873859405518,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.6039958000183105,
            "answer": "agent",
            "hit": false
          },
          {
            "score": 0.6039806008338928,
            "answer": "services",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7532402276992798
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.8297256231307983,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.7806961536407471,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.7671018242835999,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7620790004730225,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.6619241237640381,
            "answer": "analysts",
            "hit": false
          },
          {
            "score": 0.6496694087982178,
            "answer": "study",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8297256231307983
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.7272140979766846,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.6866968274116516,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.6774187088012695,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.669414758682251,
            "answer": "forces",
            "hit": false
          },
          {
            "score": 0.6605494618415833,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.6602713465690613,
            "answer": "marines",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.727214127779007
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7069995403289795,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.6581389904022217,
            "answer": "authorized",
            "hit": false
          },
          {
            "score": 0.6530829668045044,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.6439480781555176,
            "answer": "jurisdiction",
            "hit": false
          },
          {
            "score": 0.6305100321769714,
            "answer": "authorization",
            "hit": false
          },
          {
            "score": 0.6226508021354675,
            "answer": "agencies",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7069995701313019
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7357089519500732,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.6261126399040222,
            "answer": "foundations",
            "hit": false
          },
          {
            "score": 0.609654426574707,
            "answer": "base",
            "hit": false
          },
          {
            "score": 0.6058245301246643,
            "answer": "grounds",
            "hit": false
          },
          {
            "score": 0.601046621799469,
            "answer": "reasons",
            "hit": false
          },
          {
            "score": 0.5975810885429382,
            "answer": "generators",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7357089817523956
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.764223575592041,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.6503570675849915,
            "answer": "enterprises",
            "hit": false
          },
          {
            "score": 0.6440439224243164,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.6324736475944519,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.6303266882896423,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.6287553906440735,
            "answer": "corporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.764223575592041
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.6583521366119385,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.6258748769760132,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.5940219163894653,
            "answer": "classified",
            "hit": false
          },
          {
            "score": 0.5928390026092529,
            "answer": "countries",
            "hit": false
          },
          {
            "score": 0.5919792056083679,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.5889671444892883,
            "answer": "groups",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6583520770072937
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.752297043800354,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.6785271167755127,
            "answer": "medieval",
            "hit": false
          },
          {
            "score": 0.66776043176651,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.6496216058731079,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6455581188201904,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.6233748197555542,
            "answer": "renaissance",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.752297043800354
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.8065694570541382,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.7106993198394775,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.672972559928894,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.6645495295524597,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6637595891952515,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.6545282602310181,
            "answer": "childhood",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8065694570541382
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8632569313049316,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.6842566728591919,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.6513980627059937,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.6446278095245361,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.6434888243675232,
            "answer": "streets",
            "hit": false
          },
          {
            "score": 0.6361820697784424,
            "answer": "village",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8632569313049316
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.765182614326477,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.6100332140922546,
            "answer": "communal",
            "hit": false
          },
          {
            "score": 0.6072683334350586,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.6037344932556152,
            "answer": "populations",
            "hit": false
          },
          {
            "score": 0.6034117937088013,
            "answer": "neighbourhood",
            "hit": false
          },
          {
            "score": 0.6020838022232056,
            "answer": "consumer",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.765182614326477
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.7766361236572266,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.6443531513214111,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6407434940338135,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.6362320780754089,
            "answer": "countryside",
            "hit": false
          },
          {
            "score": 0.6302204132080078,
            "answer": "districts",
            "hit": false
          },
          {
            "score": 0.6287307739257812,
            "answer": "provinces",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7766361236572266
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.6920665502548218,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.6063336133956909,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6014166474342346,
            "answer": "state",
            "hit": false
          },
          {
            "score": 0.6006124019622803,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.5864380598068237,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.5856357216835022,
            "answer": "departments",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6920665353536606
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7737533450126648,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.6607840061187744,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6415823698043823,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6362378597259521,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.6040499210357666,
            "answer": "liability",
            "hit": false
          },
          {
            "score": 0.5996569395065308,
            "answer": "responsibility",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7737533748149872
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.7330970764160156,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.6727820038795471,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.6596767902374268,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.650707483291626,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.6379979252815247,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6305593252182007,
            "answer": "economical",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7330970615148544
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8676158785820007,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7148102521896362,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.6535913944244385,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.6370944976806641,
            "answer": "momentum",
            "hit": false
          },
          {
            "score": 0.6296168565750122,
            "answer": "fuels",
            "hit": false
          },
          {
            "score": 0.6251336336135864,
            "answer": "power",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8676158785820007
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.7515345811843872,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.6391666531562805,
            "answer": "entering",
            "hit": false
          },
          {
            "score": 0.6269137263298035,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.6251106262207031,
            "answer": "enters",
            "hit": false
          },
          {
            "score": 0.6184549927711487,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.5876052975654602,
            "answer": "enter",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7515345811843872
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.745962381362915,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.615039587020874,
            "answer": "hospitals",
            "hit": false
          },
          {
            "score": 0.6034740805625916,
            "answer": "equipment",
            "hit": false
          },
          {
            "score": 0.6032230257987976,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.602813184261322,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.6013633012771606,
            "answer": "buildings",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7459624111652374
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.7463064789772034,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7033002376556396,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.6798088550567627,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.6660568714141846,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.6495357751846313,
            "answer": "clan",
            "hit": false
          },
          {
            "score": 0.6360217928886414,
            "answer": "children",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7463064789772034
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.7655729055404663,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.6700242757797241,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.6486479043960571,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6252363324165344,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6188584566116333,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.609272837638855,
            "answer": "legends",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7655728757381439
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.7356343269348145,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.6626136898994446,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.6561301946640015,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.6390761733055115,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.6362231373786926,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.6301555633544922,
            "answer": "enterprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7356343567371368
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.8990752100944519,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.6203582286834717,
            "answer": "archives",
            "hit": false
          },
          {
            "score": 0.6184612512588501,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.6094077825546265,
            "answer": "collections",
            "hit": false
          },
          {
            "score": 0.607162356376648,
            "answer": "routines",
            "hit": false
          },
          {
            "score": 0.6055766940116882,
            "answer": "languages",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8990752100944519
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.6506081819534302,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.6382547616958618,
            "answer": "career",
            "hit": false
          },
          {
            "score": 0.6358733773231506,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.6344926357269287,
            "answer": "lived",
            "hit": false
          },
          {
            "score": 0.629631757736206,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.6188192367553711,
            "answer": "death",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6358733773231506
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.6456945538520813,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.607546865940094,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.6009568572044373,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.5971336960792542,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.5955524444580078,
            "answer": "incident",
            "hit": false
          },
          {
            "score": 0.5937991142272949,
            "answer": "profits",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6456945687532425
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.7974012494087219,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.666915774345398,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.640868067741394,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.636303722858429,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.6347223520278931,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.5978113412857056,
            "answer": "cognition",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7974012196063995
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.7480276823043823,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.6053624153137207,
            "answer": "incentives",
            "hit": false
          },
          {
            "score": 0.6024026870727539,
            "answer": "chance",
            "hit": false
          },
          {
            "score": 0.6020302176475525,
            "answer": "initiatives",
            "hit": false
          },
          {
            "score": 0.6010741591453552,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.6001147031784058,
            "answer": "prospects",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7480277121067047
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.7833316922187805,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.6134908199310303,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.6083773374557495,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.6070072054862976,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.6045478582382202,
            "answer": "reforms",
            "hit": false
          },
          {
            "score": 0.6011156439781189,
            "answer": "governments",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7833316922187805
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.6598260402679443,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.6100172996520996,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.5994101762771606,
            "answer": "belongings",
            "hit": false
          },
          {
            "score": 0.5958238840103149,
            "answer": "estate",
            "hit": false
          },
          {
            "score": 0.5952228903770447,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.5936649441719055,
            "answer": "entities",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6598260402679443
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8195379376411438,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7331393957138062,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.6836056113243103,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.6824577450752258,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6728817224502563,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.6451394557952881,
            "answer": "duties",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8195379376411438
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.6199934482574463,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.6162114143371582,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.6064408421516418,
            "answer": "surveillance",
            "hit": false
          },
          {
            "score": 0.6038399338722229,
            "answer": "precautions",
            "hit": false
          },
          {
            "score": 0.6019177436828613,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.5999711751937866,
            "answer": "safety",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.575540266931057
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.61385178565979,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.5919119119644165,
            "answer": "innings",
            "hit": false
          },
          {
            "score": 0.5898400545120239,
            "answer": "runs",
            "hit": false
          },
          {
            "score": 0.5893953442573547,
            "answer": "histories",
            "hit": false
          },
          {
            "score": 0.5860708355903625,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.5852960348129272,
            "answer": "titles",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9828689694404602
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.7059061527252197,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.626851499080658,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.625870943069458,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.6181466579437256,
            "answer": "federation",
            "hit": false
          },
          {
            "score": 0.6140773296356201,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.6103101372718811,
            "answer": "guild",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7059061527252197
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.6530135273933411,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.646551787853241,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.6444696187973022,
            "answer": "specimens",
            "hit": false
          },
          {
            "score": 0.6395676136016846,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.636114239692688,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.6344704627990723,
            "answer": "ecosystems",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9832333922386169
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.7403820753097534,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.6545007824897766,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.6335203051567078,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.630226731300354,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.6130830645561218,
            "answer": "storyline",
            "hit": false
          },
          {
            "score": 0.608187198638916,
            "answer": "saga",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7403820753097534
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.7364968061447144,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.6220749616622925,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.6155816316604614,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.6047439575195312,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.6025626063346863,
            "answer": "schemes",
            "hit": false
          },
          {
            "score": 0.6000118851661682,
            "answer": "tactic",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7364968061447144
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7056125402450562,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.6919476985931396,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.6583665013313293,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6515902280807495,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.6489393711090088,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.6332626342773438,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6919476985931396
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.7005685567855835,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.6853606700897217,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.6429862380027771,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.633696436882019,
            "answer": "techniques",
            "hit": false
          },
          {
            "score": 0.627291202545166,
            "answer": "technical",
            "hit": false
          },
          {
            "score": 0.623896062374115,
            "answer": "telecommunications",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7005685269832611
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.7639752626419067,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.6581399440765381,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.626583993434906,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.6132030487060547,
            "answer": "doctrine",
            "hit": false
          },
          {
            "score": 0.6117762923240662,
            "answer": "theology",
            "hit": false
          },
          {
            "score": 0.6091114282608032,
            "answer": "doctrines",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7639752328395844
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.8465422987937927,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.6860103607177734,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.6701210141181946,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.6662567257881165,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.6645585298538208,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6640644073486328,
            "answer": "college",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8465422987937927
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8192211985588074,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.6779471635818481,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.6530101895332336,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.6329177021980286,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.6309974193572998,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.6249064803123474,
            "answer": "variations",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8192211985588074
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.7817411422729492,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.7663356065750122,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7114786505699158,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7018699645996094,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.6904832124710083,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6839288473129272,
            "answer": "widow",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7817411422729492
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.6699068546295166,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.6448032259941101,
            "answer": "oman",
            "hit": false
          },
          {
            "score": 0.6304701566696167,
            "answer": "ladies",
            "hit": false
          },
          {
            "score": 0.6196717023849487,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6186982989311218,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.6159318089485168,
            "answer": "female",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6699068397283554
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 44,
      "accuracy": 0.8636363636363636
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6cbc20f6-14ec-48b1-b9bf-fba526fc7240",
      "timestamp": "2025-05-18T10:34:19.008859"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.7859228849411011,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.7117378115653992,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.6742663979530334,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6618244051933289,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.6586161851882935,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6539974212646484,
            "answer": "happier",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7859228253364563
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.708397626876831,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.7070770263671875,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.6812450289726257,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6809208393096924,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.637114942073822,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6319049596786499,
            "answer": "safer",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7083976119756699
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.7405596375465393,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.698291540145874,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.675308346748352,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6501583456993103,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.646871030330658,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6431349515914917,
            "answer": "strongly",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7405596524477005
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.760948121547699,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.7459717988967896,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6639868021011353,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6561388373374939,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.6496006846427917,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.649465799331665,
            "answer": "weakening",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.760948121547699
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0894bf05-d1d6-4d4d-b05b-269b8a59422a",
      "timestamp": "2025-05-18T10:34:19.214792"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7424864172935486,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6717109680175781,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.6062862873077393,
            "answer": "simplest",
            "hit": false
          },
          {
            "score": 0.6059621572494507,
            "answer": "fastest",
            "hit": false
          },
          {
            "score": 0.6056373119354248,
            "answer": "lowest",
            "hit": false
          },
          {
            "score": 0.6048343181610107,
            "answer": "hardest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6717109382152557
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.7446520924568176,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.6741690635681152,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.6521701812744141,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6367554664611816,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.6150665283203125,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6124933362007141,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6741690635681152
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0d515ea7-7430-4740-ac50-16e4db40cb1c",
      "timestamp": "2025-05-18T10:34:19.231212"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.7429797649383545,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.7413020133972168,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.723626434803009,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7106171250343323,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6130930185317993,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.6112423539161682,
            "answer": "allows",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7429797649383545
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.6571054458618164,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.6364315748214722,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6070933938026428,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.5810710787773132,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.5803542733192444,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.5794776082038879,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6571054309606552
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8592698574066162,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8094927072525024,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7987039685249329,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7527574300765991,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7098441123962402,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6672673225402832,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8592698276042938
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.7217222452163696,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.7010724544525146,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6837587356567383,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6458808183670044,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6246076822280884,
            "answer": "allowance",
            "hit": false
          },
          {
            "score": 0.6213021278381348,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7217222452163696
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9119463562965393,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8545027375221252,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8198803067207336,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7369924783706665,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7258696556091309,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.682435154914856,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9119463562965393
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.751806914806366,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7322465777397156,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.6285984516143799,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6187124252319336,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6186399459838867,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6004779934883118,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7322465777397156
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7297769784927368,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.7004053592681885,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6990983486175537,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6220927834510803,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6128858327865601,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6090877652168274,
            "answer": "invites",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7297769784927368
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.78606778383255,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.7805845141410828,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.7495465278625488,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.6897708177566528,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.6583151817321777,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6343709230422974,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.78606778383255
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8949680924415588,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8774564862251282,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8529578447341919,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.659529447555542,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6472229957580566,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6461583375930786,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8949680626392365
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8756585717201233,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8388280272483826,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.812445342540741,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7412375211715698,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6977387070655823,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6874662041664124,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8756585717201233
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8545284867286682,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8034147024154663,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7090345621109009,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6743098497390747,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.641802191734314,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.6333636045455933,
            "answer": "examines",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.854528546333313
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.6978907585144043,
            "answer": "consistent",
            "hit": false
          },
          {
            "score": 0.6573047637939453,
            "answer": "consistency",
            "hit": false
          },
          {
            "score": 0.6382960081100464,
            "answer": "consistently",
            "hit": false
          },
          {
            "score": 0.6373067498207092,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.6331324577331543,
            "answer": "inconsistent",
            "hit": false
          },
          {
            "score": 0.6196156740188599,
            "answer": "consisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6373067498207092
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.827976644039154,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.6983888149261475,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.69215989112854,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6755796074867249,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6586146354675293,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6570284366607666,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6983888298273087
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.724321186542511,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.6766050457954407,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6610341668128967,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6217097640037537,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.6072744727134705,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6003311276435852,
            "answer": "maintains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7243212014436722
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.73646080493927,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7334029674530029,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7057653069496155,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.6595650315284729,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6548992395401001,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6286840438842773,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7057653069496155
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8618128299713135,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8391180038452148,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7992611527442932,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.6882142424583435,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.669546902179718,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.6621972322463989,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8618128597736359
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.7483733892440796,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7249650359153748,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.6962373852729797,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6721261739730835,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6368556022644043,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6357897520065308,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7249650210142136
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8729512095451355,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8336457014083862,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7180713415145874,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6810116767883301,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.642361044883728,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6371858716011047,
            "answer": "allowed",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8729512691497803
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.744999885559082,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.7377916574478149,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7188324928283691,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6370615363121033,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.630864679813385,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6142359972000122,
            "answer": "loves",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7449999004602432
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.666990339756012,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.6619271039962769,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.6382464170455933,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.6083241105079651,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.5974127054214478,
            "answer": "guarantees",
            "hit": false
          },
          {
            "score": 0.5927221775054932,
            "answer": "maintains",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6669903695583344
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.729081928730011,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.681149959564209,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6515185236930847,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6435251832008362,
            "answer": "existing",
            "hit": false
          },
          {
            "score": 0.6282451152801514,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.625008225440979,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.729081928730011
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8670005798339844,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8580302000045776,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8417159914970398,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7598803043365479,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7338989973068237,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.6733627319335938,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8670005798339844
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.813103199005127,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.8059229850769043,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.6850152015686035,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.604056179523468,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.6026073694229126,
            "answer": "leads",
            "hit": false
          },
          {
            "score": 0.6025958061218262,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8059229850769043
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8848703503608704,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8488731384277344,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7804639339447021,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7152636051177979,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7063772082328796,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6820189952850342,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8848703801631927
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8473131656646729,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8388453722000122,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7210667729377747,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6537458896636963,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.6452186107635498,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6406513452529907,
            "answer": "listening",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8473131656646729
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.8754692077636719,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.854662299156189,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8490269780158997,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7554184198379517,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6651418209075928,
            "answer": "recognizes",
            "hit": false
          },
          {
            "score": 0.6524446606636047,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8754692375659943
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.7696367502212524,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.7642190456390381,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7613540887832642,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7548305988311768,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7170916199684143,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6429389715194702,
            "answer": "increases",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7696367502212524
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.6911845803260803,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6562910079956055,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6084381937980652,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6064679026603699,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.6051883697509766,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.6037094593048096,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6911846101284027
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9156657457351685,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8248968124389648,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7867574691772461,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.6891204714775085,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6704948544502258,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6456437110900879,
            "answer": "contain",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9156657755374908
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.717136025428772,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.6914336681365967,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6777340173721313,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.6632927656173706,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6501668691635132,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6257045865058899,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7171360552310944
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.8887596130371094,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8690811395645142,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8442245721817017,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7134522199630737,
            "answer": "maintenance",
            "hit": false
          },
          {
            "score": 0.6604703068733215,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.6408523917198181,
            "answer": "retain",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8690810799598694
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9232650399208069,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8208011984825134,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7987871766090393,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7136305570602417,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.687816858291626,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.6772327423095703,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9232650399208069
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8981621265411377,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8143348097801208,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.7200417518615723,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.6476296186447144,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6390703320503235,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6366175413131714,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8981621861457825
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.7667946219444275,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.7464163303375244,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7365336418151855,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.6480608582496643,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.634624719619751,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.6269381046295166,
            "answer": "prohibit",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7667946517467499
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9056674242019653,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8950249552726746,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8151246309280396,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7373403906822205,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6869267225265503,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.6835341453552246,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9056674242019653
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.7448935508728027,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7431042194366455,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.6610981822013855,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.6400660276412964,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.6292734146118164,
            "answer": "protector",
            "hit": false
          },
          {
            "score": 0.6287370920181274,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7431042939424515
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.7634649276733398,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.731722354888916,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6901667714118958,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6278529167175293,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6278150677680969,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.6189358234405518,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7634649276733398
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.6700162887573242,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.6564757227897644,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6463281512260437,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.5922838449478149,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.5907361507415771,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.5899696350097656,
            "answer": "accepts",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6700163334608078
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.6831897497177124,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.657201886177063,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.6534702181816101,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6425968408584595,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.6379339694976807,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6074656248092651,
            "answer": "replaces",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.68318971991539
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.824360191822052,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7869030833244324,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7755240797996521,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6260122060775757,
            "answer": "reference",
            "hit": false
          },
          {
            "score": 0.6259607076644897,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6069144606590271,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8243601620197296
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8682355284690857,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8464679718017578,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7152308225631714,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6954895257949829,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6738746166229248,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.6630766987800598,
            "answer": "retains",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8682355284690857
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.7487998604774475,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7294221520423889,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7208993434906006,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6541446447372437,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.652267336845398,
            "answer": "recalls",
            "hit": false
          },
          {
            "score": 0.6447376012802124,
            "answer": "forget",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7487998902797699
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.7007560729980469,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6947031617164612,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.6906366944313049,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.6798467636108398,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6621415019035339,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.6472494602203369,
            "answer": "representatives",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6947031617164612
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.6555683016777039,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6471360921859741,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6338329315185547,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6296873092651367,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.6039934754371643,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.6039401292800903,
            "answer": "depends",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6296872943639755
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.9047788381576538,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8463054895401001,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7551453709602356,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7404531240463257,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7382408976554871,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6943425536155701,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9047788381576538
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.7423193454742432,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.735162079334259,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.6418681144714355,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.6199358701705933,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6086438894271851,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.6018508672714233,
            "answer": "takes",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7423193454742432
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.7709017992019653,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7606669068336487,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7252152562141418,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7154034972190857,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.6940243244171143,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.6441001892089844,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7606669664382935
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.7474051117897034,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.6715075969696045,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6685304641723633,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6219688653945923,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6196005344390869,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6116441488265991,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7474050968885422
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8517670035362244,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8356325626373291,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8043708801269531,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7559535503387451,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6696439385414124,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.6585444211959839,
            "answer": "know",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8517670333385468
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 49,
      "accuracy": 0.7755102040816326
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "66554018-5147-4bdb-aac0-5b6b13b87a56",
      "timestamp": "2025-05-18T10:34:19.240213"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9155442714691162,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.8496888279914856,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7290271520614624,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7022414207458496,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.6927135586738586,
            "answer": "achievement",
            "hit": false
          },
          {
            "score": 0.6913503408432007,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9155443012714386
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.6537429094314575,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.629148006439209,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6039077043533325,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.5815721154212952,
            "answer": "inc",
            "hit": false
          },
          {
            "score": 0.5801789164543152,
            "answer": "contributing",
            "hit": false
          },
          {
            "score": 0.5790988802909851,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6537429392337799
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.7122864723205566,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.6855663061141968,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.674161434173584,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6261743307113647,
            "answer": "allowance",
            "hit": false
          },
          {
            "score": 0.6226624250411987,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.6205235719680786,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7122865170240402
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8860461115837097,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8534179329872131,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8496149778366089,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.7287156581878662,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.695828914642334,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.6887375116348267,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8496149480342865
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.7743598818778992,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.7050962448120117,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6308335661888123,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6250367164611816,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6037545204162598,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.6012498736381531,
            "answer": "using",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.774359941482544
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.7181101441383362,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.6981440782546997,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6950650215148926,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6217256188392639,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6067907214164734,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.5961702466011047,
            "answer": "tell",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7181101441383362
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8866081237792969,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.847546398639679,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.679340660572052,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6712603569030762,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6362953782081604,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6148613095283508,
            "answer": "visiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8866081237792969
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.7993834018707275,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.7601894736289978,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7505937814712524,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7017355561256409,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.6572176218032837,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6267133355140686,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7993834018707275
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8762553334236145,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8704644441604614,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8703137636184692,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.6486954092979431,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.6332632899284363,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6330776810646057,
            "answer": "growing",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8762553632259369
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8519085645675659,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8370248079299927,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.8322659730911255,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7461946606636047,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6865240931510925,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6700184345245361,
            "answer": "believer",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8322659730911255
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.8335166573524475,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8126459717750549,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7227723598480225,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.6928737163543701,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6366893649101257,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.6297483444213867,
            "answer": "discussed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7227723598480225
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8528012633323669,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.6910485029220581,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.6802291870117188,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6605260372161865,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6523401737213135,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6425248980522156,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8528012335300446
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.7020304799079895,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7006860375404358,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.6689978241920471,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6171931028366089,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6128381490707397,
            "answer": "returning",
            "hit": false
          },
          {
            "score": 0.6066169142723083,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7006860226392746
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.7533813714981079,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.7208231091499329,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.69522625207901,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6659786701202393,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6389232277870178,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.638192892074585,
            "answer": "constructing",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7533813416957855
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.7665346264839172,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.6888530254364014,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.679892897605896,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.677301287651062,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6385074853897095,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6332730054855347,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7665346264839172
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8384447693824768,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7991304397583008,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.7979050278663635,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7220871448516846,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.7187238335609436,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.6675885915756226,
            "answer": "urging",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7991304695606232
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.7549379467964172,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.7222284078598022,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.717708945274353,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.640825092792511,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6407826542854309,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.605409562587738,
            "answer": "delicious",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7549379467964172
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.6787768602371216,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.6381565928459167,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.6297001838684082,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.6060727834701538,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.600279688835144,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.5904169082641602,
            "answer": "regulating",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.678776890039444
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.910514235496521,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8636440634727478,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8388091921806335,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6967303156852722,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.664846658706665,
            "answer": "proving",
            "hit": false
          },
          {
            "score": 0.6569811701774597,
            "answer": "determining",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.910514235496521
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.7021626830101013,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.6714165806770325,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6579978466033936,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.655687689781189,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.6337659358978271,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.5963437557220459,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6556876599788666
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.704412043094635,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.6965134739875793,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.6854633092880249,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6649125814437866,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6637821197509766,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6058902740478516,
            "answer": "assert",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.704412043094635
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.8141859173774719,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.780285120010376,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6973289251327515,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.6094413995742798,
            "answer": "pursuing",
            "hit": false
          },
          {
            "score": 0.6048007011413574,
            "answer": "accompanying",
            "hit": false
          },
          {
            "score": 0.6039702892303467,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.697328969836235
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8650886416435242,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8487920165061951,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7946156859397888,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.6859841346740723,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6771568059921265,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.6697586178779602,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7946156859397888
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.8828616738319397,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8519989252090454,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8475611805915833,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7700557708740234,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6646932363510132,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.6583035588264465,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8828616738319397
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.7841817140579224,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.7620515823364258,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7512630820274353,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7370662689208984,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7270917892456055,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6293370723724365,
            "answer": "proved",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7841816544532776
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.6647523641586304,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6592285633087158,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6219202876091003,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.6216641068458557,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.6212682723999023,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.6046568155288696,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.59763253480196
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.89235520362854,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8489488363265991,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7930648922920227,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7001709342002869,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6396048665046692,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6390438079833984,
            "answer": "contain",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489488363265991
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.6982508897781372,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.6904013752937317,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6857947111129761,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.6646515130996704,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6386315226554871,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.6262535452842712,
            "answer": "teaches",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6982508897781372
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.8783196210861206,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.87830650806427,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.698748767375946,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.677747368812561,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6703197956085205,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.651476263999939,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.87830650806427
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9094638824462891,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8479210138320923,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8461862206459045,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7188871502876282,
            "answer": "maintenance",
            "hit": false
          },
          {
            "score": 0.6512242555618286,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.6488234996795654,
            "answer": "retaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9094639122486115
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.7296156883239746,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.6929547786712646,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.68486487865448,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.6344455480575562,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6127476692199707,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.61085444688797,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7296156883239746
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.879812479019165,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.815146803855896,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.7419068217277527,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.6586335301399231,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6478471755981445,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.639900803565979,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7419068068265915
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.9039309024810791,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.8716099262237549,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8358270525932312,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.6682548522949219,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6649740934371948,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6592462062835693,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9039308428764343
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.7664169073104858,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.737082839012146,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7280693650245667,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.6512826681137085,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.6262061595916748,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.6219027042388916,
            "answer": "prohibit",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7664168775081635
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9193206429481506,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8853380680084229,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8130237460136414,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7481117248535156,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6876803636550903,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.6693427562713623,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9193206429481506
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.7626913785934448,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.7166051268577576,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.6663720607757568,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.6374677419662476,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.635009765625,
            "answer": "protector",
            "hit": false
          },
          {
            "score": 0.6310938000679016,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7626914381980896
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.7534509301185608,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.7325119376182556,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6942112445831299,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6295485496520996,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6277191042900085,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.6231066584587097,
            "answer": "establishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7534509301185608
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.6822261810302734,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.6465886831283569,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6432478427886963,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6044105887413025,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.5986335873603821,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.5935275554656982,
            "answer": "accepting",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6822261810302734
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.6780338883399963,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.6590733528137207,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6539941430091858,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.649354875087738,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.6419704556465149,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6077591776847839,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6780338883399963
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8081678748130798,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.7991496324539185,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7785539031028748,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.63493412733078,
            "answer": "reference",
            "hit": false
          },
          {
            "score": 0.622664749622345,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6106544733047485,
            "answer": "referenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8081679046154022
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8538506031036377,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8408507108688354,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7338365316390991,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.6823490262031555,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6771470308303833,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.6764765977859497,
            "answer": "staying",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7338365316390991
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.7519806027412415,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.724885106086731,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7200354933738708,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6620141267776489,
            "answer": "forgetting",
            "hit": false
          },
          {
            "score": 0.6556793451309204,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.6511636972427368,
            "answer": "recall",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7519805729389191
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.7127524614334106,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7098188400268555,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.683545708656311,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6717628240585327,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.669466495513916,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.6623877286911011,
            "answer": "represented",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7127524614334106
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.6643412709236145,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6638369560241699,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.6371245384216309,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6192082166671753,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6120753884315491,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.5934141874313354,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6638369560241699
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8829476237297058,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8451916575431824,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7770413160324097,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7330163717269897,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7047865390777588,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6982392072677612,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7770413160324097
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.7036797404289246,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.6921341419219971,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.6398389339447021,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.6382309198379517,
            "answer": "situ",
            "hit": false
          },
          {
            "score": 0.6167452335357666,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6044844388961792,
            "answer": "seat",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7036797255277634
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8833720088005066,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8788154125213623,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8675521612167358,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.689591646194458,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6757222414016724,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6298775672912598,
            "answer": "paying",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8675521612167358
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8648154735565186,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8593081831932068,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7606509923934937,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.6820616722106934,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.6665816307067871,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6506378650665283,
            "answer": "instructor",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7606509923934937
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.7130823135375977,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6958844661712646,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.6653095483779907,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6305885314941406,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.61651211977005,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6001768112182617,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.695884495973587
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8386235237121582,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8364668488502502,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8298428058624268,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.7573613524436951,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6747574210166931,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.6578439474105835,
            "answer": "interpreting",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8298427760601044
      }
    ],
    "result": {
      "cnt_questions_correct": 31,
      "cnt_questions_total": 50,
      "accuracy": 0.62
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "728d6271-52c7-4e05-bf3a-5fb5946b6d2d",
      "timestamp": "2025-05-18T10:34:19.464732"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.7443029880523682,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.7321969270706177,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7180528044700623,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7094347476959229,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.6232796907424927,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.6109755039215088,
            "answer": "received",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.744302973151207
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.89572674036026,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8700418472290039,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.7286691665649414,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7105733156204224,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7032560110092163,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.6971294283866882,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8700419068336487
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.6220117807388306,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6215790510177612,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6204049587249756,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.5801116824150085,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.5787407755851746,
            "answer": "inc",
            "hit": false
          },
          {
            "score": 0.5742704272270203,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6215790584683418
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8398934602737427,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8262754082679749,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8009141087532043,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7519010305404663,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.717086911201477,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6811010241508484,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8262754678726196
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.6932040452957153,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.6877368688583374,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.682658851146698,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6331639885902405,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6204490661621094,
            "answer": "allowance",
            "hit": false
          },
          {
            "score": 0.6051375269889832,
            "answer": "permit",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6932040452957153
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8563615679740906,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8541707992553711,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8485969305038452,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7590082883834839,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7202439308166504,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6526449918746948,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8541707992553711
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8882222175598145,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8723821640014648,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8327950239181519,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7308534383773804,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6928908228874207,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.6890259981155396,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8723821640014648
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.7444431781768799,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7056921720504761,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6392718553543091,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.626142680644989,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6065772771835327,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.6029028296470642,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6392718851566315
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7139726877212524,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.6984095573425293,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6922571659088135,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6361408233642578,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.5946506261825562,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.5929045677185059,
            "answer": "begged",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7139727175235748
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8632414937019348,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.8586342334747314,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.6730636358261108,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.665500283241272,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6342006921768188,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6234380602836609,
            "answer": "visited",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8586341738700867
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8824328780174255,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8672083020210266,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.851745069026947,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6602234840393066,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.640813946723938,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6369753479957581,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8824328780174255
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8571092486381531,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8505290746688843,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8102169036865234,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7461487054824829,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6810336112976074,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6670845150947571,
            "answer": "believer",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571091890335083
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.832297682762146,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8318395614624023,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7065415382385254,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6900010108947754,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6442262530326843,
            "answer": "discussed",
            "hit": false
          },
          {
            "score": 0.634174108505249,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.832297682762146
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.6981660723686218,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6806139349937439,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6764324903488159,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.6095619201660156,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6016588807106018,
            "answer": "resumed",
            "hit": false
          },
          {
            "score": 0.5988369584083557,
            "answer": "ongoing",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6764324903488159
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7463440299034119,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7325651049613953,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6888657808303833,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6587429642677307,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6178861260414124,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6141314506530762,
            "answer": "constructed",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7463440150022507
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8398934602737427,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8209455013275146,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7340081334114075,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.7007619142532349,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6832256317138672,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.663626492023468,
            "answer": "decisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7340081483125687
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8427274227142334,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8376208543777466,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8243529200553894,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.6901413798332214,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6692109107971191,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.6474298238754272,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8243529200553894
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.7439115047454834,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7064251899719238,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.6930882930755615,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6792994737625122,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.632548987865448,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6275011897087097,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7064251899719238
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.6896946430206299,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.6862772703170776,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.646687924861908,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.6403459310531616,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.6392145752906799,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.6225473880767822,
            "answer": "uncovered",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6862772703170776
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.7314149737358093,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7300747632980347,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.7204099297523499,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6387948989868164,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6275811195373535,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6115366816520691,
            "answer": "appreciated",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7300747931003571
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.6492559313774109,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.6452465653419495,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.6301994323730469,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.5974385142326355,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.5932852029800415,
            "answer": "assured",
            "hit": false
          },
          {
            "score": 0.5917938947677612,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6452465951442719
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8863775730133057,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8599430322647095,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8586757779121399,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.6927761435508728,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6548774242401123,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6467514634132385,
            "answer": "demonstrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8586757481098175
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.711915135383606,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6850069761276245,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.682661235332489,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6617223024368286,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6553852558135986,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6062630414962769,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7119151651859283
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8308279514312744,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7842071652412415,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.688235878944397,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6118378639221191,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.603285551071167,
            "answer": "pursued",
            "hit": false
          },
          {
            "score": 0.6008119583129883,
            "answer": "followers",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8308280110359192
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8603704571723938,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8278969526290894,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7307060956954956,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6578947305679321,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6445287466049194,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.641126811504364,
            "answer": "hearings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8603704571723938
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8755979537963867,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.8539939522743225,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8503384590148926,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7645191550254822,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6645681858062744,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.645050585269928,
            "answer": "detected",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8755979537963867
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.7657883763313293,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7625008821487427,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7560063600540161,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7316603660583496,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7264760732650757,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6458216905593872,
            "answer": "proved",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7657883763313293
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.6783899068832397,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6677761077880859,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.610526442527771,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.5999944806098938,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.5975687503814697,
            "answer": "exclude",
            "hit": false
          },
          {
            "score": 0.5952668786048889,
            "answer": "incorporating",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6783899068832397
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8978390097618103,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8803205490112305,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8646080493927002,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.6374172568321228,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6245307326316833,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.6204105615615845,
            "answer": "mentioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8803204894065857
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8948390483856201,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8290599584579468,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8071712851524353,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6998167037963867,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6558939814567566,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6461624503135681,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8071713149547577
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8469430208206177,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7250273823738098,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.6671167612075806,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.6392077207565308,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6358343958854675,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.6329044699668884,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7250274121761322
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.875126302242279,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8556264638900757,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7024135589599609,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6915222406387329,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6690506935119629,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.6501218676567078,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6915222406387329
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7045882344245911,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6965148448944092,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.6906844973564148,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6247585415840149,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6150539517402649,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.606574535369873,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.696514829993248
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8714668154716492,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.7249068021774292,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7110950946807861,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.6960688233375549,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.6270972490310669,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.6236231923103333,
            "answer": "divorce",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7249067425727844
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8776070475578308,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8692637085914612,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8551453351974487,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.666513204574585,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.6631342172622681,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6608056426048279,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8551453351974487
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.7277929782867432,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7222467660903931,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7116861343383789,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.6227349638938904,
            "answer": "provision",
            "hit": false
          },
          {
            "score": 0.6094491481781006,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.6089988946914673,
            "answer": "supplying",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7116861045360565
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.6362374424934387,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6081256866455078,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.5984717607498169,
            "answer": "released",
            "hit": false
          },
          {
            "score": 0.5887183547019958,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.5859680771827698,
            "answer": "updated",
            "hit": false
          },
          {
            "score": 0.5829181671142578,
            "answer": "uploaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6081256866455078
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.6653074622154236,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.6619259119033813,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6406956911087036,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6027849912643433,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.5998318195343018,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.5855843424797058,
            "answer": "receipts",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.665307492017746
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.6615564823150635,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.6571288704872131,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6474912166595459,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.6455830335617065,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.6333826184272766,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.5871893763542175,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6615565121173859
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.7991968393325806,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7931637167930603,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.7890963554382324,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.6355463266372681,
            "answer": "reference",
            "hit": false
          },
          {
            "score": 0.6204544305801392,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.6013928651809692,
            "answer": "corresponds",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7931637167930603
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8206245303153992,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7774472236633301,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6533142328262329,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6491218209266663,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.6141278743743896,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6105239391326904,
            "answer": "relationship",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6533142924308777
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.861061692237854,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8531160354614258,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7271108031272888,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6741116642951965,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.673765242099762,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.6642793416976929,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8610616624355316
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8806008100509644,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8631540536880493,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8416079878807068,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7084953188896179,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7028749585151672,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.6475542187690735,
            "answer": "placed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631539940834045
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.6601014733314514,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.638882577419281,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6333011388778687,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6134287118911743,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6112514138221741,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.5988932847976685,
            "answer": "requested",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6134287416934967
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8783895969390869,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8562569618225098,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.7598245739936829,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7425068020820618,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7140329480171204,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6994435787200928,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8562569618225098
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.7328523397445679,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7115444540977478,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.6600518226623535,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6088780164718628,
            "answer": "transmitted",
            "hit": false
          },
          {
            "score": 0.603251576423645,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.600875198841095,
            "answer": "dispatched",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6600518077611923
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.893718957901001,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8766915798187256,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8451077342033386,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6878557205200195,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6719468832015991,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6387249231338501,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8937189877033234
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.709301233291626,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6820330023765564,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.6775301694869995,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6023916602134705,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.5969598293304443,
            "answer": "assured",
            "hit": false
          },
          {
            "score": 0.5959485769271851,
            "answer": "gave",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6820330023765564
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8540409207344055,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8333118557929993,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8046764731407166,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7510315775871277,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6625810861587524,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.6592638492584229,
            "answer": "misunderstood",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8540410101413727
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.6849231123924255,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.6256405115127563,
            "answer": "joined",
            "hit": false
          },
          {
            "score": 0.6151606440544128,
            "answer": "joins",
            "hit": false
          },
          {
            "score": 0.6077007055282593,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.6011320352554321,
            "answer": "revived",
            "hit": false
          },
          {
            "score": 0.6003201603889465,
            "answer": "join",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 672,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.545089740306139
      }
    ],
    "result": {
      "cnt_questions_correct": 18,
      "cnt_questions_total": 50,
      "accuracy": 0.36
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f9912fbd-858f-4ec4-964e-23b2bc36553a",
      "timestamp": "2025-05-18T10:34:19.691145"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8401069641113281,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8244919776916504,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6589127779006958,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6530675888061523,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6258633732795715,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.6246465444564819,
            "answer": "introduces",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8401069641113281
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8931648135185242,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8219900131225586,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.7273945808410645,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7239758968353271,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7142188549041748,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6964155435562134,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8931648135185242
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8405428528785706,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8343542218208313,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8330222368240356,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.6849645376205444,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.669476330280304,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.66279137134552,
            "answer": "seem",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8343542218208313
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8066007494926453,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7548965811729431,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.6526023149490356,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6466248631477356,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6350634098052979,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6270283460617065,
            "answer": "application",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8066007792949677
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8383921384811401,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8298105001449585,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6994856595993042,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.64457106590271,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6437519192695618,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6372042298316956,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8383921384811401
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8581190705299377,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8410308361053467,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8331731557846069,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.6787278056144714,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6527348160743713,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6496711373329163,
            "answer": "being",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8331731855869293
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8118693232536316,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.8066767454147339,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.783843994140625,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7198349237442017,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6693442463874817,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6637678146362305,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8066767752170563
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7265129089355469,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7096406817436218,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7075701951980591,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6555453538894653,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.6470809578895569,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6191754937171936,
            "answer": "represents",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7265129089355469
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8714814186096191,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.832314670085907,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.717444896697998,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6939882040023804,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6925976276397705,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6893779039382935,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8714814782142639
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8403159379959106,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.6883507370948792,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.6792197227478027,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6620110869407654,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6508567929267883,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6501073837280273,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6883507072925568
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.7907307744026184,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.6781716346740723,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6647915840148926,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.6608537435531616,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6484231948852539,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6338363289833069,
            "answer": "begins",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7907307744026184
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.7365139126777649,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7305360436439514,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6670339107513428,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.6626616716384888,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6410384774208069,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6302381753921509,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6670339107513428
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8013954162597656,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.7445619106292725,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.6729593873023987,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6697332262992859,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.6523287892341614,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.6382054090499878,
            "answer": "according",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8013954162597656
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8522297739982605,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8476173877716064,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.7976570725440979,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7189897298812866,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6565477848052979,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.6554602980613708,
            "answer": "explaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8476173281669617
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8251212239265442,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8073832988739014,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7406558990478516,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7037830352783203,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6649830937385559,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6585822105407715,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8251212239265442
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8243764638900757,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8027021884918213,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.7292932271957397,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.7014104723930359,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.6881127953529358,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.6755290627479553,
            "answer": "reveals",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8027021884918213
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8590224385261536,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8297313451766968,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7031912803649902,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6696268320083618,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6481500864028931,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.6456579566001892,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8590224385261536
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7111690044403076,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7000484466552734,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6458821296691895,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.6380802392959595,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6267886757850647,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6235389113426208,
            "answer": "existence",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7111690044403076
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8571076393127441,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8561050891876221,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.8498662710189819,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7442808747291565,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7184428572654724,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.6563628315925598,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571076393127441
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7434367537498474,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.6866569519042969,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6642956733703613,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6167953014373779,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.602681040763855,
            "answer": "comes",
            "hit": false
          },
          {
            "score": 0.602560818195343,
            "answer": "below",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7434367537498474
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.80109703540802,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.789507269859314,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7816466093063354,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.6945184469223022,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.6764857769012451,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6693371534347534,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8010970056056976
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.794521689414978,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7456853985786438,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7356433272361755,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7345423102378845,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6205735802650452,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.615905225276947,
            "answer": "proceedings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7456853836774826
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8818124532699585,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8181942701339722,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7713185548782349,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7580817937850952,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7552523612976074,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.6737384796142578,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8818124532699585
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.6278457045555115,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6015390753746033,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.5951209664344788,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.59132981300354,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.5902091264724731,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.5816997289657593,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6278457045555115
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8436432480812073,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8352459073066711,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7370104789733887,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.6490626335144043,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6485745906829834,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6445971727371216,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8436431884765625
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7439087629318237,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.7039674520492554,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6927919387817383,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.6907998919487,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6479540467262268,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.62931889295578,
            "answer": "teaches",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7439087778329849
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8689264059066772,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8630597591400146,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.6932999491691589,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6905934810638428,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6534741520881653,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.6340851187705994,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8689264357089996
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.810594379901886,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7024072408676147,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.6663471460342407,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.6594668030738831,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.648325502872467,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6440041065216064,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8105943500995636
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8330274820327759,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8232598304748535,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7717639207839966,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.685499906539917,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.6835086345672607,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.6806028485298157,
            "answer": "occurrences",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8330274522304535
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.7421314716339111,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7285329103469849,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7059280872344971,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.6442521810531616,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6259461641311646,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6164577007293701,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7285329401493073
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8882436752319336,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.868661642074585,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.8161879181861877,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.6859649419784546,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6821936964988708,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.6659577488899231,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8686616122722626
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9084818363189697,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8703565001487732,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8029007911682129,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7431023716926575,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6920493841171265,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.6694516539573669,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8703565001487732
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8502341508865356,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.7506134510040283,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.7219846248626709,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6830699443817139,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6674245595932007,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6650122404098511,
            "answer": "supplying",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8502341210842133
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8460468649864197,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8052852153778076,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6674520373344421,
            "answer": "receiver",
            "hit": false
          },
          {
            "score": 0.6643311977386475,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6602338552474976,
            "answer": "receivers",
            "hit": false
          },
          {
            "score": 0.656687319278717,
            "answer": "receipt",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8460469245910645
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8346424102783203,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.7281439900398254,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7257034778594971,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.7146444916725159,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6737427711486816,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.66133713722229,
            "answer": "increases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8346424102783203
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.807785153388977,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7986197471618652,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7516711950302124,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.639651894569397,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6329174041748047,
            "answer": "reference",
            "hit": false
          },
          {
            "score": 0.6154192686080933,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.807785153388977
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.7932252883911133,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7565022110939026,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.6894544959068298,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6327663064002991,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.6322914361953735,
            "answer": "related",
            "hit": false
          },
          {
            "score": 0.6169265508651733,
            "answer": "regarding",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7565022706985474
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7262532711029053,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7146965861320496,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7120100259780884,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6448498368263245,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.6271154880523682,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.6233669519424438,
            "answer": "residual",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7146965712308884
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8579010367393494,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7077687978744507,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6992315053939819,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.6813912391662598,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6678802967071533,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6596434116363525,
            "answer": "reflects",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8579010367393494
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7100298404693604,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.6986541152000427,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6754502058029175,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6670722961425781,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.654750406742096,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.6547196507453918,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7100298404693604
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.7790406942367554,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7710856199264526,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.7692458629608154,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7124460935592651,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.6764005422592163,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.663907527923584,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7710855901241302
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8283709287643433,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.8028412461280823,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.7250981330871582,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6803820133209229,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.6395645141601562,
            "answer": "stood",
            "hit": false
          },
          {
            "score": 0.6362050771713257,
            "answer": "seat",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.828370988368988
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8541814088821411,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8329412341117859,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.8022404909133911,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7150337100028992,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6862022876739502,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6474104523658752,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.832941323518753
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8697522878646851,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8001810312271118,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7587655186653137,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7409529685974121,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.7140076160430908,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.7137629985809326,
            "answer": "indicate",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8697522878646851
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.752392590045929,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7377481460571289,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.7143669128417969,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.6588538885116577,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.6501198410987854,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.6308148503303528,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7377481013536453
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.7312974333763123,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7126776576042175,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.673901379108429,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.644463837146759,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6213348507881165,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.6207894086837769,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7312974333763123
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8189650774002075,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7609736919403076,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7541186213493347,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.6967682242393494,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.6813304424285889,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6686896681785583,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7609736919403076
      }
    ],
    "result": {
      "cnt_questions_correct": 30,
      "cnt_questions_total": 47,
      "accuracy": 0.6382978723404256
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1f99f792-0162-4be8-9856-dc6b193ed624",
      "timestamp": "2025-05-18T10:34:19.909262"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8524793982505798,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8162356019020081,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6686117053031921,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6627497673034668,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.627800703048706,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6176538467407227,
            "answer": "created",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8524794280529022
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8284487724304199,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8061133027076721,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7846446633338928,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.6961808204650879,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6772195100784302,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.6751132607460022,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8284488022327423
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8678377866744995,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8430017232894897,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7274644374847412,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7138407230377197,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6970099210739136,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6921075582504272,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8430017530918121
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.862933337688446,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8488820791244507,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.831152617931366,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7558082342147827,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7100783586502075,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6572156548500061,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.862933337688446
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8403950929641724,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.829582929611206,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7997462153434753,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6878659725189209,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.6566214561462402,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.6564619541168213,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8403950333595276
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.7821745872497559,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7535150647163391,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.6621646881103516,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6612083911895752,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.6399936676025391,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6271991729736328,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.661208376288414
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8498742580413818,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8145459890365601,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6947414875030518,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6572037935256958,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.641209602355957,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.6381421089172363,
            "answer": "questioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8498742878437042
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8747559189796448,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.8727496862411499,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.6665206551551819,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6562741994857788,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6465635299682617,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6274010539054871,
            "answer": "visited",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8727496862411499
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8591024875640869,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8479476571083069,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8064078092575073,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.6569855809211731,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6513943076133728,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.651073694229126,
            "answer": "being",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8479476571083069
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.732926607131958,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7047528624534607,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7023329138755798,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6612462401390076,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6420833468437195,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.6246078014373779,
            "answer": "given",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.732926607131958
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8242852687835693,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.6822341680526733,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.6752048134803772,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.6485210657119751,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.644716739654541,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6399353742599487,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6822341084480286
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7655779719352722,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6828603148460388,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6808338761329651,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.6729118824005127,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.6508598923683167,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.632462739944458,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6808338761329651
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7455986142158508,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7289429306983948,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.6633676886558533,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6475548148155212,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6217086315155029,
            "answer": "crafted",
            "hit": false
          },
          {
            "score": 0.6213136315345764,
            "answer": "creations",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7455986142158508
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8200118541717529,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7676612734794617,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7225332856178284,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.6928299069404602,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6758375763893127,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.6501514911651611,
            "answer": "decisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7225333154201508
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8475927114486694,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8186647295951843,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8186476230621338,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7195658683776855,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6534543037414551,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.6510993242263794,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8186646699905396
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8240953683853149,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7975835800170898,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7428379654884338,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7149718403816223,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6641016602516174,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6535984873771667,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8240953683853149
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8938538432121277,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8484548926353455,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8388751149177551,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7103752493858337,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6444839239120483,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6441423892974854,
            "answer": "proving",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8484548926353455
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7119099497795105,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.6898055076599121,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.6553750038146973,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6479705572128296,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.6350244879722595,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6192923188209534,
            "answer": "proposed",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7119099497795105
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7397559285163879,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6906826496124268,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6831235289573669,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.6479309797286987,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6443179845809937,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.6398183107376099,
            "answer": "hoping",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6906826794147491
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.7768318057060242,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.7148686647415161,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.6887702941894531,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.6547855138778687,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.642950713634491,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.6125184297561646,
            "answer": "declining",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6547855585813522
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7218590974807739,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6841446161270142,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6823880672454834,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.6197222471237183,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.594506025314331,
            "answer": "below",
            "hit": false
          },
          {
            "score": 0.5925437808036804,
            "answer": "this",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6823880523443222
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7936398983001709,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7471691370010376,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7230554819107056,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7169621586799622,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6274812817573547,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6170742511749268,
            "answer": "proceedings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7471691370010376
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8536390066146851,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8351406455039978,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7869695425033569,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7650862336158752,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7554101347923279,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.670922577381134,
            "answer": "proved",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8351406455039978
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.6115443706512451,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.5970504283905029,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.5804520845413208,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.578132152557373,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.5775697231292725,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.5775457620620728,
            "answer": "implied",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6115443706512451
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9003743529319763,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8911056518554688,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8458017706871033,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.6391244530677795,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6238537430763245,
            "answer": "inserted",
            "hit": false
          },
          {
            "score": 0.6223967671394348,
            "answer": "created",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8911056220531464
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8263579607009888,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8155679702758789,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7538964748382568,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6571405529975891,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6406103372573853,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.6364758014678955,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7538965046405792
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8549325466156006,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7356278896331787,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.6444052457809448,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6406204104423523,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.633582353591919,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.6316491365432739,
            "answer": "situated",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7356278896331787
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8588809370994568,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8464143872261047,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7171564102172852,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6973077058792114,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6669095754623413,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.642363965511322,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7171564251184464
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7872584462165833,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7091115713119507,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.687566876411438,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.6639207601547241,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.650537371635437,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.6489332914352417,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6875668466091156
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8798927068710327,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7360639572143555,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7084405422210693,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.6911072134971619,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.6422924995422363,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.6278799772262573,
            "answer": "bride",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7360639870166779
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7285805940628052,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7134144306182861,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.6986562013626099,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.6442644000053406,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6363324522972107,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6158835887908936,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7134144604206085
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8856005668640137,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8459063768386841,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8388252258300781,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.6842401623725891,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.683113694190979,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.6685999631881714,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8388252258300781
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8506056666374207,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8499895930290222,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.848696768283844,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7433381080627441,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7262709140777588,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.68113112449646,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8506056368350983
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8210179209709167,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7794443964958191,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.718680202960968,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6704896688461304,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.6617942452430725,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6582081317901611,
            "answer": "offers",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7794444561004639
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.6405676603317261,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.6234992146492004,
            "answer": "books",
            "hit": false
          },
          {
            "score": 0.6197630167007446,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.608497679233551,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.5898343920707703,
            "answer": "illustrations",
            "hit": false
          },
          {
            "score": 0.5870112180709839,
            "answer": "reproduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6084976717829704
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8246183395385742,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8164324760437012,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6747900247573853,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6680246591567993,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6616312265396118,
            "answer": "receiver",
            "hit": false
          },
          {
            "score": 0.649716317653656,
            "answer": "receivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8246182799339294
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.803092360496521,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7509258389472961,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.7342011332511902,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.7147678136825562,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6633948087692261,
            "answer": "decreased",
            "hit": false
          },
          {
            "score": 0.6575966477394104,
            "answer": "decrease",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7509258389472961
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.7773770093917847,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7329145073890686,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.6920595765113831,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6518582105636597,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6301479339599609,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.613645613193512,
            "answer": "regarding",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6518582105636597
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.7168026566505432,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.713586151599884,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6861158013343811,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6410370469093323,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.6247959136962891,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.623537540435791,
            "answer": "residual",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168026715517044
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8813283443450928,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8685024976730347,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8379720449447632,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7191477417945862,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7078268527984619,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.6400789022445679,
            "answer": "placed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8685024976730347
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8334342241287231,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7335447072982788,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7198317646980286,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6932411193847656,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6771925091743469,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6593390703201294,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7335447072982788
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7096691727638245,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6969980001449585,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.679587721824646,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6764038801193237,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6575287580490112,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6567586660385132,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6764038801193237
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8490167856216431,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7283483743667603,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7003538608551025,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6265655755996704,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.624659538269043,
            "answer": "transmit",
            "hit": false
          },
          {
            "score": 0.6237360239028931,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7003538608551025
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.850487232208252,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8162028789520264,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8076427578926086,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7220727205276489,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6931858062744141,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6401785612106323,
            "answer": "budget",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8162028193473816
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8257296085357666,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8176742792129517,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.7952553033828735,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.6227956414222717,
            "answer": "undergone",
            "hit": false
          },
          {
            "score": 0.6216335296630859,
            "answer": "endured",
            "hit": false
          },
          {
            "score": 0.6206420660018921,
            "answer": "misery",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8176742494106293
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.7417986392974854,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7223293781280518,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.7118122577667236,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6672098636627197,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.6553101539611816,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.6283581256866455,
            "answer": "educators",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.722329393029213
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7242653965950012,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.6922854781150818,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6723958849906921,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6218796968460083,
            "answer": "informed",
            "hit": false
          },
          {
            "score": 0.6151661276817322,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.614511251449585,
            "answer": "assured",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7242653965950012
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8170971870422363,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7696541547775269,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7403939962387085,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.6991286277770996,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.6752334237098694,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6737352013587952,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7696542143821716
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 48,
      "accuracy": 0.2916666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8ec043db-d824-4479-a581-b25f3e279c90",
      "timestamp": "2025-05-18T10:34:20.111826"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8265029788017273,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8144146203994751,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6552822589874268,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6480354070663452,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6321443915367126,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6171503067016602,
            "answer": "created",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8265029788017273
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8348703384399414,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8322762846946716,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7814173698425293,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7046694755554199,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6880665421485901,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.6864426136016846,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.832276314496994
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8634804487228394,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8242608904838562,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7217975854873657,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7076137661933899,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6946302652359009,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.6921398043632507,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242608904838562
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.862542986869812,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8463778495788574,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8373990654945374,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7332615852355957,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7085905075073242,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6410253047943115,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8625429570674896
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8913668394088745,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8697597980499268,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8040188550949097,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7222385406494141,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7067650556564331,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6865713596343994,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8697597086429596
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.772148609161377,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7025226354598999,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.6996595859527588,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6448735594749451,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.614570140838623,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.5969594120979309,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6448735594749451
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8750733733177185,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8056480884552002,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6943716406822205,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.685519814491272,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6484279036521912,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.6459999084472656,
            "answer": "questioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8750733733177185
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.880852460861206,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8637349605560303,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8059968948364258,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6521538496017456,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6238102316856384,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6225816011428833,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.863735020160675
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8539029955863953,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.838591456413269,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7838270664215088,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7276930809020996,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6819643974304199,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6725197434425354,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8385914266109467
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8304349184036255,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.8295083045959473,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7026322484016418,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6823223829269409,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.671748697757721,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.6488323211669922,
            "answer": "regarded",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8295083045959473
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.8801752328872681,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.8443106412887573,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7103596925735474,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6986602544784546,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.695578396320343,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.6661306619644165,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8801752626895905
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.6717154383659363,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.6707497835159302,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.665507972240448,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.5943586230278015,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.5911173224449158,
            "answer": "possessing",
            "hit": false
          },
          {
            "score": 0.5897523164749146,
            "answer": "filled",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.665507972240448
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7734363079071045,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7183830738067627,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.7034145593643188,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6464821696281433,
            "answer": "persisted",
            "hit": false
          },
          {
            "score": 0.6461663246154785,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.643262505531311,
            "answer": "began",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7183830887079239
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.6822302937507629,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.6656522750854492,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.6479580402374268,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6341724395751953,
            "answer": "construct",
            "hit": false
          },
          {
            "score": 0.614416778087616,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.5946673154830933,
            "answer": "constructed",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6656522750854492
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8324438333511353,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7678593397140503,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7230221033096313,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.673141360282898,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6494524478912354,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.6465983390808105,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7230221182107925
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8385530114173889,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8211213946342468,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8164583444595337,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6923948526382446,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6475790143013,
            "answer": "discussed",
            "hit": false
          },
          {
            "score": 0.6411536931991577,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8211214542388916
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8127380013465881,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.793986976146698,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6944208145141602,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.6830964684486389,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.667013943195343,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6418564319610596,
            "answer": "evolved",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8127379715442657
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8605952262878418,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8395123481750488,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8303386569023132,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.6722657680511475,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6586448550224304,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6350518465042114,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8303386867046356
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7480648756027222,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7089352011680603,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6875080466270447,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.6577920913696289,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6514864563941956,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6408290266990662,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7089351862668991
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.772932767868042,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.7227144837379456,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7040368914604187,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.6899093389511108,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.6614671349525452,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.6196094751358032,
            "answer": "refused",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6899093687534332
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7839083671569824,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7500762939453125,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7204024195671082,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6067491769790649,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.5980292558670044,
            "answer": "obtained",
            "hit": false
          },
          {
            "score": 0.5974193811416626,
            "answer": "developed",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7500762939453125
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.8629042506217957,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8580132722854614,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.7757448554039001,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.6811871528625488,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.6773462295532227,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6771764159202576,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8580132722854614
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8381136655807495,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.826327919960022,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7308441400527954,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6510549783706665,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.6425389051437378,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6422095894813538,
            "answer": "sees",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8381137251853943
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8134507536888123,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7247536778450012,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.689117968082428,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.6868765354156494,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6836217641830444,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.667448103427887,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8134507536888123
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.812373161315918,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.755164384841919,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.7018623948097229,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.6823469400405884,
            "answer": "intention",
            "hit": false
          },
          {
            "score": 0.6611857414245605,
            "answer": "intentions",
            "hit": false
          },
          {
            "score": 0.6530342698097229,
            "answer": "intent",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.755164384841919
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.868332028388977,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8502005338668823,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8494516611099243,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.6429548859596252,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6297812461853027,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6273844242095947,
            "answer": "announced",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8502005040645599
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8931502103805542,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.816015362739563,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7884055376052856,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6679562926292419,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6502729058265686,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.646756112575531,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.788405567407608
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.876944363117218,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8467277884483337,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7147237062454224,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7022877335548401,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6521497964859009,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.6376501321792603,
            "answer": "loose",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7147237360477448
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7812126874923706,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7116467356681824,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.6972450017929077,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.6483019590377808,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6235164403915405,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.6216849088668823,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7116467207670212
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9046059250831604,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8477209806442261,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8034866452217102,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.6844956874847412,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.6791236400604248,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.6761683821678162,
            "answer": "happened",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8477209210395813
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8786389827728271,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8163657784461975,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.7075110077857971,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.648941159248352,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6275404691696167,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.6254379153251648,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8163657784461975
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8702104091644287,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8404632210731506,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8173429369926453,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.6592918038368225,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6585997343063354,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6583914756774902,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8173429667949677
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8604621291160583,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8600233793258667,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8411427140235901,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.7282924652099609,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7138913869857788,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.6930969953536987,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8604621589183807
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8224128484725952,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7624796032905579,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.7260661125183105,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6726535558700562,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6628336906433105,
            "answer": "provision",
            "hit": false
          },
          {
            "score": 0.6496614217758179,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7624796032905579
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8327676057815552,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8314676284790039,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6525070667266846,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6471377611160278,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6387192010879517,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6364959478378296,
            "answer": "recipient",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8327675461769104
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8020473718643188,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7789761424064636,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7656115293502808,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.6280134320259094,
            "answer": "reference",
            "hit": false
          },
          {
            "score": 0.6122326850891113,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6122084856033325,
            "answer": "referenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7656115591526031
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8036633729934692,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7300727963447571,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.618554949760437,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6113874316215515,
            "answer": "invention",
            "hit": false
          },
          {
            "score": 0.6056371331214905,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.6056084632873535,
            "answer": "disclosed",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6185549423098564
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8454258441925049,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8287713527679443,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.6977936029434204,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6507179141044617,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6422069668769836,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.639382004737854,
            "answer": "becoming",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8287713527679443
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.844386875629425,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8411767482757568,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8366750478744507,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.6995769143104553,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.6810133457183838,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.654384970664978,
            "answer": "placed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8411767780780792
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8301399946212769,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7288656830787659,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.6761084794998169,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6760154366493225,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6682946085929871,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.6449456810951233,
            "answer": "constitutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7288656830787659
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.6836199164390564,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6505348086357117,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6293855905532837,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6154377460479736,
            "answer": "needs",
            "hit": false
          },
          {
            "score": 0.6152896881103516,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.6104363203048706,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6505348086357117
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8877894282341003,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8738917708396912,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.7448165416717529,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7244652509689331,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6976622343063354,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.6892693638801575,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8738917708396912
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8535910248756409,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7096160650253296,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.709608256816864,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6409499645233154,
            "answer": "transmit",
            "hit": false
          },
          {
            "score": 0.6400140523910522,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6348409652709961,
            "answer": "transmitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7096160352230072
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8827800750732422,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8785232305526733,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8136966228485107,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6765075325965881,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.662726640701294,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6334582567214966,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8785231709480286
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.841640830039978,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8414243459701538,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7402834892272949,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.7167613506317139,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7087714076042175,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.7030972242355347,
            "answer": "indicating",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8416408896446228
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7475452423095703,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7176430225372314,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7096987962722778,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6754680871963501,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6417386531829834,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6365974545478821,
            "answer": "warns",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7475452125072479
      }
    ],
    "result": {
      "cnt_questions_correct": 11,
      "cnt_questions_total": 46,
      "accuracy": 0.2391304347826087
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "93d05795-1e1b-4b99-b2c3-9fffd757280a",
      "timestamp": "2025-05-18T10:34:20.319173"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7628359198570251,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.6738864183425903,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.600412905216217,
            "answer": "brutal",
            "hit": false
          },
          {
            "score": 0.5938690900802612,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.590732216835022,
            "answer": "bedroom",
            "hit": false
          },
          {
            "score": 0.5906828045845032,
            "answer": "luxurious",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 76,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.565886102616787
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7672812938690186,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.5839226841926575,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.5833934545516968,
            "answer": "tuberculosis",
            "hit": false
          },
          {
            "score": 0.5827584862709045,
            "answer": "unemployed",
            "hit": false
          },
          {
            "score": 0.5797500610351562,
            "answer": "clare",
            "hit": false
          },
          {
            "score": 0.5794448256492615,
            "answer": "deaf",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5718896016478539
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d6c4e23e-a367-4014-81d0-38c5cde9bc93",
      "timestamp": "2025-05-18T10:34:20.520052"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.59555584192276,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.5950018763542175,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.5935963988304138,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.5925818085670471,
            "answer": "abilities",
            "hit": false
          },
          {
            "score": 0.5905620455741882,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.5902940630912781,
            "answer": "unavailable",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5771711245179176
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.7902300357818604,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.6895550489425659,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.6625570058822632,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.6335532069206238,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.6316691040992737,
            "answer": "disappointing",
            "hit": false
          },
          {
            "score": 0.6309117674827576,
            "answer": "uncomfortable",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7902299761772156
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.7163575291633606,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.6774485111236572,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.6753876209259033,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.670161783695221,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.6526696085929871,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.6360286474227905,
            "answer": "influenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7163575142621994
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.7290323972702026,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.6791359186172485,
            "answer": "availability",
            "hit": false
          },
          {
            "score": 0.627173900604248,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.6221437454223633,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.6169466972351074,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.6164699792861938,
            "answer": "unpublished",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7290323972702026
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.7125237584114075,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.6302691102027893,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6212657690048218,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.6147138476371765,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.6060217618942261,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.602205753326416,
            "answer": "unfamiliar",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7125237733125687
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.6575920581817627,
            "answer": "uncertain",
            "hit": true
          },
          {
            "score": 0.6452397108078003,
            "answer": "certainty",
            "hit": false
          },
          {
            "score": 0.6219629049301147,
            "answer": "sure",
            "hit": false
          },
          {
            "score": 0.6169109344482422,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.6160909533500671,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.613470196723938,
            "answer": "unknown",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6575920581817627
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.6922800540924072,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.6476446390151978,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.6447799205780029,
            "answer": "unchanged",
            "hit": true
          },
          {
            "score": 0.6275615096092224,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.622613251209259,
            "answer": "exchanged",
            "hit": false
          },
          {
            "score": 0.6121500730514526,
            "answer": "altered",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6447799652814865
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8090001940727234,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.696723222732544,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.695302426815033,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.6702204942703247,
            "answer": "comforting",
            "hit": false
          },
          {
            "score": 0.667868971824646,
            "answer": "comfort",
            "hit": false
          },
          {
            "score": 0.6498246192932129,
            "answer": "unhappy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8090002536773682
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.7470740675926208,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7370026111602783,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7198355197906494,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.6468977332115173,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6426149606704712,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.623173713684082,
            "answer": "intentional",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7198355495929718
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.7320958375930786,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.673306405544281,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6669899225234985,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.6493518948554993,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.6468129754066467,
            "answer": "unemployment",
            "hit": false
          },
          {
            "score": 0.6329575181007385,
            "answer": "employ",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7320958077907562
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.6836746335029602,
            "answer": "unexpected",
            "hit": true
          },
          {
            "score": 0.6780100464820862,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6779009103775024,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.6663382649421692,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.6515991687774658,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6503098011016846,
            "answer": "unexpectedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6836746335029602
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.740452229976654,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.7132598757743835,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.687350869178772,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.6547065377235413,
            "answer": "finish",
            "hit": false
          },
          {
            "score": 0.6427944898605347,
            "answer": "completed",
            "hit": false
          },
          {
            "score": 0.6359634399414062,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7404522746801376
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8148666620254517,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7248003482818604,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.663493812084198,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.6523445248603821,
            "answer": "fortunately",
            "hit": false
          },
          {
            "score": 0.6429089307785034,
            "answer": "unfortunately",
            "hit": false
          },
          {
            "score": 0.6424950957298279,
            "answer": "luckily",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7248003780841827
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7679516673088074,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.6832412481307983,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.650773286819458,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.6485791206359863,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6439868807792664,
            "answer": "miserable",
            "hit": false
          },
          {
            "score": 0.6380322575569153,
            "answer": "angry",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7679516673088074
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.8377170562744141,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.8137149810791016,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7963130474090576,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7628547549247742,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6721726059913635,
            "answer": "detected",
            "hit": false
          },
          {
            "score": 0.6652995347976685,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6571950018405914
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.6506292819976807,
            "answer": "unknown",
            "hit": true
          },
          {
            "score": 0.6178799867630005,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.6160657405853271,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.6128306984901428,
            "answer": "unused",
            "hit": false
          },
          {
            "score": 0.610770583152771,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6101336479187012,
            "answer": "renowned",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6506292372941971
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.6892315149307251,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.646403431892395,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.6267171502113342,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.6142327785491943,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.6138719320297241,
            "answer": "unconstitutional",
            "hit": false
          },
          {
            "score": 0.6104944348335266,
            "answer": "unauthorized",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6892315149307251
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.822373628616333,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.7713977694511414,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7236454486846924,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.6992928385734558,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.6977661848068237,
            "answer": "payments",
            "hit": false
          },
          {
            "score": 0.6949018239974976,
            "answer": "payment",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.72364541888237
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.7772126197814941,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.7368485927581787,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.6945825815200806,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.653937578201294,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.6528642177581787,
            "answer": "amusing",
            "hit": false
          },
          {
            "score": 0.6515745520591736,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7772126197814941
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.7484345436096191,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7217384576797485,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.6240612864494324,
            "answer": "controversial",
            "hit": false
          },
          {
            "score": 0.6211060881614685,
            "answer": "widespread",
            "hit": false
          },
          {
            "score": 0.6201493740081787,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6166793704032898,
            "answer": "fashionable",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7484345883131027
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.7328728437423706,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.6726357936859131,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.6427508592605591,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.6403168439865112,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.636188268661499,
            "answer": "disappointing",
            "hit": false
          },
          {
            "score": 0.6269223690032959,
            "answer": "recognizable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7328728586435318
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.6353411078453064,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6278736591339111,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.6070980429649353,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.5963266491889954,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.5955196619033813,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.5913240313529968,
            "answer": "unavailable",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6278735995292664
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.7787059545516968,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7750688791275024,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.6388057470321655,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.6359277367591858,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6343410611152649,
            "answer": "rational",
            "hit": false
          },
          {
            "score": 0.6319171786308289,
            "answer": "realistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7787059545516968
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.707760751247406,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.6561144590377808,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.6317569017410278,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.6309423446655273,
            "answer": "correlated",
            "hit": false
          },
          {
            "score": 0.6289385557174683,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6152186393737793,
            "answer": "relevant",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7077607810497284
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.7927954792976379,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.7465780973434448,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.6503707766532898,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.6442932486534119,
            "answer": "inaccurate",
            "hit": false
          },
          {
            "score": 0.6393141746520996,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.6279127597808838,
            "answer": "unavailable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7927954494953156
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.7783099412918091,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7463030815124512,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.6762999296188354,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.6644233465194702,
            "answer": "specifications",
            "hit": false
          },
          {
            "score": 0.6565956473350525,
            "answer": "specification",
            "hit": false
          },
          {
            "score": 0.6288115978240967,
            "answer": "indicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6762998849153519
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.7962096333503723,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.7680445909500122,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.689248263835907,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.6887239217758179,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.6726046800613403,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6657708883285522,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7962096333503723
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.6157227754592896,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.5985212326049805,
            "answer": "unwanted",
            "hit": false
          },
          {
            "score": 0.5883884429931641,
            "answer": "unnecessary",
            "hit": false
          },
          {
            "score": 0.5825275778770447,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.5803856253623962,
            "answer": "unemployed",
            "hit": false
          },
          {
            "score": 0.5760971307754517,
            "answer": "unspecified",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6157227605581284
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.674235463142395,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.6449378728866577,
            "answer": "unusual",
            "hit": true
          },
          {
            "score": 0.6443260908126831,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.634272575378418,
            "answer": "ordinary",
            "hit": false
          },
          {
            "score": 0.6180902123451233,
            "answer": "unusually",
            "hit": false
          },
          {
            "score": 0.6083070039749146,
            "answer": "familiar",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6449378728866577
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.7413532733917236,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.7116600275039673,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.6869394779205322,
            "answer": "unwanted",
            "hit": true
          },
          {
            "score": 0.665514349937439,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.6522212028503418,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.63749760389328,
            "answer": "wished",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6869394183158875
      }
    ],
    "result": {
      "cnt_questions_correct": 20,
      "cnt_questions_total": 30,
      "accuracy": 0.6666666666666666
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "265c9f25-6f80-481b-9f59-662c0b8846d8",
      "timestamp": "2025-05-18T10:34:20.528087"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.6871941089630127,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.652706503868103,
            "answer": "accordingly",
            "hit": true
          },
          {
            "score": 0.6431540250778198,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.6134611368179321,
            "answer": "supposedly",
            "hit": false
          },
          {
            "score": 0.6113132238388062,
            "answer": "reportedly",
            "hit": false
          },
          {
            "score": 0.6029723882675171,
            "answer": "pursuant",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6527064889669418
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.6692593097686768,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.6120553016662598,
            "answer": "outright",
            "hit": false
          },
          {
            "score": 0.6104438304901123,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.609952449798584,
            "answer": "allegedly",
            "hit": false
          },
          {
            "score": 0.6099131107330322,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.6080776453018188,
            "answer": "exact",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6692593097686768
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.6522390842437744,
            "answer": "supplementary",
            "hit": false
          },
          {
            "score": 0.6495524644851685,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.645476222038269,
            "answer": "supplemental",
            "hit": false
          },
          {
            "score": 0.6302634477615356,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.6181446313858032,
            "answer": "supporting",
            "hit": false
          },
          {
            "score": 0.6173598170280457,
            "answer": "extra",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6495524942874908
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.7125809788703918,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.6957117319107056,
            "answer": "apparently",
            "hit": true
          },
          {
            "score": 0.6856188178062439,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.6777426600456238,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.6620019674301147,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6551166772842407,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.695711761713028
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.7814791798591614,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.7610355615615845,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.7409235239028931,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.7290611863136292,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.69749516248703,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.680506706237793,
            "answer": "beauty",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7610355615615845
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.715724527835846,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.6311241388320923,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6233350038528442,
            "answer": "negatively",
            "hit": false
          },
          {
            "score": 0.6102070808410645,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6039129495620728,
            "answer": "positively",
            "hit": false
          },
          {
            "score": 0.6028342247009277,
            "answer": "importantly",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7157245427370071
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.7537202835083008,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.6701446771621704,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.6383366584777832,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.6359261274337769,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.6201338768005371,
            "answer": "politically",
            "hit": false
          },
          {
            "score": 0.6185275316238403,
            "answer": "literary",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7537203133106232
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.7052938938140869,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.6942195296287537,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.6917852163314819,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.6282188892364502,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6223529577255249,
            "answer": "decisions",
            "hit": false
          },
          {
            "score": 0.6164171695709229,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6112379059195518
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7680718302726746,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.6870579719543457,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.679827868938446,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.6701381206512451,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.6669648885726929,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.6647966504096985,
            "answer": "differ",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7680718302726746
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.7319723963737488,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.6353029012680054,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6174412965774536,
            "answer": "financially",
            "hit": false
          },
          {
            "score": 0.6070519089698792,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.6043035984039307,
            "answer": "commercially",
            "hit": false
          },
          {
            "score": 0.601352334022522,
            "answer": "digit",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7319724410772324
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7696102857589722,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.6921477317810059,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6572980284690857,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.6495872735977173,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.6371347904205322,
            "answer": "adequately",
            "hit": false
          },
          {
            "score": 0.6309661269187927,
            "answer": "successful",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7696102857589722
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.7402217984199524,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.7274560332298279,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.6803361177444458,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6485260128974915,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.6341214776039124,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.6308868527412415,
            "answer": "ecology",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7402217835187912
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.7486003637313843,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.6611803770065308,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.6610134243965149,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.658334493637085,
            "answer": "thoroughly",
            "hit": false
          },
          {
            "score": 0.6511332988739014,
            "answer": "comprehensive",
            "hit": false
          },
          {
            "score": 0.6495391130447388,
            "answer": "widespread",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7486003637313843
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.7653329372406006,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7493855953216553,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7409933805465698,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7201932668685913,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7094174027442932,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6608672142028809,
            "answer": "celebrated",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7201932966709137
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7308188676834106,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.6624355912208557,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.6442225575447083,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.640471339225769,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6378030776977539,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.6167401671409607,
            "answer": "economic",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7308189272880554
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8103066086769104,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.7108811736106873,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6517868041992188,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.6468794941902161,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.6164716482162476,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.6114003658294678,
            "answer": "locally",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8103066086769104
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.7054767608642578,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.6710062026977539,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.6425893306732178,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.6359503269195557,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.6355302333831787,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6324033141136169,
            "answer": "histories",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7054767310619354
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.7789014577865601,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.7502796053886414,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7381795048713684,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.7217454314231873,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.7201191782951355,
            "answer": "big",
            "hit": false
          },
          {
            "score": 0.7081002593040466,
            "answer": "massive",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.738179475069046
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.7836011648178101,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.6933721303939819,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.6446399092674255,
            "answer": "readily",
            "hit": false
          },
          {
            "score": 0.6405085325241089,
            "answer": "directly",
            "hit": false
          },
          {
            "score": 0.6368433237075806,
            "answer": "promptly",
            "hit": false
          },
          {
            "score": 0.6325243711471558,
            "answer": "quickly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7836011648178101
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.6534514427185059,
            "answer": "importance",
            "hit": false
          },
          {
            "score": 0.6470749378204346,
            "answer": "importantly",
            "hit": true
          },
          {
            "score": 0.6435149908065796,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6281798481941223,
            "answer": "valuable",
            "hit": false
          },
          {
            "score": 0.6191974878311157,
            "answer": "significantly",
            "hit": false
          },
          {
            "score": 0.6093870997428894,
            "answer": "useful",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6470749378204346
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.7040219902992249,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7014542818069458,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.7013634443283081,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.6979269981384277,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.6891753673553467,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.6405753493309021,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6979269981384277
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.6916195750236511,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.6355897784233093,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.6205472946166992,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6060406565666199,
            "answer": "appropriately",
            "hit": false
          },
          {
            "score": 0.6031758189201355,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.6015111804008484,
            "answer": "publicly",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6916195452213287
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.7831028699874878,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7005261778831482,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6637409329414368,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.648469090461731,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.6461116075515747,
            "answer": "overseas",
            "hit": false
          },
          {
            "score": 0.6338561773300171,
            "answer": "countries",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7831028699874878
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.6998451948165894,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.6309221386909485,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6278988718986511,
            "answer": "law",
            "hit": false
          },
          {
            "score": 0.6141288876533508,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.6132787466049194,
            "answer": "lawful",
            "hit": false
          },
          {
            "score": 0.6106957197189331,
            "answer": "morally",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6998451948165894
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.7481613755226135,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.6662614345550537,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.6373761892318726,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.6299161314964294,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.6114526987075806,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.6072046160697937,
            "answer": "psychologists",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7481613904237747
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.7322638034820557,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.6930704712867737,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.6505686640739441,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.6420444250106812,
            "answer": "cute",
            "hit": false
          },
          {
            "score": 0.6417160034179688,
            "answer": "pleasant",
            "hit": false
          },
          {
            "score": 0.6398457288742065,
            "answer": "neat",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.732263833284378
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.7080549001693726,
            "answer": "obviously",
            "hit": true
          },
          {
            "score": 0.6864885687828064,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.6854731440544128,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.6779996156692505,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.6644483208656311,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6464544534683228,
            "answer": "plainly",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7080549150705338
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.7820291519165039,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.629087507724762,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.6171402931213379,
            "answer": "mechanically",
            "hit": false
          },
          {
            "score": 0.6088279485702515,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.602411150932312,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.6003365516662598,
            "answer": "fundamentally",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7820291519165039
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.7563755512237549,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.6868226528167725,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.6530706286430359,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6418952941894531,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.6372406482696533,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.6251610517501831,
            "answer": "emotionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7563755512237549
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.6790494918823242,
            "answer": "practically",
            "hit": true
          },
          {
            "score": 0.63767009973526,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.624563992023468,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.6188584566116333,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6149923801422119,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.6139194965362549,
            "answer": "efficiently",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6790495216846466
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.6860274076461792,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.6397039294242859,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.6324869394302368,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6195749044418335,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.6132551431655884,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.6095609068870544,
            "answer": "preliminary",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6860273778438568
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.6679158806800842,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.6489430665969849,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.6245576739311218,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.6112222671508789,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.6070164442062378,
            "answer": "unusually",
            "hit": false
          },
          {
            "score": 0.603793203830719,
            "answer": "scarce",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.667915865778923
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.7112871408462524,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.6766786575317383,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.6738004684448242,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.6288880109786987,
            "answer": "significantly",
            "hit": false
          },
          {
            "score": 0.6223230957984924,
            "answer": "desperately",
            "hit": false
          },
          {
            "score": 0.6209124326705933,
            "answer": "sincerely",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6766786426305771
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8230189085006714,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.6987970471382141,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.661397397518158,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.6576964259147644,
            "answer": "sex",
            "hit": false
          },
          {
            "score": 0.6514548063278198,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.6467750072479248,
            "answer": "erotic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8230188488960266
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.7688109874725342,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.7069525718688965,
            "answer": "insignificant",
            "hit": false
          },
          {
            "score": 0.6914547681808472,
            "answer": "significance",
            "hit": false
          },
          {
            "score": 0.6588454246520996,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.649060070514679,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.6452564597129822,
            "answer": "substantially",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7688109278678894
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.6597137451171875,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.6477420330047607,
            "answer": "similarities",
            "hit": false
          },
          {
            "score": 0.6444912552833557,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.6402636766433716,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.6359449625015259,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.6276469826698303,
            "answer": "resembles",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.640263706445694
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.7022192478179932,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.663346529006958,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6468273401260376,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6314854621887207,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6311169862747192,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.6231814026832581,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7022192478179932
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.7054898738861084,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.6633474826812744,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.6400119066238403,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.6387614607810974,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.6340010166168213,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.6288079619407654,
            "answer": "succeeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7054898738861084
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8078044652938843,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.755577802658081,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.6930610537528992,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.6848896741867065,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.6846436262130737,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6745346784591675,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8078044652938843
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.7488462924957275,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.672523021697998,
            "answer": "tradition",
            "hit": false
          },
          {
            "score": 0.6670312881469727,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.6576417684555054,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.6264877319335938,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6184901595115662,
            "answer": "culturally",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7488463222980499
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.71651291847229,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.6546334624290466,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.6514353156089783,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.6196650862693787,
            "answer": "examples",
            "hit": false
          },
          {
            "score": 0.6193768382072449,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.616571843624115,
            "answer": "characteristic",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.71651291847229
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.7143101692199707,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.6266106367111206,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.6022046804428101,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.6014976501464844,
            "answer": "peculiar",
            "hit": false
          },
          {
            "score": 0.5988049507141113,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.5961177349090576,
            "answer": "individually",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7143102288246155
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.6427098512649536,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.6303356885910034,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.6015811562538147,
            "answer": "automatically",
            "hit": false
          },
          {
            "score": 0.5978877544403076,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.5867078304290771,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.5866591334342957,
            "answer": "online",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6427098363637924
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.6992318034172058,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.596299409866333,
            "answer": "culturally",
            "hit": false
          },
          {
            "score": 0.5956006050109863,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.5948521494865417,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.593429446220398,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.5926457643508911,
            "answer": "financially",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6992318332195282
      }
    ],
    "result": {
      "cnt_questions_correct": 33,
      "cnt_questions_total": 44,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9fb7f7f6-1807-4135-bfad-b0136871844e",
      "timestamp": "2025-05-18T10:34:20.649126"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.6618602275848389,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.6570720672607422,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.6393454074859619,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6135799884796143,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.6104675531387329,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6093364357948303,
            "answer": "happiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6618602275848389
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.7679076194763184,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7407841682434082,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7126830816268921,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6732542514801025,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.6486536860466003,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6225334405899048,
            "answer": "conscience",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7679077386856079
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.709984540939331,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6861016154289246,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6490741968154907,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.6342008709907532,
            "answer": "efficiency",
            "hit": false
          },
          {
            "score": 0.6312471032142639,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.6199841499328613,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6490741968154907
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.7065447568893433,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.693191409111023,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.6730260252952576,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6417480111122131,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.637513279914856,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.6352933645248413,
            "answer": "happily",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.693191409111023
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.6273481845855713,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.6185039281845093,
            "answer": "madame",
            "hit": false
          },
          {
            "score": 0.608016312122345,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6012522578239441,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.5995391607284546,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.5936655402183533,
            "answer": "weakness",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6273481547832489
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7038518786430359,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.6440976858139038,
            "answer": "sadly",
            "hit": false
          },
          {
            "score": 0.6211255192756653,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.615705132484436,
            "answer": "tragedy",
            "hit": false
          },
          {
            "score": 0.6104655265808105,
            "answer": "tragic",
            "hit": false
          },
          {
            "score": 0.6102689504623413,
            "answer": "happiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7038518935441971
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.7304068803787231,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.6402422189712524,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.6250404119491577,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6230795383453369,
            "answer": "madness",
            "hit": false
          },
          {
            "score": 0.6198592185974121,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6161991357803345,
            "answer": "enthusiasm",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7304069399833679
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.6944480538368225,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.6778987646102905,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6538233757019043,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.6335049867630005,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.6315470933914185,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6250963807106018,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6944480538368225
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 8,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9ad7f3a5-dfea-4660-b8ba-6e593cc4e01e",
      "timestamp": "2025-05-18T10:34:20.837342"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.7231367230415344,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7140579223632812,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.701521635055542,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6888748407363892,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.6504136323928833,
            "answer": "acceptable",
            "hit": true
          },
          {
            "score": 0.6188441514968872,
            "answer": "affordable",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6504136621952057
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.7615240812301636,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7542355060577393,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.7085977792739868,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.6898910403251648,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.660875678062439,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.6054031252861023,
            "answer": "reliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.660875678062439
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.7399610877037048,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.6822770833969116,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.6299386024475098,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.6294715404510498,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.6155469417572021,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.6143107414245605,
            "answer": "expensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6822770982980728
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7943567633628845,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7914429903030396,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6903056502342224,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6844398975372314,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6333271265029907,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.6293470859527588,
            "answer": "discussed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5931553542613983
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.723788857460022,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.702653169631958,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6996980905532837,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6756699085235596,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.6462134122848511,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6349872350692749,
            "answer": "delicious",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.675669938325882
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8280612230300903,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8237529993057251,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8190747499465942,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7448088526725769,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6803185343742371,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.6369955539703369,
            "answer": "unidentified",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6803185045719147
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8519164323806763,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.784023642539978,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7509504556655884,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.7344534397125244,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.6844871044158936,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.6437060832977295,
            "answer": "unpredictable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6844870448112488
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.6390424966812134,
            "answer": "merely",
            "hit": false
          },
          {
            "score": 0.6030082106590271,
            "answer": "simply",
            "hit": false
          },
          {
            "score": 0.6011142730712891,
            "answer": "ely",
            "hit": false
          },
          {
            "score": 0.5999355316162109,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.5981610417366028,
            "answer": "predictable",
            "hit": false
          },
          {
            "score": 0.5981284976005554,
            "answer": "mere",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5729079023003578
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.6523710489273071,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.642115592956543,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.6376206874847412,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.6207264065742493,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.6079750061035156,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.5914298295974731,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.642115592956543
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8125731945037842,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.776648998260498,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.6692619323730469,
            "answer": "sustainable",
            "hit": true
          },
          {
            "score": 0.6230763792991638,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.6184878349304199,
            "answer": "upheld",
            "hit": false
          },
          {
            "score": 0.6115956902503967,
            "answer": "uphold",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6692619025707245
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.6585698127746582,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.6395685076713562,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.6349259614944458,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.6090648770332336,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.6065512895584106,
            "answer": "predictable",
            "hit": false
          },
          {
            "score": 0.6016114950180054,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5922900289297104
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "baf89961-38e4-4568-9bbf-7b9029ae2e1e",
      "timestamp": "2025-05-18T10:34:20.869155"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.8256325721740723,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8139809966087341,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7888879776000977,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7384741902351379,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.683641791343689,
            "answer": "believer",
            "hit": true
          },
          {
            "score": 0.6756938099861145,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6836417615413666
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8441650867462158,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.7425334453582764,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6612895727157593,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6596816778182983,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.6472195982933044,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.6093698740005493,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6612895727157593
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.793038010597229,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.7328879237174988,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.6800508499145508,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6505058407783508,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.6448879241943359,
            "answer": "consumer",
            "hit": true
          },
          {
            "score": 0.6301838159561157,
            "answer": "ate",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6448878943920135
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7265729904174805,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.7105460166931152,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.677861750125885,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.6656280755996704,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.6379505395889282,
            "answer": "arguing",
            "hit": false
          },
          {
            "score": 0.6257957816123962,
            "answer": "asserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6106750518083572
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8222737312316895,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8202862739562988,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.6972960233688354,
            "answer": "defense",
            "hit": false
          },
          {
            "score": 0.6910042762756348,
            "answer": "defence",
            "hit": false
          },
          {
            "score": 0.6680421829223633,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.6550185680389404,
            "answer": "defenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5936990156769753
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.7163742184638977,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6670064926147461,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6644018292427063,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6586875915527344,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6459572315216064,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6258519887924194,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6083694621920586
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.849423885345459,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8283185362815857,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7913463115692139,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.6835227012634277,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.6796439290046692,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6614052653312683,
            "answer": "investigated",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6341566294431686
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8682584762573242,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8553192019462585,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.7871732711791992,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7685593962669373,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.6850481629371643,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6760133504867554,
            "answer": "explorer",
            "hit": true
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6760133355855942
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7935516834259033,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.758884072303772,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6755475997924805,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6219249963760376,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.6112440824508667,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.5857526659965515,
            "answer": "accompanying",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.621924988925457
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.7385897636413574,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.7264241576194763,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.7239494323730469,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.7048524618148804,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.6357980370521545,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.614524781703949,
            "answer": "misunderstood",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6357980072498322
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.7575271129608154,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7381512522697449,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6852750182151794,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6149575710296631,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.5954781770706177,
            "answer": "reader",
            "hit": false
          },
          {
            "score": 0.5899277329444885,
            "answer": "watches",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6149575412273407
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.8554760813713074,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8422964811325073,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.6913356781005859,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6749811172485352,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6429977416992188,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.6400099396705627,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6370869725942612
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.6885091066360474,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6743875741958618,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.668707549571991,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6335636377334595,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.6257291436195374,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6222410202026367,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6335636526346207
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.6852271556854248,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.6744569540023804,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6324029564857483,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.6296239495277405,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6290612816810608,
            "answer": "notice",
            "hit": false
          },
          {
            "score": 0.6254135370254517,
            "answer": "observed",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5906827449798584
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.847724199295044,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.7466333508491516,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.7325595617294312,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7323579788208008,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.6991845369338989,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.6595029830932617,
            "answer": "organizations",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7323580384254456
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.86519455909729,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8501628041267395,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8141077756881714,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.6850687861442566,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.6733416318893433,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6628148555755615,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.685068815946579
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8183116912841797,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.7106980085372925,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.6736773252487183,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.6286252737045288,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.6268633604049683,
            "answer": "missionaries",
            "hit": false
          },
          {
            "score": 0.6208869218826294,
            "answer": "clergy",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7106980383396149
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8833997249603271,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8602410554885864,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7986814379692078,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7472317218780518,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6879699230194092,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.6373152136802673,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6124909296631813
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.7002668976783752,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6978283524513245,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6762924194335938,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6153649091720581,
            "answer": "provision",
            "hit": false
          },
          {
            "score": 0.6147623658180237,
            "answer": "provider",
            "hit": true
          },
          {
            "score": 0.6089988946914673,
            "answer": "providers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6147623807191849
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.6291030049324036,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6140727996826172,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.5968796014785767,
            "answer": "observer",
            "hit": false
          },
          {
            "score": 0.5932418704032898,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.5900617837905884,
            "answer": "repository",
            "hit": false
          },
          {
            "score": 0.5873271226882935,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5932418406009674
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.6456156969070435,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6242008805274963,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6180335283279419,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6103945374488831,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.5940694808959961,
            "answer": "receipts",
            "hit": false
          },
          {
            "score": 0.5926951766014099,
            "answer": "receiver",
            "hit": true
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5926951766014099
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8255691528320312,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.8027358055114746,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.7069410085678101,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.6598560810089111,
            "answer": "talk",
            "hit": false
          },
          {
            "score": 0.6559824347496033,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.6471685767173767,
            "answer": "speaker",
            "hit": true
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6471686065196991
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8477000594139099,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.836754322052002,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7373592853546143,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.717046856880188,
            "answer": "teacher",
            "hit": true
          },
          {
            "score": 0.6776649355888367,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.6539796590805054,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7170468419790268
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.6531423926353455,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.6457423567771912,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.6373575329780579,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.6281306147575378,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.6127086281776428,
            "answer": "writers",
            "hit": false
          },
          {
            "score": 0.6014040112495422,
            "answer": "wrote",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6281306147575378
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9f974779-6145-49ed-bdc8-553da867bb0a",
      "timestamp": "2025-05-18T10:34:20.910378"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8350286483764648,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.80375075340271,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.7245738506317139,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.7235509753227234,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.6458154916763306,
            "answer": "suspected",
            "hit": false
          },
          {
            "score": 0.6385434865951538,
            "answer": "allegations",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7245738357305527
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8027346134185791,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.7368305921554565,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.6154073476791382,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.6140405535697937,
            "answer": "appreciated",
            "hit": false
          },
          {
            "score": 0.6130302548408508,
            "answer": "praised",
            "hit": false
          },
          {
            "score": 0.6094167232513428,
            "answer": "inspiration",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7368305325508118
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.7804975509643555,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.7750374674797058,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.7142874002456665,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.7094752788543701,
            "answer": "calculating",
            "hit": false
          },
          {
            "score": 0.691213846206665,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.6682968735694885,
            "answer": "calculated",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7804975509643555
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.6755991578102112,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6609432697296143,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6586678624153137,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6294615864753723,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.5993438363075256,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.5921365022659302,
            "answer": "continually",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6294615864753723
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8096833229064941,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.803584098815918,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.792553186416626,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.7369763255119324,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.6438895463943481,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.6073407530784607,
            "answer": "statement",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7369763106107712
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8360537886619568,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7839500904083252,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7637526988983154,
            "answer": "determination",
            "hit": true
          },
          {
            "score": 0.7277974486351013,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.6625860333442688,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.6446406245231628,
            "answer": "calculation",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.763752669095993
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8450364470481873,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8288969993591309,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7934613227844238,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.710002601146698,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.6851553916931152,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6606411933898926,
            "answer": "investigated",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6570320129394531
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8718029856681824,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8515145182609558,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.793846070766449,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.7842645049095154,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6897592544555664,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6578971147537231,
            "answer": "investigating",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.793846070766449
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.6968896389007568,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.6809849143028259,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.6140686273574829,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.6125292778015137,
            "answer": "imagination",
            "hit": true
          },
          {
            "score": 0.6003199815750122,
            "answer": "remember",
            "hit": false
          },
          {
            "score": 0.59709233045578,
            "answer": "dreamed",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6125292778015137
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.7730598449707031,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7705293893814087,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.7370157241821289,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.6263555884361267,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.6228002905845642,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6173566579818726,
            "answer": "encouraged",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7370157837867737
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.689717710018158,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.6741679906845093,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6656074523925781,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.651818037033081,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6323084831237793,
            "answer": "remark",
            "hit": false
          },
          {
            "score": 0.6272061467170715,
            "answer": "notice",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6656074374914169
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.860931932926178,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8332244753837585,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.712189793586731,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.6984018683433533,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.6667993664741516,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.6154857873916626,
            "answer": "inhabit",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6984018683433533
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8445411324501038,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.7463842034339905,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.7389330267906189,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7017896175384521,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.6744871139526367,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.6678905487060547,
            "answer": "organisation",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6588030755519867
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.681850254535675,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.6729415655136108,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.6602585315704346,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.6598401069641113,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.6598146557807922,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.6411649584770203,
            "answer": "prep",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6598401218652725
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.700458288192749,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.695563018321991,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.6807897090911865,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.6057313084602356,
            "answer": "reconstruction",
            "hit": false
          },
          {
            "score": 0.6032524704933167,
            "answer": "rebuilding",
            "hit": false
          },
          {
            "score": 0.6002867221832275,
            "answer": "recovery",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6955630481243134
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8274630308151245,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8223406076431274,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.7255597114562988,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6761831641197205,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.6148063540458679,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.6066808700561523,
            "answer": "maintenance",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8274631202220917
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 16,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "aa870448-de75-40cf-9f79-5246be4d31b2",
      "timestamp": "2025-05-18T10:34:21.007387"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8028240203857422,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7307259440422058,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.7039222717285156,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.6837896108627319,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.6748144030570984,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.6627780199050903,
            "answer": "achievement",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7307259440422058
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.8848074674606323,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8382362723350525,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7213990092277527,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7171626091003418,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.6843926906585693,
            "answer": "achievements",
            "hit": false
          },
          {
            "score": 0.6828114986419678,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7213990390300751
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.7601774334907532,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.7577329277992249,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7423476576805115,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.7165123224258423,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.607332170009613,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.6003663539886475,
            "answer": "adaptation",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7423476576805115
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8257508277893066,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7977306246757507,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7942038178443909,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.744385838508606,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7028472423553467,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6958773136138916,
            "answer": "agreement",
            "hit": true
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6958773136138916
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.7886812686920166,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.6129169464111328,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.5908278226852417,
            "answer": "conform",
            "hit": false
          },
          {
            "score": 0.5900354981422424,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.5899972319602966,
            "answer": "orientation",
            "hit": false
          },
          {
            "score": 0.582781195640564,
            "answer": "affiliation",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7886812686920166
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.7320446968078613,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.7158767580986023,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.6575419902801514,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.6058889627456665,
            "answer": "modification",
            "hit": false
          },
          {
            "score": 0.6000860929489136,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.5912818908691406,
            "answer": "adjustment",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7320446670055389
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8436040878295898,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8349831104278564,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8345250487327576,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.788831353187561,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.747951090335846,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6284335851669312,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888314127922058
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8164992928504944,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.7394407987594604,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.697868287563324,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.6102579832077026,
            "answer": "election",
            "hit": false
          },
          {
            "score": 0.6066062450408936,
            "answer": "elected",
            "hit": false
          },
          {
            "score": 0.6053000688552856,
            "answer": "assignment",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7394408285617828
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8746421337127686,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.832147479057312,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.7223584055900574,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7221666574478149,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.642674446105957,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.6302288174629211,
            "answer": "organize",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7221666425466537
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8500217199325562,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.831095814704895,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.7852859497070312,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.7382792234420776,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.696566104888916,
            "answer": "evaluated",
            "hit": false
          },
          {
            "score": 0.6740556955337524,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7382791936397552
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8171131610870361,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.803074836730957,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.767552375793457,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7427927851676941,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.6386496424674988,
            "answer": "allocated",
            "hit": false
          },
          {
            "score": 0.6201698780059814,
            "answer": "allocation",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7675524055957794
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.7371481657028198,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.7347533702850342,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.7254790663719177,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.7187954187393188,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.6845273971557617,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.6010973453521729,
            "answer": "investment",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7187954187393188
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.7352281212806702,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7070634365081787,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.6736057996749878,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6730868816375732,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6565030813217163,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6340805292129517,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7070634812116623
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8172712922096252,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7436308264732361,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7228876352310181,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.6650819778442383,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.6620779037475586,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.635833740234375,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7436308115720749
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8197024464607239,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7955092191696167,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7785829305648804,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.7413803935050964,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.7077755928039551,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.6581748723983765,
            "answer": "discouraged",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7413803935050964
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8617649078369141,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.778182864189148,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7426736354827881,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.6384949684143066,
            "answer": "forcing",
            "hit": false
          },
          {
            "score": 0.6247022151947021,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.6141462326049805,
            "answer": "punishment",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7426736652851105
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.8803088665008545,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8783354759216309,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8461247682571411,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.7832695245742798,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.6416327953338623,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6228606104850769,
            "answer": "participation",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7832694947719574
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8454498052597046,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7831385135650635,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.6935190558433533,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.6648715734481812,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.6518111824989319,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6505968570709229,
            "answer": "improving",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7831385433673859
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.7157219052314758,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6985510587692261,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6973763704299927,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6593331098556519,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.6384062767028809,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6172512769699097,
            "answer": "entertainment",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.659333124756813
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.830769419670105,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7847917079925537,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.6509305238723755,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.615557074546814,
            "answer": "amusement",
            "hit": false
          },
          {
            "score": 0.6009377837181091,
            "answer": "television",
            "hit": false
          },
          {
            "score": 0.5982328057289124,
            "answer": "amusing",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6509304791688919
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.88194340467453,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8449519276618958,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8412600159645081,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7193257808685303,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.6451330780982971,
            "answer": "demonstrate",
            "hit": false
          },
          {
            "score": 0.6336376667022705,
            "answer": "determination",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7193258106708527
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8160284757614136,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.7987638711929321,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.7438560724258423,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.6470143795013428,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.6308046579360962,
            "answer": "satisfying",
            "hit": false
          },
          {
            "score": 0.6262822151184082,
            "answer": "accomplishment",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7438561022281647
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.7765146493911743,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7500160932540894,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.7416552305221558,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7377665638923645,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7143318057060242,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.6361105442047119,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7500160336494446
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.723845899105072,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7161145806312561,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7124810218811035,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.6937486529350281,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.686752200126648,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.6837426424026489,
            "answer": "investors",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6937486231327057
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8812745809555054,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8139340877532959,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7816986441612244,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7239747047424316,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.6279213428497314,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6225824952125549,
            "answer": "contain",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7239746600389481
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.6924905776977539,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.682524561882019,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.6711124181747437,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6520868539810181,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.6155847311019897,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.6141664981842041,
            "answer": "development",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6520868390798569
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8118177652359009,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.7766623497009277,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.6393115520477295,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.6271519660949707,
            "answer": "reward",
            "hit": false
          },
          {
            "score": 0.6266946792602539,
            "answer": "penalty",
            "hit": false
          },
          {
            "score": 0.6253024339675903,
            "answer": "imprisonment",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7766623497009277
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.7964076995849609,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.7498241662979126,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.6732394099235535,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.6658528447151184,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6629953384399414,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.6289357542991638,
            "answer": "encouragement",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7498241662979126
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.8698021173477173,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8366878032684326,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.8253951072692871,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7288864850997925,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7217981219291687,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.6503729820251465,
            "answer": "placement",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7217981219291687
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.681732177734375,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.6570244431495667,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6225952506065369,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6025424599647522,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.5957396030426025,
            "answer": "dependency",
            "hit": false
          },
          {
            "score": 0.5953605771064758,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817321181297302
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 30,
      "accuracy": 0.1
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f9d21b98-f177-45d5-ae45-3ebbea1e337a",
      "timestamp": "2025-05-18T10:34:21.069028"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.7803161144256592,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7107443809509277,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.709053099155426,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6916823983192444,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.673183262348175,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.6709848642349243,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7803161144256592
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.7500520944595337,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.7382593154907227,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7103768587112427,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.6821625232696533,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.6745849847793579,
            "answer": "kuwait",
            "hit": false
          },
          {
            "score": 0.6678659915924072,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7500520646572113
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.8183018565177917,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.7180005311965942,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.7020586729049683,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.6878915429115295,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.6753223538398743,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.6738729476928711,
            "answer": "japan",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8183018565177917
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.7896240949630737,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.6961721181869507,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.6808813214302063,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.6749212145805359,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.6727608442306519,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.6707087159156799,
            "answer": "taiwan",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7896240651607513
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.7563938498497009,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7137095928192139,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6915411949157715,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.6905192136764526,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6863977313041687,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.6818751096725464,
            "answer": "austria",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7563938498497009
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.6283550262451172,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6232463717460632,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.6154066324234009,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.6144837737083435,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6133107542991638,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.611031174659729,
            "answer": "chile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6232463717460632
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.7190394997596741,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.6811087727546692,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6787846684455872,
            "answer": "europe",
            "hit": false
          },
          {
            "score": 0.6677378416061401,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6677285432815552,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.6663618087768555,
            "answer": "switzerland",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7190394997596741
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.7878738641738892,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.7591259479522705,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.6804430484771729,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.679564356803894,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.6773985624313354,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.6741107106208801,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7878738045692444
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.7413593530654907,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.7032740712165833,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.6706849336624146,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.6569572687149048,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.6569533348083496,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6561776399612427,
            "answer": "syria",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7413593530654907
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.7525599002838135,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.7226011157035828,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7047308087348938,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.6988105177879333,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.6676716804504395,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.6676260828971863,
            "answer": "netherlands",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7525598704814911
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.7287461161613464,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.6749946475028992,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.665024995803833,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.6637190580368042,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.6597582101821899,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.6585307121276855,
            "answer": "lebanon",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7287461161613464
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.7962507605552673,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.6994856595993042,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.6832197308540344,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.6703744530677795,
            "answer": "scotland",
            "hit": false
          },
          {
            "score": 0.6657402515411377,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6651842594146729,
            "answer": "australia",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7962507605552673
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.7273138761520386,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.6923668384552002,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.6775535941123962,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6684602499008179,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.6521893739700317,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.6513590216636658,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7273138612508774
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.6525676250457764,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.6273518204689026,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.6232125163078308,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.618100643157959,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.6173349022865295,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.6151373386383057,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6525676101446152
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.7562007904052734,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.6984305381774902,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6837323904037476,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6660215854644775,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.6647456884384155,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.664644718170166,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7562007904052734
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.7193023562431335,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.7027817368507385,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6964809894561768,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.6809156537055969,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.6781520843505859,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6638925075531006,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7193023562431335
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.7844521999359131,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.7423868775367737,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.6823819875717163,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.6716054677963257,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.6550238132476807,
            "answer": "india",
            "hit": false
          },
          {
            "score": 0.6539636254310608,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7844521999359131
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.7773404121398926,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.7086409330368042,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7063462734222412,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.6948490142822266,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6891183853149414,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6765026450157166,
            "answer": "ukraine",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7773404717445374
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.748469352722168,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.7137224674224854,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.6886723041534424,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.686230480670929,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.667877197265625,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.657981276512146,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7484693974256516
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.7168980836868286,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.7006316184997559,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.6951460838317871,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.6940517425537109,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.6868453621864319,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.6868451237678528,
            "answer": "toronto",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168980836868286
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.742550253868103,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.70988929271698,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.681252658367157,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6757667064666748,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6625010967254639,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6587243676185608,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7425503134727478
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.6297028064727783,
            "answer": "chrome",
            "hit": false
          },
          {
            "score": 0.6164257526397705,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.6065532565116882,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.6042328476905823,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.5985411405563354,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.5912562608718872,
            "answer": "rom",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6065532341599464
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.6519997119903564,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.6502651572227478,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6425786018371582,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6380972862243652,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.635820746421814,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.6314142346382141,
            "answer": "portugal",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6519996821880341
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.769201934337616,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.7387538552284241,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7200219631195068,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7131833434104919,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.6770164966583252,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.6748977899551392,
            "answer": "switzerland",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7692019641399384
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8155784010887146,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.7627465724945068,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.6720348596572876,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.6663095951080322,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.6660978198051453,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.6625102758407593,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8155783712863922
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.7527374029159546,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.6853775978088379,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6840725541114807,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6705136299133301,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.6596090793609619,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.6560220718383789,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7527374029159546
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.7331351041793823,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.7040022611618042,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6958894729614258,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6846058368682861,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6819510459899902,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.6758890151977539,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7331351339817047
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.7513841390609741,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.6817618012428284,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.6759210228919983,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6727896332740784,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6696016788482666,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6664106249809265,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7513841986656189
      }
    ],
    "result": {
      "cnt_questions_correct": 26,
      "cnt_questions_total": 28,
      "accuracy": 0.9285714285714286
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d3b8b84c-9d15-4a95-8329-88cb0d905d69",
      "timestamp": "2025-05-18T10:34:21.189973"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.759352445602417,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.756324052810669,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7079477906227112,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.704900860786438,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6889077425003052,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.673361599445343,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.759352445602417
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7732868194580078,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7699241042137146,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7186151146888733,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7121915221214294,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6866745948791504,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.677587628364563,
            "answer": "sydney",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7121915221214294
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7484663128852844,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7417114973068237,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7126466035842896,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.699292778968811,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6985151171684265,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6836420297622681,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6985151171684265
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.7592628002166748,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7440404891967773,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7182406187057495,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6881091594696045,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6775751709938049,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6623247861862183,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6572909504175186
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.7297719717025757,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7282961010932922,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7075564861297607,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.6823374629020691,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6707127690315247,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6703561544418335,
            "answer": "french",
            "hit": true
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6823374778032303
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7551169395446777,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6873466968536377,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6814059019088745,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6689664125442505,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.667985200881958,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.6594669222831726,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7551169097423553
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7513597011566162,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7163304090499878,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6987818479537964,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6744248867034912,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6573682427406311,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.6508355140686035,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.751359760761261
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7585169672966003,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7528197765350342,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6805699467658997,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6791777610778809,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6592218279838562,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6511368751525879,
            "answer": "chinese",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7528197765350342
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.7264550924301147,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6967793703079224,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.678134024143219,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6659322381019592,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.6445863246917725,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6431750059127808,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6659322530031204
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8214579224586487,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7265178561210632,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7247227430343628,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6904882788658142,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6811926364898682,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6751934885978699,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7247227430343628
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7487943172454834,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7107731699943542,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6715547442436218,
            "answer": "mexico",
            "hit": false
          },
          {
            "score": 0.6613828539848328,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6577748656272888,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6542866826057434,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7487943172454834
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8221914768218994,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.7339038252830505,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7271647453308105,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.712207019329071,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.708614706993103,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6633765697479248,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7122069895267487
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.7949544787406921,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7296198606491089,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7030836939811707,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6750423312187195,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.6585469841957092,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.6546235084533691,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7296198606491089
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.792094349861145,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7205857634544373,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.7056363821029663,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7054052352905273,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7021377086639404,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.6960155963897705,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7021377384662628
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.6883920431137085,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6804170608520508,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.652005672454834,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6337061524391174,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6187076568603516,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6143161058425903,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6883920431137085
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7211717367172241,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7142648100852966,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6559733152389526,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.6535869836807251,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6434023380279541,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6369063258171082,
            "answer": "dubai",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7211717516183853
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7496746182441711,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.7066475749015808,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7058688402175903,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6921041011810303,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.67612624168396,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6738951206207275,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7066475749015808
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7301561832427979,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6931544542312622,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6828535199165344,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6655189990997314,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6484659910202026,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6381217241287231,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7301561683416367
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.7440445423126221,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7357115745544434,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.6963087916374207,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6854290962219238,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.6832268834114075,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6822648048400879,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6815988272428513
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8134160041809082,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.712398886680603,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.703983724117279,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6690938472747803,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.661017656326294,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.6559883952140808,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7123989164829254
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.7258694171905518,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6804725527763367,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.679366946220398,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.6786107420921326,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6659980416297913,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6648613214492798,
            "answer": "korean",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6793669164180756
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.6755075454711914,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6497445106506348,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6256411075592041,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6091961860656738,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6035808324813843,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.5997531414031982,
            "answer": "chinese",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6256411075592041
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7518360018730164,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7108762264251709,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6730688810348511,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6711922883987427,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6516166925430298,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6471233367919922,
            "answer": "brazilian",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.751835972070694
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 23,
      "accuracy": 0.34782608695652173
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8a8bf317-76ad-4487-8962-fdd8a9e34806",
      "timestamp": "2025-05-18T10:34:21.303677"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7697544693946838,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7274237275123596,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6291486024856567,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.6192080974578857,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.618857204914093,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.6097605228424072,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6192080900073051
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7953363656997681,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.685180127620697,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.65357506275177,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6519027948379517,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6342546939849854,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.6302552819252014,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7953363060951233
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8138113021850586,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7366948127746582,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7025322914123535,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.6916323900222778,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6788354516029358,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.6764243841171265,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7025323212146759
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7719161510467529,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6983243227005005,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6739027500152588,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6576853394508362,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.6456278562545776,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6376293897628784,
            "answer": "shire",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7719161510467529
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8196803331375122,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7230224013328552,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7093143463134766,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6914704442024231,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.6910417675971985,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6784823536872864,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8196803331375122
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.787679135799408,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7107194662094116,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6659054160118103,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6599434018135071,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.6417371034622192,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.6393457651138306,
            "answer": "cornwall",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6417370736598969
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8090211153030396,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7406224012374878,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7162033915519714,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7014150619506836,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.6944252848625183,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6872406005859375,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8090211749076843
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7164390087127686,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6050426363945007,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.5987266898155212,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.5961145758628845,
            "answer": "well",
            "hit": false
          },
          {
            "score": 0.5941913723945618,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.594078540802002,
            "answer": "groundwater",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5941913649439812
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7575048208236694,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6893265247344971,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.635594367980957,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6319433450698853,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.6203922033309937,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6200183033943176,
            "answer": "hampshire",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7575048208236694
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b95b0a2d-fbbf-48b6-bdcb-4c06fcc782fe",
      "timestamp": "2025-05-18T10:34:21.393369"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.6979274153709412,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.6796326041221619,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6710132360458374,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6664248704910278,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.6632409691810608,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.660034716129303,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6979274451732635
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7014332413673401,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6777172684669495,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6730297207832336,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.6636773347854614,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6607929468154907,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6552739143371582,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6730297058820724
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6926125288009644,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6570044159889221,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6546295285224915,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6434418559074402,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6360468864440918,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6354299783706665,
            "answer": "australian",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6546295285224915
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.6719521880149841,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6488736867904663,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6392581462860107,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6365221738815308,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6209010481834412,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.6194570660591125,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6392581164836884
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7350515723228455,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6762827634811401,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6708647012710571,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6566387414932251,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6501897573471069,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6492873430252075,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5705067962408066
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.7763452529907227,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7455193400382996,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.735977292060852,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7353385090827942,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7093592882156372,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6637945175170898,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7763451933860779
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.702610194683075,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6835484504699707,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.6574291586875916,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6470450162887573,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6386871933937073,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6324656009674072,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6835484206676483
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.686808168888092,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6710900068283081,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6559882164001465,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6509490013122559,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6468871235847473,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6395780444145203,
            "answer": "british",
            "hit": true
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6314006149768829
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7269914150238037,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6556506752967834,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6475929021835327,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6454559564590454,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6417169570922852,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.638247013092041,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7269914448261261
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.6512215733528137,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6458073854446411,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6265718936920166,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6229692697525024,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6211204528808594,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6077002286911011,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6512215733528137
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.7188718318939209,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6713249087333679,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6646844148635864,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6493374109268188,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6476885080337524,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6462653875350952,
            "answer": "germans",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6442428678274155
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7041732668876648,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6832252144813538,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6632140874862671,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.649461567401886,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6465129852294922,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.6441937685012817,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6632140874862671
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6550593376159668,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6523314714431763,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6463189721107483,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6454066634178162,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6319766044616699,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6316327452659607,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6550593674182892
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.71918123960495,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7093940377235413,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6531485915184021,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6527620553970337,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6414194107055664,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6364098787307739,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7093940377235413
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6785558462142944,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6678341627120972,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6549851894378662,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6412074565887451,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6266207098960876,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6254822611808777,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6117868572473526
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6954041123390198,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6444007158279419,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6387325525283813,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6345230340957642,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6281031370162964,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6235204339027405,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6387325525283813
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7044135332107544,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.6899467706680298,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6762527823448181,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6692688465118408,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.6559069156646729,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6543421745300293,
            "answer": "scottish",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7044135332107544
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7118611335754395,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.660615086555481,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6567825675010681,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6515985131263733,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6293041706085205,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.6287765502929688,
            "answer": "scottish",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6515985131263733
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.71547931432724,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6620014905929565,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6563838124275208,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6407419443130493,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6395803093910217,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6391193866729736,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7154792845249176
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 19,
      "accuracy": 0.42105263157894735
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7c02376e-e87a-48fa-bae0-100fd2892f98",
      "timestamp": "2025-05-18T10:34:21.427654"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.749398946762085,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7120768427848816,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6636990308761597,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.6615013480186462,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6583966612815857,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6493606567382812,
            "answer": "philosophy",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7493989914655685
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.724811315536499,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.657659649848938,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6293739080429077,
            "answer": "romans",
            "hit": false
          },
          {
            "score": 0.628615140914917,
            "answer": "roman",
            "hit": false
          },
          {
            "score": 0.6214667558670044,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.6145507097244263,
            "answer": "dictator",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6214667186141014
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.6706522703170776,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6276595592498779,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.6210200190544128,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.609674870967865,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6075599789619446,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6006409525871277,
            "answer": "rochester",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5886927396059036
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7071591019630432,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6374257802963257,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6346993446350098,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.6114640831947327,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6091987490653992,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6046236753463745,
            "answer": "philosophy",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6346993148326874
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.6734577417373657,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6075310707092285,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6069314479827881,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6006752848625183,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.5983699560165405,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.596862256526947,
            "answer": "emperor",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5963736027479172
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7010535597801208,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6682832837104797,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6477392911911011,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6365617513656616,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.6255926489830017,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.6248241662979126,
            "answer": "gravitational",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6682832688093185
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.7283481359481812,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7256416082382202,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.7031736373901367,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6712433099746704,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.6498414278030396,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6435573101043701,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6403515338897705
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7192668318748474,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6683768033981323,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.645857572555542,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6343609690666199,
            "answer": "philosophy",
            "hit": false
          },
          {
            "score": 0.6230423450469971,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6210114359855652,
            "answer": "philosophical",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7192668616771698
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.724563479423523,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6643569469451904,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6320708990097046,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6277340054512024,
            "answer": "philosophy",
            "hit": false
          },
          {
            "score": 0.6274739503860474,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.6218072175979614,
            "answer": "nietzsche",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.724563479423523
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.688434362411499,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6053166389465332,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6041048169136047,
            "answer": "presidents",
            "hit": false
          },
          {
            "score": 0.6012383699417114,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6000818014144897,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.597791314125061,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5907314643263817
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7112973928451538,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6663037538528442,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.64134281873703,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6156189441680908,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6102619171142578,
            "answer": "philosophy",
            "hit": false
          },
          {
            "score": 0.6070051193237305,
            "answer": "philosophical",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7112974226474762
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.7267720699310303,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7217758893966675,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6548629403114319,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.646691083908081,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6443780660629272,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.642799437046051,
            "answer": "communism",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7217758595943451
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.6791303157806396,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6303443908691406,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6145889759063721,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.5999746322631836,
            "answer": "electromagnetic",
            "hit": false
          },
          {
            "score": 0.5956772565841675,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.5942164063453674,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6303444355726242
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.6982999444007874,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6459605693817139,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.6387553811073303,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.6350570917129517,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6186226010322571,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.6181378364562988,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6459605842828751
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7169114351272583,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6456306576728821,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6359801292419434,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6307522654533386,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.630322277545929,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6234895586967468,
            "answer": "explorer",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6307522356510162
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7671018838882446,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7225964665412903,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6947170495986938,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6708287596702576,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.6550227999687195,
            "answer": "philosophy",
            "hit": false
          },
          {
            "score": 0.6496009826660156,
            "answer": "philosophical",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7671018540859222
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.6762175559997559,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.628886342048645,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.6280917525291443,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.6227594614028931,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6175921559333801,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.6158875226974487,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5973331332206726
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.697540283203125,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6286451816558838,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6246041655540466,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6102830767631531,
            "answer": "philosophy",
            "hit": false
          },
          {
            "score": 0.6094313859939575,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.6081079840660095,
            "answer": "composer",
            "hit": true
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6081079542636871
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d147d0f4-1789-4838-9cdf-6471ec88e1d0",
      "timestamp": "2025-05-18T10:34:21.501051"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.6607731580734253,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6244465708732605,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6044958233833313,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.5736508965492249,
            "answer": "tape",
            "hit": false
          },
          {
            "score": 0.5646336078643799,
            "answer": "pablo",
            "hit": false
          },
          {
            "score": 0.5633956789970398,
            "answer": "cap",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 1041,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5153272515162826
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8157786130905151,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6892406344413757,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.6828868389129639,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.6705656051635742,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6634005904197693,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6402174830436707,
            "answer": "bearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6705656051635742
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7136716842651367,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6363352537155151,
            "answer": "albany",
            "hit": false
          },
          {
            "score": 0.6337922811508179,
            "answer": "syracuse",
            "hit": false
          },
          {
            "score": 0.6312358975410461,
            "answer": "pittsburgh",
            "hit": false
          },
          {
            "score": 0.6291443109512329,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.6260894536972046,
            "answer": "cincinnati",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6232570186257362
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7834709882736206,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7088110446929932,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6489529609680176,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6175254583358765,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.6162479519844055,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6077139973640442,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.64895299077034
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.7323085069656372,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7207508087158203,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.690078616142273,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6694262027740479,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6473188400268555,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6328760385513306,
            "answer": "rabbit",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 92,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5564494878053665
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6769031882286072,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6489021182060242,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6009751558303833,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.5913160443305969,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.5909386873245239,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.5839401483535767,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.676903173327446
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7532991766929626,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.69395512342453,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6625403761863708,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6215091943740845,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.619962751865387,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6135503053665161,
            "answer": "babies",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5853937417268753
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8114296197891235,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7496579885482788,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6942572593688965,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6936666369438171,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6640797853469849,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.5942190289497375,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5600330829620361
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7767902612686157,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6537737250328064,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.638492226600647,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.610252857208252,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.6003893613815308,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6003415584564209,
            "answer": "pup",
            "hit": true
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.638492226600647
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6748425364494324,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6479636430740356,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6354637742042542,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.5996528267860413,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.5990421772003174,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.5925143957138062,
            "answer": "pup",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6748425364494324
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.765404224395752,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7013828158378601,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6531746983528137,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6305055022239685,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.626572847366333,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6063486933708191,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6531747281551361
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 11,
      "accuracy": 0.18181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ed43801e-d2ff-4d8c-b6fd-58f95b5d0972",
      "timestamp": "2025-05-18T10:34:21.569523"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.653852105140686,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.6499292850494385,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6334343552589417,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.5877736806869507,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.5774781703948975,
            "answer": "boo",
            "hit": false
          },
          {
            "score": 0.5757132768630981,
            "answer": "daisy",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6538520753383636
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.657298743724823,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.6492089033126831,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6408672332763672,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.635211706161499,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6198076605796814,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6099874377250671,
            "answer": "bark",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.657298743724823
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.761111319065094,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.721847414970398,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7114049196243286,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6710451245307922,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6071881651878357,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.5786938071250916,
            "answer": "stamp",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 4591,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5079335924237967
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7452457547187805,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7291132211685181,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6566306948661804,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6258143782615662,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6130580306053162,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.5931158065795898,
            "answer": "elephant",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 9053,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4976905635558069
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 4,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e2445ce6-8c05-43d9-9fd5-43ee7450a11c",
      "timestamp": "2025-05-18T10:34:21.612825"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6807534694671631,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6269353628158569,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6110414862632751,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5826654434204102,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5654361844062805,
            "answer": "amp",
            "hit": false
          },
          {
            "score": 0.5632104277610779,
            "answer": "place",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 158,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5120084034278989
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6922997236251831,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6305792331695557,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6240684390068054,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6135534048080444,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.5925865769386292,
            "answer": "batting",
            "hit": false
          },
          {
            "score": 0.5759468674659729,
            "answer": "barn",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 369,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5234158430248499
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8236425518989563,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7145511507987976,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.692706286907196,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.6831108927726746,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.6368486285209656,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.620245635509491,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5929501503705978
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.705865204334259,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.6934664249420166,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6727652549743652,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6666457653045654,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6529964208602905,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6409493684768677,
            "answer": "herd",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 344,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5167630165815353
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6530976295471191,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.6508772373199463,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6277818083763123,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.6171224117279053,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.6078511476516724,
            "answer": "football",
            "hit": false
          },
          {
            "score": 0.6026718020439148,
            "answer": "tennis",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6508772075176239
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6770744323730469,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.614224910736084,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6098514795303345,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.606751024723053,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.600399911403656,
            "answer": "row",
            "hit": false
          },
          {
            "score": 0.5906285047531128,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6770744621753693
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7098873257637024,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6459118723869324,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.6337169408798218,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6293144822120667,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6126973628997803,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5885000228881836,
            "answer": "goose",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5572896413505077
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6773790121078491,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6749891638755798,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6619607210159302,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.6401462554931641,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6258420944213867,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.6091682314872742,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6749891936779022
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7227187156677246,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6543837189674377,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5977416038513184,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.5842355489730835,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.5809967517852783,
            "answer": "frog",
            "hit": false
          },
          {
            "score": 0.5794289708137512,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5842355191707611
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.7570770978927612,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7022871971130371,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6440809369087219,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6320701241493225,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.6238133311271667,
            "answer": "moth",
            "hit": false
          },
          {
            "score": 0.6167639493942261,
            "answer": "den",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7022871971130371
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7000082731246948,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6330676078796387,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6125901937484741,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.59482741355896,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5791549682617188,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.5784387588500977,
            "answer": "ole",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5597062334418297
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7536258101463318,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7078977227210999,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6312300562858582,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6195502877235413,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6066222190856934,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.6002076864242554,
            "answer": "donkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 43,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5106651652604342
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6724818348884583,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6527565717697144,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.6177757978439331,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5980560779571533,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5865361094474792,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5830839276313782,
            "answer": "rodents",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6724818646907806
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6615316867828369,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.647838830947876,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6149076223373413,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.603579044342041,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5787556767463684,
            "answer": "ratings",
            "hit": false
          },
          {
            "score": 0.5691048502922058,
            "answer": "alter",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6615316867828369
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6773910522460938,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6336686611175537,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6009783744812012,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5931342244148254,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.5785324573516846,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5752562284469604,
            "answer": "logan",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6773910224437714
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6736854910850525,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6270573735237122,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.5971696972846985,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.5940626859664917,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5874086618423462,
            "answer": "tree",
            "hit": false
          },
          {
            "score": 0.5806070566177368,
            "answer": "den",
            "hit": true
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5806070566177368
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.786543071269989,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7156764268875122,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6446387767791748,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6157981753349304,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6140686273574829,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6089269518852234,
            "answer": "elephant",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 502,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5179066266864538
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6971139907836914,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6199622750282288,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5929974913597107,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.5902109742164612,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.5857884287834167,
            "answer": "hunter",
            "hit": false
          },
          {
            "score": 0.5793643593788147,
            "answer": "woods",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5669206529855728
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 18,
      "accuracy": 0.3333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3203e284-bd3d-4ea1-a1d8-c647b521239c",
      "timestamp": "2025-05-18T10:34:21.635016"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.6928566098213196,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6848896741867065,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6644538640975952,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6619099378585815,
            "answer": "anti",
            "hit": false
          },
          {
            "score": 0.6329963207244873,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6144872903823853,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6848897188901901
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7318710088729858,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7240327596664429,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6440855860710144,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6271295547485352,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6197680234909058,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6163522005081177,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6440856009721756
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.729339599609375,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7258930802345276,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6278110146522522,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6237773299217224,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6124767065048218,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.607890248298645,
            "answer": "bloody",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6278110146522522
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7019650936126709,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6994245052337646,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6592758297920227,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6509945392608643,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6412661671638489,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6356194615364075,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6208085045218468
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7003681063652039,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6929464340209961,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6594517230987549,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6456848382949829,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6371526122093201,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6287041902542114,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6287042200565338
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7252445220947266,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7080207467079163,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6488313674926758,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6469078660011292,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6366071105003357,
            "answer": "orange",
            "hit": false
          },
          {
            "score": 0.6357979774475098,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.648831307888031
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7313254475593567,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6885882616043091,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6605240702629089,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6466820240020752,
            "answer": "orange",
            "hit": false
          },
          {
            "score": 0.6452939510345459,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6411316394805908,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6885883212089539
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7794438600540161,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7221333980560303,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.680770754814148,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6385880708694458,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6228160262107849,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6226223707199097,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6807707697153091
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7047353386878967,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6881084442138672,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6616009473800659,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6223890781402588,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6213018298149109,
            "answer": "charcoal",
            "hit": false
          },
          {
            "score": 0.6175683736801147,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6881084442138672
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7143024206161499,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.700107753276825,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6734409332275391,
            "answer": "tea",
            "hit": false
          },
          {
            "score": 0.6486722230911255,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6327774524688721,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6189331412315369,
            "answer": "cocoa",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.700107753276825
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.6964584589004517,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6930779218673706,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6493526697158813,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6485828757286072,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6430627703666687,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.6391080617904663,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6930778622627258
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7049683332443237,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7031418681144714,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6461074352264404,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6437979936599731,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6257317662239075,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6152552366256714,
            "answer": "grey",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7031418681144714
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7935106158256531,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.6902949810028076,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6727191209793091,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6270414590835571,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6116951704025269,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.6102343797683716,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6727191209793091
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.6846011877059937,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.675670325756073,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6299554705619812,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6219472289085388,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6123504638671875,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6119413375854492,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6219472214579582
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.7153646945953369,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6979252696037292,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.6965926885604858,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6397402286529541,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6388906240463257,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6294540166854858,
            "answer": "whites",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6965927183628082
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7211341261863708,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.703953742980957,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6599267721176147,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6332923769950867,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6208952069282532,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6110230684280396,
            "answer": "blacks",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6599267423152924
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7416138648986816,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.7189210057258606,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7078813910484314,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6951783895492554,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.6777662634849548,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.6385778188705444,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.615813210606575
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7162715196609497,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7110797166824341,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6556957364082336,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.624649703502655,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6242138743400574,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.6202610731124878,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7162714898586273
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.7172588109970093,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7021076083183289,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6834583282470703,
            "answer": "papers",
            "hit": false
          },
          {
            "score": 0.626288652420044,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6243322491645813,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6076738238334656,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.717258870601654
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7086000442504883,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6989963054656982,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.6947509050369263,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6438318490982056,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6309265494346619,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6265431642532349,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6947509050369263
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7225842475891113,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.7045862674713135,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.695399284362793,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6624228954315186,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6458097696304321,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.6322442293167114,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5936998575925827
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.6956508159637451,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6898744702339172,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6708114743232727,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6266987919807434,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.6159274578094482,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6125093102455139,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6898744702339172
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7212114334106445,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6934173703193665,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6659872531890869,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6549383401870728,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6407458782196045,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6270922422409058,
            "answer": "pink",
            "hit": true
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6659872531890869
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7099297046661377,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6945664286613464,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6804180145263672,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.639243483543396,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6378569602966309,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6343110799789429,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6804180294275284
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7001840472221375,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6952388882637024,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6591304540634155,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6357752084732056,
            "answer": "salts",
            "hit": false
          },
          {
            "score": 0.6318938732147217,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6162302494049072,
            "answer": "grey",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7001840323209763
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6907795667648315,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.679589569568634,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6294272541999817,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6234095692634583,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6164143681526184,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6146320104598999,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6234095916152
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7042922973632812,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.693416953086853,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6812902092933655,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6425505876541138,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6269087791442871,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6261579394340515,
            "answer": "skies",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6269087940454483
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7104803919792175,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6986608505249023,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6564129590988159,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6411257386207581,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6387944221496582,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6351922154426575,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.69866082072258
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.7973574995994568,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.6951552629470825,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6814296245574951,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6486732959747314,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6280402541160583,
            "answer": "dirt",
            "hit": false
          },
          {
            "score": 0.6260251998901367,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6814296394586563
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7196108102798462,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6961007118225098,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6531791687011719,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6381230354309082,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6330610513687134,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6281391382217407,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6961006820201874
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7134504318237305,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7047826051712036,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6922073364257812,
            "answer": "sunlight",
            "hit": false
          },
          {
            "score": 0.6454339623451233,
            "answer": "moon",
            "hit": false
          },
          {
            "score": 0.6430485248565674,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.639308750629425,
            "answer": "sunshine",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5902042239904404
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6918035745620728,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6883599162101746,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6308925151824951,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6263881921768188,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.620573878288269,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6193494200706482,
            "answer": "grey",
            "hit": true
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6918035447597504
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7113727331161499,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6884713172912598,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.673839807510376,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.6378498077392578,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6272715926170349,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6171330809593201,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6884713470935822
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7316907644271851,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7206530570983887,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7145996689796448,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6674792766571045,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6629733443260193,
            "answer": "orange",
            "hit": false
          },
          {
            "score": 0.6509983539581299,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6509983241558075
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 34,
      "accuracy": 0.20588235294117646
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "33f3cca5-6932-483d-ab8d-99ff3e22cf26",
      "timestamp": "2025-05-18T10:34:21.704306"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.8636984825134277,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.7010860443115234,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.667628288269043,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6593759059906006,
            "answer": "dancer",
            "hit": false
          },
          {
            "score": 0.6407503485679626,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6398606300354004,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8636984825134277
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.8216670751571655,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.6653823256492615,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.6568869948387146,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.6555968523025513,
            "answer": "child",
            "hit": false
          },
          {
            "score": 0.6402878761291504,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.6311122179031372,
            "answer": "girls",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8216670155525208
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.7342602014541626,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7012138366699219,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.6918089985847473,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6714970469474792,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.6708259582519531,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.66156005859375,
            "answer": "siblings",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6372974216938019
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.5914575457572937,
            "answer": "bride",
            "hit": false
          },
          {
            "score": 0.5810303092002869,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.573335587978363,
            "answer": "buffalo",
            "hit": false
          },
          {
            "score": 0.5729288458824158,
            "answer": "chuck",
            "hit": false
          },
          {
            "score": 0.5707187056541443,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.5693204402923584,
            "answer": "dash",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 10132,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.49062550347298384
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.6299119591712952,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.5895469188690186,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.5872049331665039,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.5845462083816528,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.5837639570236206,
            "answer": "abbott",
            "hit": false
          },
          {
            "score": 0.5829144716262817,
            "answer": "australia",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5667095631361008
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.6939284801483154,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6852476596832275,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6823526620864868,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.6783400774002075,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.675489068031311,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.6653685569763184,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6754890978336334
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7256026268005371,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.6694160103797913,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.6536140441894531,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6366221904754639,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6353746056556702,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.6115694046020508,
            "answer": "aunt",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7256026566028595
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.6839170455932617,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.6585565805435181,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.6474728584289551,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.6329920887947083,
            "answer": "mom",
            "hit": false
          },
          {
            "score": 0.6310957670211792,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6286885142326355,
            "answer": "mothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6839170455932617
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.6716364622116089,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.6665549874305725,
            "answer": "heaven",
            "hit": false
          },
          {
            "score": 0.6634714603424072,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.6488502025604248,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.6474512815475464,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.6471540331840515,
            "answer": "lord",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6474512368440628
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8395943641662598,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.7720533609390259,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.710555374622345,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7079170942306519,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6773446798324585,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.6746916174888611,
            "answer": "grandchildren",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8395944237709045
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.5968853235244751,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.5937010049819946,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.5901617407798767,
            "answer": "glands",
            "hit": false
          },
          {
            "score": 0.5876970887184143,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.5821850299835205,
            "answer": "blonde",
            "hit": false
          },
          {
            "score": 0.5814116597175598,
            "answer": "mistress",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5796352177858353
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.7923310995101929,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.7869580984115601,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7018026113510132,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.6997300386428833,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.6765178442001343,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.6727870106697083,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7923310995101929
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7513311505317688,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.6728816032409668,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6597086191177368,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.6474132537841797,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.6405279040336609,
            "answer": "pope",
            "hit": false
          },
          {
            "score": 0.6209530830383301,
            "answer": "goddess",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7513311803340912
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.6375494003295898,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.63238126039505,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.5921880602836609,
            "answer": "oman",
            "hit": false
          },
          {
            "score": 0.5912923216819763,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.5911668539047241,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.5908458232879639,
            "answer": "maiden",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6375494003295898
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.8448015451431274,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.766839325428009,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7510894536972046,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7233802676200867,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.6800975799560547,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.6661955714225769,
            "answer": "cousins",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8448014855384827
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.7556301355361938,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.7503223419189453,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.6560783386230469,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.645982563495636,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.6289397478103638,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6264729499816895,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7556301355361938
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.6601651906967163,
            "answer": "sons",
            "hit": false
          },
          {
            "score": 0.6329984664916992,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.6322479248046875,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.6284332275390625,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6172282695770264,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.6051215529441833,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6329984962940216
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.7709293365478516,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.6667892336845398,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6550899147987366,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.648521900177002,
            "answer": "mama",
            "hit": false
          },
          {
            "score": 0.637031078338623,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.6368237137794495,
            "answer": "mom",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.770929366350174
      }
    ],
    "result": {
      "cnt_questions_correct": 11,
      "cnt_questions_total": 18,
      "accuracy": 0.6111111111111112
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "95ebe71d-6875-4c85-a371-0b6662a89092",
      "timestamp": "2025-05-18T10:34:21.842572"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.734830915927887,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.6282012462615967,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.625758171081543,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.6241560578346252,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6233192086219788,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.6227420568466187,
            "answer": "gases",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5956206917762756
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7242141366004944,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.6145197749137878,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6088829636573792,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.6016524434089661,
            "answer": "baggage",
            "hit": false
          },
          {
            "score": 0.5983523726463318,
            "answer": "gas",
            "hit": false
          },
          {
            "score": 0.588996171951294,
            "answer": "gases",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5742164999246597
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6383665800094604,
            "answer": "hairs",
            "hit": false
          },
          {
            "score": 0.63304603099823,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.6185044050216675,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6020041108131409,
            "answer": "eyebrows",
            "hit": false
          },
          {
            "score": 0.5958075523376465,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.5946927666664124,
            "answer": "wool",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6330460160970688
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.7635870575904846,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.6158388257026672,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.599950909614563,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5997167825698853,
            "answer": "head",
            "hit": false
          },
          {
            "score": 0.5996113419532776,
            "answer": "tissue",
            "hit": false
          },
          {
            "score": 0.5994294285774231,
            "answer": "torso",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5720221847295761
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7094897627830505,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.6901159286499023,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.6527711153030396,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.6331037878990173,
            "answer": "shoe",
            "hit": false
          },
          {
            "score": 0.630086362361908,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.6233465671539307,
            "answer": "leather",
            "hit": true
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.623346596956253
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8604215979576111,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.6548855304718018,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.627573549747467,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.6195563077926636,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.6138074398040771,
            "answer": "drinking",
            "hit": false
          },
          {
            "score": 0.610944926738739,
            "answer": "vodka",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.654885470867157
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.7788089513778687,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.6365216970443726,
            "answer": "cup",
            "hit": false
          },
          {
            "score": 0.6351553201675415,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6156838536262512,
            "answer": "flour",
            "hit": false
          },
          {
            "score": 0.6130567193031311,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.6046708226203918,
            "answer": "water",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6351552605628967
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.6912631392478943,
            "answer": "tails",
            "hit": false
          },
          {
            "score": 0.6477407217025757,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6443600654602051,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.6358356475830078,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6344432234764099,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.6236943006515503,
            "answer": "beverage",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5672558471560478
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6302571296691895,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.6217252016067505,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.6150659918785095,
            "answer": "chair",
            "hit": false
          },
          {
            "score": 0.6114773750305176,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.602177619934082,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.5972842574119568,
            "answer": "paper",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5453867800533772
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7121625542640686,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.6248379349708557,
            "answer": "silver",
            "hit": false
          },
          {
            "score": 0.6235969066619873,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.6052512526512146,
            "answer": "mineral",
            "hit": false
          },
          {
            "score": 0.6044296026229858,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.6032838225364685,
            "answer": "aluminum",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5664159655570984
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.6249140501022339,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.5923343896865845,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.5907671451568604,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.5803779363632202,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.577998697757721,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.575035572052002,
            "answer": "tagged",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 312,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5187993887811899
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.715344250202179,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6317648887634277,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6273134350776672,
            "answer": "cottage",
            "hit": false
          },
          {
            "score": 0.6089895963668823,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.606441855430603,
            "answer": "cellar",
            "hit": false
          },
          {
            "score": 0.6055494546890259,
            "answer": "home",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5455462969839573
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.591241717338562,
            "answer": "rock",
            "hit": false
          },
          {
            "score": 0.5847575664520264,
            "answer": "tal",
            "hit": false
          },
          {
            "score": 0.5835808515548706,
            "answer": "jamie",
            "hit": false
          },
          {
            "score": 0.5827284455299377,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.5823533535003662,
            "answer": "jelly",
            "hit": false
          },
          {
            "score": 0.5791899561882019,
            "answer": "juice",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 362,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5064527671784163
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.6266257762908936,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6259551048278809,
            "answer": "driveway",
            "hit": false
          },
          {
            "score": 0.6141960620880127,
            "answer": "backyard",
            "hit": false
          },
          {
            "score": 0.613828182220459,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.6113173961639404,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6081312894821167,
            "answer": "gardening",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.593601867556572
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8724927306175232,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.6442686319351196,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6364908814430237,
            "answer": "prism",
            "hit": false
          },
          {
            "score": 0.623677134513855,
            "answer": "optics",
            "hit": false
          },
          {
            "score": 0.6115949749946594,
            "answer": "aperture",
            "hit": false
          },
          {
            "score": 0.6096655130386353,
            "answer": "cameras",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.644268661737442
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.6778760552406311,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.6256634593009949,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6134377717971802,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5881065130233765,
            "answer": "guardian",
            "hit": false
          },
          {
            "score": 0.5852763056755066,
            "answer": "reflecting",
            "hit": false
          },
          {
            "score": 0.582400918006897,
            "answer": "paper",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6256634742021561
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6372896432876587,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.6328380703926086,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.6277923583984375,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6215394735336304,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.6142697334289551,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.6057183742523193,
            "answer": "financial",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5513500198721886
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.6687159538269043,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6219320297241211,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6165381669998169,
            "answer": "water",
            "hit": true
          },
          {
            "score": 0.6158513426780701,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6123602390289307,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.610435962677002,
            "answer": "atlantic",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6165381968021393
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.6823052167892456,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.6318483948707581,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.6236858367919922,
            "answer": "cakes",
            "hit": false
          },
          {
            "score": 0.6220883131027222,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.619748592376709,
            "answer": "flour",
            "hit": true
          },
          {
            "score": 0.6190714240074158,
            "answer": "leather",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.619748592376709
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.5970847606658936,
            "answer": "jenny",
            "hit": false
          },
          {
            "score": 0.5907108783721924,
            "answer": "sally",
            "hit": false
          },
          {
            "score": 0.5889459848403931,
            "answer": "lily",
            "hit": false
          },
          {
            "score": 0.5887497663497925,
            "answer": "jennifer",
            "hit": false
          },
          {
            "score": 0.5859790444374084,
            "answer": "karen",
            "hit": false
          },
          {
            "score": 0.585411548614502,
            "answer": "tobacco",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 89,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5622010380029678
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7201733589172363,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.6148471236228943,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6037749648094177,
            "answer": "medication",
            "hit": false
          },
          {
            "score": 0.5930473208427429,
            "answer": "medications",
            "hit": false
          },
          {
            "score": 0.5924825072288513,
            "answer": "tablets",
            "hit": false
          },
          {
            "score": 0.5908788442611694,
            "answer": "alcohol",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5655576065182686
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.6493065357208252,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6413777470588684,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.6199908256530762,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.6147518157958984,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.6129181385040283,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5958987474441528,
            "answer": "metals",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 57,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5553481355309486
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.5851073861122131,
            "answer": "water",
            "hit": true
          },
          {
            "score": 0.5754793882369995,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5737446546554565,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5668545961380005,
            "answer": "stone",
            "hit": false
          },
          {
            "score": 0.5668395161628723,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.5667283535003662,
            "answer": "foam",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5851073861122131
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6384450793266296,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6227738857269287,
            "answer": "syrup",
            "hit": false
          },
          {
            "score": 0.5990045666694641,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.5967696905136108,
            "answer": "bowl",
            "hit": false
          },
          {
            "score": 0.5932006239891052,
            "answer": "poured",
            "hit": false
          },
          {
            "score": 0.5913015604019165,
            "answer": "knife",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5399401262402534
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.6662144660949707,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6146368980407715,
            "answer": "figure",
            "hit": false
          },
          {
            "score": 0.6088879704475403,
            "answer": "fig",
            "hit": false
          },
          {
            "score": 0.6043483018875122,
            "answer": "tab",
            "hit": false
          },
          {
            "score": 0.5858131647109985,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5821851491928101,
            "answer": "columns",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 166,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5436447933316231
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6236140727996826,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.5990556478500366,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5765600204467773,
            "answer": "war",
            "hit": false
          },
          {
            "score": 0.5750606656074524,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.5692062377929688,
            "answer": "worms",
            "hit": false
          },
          {
            "score": 0.5675637125968933,
            "answer": "grapes",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5750606656074524
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.673171877861023,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.6182358264923096,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.611376166343689,
            "answer": "beers",
            "hit": false
          },
          {
            "score": 0.6087397336959839,
            "answer": "grape",
            "hit": true
          },
          {
            "score": 0.6080431342124939,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6058329939842224,
            "answer": "water",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6055730506777763
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.6734493970870972,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.6159459352493286,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.6117370128631592,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.6058583855628967,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.603034257888794,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5964165925979614,
            "answer": "wiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5858046114444733
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 28,
      "accuracy": 0.03571428571428571
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "032bb471-378f-41a3-8eb0-716eef58b438",
      "timestamp": "2025-05-18T10:34:21.916535"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.6726323962211609,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.5966639518737793,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.5874503254890442,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.5862964391708374,
            "answer": "species",
            "hit": false
          },
          {
            "score": 0.5855451822280884,
            "answer": "chick",
            "hit": false
          },
          {
            "score": 0.583871066570282,
            "answer": "ducks",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5771412402391434
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7601596117019653,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6184154748916626,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6118918657302856,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.5964556932449341,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.596001386642456,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.5893124341964722,
            "answer": "cattle",
            "hit": true
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5893124490976334
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.608350396156311,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.5925122499465942,
            "answer": "cas",
            "hit": false
          },
          {
            "score": 0.5861673355102539,
            "answer": "drivers",
            "hit": false
          },
          {
            "score": 0.5851846933364868,
            "answer": "can",
            "hit": false
          },
          {
            "score": 0.5788561701774597,
            "answer": "ferrari",
            "hit": false
          },
          {
            "score": 0.5788371562957764,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 384,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5376339480280876
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.726563572883606,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7121112942695618,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7026500701904297,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6810715198516846,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.667702317237854,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6537896990776062,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6810715347528458
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.7753073573112488,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.736501932144165,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.6667047142982483,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.6626901626586914,
            "answer": "religious",
            "hit": false
          },
          {
            "score": 0.6524925827980042,
            "answer": "church",
            "hit": true
          },
          {
            "score": 0.6516740322113037,
            "answer": "gospel",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5811573266983032
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.7294836044311523,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7187309265136719,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6725398302078247,
            "answer": "university",
            "hit": true
          },
          {
            "score": 0.6473333835601807,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.6417374610900879,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.632145345211029,
            "answer": "academy",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6725398600101471
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.6758673191070557,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.5979007482528687,
            "answer": "state",
            "hit": true
          },
          {
            "score": 0.5966527462005615,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.5951224565505981,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.5923722982406616,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.5900856256484985,
            "answer": "borough",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.597900778055191
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.62721848487854,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6028123497962952,
            "answer": "cowboys",
            "hit": false
          },
          {
            "score": 0.5974398851394653,
            "answer": "bow",
            "hit": false
          },
          {
            "score": 0.5966916084289551,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.5904940962791443,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.58709716796875,
            "answer": "herd",
            "hit": true
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5870971530675888
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.6371328234672546,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.6182170510292053,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.6034389138221741,
            "answer": "row",
            "hit": false
          },
          {
            "score": 0.6021925210952759,
            "answer": "crowds",
            "hit": false
          },
          {
            "score": 0.5952275991439819,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.5824933648109436,
            "answer": "staff",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 13038,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4772471506148577
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8309511542320251,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6233770251274109,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.6230549216270447,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.6201895475387573,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.6148107051849365,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6055514216423035,
            "answer": "monkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6148107498884201
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.7138407826423645,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.6476683616638184,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.6401160955429077,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.6268481016159058,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.6245242357254028,
            "answer": "staff",
            "hit": true
          },
          {
            "score": 0.6239632964134216,
            "answer": "employers",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.624524250626564
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.5845193266868591,
            "answer": "mal",
            "hit": false
          },
          {
            "score": 0.5837838649749756,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.58103346824646,
            "answer": "stained",
            "hit": false
          },
          {
            "score": 0.5809087157249451,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.5709058046340942,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.5703827142715454,
            "answer": "enrichment",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 6657,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5032729031518102
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8623801469802856,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.6447826623916626,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.6304820775985718,
            "answer": "universe",
            "hit": true
          },
          {
            "score": 0.6280903816223145,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.6106614470481873,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.6041610240936279,
            "answer": "cosmic",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6304820626974106
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.5993815064430237,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.5796844363212585,
            "answer": "iteration",
            "hit": false
          },
          {
            "score": 0.568166971206665,
            "answer": "literature",
            "hit": false
          },
          {
            "score": 0.5679792165756226,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.5665204524993896,
            "answer": "orchestra",
            "hit": false
          },
          {
            "score": 0.566409170627594,
            "answer": "newsletter",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 188,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5383777394890785
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.6423215866088867,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.6215155720710754,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.5981451272964478,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.5907760262489319,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.5853557586669922,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.5848538279533386,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 108,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.553250577300787
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.6389768719673157,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6347282528877258,
            "answer": "handler",
            "hit": false
          },
          {
            "score": 0.6016669273376465,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.5981854796409607,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.5833491086959839,
            "answer": "observer",
            "hit": false
          },
          {
            "score": 0.583283007144928,
            "answer": "enabled",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5697903037071228
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.6874272227287292,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6291221380233765,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.5880503058433533,
            "answer": "staff",
            "hit": false
          },
          {
            "score": 0.5872851014137268,
            "answer": "team",
            "hit": true
          },
          {
            "score": 0.5790690183639526,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.5762481093406677,
            "answer": "partner",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5557818599045277
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8092768788337708,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.7031244039535522,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.6961592435836792,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.6909517049789429,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.671668529510498,
            "answer": "musical",
            "hit": false
          },
          {
            "score": 0.6710014939308167,
            "answer": "drummer",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6260752826929092
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7555206418037415,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7277941703796387,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.6539419889450073,
            "answer": "individuals",
            "hit": false
          },
          {
            "score": 0.6531105041503906,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.6467610597610474,
            "answer": "persona",
            "hit": false
          },
          {
            "score": 0.625716507434845,
            "answer": "everyone",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5325144231319427
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.646220326423645,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.6347444653511047,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.6326602101325989,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.6194657683372498,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.6183342337608337,
            "answer": "picture",
            "hit": false
          },
          {
            "score": 0.6177838444709778,
            "answer": "photographer",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 451,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5383924506604671
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.6784493327140808,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.6286706328392029,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.6043393015861511,
            "answer": "play",
            "hit": false
          },
          {
            "score": 0.602390706539154,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.6020870208740234,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.5944271087646484,
            "answer": "gameplay",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5850407108664513
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.6888250708580017,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.6804713010787964,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.6604145169258118,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6363904476165771,
            "answer": "bureaucracy",
            "hit": false
          },
          {
            "score": 0.6347975134849548,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.6345173120498657,
            "answer": "cop",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.680471271276474
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.641920804977417,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.6376598477363586,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.6269152164459229,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.620787501335144,
            "answer": "ministers",
            "hit": false
          },
          {
            "score": 0.6195053458213806,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6157811880111694,
            "answer": "chancellor",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 166,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5583077855408192
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.7494081258773804,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.7216354608535767,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7075825333595276,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.7065585851669312,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.6477797627449036,
            "answer": "congressional",
            "hit": false
          },
          {
            "score": 0.6345641613006592,
            "answer": "legislators",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7216354310512543
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.6847279667854309,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.6804468035697937,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.6715402007102966,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6609593629837036,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6609385013580322,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.6477462649345398,
            "answer": "cows",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.606504499912262
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8354873061180115,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.6754221320152283,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.6627411246299744,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.6595072746276855,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.6575590372085571,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.6466132998466492,
            "answer": "warriors",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6627411246299744
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.70233154296875,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6778464317321777,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.6638110280036926,
            "answer": "partner",
            "hit": false
          },
          {
            "score": 0.6533541083335876,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.6501277685165405,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.6411526203155518,
            "answer": "husbands",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5570691674947739
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.6055290102958679,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.5943058729171753,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.5939309597015381,
            "answer": "commonwealth",
            "hit": false
          },
          {
            "score": 0.591809093952179,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.5886262059211731,
            "answer": "wealth",
            "hit": false
          },
          {
            "score": 0.5792662501335144,
            "answer": "legislature",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 228,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.521199831739068
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.7465240955352783,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.6455518007278442,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.6330270171165466,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.6310402750968933,
            "answer": "school",
            "hit": true
          },
          {
            "score": 0.630039632320404,
            "answer": "classmates",
            "hit": false
          },
          {
            "score": 0.622195303440094,
            "answer": "schools",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5525883659720421
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.7265965938568115,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.6151610016822815,
            "answer": "rees",
            "hit": false
          },
          {
            "score": 0.6060439944267273,
            "answer": "hierarchy",
            "hit": false
          },
          {
            "score": 0.5892176628112793,
            "answer": "heap",
            "hit": false
          },
          {
            "score": 0.5840504765510559,
            "answer": "plants",
            "hit": false
          },
          {
            "score": 0.5820010900497437,
            "answer": "forest",
            "hit": true
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.582001082599163
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.6240630149841309,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6019643545150757,
            "answer": "wild",
            "hit": false
          },
          {
            "score": 0.6011819243431091,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.589430570602417,
            "answer": "hughes",
            "hit": false
          },
          {
            "score": 0.5880954265594482,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.585098385810852,
            "answer": "rosen",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 543,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5398178547620773
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.6747207045555115,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.6105126142501831,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.5992721319198608,
            "answer": "term",
            "hit": false
          },
          {
            "score": 0.5965599417686462,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.5886303782463074,
            "answer": "sentence",
            "hit": true
          },
          {
            "score": 0.5858992338180542,
            "answer": "writing",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5407974496483803
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 32,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0c1173a0-5bb3-42e5-b1a7-7dd48b438ebe",
      "timestamp": "2025-05-18T10:34:22.030427"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.6693644523620605,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.6650060415267944,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6314412355422974,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.61616450548172,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.5742582082748413,
            "answer": "pins",
            "hit": false
          },
          {
            "score": 0.5702200531959534,
            "answer": "tram",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 61,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5347702950239182
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.6928116083145142,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.6636466979980469,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6608637571334839,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6189492344856262,
            "answer": "seat",
            "hit": false
          },
          {
            "score": 0.6186102628707886,
            "answer": "tooth",
            "hit": false
          },
          {
            "score": 0.6022791862487793,
            "answer": "cent",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5862574130296707
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.6380472183227539,
            "answer": "combination",
            "hit": false
          },
          {
            "score": 0.6316872239112854,
            "answer": "combined",
            "hit": false
          },
          {
            "score": 0.62729811668396,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.626103937625885,
            "answer": "combining",
            "hit": false
          },
          {
            "score": 0.6247012615203857,
            "answer": "combines",
            "hit": false
          },
          {
            "score": 0.6212435960769653,
            "answer": "seats",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 360,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5148202823475003
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.718456506729126,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6524271965026855,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6483672857284546,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6478224396705627,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6333877444267273,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6232970952987671,
            "answer": "seat",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 979,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5348862409591675
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0af513b3-93e9-43fb-92ed-ba927e63a904",
      "timestamp": "2025-05-18T10:34:22.169479"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.7175282835960388,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.7119169235229492,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.669166088104248,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.6512776017189026,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.6300966143608093,
            "answer": "pleased",
            "hit": false
          },
          {
            "score": 0.6287385821342468,
            "answer": "exhausted",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6106636077165604
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.7007279396057129,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6277645826339722,
            "answer": "cottage",
            "hit": false
          },
          {
            "score": 0.6083444356918335,
            "answer": "horse",
            "hit": false
          },
          {
            "score": 0.6023067831993103,
            "answer": "cellar",
            "hit": false
          },
          {
            "score": 0.602015495300293,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.5983402729034424,
            "answer": "warehouse",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5781750530004501
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7640226483345032,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7109857797622681,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.6784626245498657,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.642654299736023,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6233642101287842,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6092793941497803,
            "answer": "waters",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.467068076133728
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.6970791816711426,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.6960160732269287,
            "answer": "pains",
            "hit": false
          },
          {
            "score": 0.6484389901161194,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.6429711580276489,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.6418658494949341,
            "answer": "headache",
            "hit": false
          },
          {
            "score": 0.6245070695877075,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5884327068924904
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.6079851984977722,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.604448139667511,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.5946823954582214,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.5881283283233643,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.5848751068115234,
            "answer": "saddle",
            "hit": false
          },
          {
            "score": 0.5821728706359863,
            "answer": "elephants",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6044481247663498
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.5713916420936584,
            "answer": "torment",
            "hit": false
          },
          {
            "score": 0.5681262016296387,
            "answer": "ara",
            "hit": false
          },
          {
            "score": 0.5664039850234985,
            "answer": "palace",
            "hit": false
          },
          {
            "score": 0.5646423697471619,
            "answer": "criteria",
            "hit": false
          },
          {
            "score": 0.563202977180481,
            "answer": "analyses",
            "hit": false
          },
          {
            "score": 0.5625083446502686,
            "answer": "unchanged",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 3595,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5137541200965643
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.7768160700798035,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.630817174911499,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.6248010396957397,
            "answer": "lunch",
            "hit": false
          },
          {
            "score": 0.6163967251777649,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.6077024936676025,
            "answer": "candy",
            "hit": false
          },
          {
            "score": 0.6065737009048462,
            "answer": "sandwiches",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.596568651497364
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.7213568687438965,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.6707811951637268,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.6312589049339294,
            "answer": "sleepy",
            "hit": false
          },
          {
            "score": 0.6149376034736633,
            "answer": "sick",
            "hit": false
          },
          {
            "score": 0.6117255687713623,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.6112566590309143,
            "answer": "agitated",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6707812249660492
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 8,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5f49aa7d-ec07-4ede-b69e-39491606d95f",
      "timestamp": "2025-05-18T10:34:22.185001"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8207408785820007,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.7782729268074036,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7012308835983276,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.6988973617553711,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.6797452569007874,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.6447610259056091,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8207409083843231
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.6473053693771362,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.6315096616744995,
            "answer": "clothes",
            "hit": false
          },
          {
            "score": 0.6280356645584106,
            "answer": "clothing",
            "hit": false
          },
          {
            "score": 0.6235172748565674,
            "answer": "wool",
            "hit": false
          },
          {
            "score": 0.6105804443359375,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.6105263829231262,
            "answer": "blankets",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5641947537660599
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.7614856362342834,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7049611210823059,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.654731035232544,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.6490080952644348,
            "answer": "euros",
            "hit": false
          },
          {
            "score": 0.6327250003814697,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.6248385310173035,
            "answer": "money",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7049611061811447
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.670056939125061,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6565887928009033,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.6429795026779175,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.6259230375289917,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.6237992644309998,
            "answer": "papa",
            "hit": false
          },
          {
            "score": 0.6166847944259644,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6429795026779175
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7396783232688904,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7091100215911865,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.7063822746276855,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.6223427057266235,
            "answer": "assist",
            "hit": true
          },
          {
            "score": 0.6184794902801514,
            "answer": "assisting",
            "hit": false
          },
          {
            "score": 0.6171044111251831,
            "answer": "helpful",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5229870788753033
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.6603180766105652,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.6511667966842651,
            "answer": "smart",
            "hit": true
          },
          {
            "score": 0.6355220675468445,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.6306668519973755,
            "answer": "intelligence",
            "hit": false
          },
          {
            "score": 0.6205156445503235,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.6178903579711914,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6355221122503281
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7349553108215332,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.6303170323371887,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.6077345609664917,
            "answer": "gem",
            "hit": true
          },
          {
            "score": 0.5984969735145569,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.5941550135612488,
            "answer": "treasures",
            "hit": false
          },
          {
            "score": 0.5938527584075928,
            "answer": "necklace",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6077345758676529
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.7979463338851929,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.6507372260093689,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.6465812921524048,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.6420643329620361,
            "answer": "statues",
            "hit": false
          },
          {
            "score": 0.6223189234733582,
            "answer": "tomb",
            "hit": false
          },
          {
            "score": 0.6114647388458252,
            "answer": "sculpture",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6507372260093689
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.6310110092163086,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.628978431224823,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.6272997856140137,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.5971366167068481,
            "answer": "fresh",
            "hit": false
          },
          {
            "score": 0.5894514322280884,
            "answer": "latest",
            "hit": false
          },
          {
            "score": 0.5866609811782837,
            "answer": "other",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5505404695868492
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.728285551071167,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.6263608932495117,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.612004280090332,
            "answer": "pack",
            "hit": true
          },
          {
            "score": 0.6019706726074219,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.5813501477241516,
            "answer": "modules",
            "hit": false
          },
          {
            "score": 0.5754413604736328,
            "answer": "program",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5412192791700363
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.7599661350250244,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.6531252861022949,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.6454704999923706,
            "answer": "subway",
            "hit": false
          },
          {
            "score": 0.6233158111572266,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.6211348176002502,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.6132389903068542,
            "answer": "airline",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7599661350250244
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.7081573009490967,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.6296902894973755,
            "answer": "reasonable",
            "hit": true
          },
          {
            "score": 0.6190279126167297,
            "answer": "reasoned",
            "hit": false
          },
          {
            "score": 0.6163574457168579,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.6051488518714905,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.6043739914894104,
            "answer": "justified",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6010140031576157
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.7719898223876953,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7449015974998474,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.6343749761581421,
            "answer": "rational",
            "hit": false
          },
          {
            "score": 0.6332415342330933,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6282933950424194,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.6252990365028381,
            "answer": "realistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6076091006398201
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.6536567211151123,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.6243996620178223,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6042475700378418,
            "answer": "brock",
            "hit": false
          },
          {
            "score": 0.5922886729240417,
            "answer": "punk",
            "hit": false
          },
          {
            "score": 0.5818817615509033,
            "answer": "rocky",
            "hit": false
          },
          {
            "score": 0.5813556909561157,
            "answer": "groove",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5604696124792099
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.7262753844261169,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.6567049622535706,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.6454221606254578,
            "answer": "chair",
            "hit": false
          },
          {
            "score": 0.6439943909645081,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.6311398148536682,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.6251988410949707,
            "answer": "carpet",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7262753695249557
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.7257747650146484,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.6451682448387146,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.6188423037528992,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.5916151404380798,
            "answer": "fashion",
            "hit": true
          },
          {
            "score": 0.5871094465255737,
            "answer": "color",
            "hit": false
          },
          {
            "score": 0.5860320925712585,
            "answer": "shape",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5568746216595173
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "23d17eac-ac26-40ee-bf84-e5f374758b50",
      "timestamp": "2025-05-18T10:34:22.217617"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.6597859263420105,
            "answer": "afterwards",
            "hit": false
          },
          {
            "score": 0.6411464810371399,
            "answer": "upon",
            "hit": false
          },
          {
            "score": 0.6304437518119812,
            "answer": "subsequently",
            "hit": false
          },
          {
            "score": 0.6281895041465759,
            "answer": "once",
            "hit": false
          },
          {
            "score": 0.623755693435669,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.6223275065422058,
            "answer": "before",
            "hit": true
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6223275065422058
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.6255027055740356,
            "answer": "front",
            "hit": false
          },
          {
            "score": 0.6067570447921753,
            "answer": "forward",
            "hit": false
          },
          {
            "score": 0.602496325969696,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.596565842628479,
            "answer": "alongside",
            "hit": false
          },
          {
            "score": 0.5929769277572632,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.5928528904914856,
            "answer": "around",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.602496325969696
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.7577951550483704,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.6632670760154724,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.6434069871902466,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.6190638542175293,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.6187865138053894,
            "answer": "anatomical",
            "hit": false
          },
          {
            "score": 0.6185521483421326,
            "answer": "inferior",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7577951848506927
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.6365094184875488,
            "answer": "until",
            "hit": false
          },
          {
            "score": 0.6344097852706909,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.6269164085388184,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.6018710136413574,
            "answer": "without",
            "hit": false
          },
          {
            "score": 0.5982146859169006,
            "answer": "outside",
            "hit": false
          },
          {
            "score": 0.5942102074623108,
            "answer": "from",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6344097852706909
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7369647026062012,
            "answer": "starting",
            "hit": false
          },
          {
            "score": 0.6844430565834045,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.6716567277908325,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.6630164384841919,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.6499431133270264,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.6274064183235168,
            "answer": "commencement",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5811162441968918
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.622824490070343,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.6203418970108032,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.6189106702804565,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.6148685216903687,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.6113624572753906,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6052219867706299,
            "answer": "killing",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5892579033970833
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.7930278778076172,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.6529234647750854,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.6082448363304138,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.605998694896698,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.5965653657913208,
            "answer": "diver",
            "hit": false
          },
          {
            "score": 0.5956566333770752,
            "answer": "jumps",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 2010,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5245466530323029
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.8055873513221741,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.786041259765625,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.7659173607826233,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7077094316482544,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.672005295753479,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.6339162588119507,
            "answer": "collapse",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6032417267560959
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7194963097572327,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.6548200249671936,
            "answer": "third",
            "hit": false
          },
          {
            "score": 0.6294715404510498,
            "answer": "last",
            "hit": true
          },
          {
            "score": 0.611359715461731,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.6085125207901001,
            "answer": "secondly",
            "hit": false
          },
          {
            "score": 0.6076033115386963,
            "answer": "ninth",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6294715255498886
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.6524391174316406,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.6003612279891968,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.5779505968093872,
            "answer": "feedback",
            "hit": false
          },
          {
            "score": 0.5770814418792725,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.5761599540710449,
            "answer": "options",
            "hit": false
          },
          {
            "score": 0.5752185583114624,
            "answer": "images",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6003612130880356
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7142404913902283,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.689713716506958,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.6709425449371338,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.6276645064353943,
            "answer": "behind",
            "hit": false
          },
          {
            "score": 0.625204861164093,
            "answer": "indoors",
            "hit": false
          },
          {
            "score": 0.6223349571228027,
            "answer": "atop",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7142404913902283
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.653892993927002,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.6398041844367981,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.6127995252609253,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.6036747097969055,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.5907694697380066,
            "answer": "public",
            "hit": false
          },
          {
            "score": 0.5891638398170471,
            "answer": "externally",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6127995327115059
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.606589674949646,
            "answer": "deadly",
            "hit": false
          },
          {
            "score": 0.600951611995697,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.6000367403030396,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.5958085060119629,
            "answer": "assassin",
            "hit": false
          },
          {
            "score": 0.5930308699607849,
            "answer": "soul",
            "hit": false
          },
          {
            "score": 0.5930092334747314,
            "answer": "mort",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6009515896439552
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.7148833274841309,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7083739042282104,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.6872223019599915,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.6787301301956177,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.6364710927009583,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.634456992149353,
            "answer": "inhabited",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6272480487823486
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.6926282644271851,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.6020323634147644,
            "answer": "covered",
            "hit": false
          },
          {
            "score": 0.5889085531234741,
            "answer": "out",
            "hit": false
          },
          {
            "score": 0.5884060263633728,
            "answer": "cover",
            "hit": false
          },
          {
            "score": 0.5822612643241882,
            "answer": "off",
            "hit": false
          },
          {
            "score": 0.5791115760803223,
            "answer": "covers",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 38,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5558351427316666
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.6888386011123657,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6466083526611328,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.645053505897522,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.6335817575454712,
            "answer": "currently",
            "hit": false
          },
          {
            "score": 0.6331949830055237,
            "answer": "recently",
            "hit": false
          },
          {
            "score": 0.6285710334777832,
            "answer": "subsequently",
            "hit": true
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6285710036754608
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8139349222183228,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7428107261657715,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7284548282623291,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.6440275311470032,
            "answer": "proceedings",
            "hit": false
          },
          {
            "score": 0.6215059757232666,
            "answer": "progressing",
            "hit": false
          },
          {
            "score": 0.6180722117424011,
            "answer": "progressed",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 344,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.548278447240591
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.8313436508178711,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7871572971343994,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.76651930809021,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.6577433943748474,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.655288577079773,
            "answer": "decline",
            "hit": false
          },
          {
            "score": 0.640296220779419,
            "answer": "arise",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5455751717090607
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.8112438321113586,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.683944582939148,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.6441430449485779,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.6263397932052612,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.6235668659210205,
            "answer": "west",
            "hit": false
          },
          {
            "score": 0.6046097874641418,
            "answer": "northern",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8112438321113586
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.7090668678283691,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.6697940826416016,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.6650152206420898,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.6521886587142944,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.6229596138000488,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.6015239357948303,
            "answer": "midwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.669794112443924
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.8561322689056396,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.6287192702293396,
            "answer": "approaching",
            "hit": false
          },
          {
            "score": 0.6276965141296387,
            "answer": "against",
            "hit": false
          },
          {
            "score": 0.6169544458389282,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6061105132102966,
            "answer": "recognizing",
            "hit": false
          },
          {
            "score": 0.6045652627944946,
            "answer": "favors",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 185,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5405913218855858
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.6169446110725403,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.5981974005699158,
            "answer": "yes",
            "hit": false
          },
          {
            "score": 0.5655924677848816,
            "answer": "absolute",
            "hit": false
          },
          {
            "score": 0.564880907535553,
            "answer": "test",
            "hit": false
          },
          {
            "score": 0.5648453235626221,
            "answer": "tidy",
            "hit": false
          },
          {
            "score": 0.5635883212089539,
            "answer": "condition",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6169446185231209
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.6952901482582092,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.6634572744369507,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.6587064862251282,
            "answer": "western",
            "hit": false
          },
          {
            "score": 0.6389904022216797,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.6349570155143738,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.6346467137336731,
            "answer": "south",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6952901482582092
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 23,
      "accuracy": 0.2608695652173913
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "be87f9b1-6441-46fe-b9d1-b0618f34055b",
      "timestamp": "2025-05-18T10:34:22.278921"
    }
  }
]