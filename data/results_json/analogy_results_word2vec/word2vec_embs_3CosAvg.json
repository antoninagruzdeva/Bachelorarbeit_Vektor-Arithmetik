[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.9203090071678162,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.8556221723556519,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.8139103651046753,
            "answer": "song",
            "hit": false
          },
          {
            "score": 0.7769106030464172,
            "answer": "tunes",
            "hit": false
          },
          {
            "score": 0.7744803428649902,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.7680177688598633,
            "answer": "band",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9203089773654938
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.8851804733276367,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.7578008770942688,
            "answer": "applicant",
            "hit": false
          },
          {
            "score": 0.7371803522109985,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.736038088798523,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.733695387840271,
            "answer": "submissions",
            "hit": false
          },
          {
            "score": 0.7295388579368591,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8851804733276367
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.8800735473632812,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.7940731048583984,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7814825177192688,
            "answer": "region",
            "hit": false
          },
          {
            "score": 0.7707247734069824,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.7655954360961914,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.7514672875404358,
            "answer": "places",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8800735175609589
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.8925191760063171,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.8728637099266052,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.8347006440162659,
            "answer": "suv",
            "hit": false
          },
          {
            "score": 0.8281494975090027,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.8203479647636414,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.8071858882904053,
            "answer": "sedan",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8925192058086395
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.853005588054657,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.7845298051834106,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7800653576850891,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7605564594268799,
            "answer": "graduation",
            "hit": false
          },
          {
            "score": 0.7535387277603149,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7521756887435913,
            "answer": "universities",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8530056178569794
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.7945998907089233,
            "answer": "commission",
            "hit": false
          },
          {
            "score": 0.7917124629020691,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7403583526611328,
            "answer": "chamber",
            "hit": false
          },
          {
            "score": 0.7391077280044556,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.7330695390701294,
            "answer": "association",
            "hit": false
          },
          {
            "score": 0.7273008823394775,
            "answer": "committees",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7917124927043915
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8901882171630859,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.7998682260513306,
            "answer": "clients",
            "hit": false
          },
          {
            "score": 0.7581415772438049,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.7555029988288879,
            "answer": "client",
            "hit": false
          },
          {
            "score": 0.7420343160629272,
            "answer": "suppliers",
            "hit": false
          },
          {
            "score": 0.7376289367675781,
            "answer": "consumer",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8901882469654083
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.8391702175140381,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.8052464723587036,
            "answer": "hours",
            "hit": false
          },
          {
            "score": 0.7992750406265259,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7819349765777588,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7654650211334229,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.765158474445343,
            "answer": "weeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8391701877117157
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.829062283039093,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.8023720383644104,
            "answer": "murder",
            "hit": false
          },
          {
            "score": 0.770922064781189,
            "answer": "fatal",
            "hit": false
          },
          {
            "score": 0.7704577445983887,
            "answer": "killing",
            "hit": false
          },
          {
            "score": 0.7674023509025574,
            "answer": "murders",
            "hit": false
          },
          {
            "score": 0.7662358283996582,
            "answer": "murdered",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8290623128414154
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.7839513421058655,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.7768247127532959,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.7745333909988403,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.7379943132400513,
            "answer": "commission",
            "hit": false
          },
          {
            "score": 0.7310312390327454,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.723068356513977,
            "answer": "secretary",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7839513421058655
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7807514667510986,
            "answer": "projects",
            "hit": false
          },
          {
            "score": 0.7743314504623413,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7657432556152344,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.7636723518371582,
            "answer": "advancement",
            "hit": false
          },
          {
            "score": 0.7565068006515503,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7449630498886108,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7657432556152344
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.791495144367218,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7241137623786926,
            "answer": "gap",
            "hit": false
          },
          {
            "score": 0.7226586937904358,
            "answer": "similarities",
            "hit": false
          },
          {
            "score": 0.712675154209137,
            "answer": "correlation",
            "hit": false
          },
          {
            "score": 0.7115180492401123,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7106447219848633,
            "answer": "changes",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.791495144367218
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8409926295280457,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.8226438164710999,
            "answer": "executive",
            "hit": false
          },
          {
            "score": 0.8052672147750854,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.784461259841919,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.7717045545578003,
            "answer": "administrator",
            "hit": false
          },
          {
            "score": 0.7715076804161072,
            "answer": "associate",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7191755771636963
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.8758904337882996,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.759138822555542,
            "answer": "festival",
            "hit": false
          },
          {
            "score": 0.73818439245224,
            "answer": "gatherings",
            "hit": false
          },
          {
            "score": 0.7370953559875488,
            "answer": "celebration",
            "hit": false
          },
          {
            "score": 0.735295295715332,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7332131862640381,
            "answer": "competitions",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.875890463590622
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8752948045730591,
            "answer": "instance",
            "hit": false
          },
          {
            "score": 0.842461884021759,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.7435061931610107,
            "answer": "illustration",
            "hit": false
          },
          {
            "score": 0.7149235606193542,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.713438868522644,
            "answer": "reason",
            "hit": false
          },
          {
            "score": 0.7084947824478149,
            "answer": "reasons",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8424618542194366
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7489722967147827,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.7254104018211365,
            "answer": "actually",
            "hit": false
          },
          {
            "score": 0.7194353342056274,
            "answer": "that",
            "hit": false
          },
          {
            "score": 0.7158763408660889,
            "answer": "though",
            "hit": false
          },
          {
            "score": 0.711976170539856,
            "answer": "indeed",
            "hit": false
          },
          {
            "score": 0.7077171802520752,
            "answer": "evidently",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6942297965288162
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.8750274181365967,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.8601161241531372,
            "answer": "pal",
            "hit": false
          },
          {
            "score": 0.8328835964202881,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.817112922668457,
            "answer": "acquaintance",
            "hit": false
          },
          {
            "score": 0.8151386976242065,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7961516976356506,
            "answer": "colleague",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8750273883342743
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.8457019329071045,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.814001739025116,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.810548722743988,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.8069087862968445,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7935118079185486,
            "answer": "scripture",
            "hit": false
          },
          {
            "score": 0.78349769115448,
            "answer": "prophets",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7589036524295807
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8559257388114929,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.7778483629226685,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7549244165420532,
            "answer": "administration",
            "hit": false
          },
          {
            "score": 0.7549190521240234,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.7547082901000977,
            "answer": "parliament",
            "hit": false
          },
          {
            "score": 0.7428116202354431,
            "answer": "legislators",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8559257388114929
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.8844046592712402,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.8276513814926147,
            "answer": "minutes",
            "hit": false
          },
          {
            "score": 0.7869243621826172,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.7670989632606506,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.7371237277984619,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.7310777902603149,
            "answer": "miles",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8844046592712402
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.8257348537445068,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.8212224841117859,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.819477379322052,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7829234600067139,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.7714629173278809,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7540932297706604,
            "answer": "theories",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8257348537445068
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.8439340591430664,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.7870834469795227,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7791184186935425,
            "answer": "dialect",
            "hit": false
          },
          {
            "score": 0.7698091268539429,
            "answer": "translations",
            "hit": false
          },
          {
            "score": 0.7690475583076477,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7611656188964844,
            "answer": "vocabulary",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8439340889453888
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.8821995258331299,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.8543548583984375,
            "answer": "statutes",
            "hit": false
          },
          {
            "score": 0.8230835199356079,
            "answer": "statute",
            "hit": false
          },
          {
            "score": 0.7802470922470093,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.7723518013954163,
            "answer": "regulations",
            "hit": false
          },
          {
            "score": 0.7644671201705933,
            "answer": "rules",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8821995258331299
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.8920673131942749,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7577399015426636,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.7420773506164551,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7358258962631226,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.7353857755661011,
            "answer": "chair",
            "hit": false
          },
          {
            "score": 0.7198765277862549,
            "answer": "founding",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8920672833919525
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8987362384796143,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.8610711693763733,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.8541561961174011,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.8510403037071228,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.8162493705749512,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.7955299615859985,
            "answer": "february",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8610712289810181
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.881026566028595,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.8555551767349243,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.8327988386154175,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.804774284362793,
            "answer": "saturday",
            "hit": false
          },
          {
            "score": 0.8010125160217285,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7918187975883484,
            "answer": "tonight",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8555552065372467
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.8546925783157349,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7375945448875427,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.7363475561141968,
            "answer": "headquarters",
            "hit": false
          },
          {
            "score": 0.716027021408081,
            "answer": "branch",
            "hit": false
          },
          {
            "score": 0.7016324996948242,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.6924642324447632,
            "answer": "departments",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8546926081180573
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8932766318321228,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7328684329986572,
            "answer": "quarter",
            "hit": false
          },
          {
            "score": 0.7259426116943359,
            "answer": "quarters",
            "hit": false
          },
          {
            "score": 0.7235082387924194,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7117825746536255,
            "answer": "span",
            "hit": false
          },
          {
            "score": 0.7117017507553101,
            "answer": "time",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8932766318321228
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.8924970626831055,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7653874158859253,
            "answer": "footballer",
            "hit": false
          },
          {
            "score": 0.7571294903755188,
            "answer": "league",
            "hit": false
          },
          {
            "score": 0.7559759616851807,
            "answer": "athlete",
            "hit": false
          },
          {
            "score": 0.7473654747009277,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7442227602005005,
            "answer": "teammate",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8924970924854279
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8969928026199341,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.786899209022522,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.7450953722000122,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.7316246628761292,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.7306769490242004,
            "answer": "prevalence",
            "hit": false
          },
          {
            "score": 0.7305004596710205,
            "answer": "census",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8969928026199341
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.9104350209236145,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7993165254592896,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.7808874845504761,
            "answer": "difficulties",
            "hit": false
          },
          {
            "score": 0.7805225849151611,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7625821828842163,
            "answer": "issue",
            "hit": false
          },
          {
            "score": 0.7587300539016724,
            "answer": "trouble",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9104349911212921
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.9020488858222961,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.7622148990631104,
            "answer": "brands",
            "hit": false
          },
          {
            "score": 0.7485669851303101,
            "answer": "offerings",
            "hit": false
          },
          {
            "score": 0.7400089502334595,
            "answer": "brand",
            "hit": false
          },
          {
            "score": 0.7366703152656555,
            "answer": "technologies",
            "hit": false
          },
          {
            "score": 0.7302498817443848,
            "answer": "customers",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9020489454269409
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.8602888584136963,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.7347729206085205,
            "answer": "minerals",
            "hit": false
          },
          {
            "score": 0.7157715559005737,
            "answer": "mineral",
            "hit": false
          },
          {
            "score": 0.7122200131416321,
            "answer": "mining",
            "hit": false
          },
          {
            "score": 0.7078502178192139,
            "answer": "tools",
            "hit": false
          },
          {
            "score": 0.6983200311660767,
            "answer": "exploration",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8602887988090515
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.8333545923233032,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.8194422125816345,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.8021400570869446,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7969226837158203,
            "answer": "valley",
            "hit": false
          },
          {
            "score": 0.7667904496192932,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.756809651851654,
            "answer": "basin",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8333545625209808
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8354403972625732,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7967949509620667,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.7814387083053589,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7526634335517883,
            "answer": "lanes",
            "hit": false
          },
          {
            "score": 0.746546745300293,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.7368601560592651,
            "answer": "pavement",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8354403972625732
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.9131659269332886,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7604817152023315,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7326979637145996,
            "answer": "integral",
            "hit": false
          },
          {
            "score": 0.7260662913322449,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.7128833532333374,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.7123463153839111,
            "answer": "duties",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9131659865379333
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8178543448448181,
            "answer": "biology",
            "hit": false
          },
          {
            "score": 0.8178352117538452,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.8000267744064331,
            "answer": "mathematics",
            "hit": false
          },
          {
            "score": 0.7814821600914001,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.7755934000015259,
            "answer": "astronomy",
            "hit": false
          },
          {
            "score": 0.7607898712158203,
            "answer": "scientists",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7030931562185287
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.894682765007019,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7437292337417603,
            "answer": "alternatives",
            "hit": false
          },
          {
            "score": 0.7396844625473022,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.7269790172576904,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.7263442277908325,
            "answer": "remedy",
            "hit": false
          },
          {
            "score": 0.7189021110534668,
            "answer": "systems",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8946827054023743
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.9453595280647278,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.8800912499427795,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.8734050393104553,
            "answer": "tunes",
            "hit": false
          },
          {
            "score": 0.8405181765556335,
            "answer": "anthem",
            "hit": false
          },
          {
            "score": 0.8354929685592651,
            "answer": "album",
            "hit": false
          },
          {
            "score": 0.832282543182373,
            "answer": "melody",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9453595876693726
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.9037926197052002,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.8083851337432861,
            "answer": "ave",
            "hit": false
          },
          {
            "score": 0.7941937446594238,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.782654881477356,
            "answer": "avenues",
            "hit": false
          },
          {
            "score": 0.7814545631408691,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.7550841569900513,
            "answer": "intersection",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7941937744617462
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8867028951644897,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.8161437511444092,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.8047393560409546,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7947466969490051,
            "answer": "classmates",
            "hit": false
          },
          {
            "score": 0.7903566360473633,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.7895734906196594,
            "answer": "school",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8867028951644897
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.8925674557685852,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.7408331632614136,
            "answer": "mechanism",
            "hit": false
          },
          {
            "score": 0.7389371395111084,
            "answer": "mechanisms",
            "hit": false
          },
          {
            "score": 0.7229663133621216,
            "answer": "centralized",
            "hit": false
          },
          {
            "score": 0.722537636756897,
            "answer": "processes",
            "hit": false
          },
          {
            "score": 0.7211105227470398,
            "answer": "programs",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8925674259662628
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.8631641268730164,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.8080710172653198,
            "answer": "stuff",
            "hit": false
          },
          {
            "score": 0.8073852062225342,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.7846800088882446,
            "answer": "really",
            "hit": false
          },
          {
            "score": 0.7813118696212769,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.765454888343811,
            "answer": "guys",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631641566753387
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8854843378067017,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.8505821228027344,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.8147352933883667,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7906832098960876,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7639955878257751,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7554119229316711,
            "answer": "residents",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8854843974113464
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.8753357529640198,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.7610238194465637,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.751885175704956,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.7402239441871643,
            "answer": "functionality",
            "hit": false
          },
          {
            "score": 0.7328426837921143,
            "answer": "browser",
            "hit": false
          },
          {
            "score": 0.7315412759780884,
            "answer": "customers",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8753357231616974
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.9300441145896912,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.7735730409622192,
            "answer": "iteration",
            "hit": false
          },
          {
            "score": 0.7507278919219971,
            "answer": "variant",
            "hit": false
          },
          {
            "score": 0.7499631643295288,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.729833722114563,
            "answer": "edition",
            "hit": false
          },
          {
            "score": 0.7198706269264221,
            "answer": "variants",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9300441443920135
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.8929483294487,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8391174077987671,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.8150562644004822,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.811687707901001,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.7570596933364868,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7544748783111572,
            "answer": "locality",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8929483592510223
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.8616218566894531,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.7889662981033325,
            "answer": "www",
            "hit": false
          },
          {
            "score": 0.7666995525360107,
            "answer": "online",
            "hit": false
          },
          {
            "score": 0.757548451423645,
            "answer": "blog",
            "hit": false
          },
          {
            "score": 0.7568531036376953,
            "answer": "page",
            "hit": false
          },
          {
            "score": 0.7506414651870728,
            "answer": "sites",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8616218566894531
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.8865039944648743,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.8735438585281372,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.8420110940933228,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.825553834438324,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.8044894933700562,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.7978357672691345,
            "answer": "summer",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8735438883304596
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.8562167882919312,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.8108183145523071,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.8089169859886169,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.8076024055480957,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7839836478233337,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7727494835853577,
            "answer": "weeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8076024055480957
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 50,
      "accuracy": 0.76
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1dc1175a-03d3-4fd0-ada4-6a0478086c0b",
      "timestamp": "2025-05-18T13:34:03.380558"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.8123196959495544,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.8021829128265381,
            "answer": "inability",
            "hit": false
          },
          {
            "score": 0.7791599035263062,
            "answer": "willingness",
            "hit": false
          },
          {
            "score": 0.7577382922172546,
            "answer": "able",
            "hit": false
          },
          {
            "score": 0.7549429535865784,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7533408999443054,
            "answer": "capabilities",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8123197555541992
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8357300758361816,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.7177286148071289,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.6977484226226807,
            "answer": "behavior",
            "hit": false
          },
          {
            "score": 0.6916112899780273,
            "answer": "patterns",
            "hit": false
          },
          {
            "score": 0.6876744031906128,
            "answer": "transactions",
            "hit": false
          },
          {
            "score": 0.687427282333374,
            "answer": "movements",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.835730105638504
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.8412726521492004,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7225254774093628,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.7122102975845337,
            "answer": "organization",
            "hit": false
          },
          {
            "score": 0.7000085711479187,
            "answer": "agent",
            "hit": false
          },
          {
            "score": 0.6847982406616211,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.6842876672744751,
            "answer": "entities",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8412726521492004
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.7814285755157471,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.7761356830596924,
            "answer": "assessment",
            "hit": false
          },
          {
            "score": 0.7744250297546387,
            "answer": "analytical",
            "hit": false
          },
          {
            "score": 0.7691695094108582,
            "answer": "evaluation",
            "hit": false
          },
          {
            "score": 0.768091082572937,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.7580876350402832,
            "answer": "assessments",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7238744348287582
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8143026828765869,
            "answer": "navy",
            "hit": false
          },
          {
            "score": 0.8088584542274475,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.8082084655761719,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.8035013675689697,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7888014316558838,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.7664930820465088,
            "answer": "soldier",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6984031945466995
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7995849251747131,
            "answer": "jurisdiction",
            "hit": false
          },
          {
            "score": 0.7929918766021729,
            "answer": "powers",
            "hit": false
          },
          {
            "score": 0.7491880655288696,
            "answer": "oversight",
            "hit": false
          },
          {
            "score": 0.748953104019165,
            "answer": "councils",
            "hit": false
          },
          {
            "score": 0.7365953922271729,
            "answer": "mandate",
            "hit": false
          },
          {
            "score": 0.7321547865867615,
            "answer": "discretion",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6639997661113739
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.672117292881012,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.6661996841430664,
            "answer": "rely",
            "hit": false
          },
          {
            "score": 0.6660951375961304,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.6622376441955566,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.6617594957351685,
            "answer": "purely",
            "hit": false
          },
          {
            "score": 0.6598077416419983,
            "answer": "therefore",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 381,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6004166454076767
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.8626102805137634,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7786819338798523,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7606542110443115,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.7515486478805542,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.7475593090057373,
            "answer": "enterprises",
            "hit": false
          },
          {
            "score": 0.7452161908149719,
            "answer": "ventures",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.862610250711441
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.9117199778556824,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7299507856369019,
            "answer": "segments",
            "hit": false
          },
          {
            "score": 0.7295271158218384,
            "answer": "classification",
            "hit": false
          },
          {
            "score": 0.7206093072891235,
            "answer": "segment",
            "hit": false
          },
          {
            "score": 0.716256856918335,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.7129570841789246,
            "answer": "awards",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9117200374603271
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.8903626203536987,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.7923940420150757,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.7853794097900391,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7160783410072327,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.7055851817131042,
            "answer": "generations",
            "hit": false
          },
          {
            "score": 0.6951753497123718,
            "answer": "eras",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8903626501560211
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.8751912713050842,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.8353476524353027,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.8118892312049866,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.8109895586967468,
            "answer": "newborn",
            "hit": false
          },
          {
            "score": 0.807594895362854,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7995340824127197,
            "answer": "babies",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8751912713050842
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8328497409820557,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.8212816715240479,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.8199480175971985,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.8188966512680054,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.8145656585693359,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.806168794631958,
            "answer": "municipal",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8328498005867004
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.8849736452102661,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7849168181419373,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.7534355521202087,
            "answer": "families",
            "hit": false
          },
          {
            "score": 0.7520498633384705,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7482274770736694,
            "answer": "residents",
            "hit": false
          },
          {
            "score": 0.7476630210876465,
            "answer": "churches",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8849736750125885
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.8418641686439514,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.8054189085960388,
            "answer": "continent",
            "hit": false
          },
          {
            "score": 0.8034051060676575,
            "answer": "region",
            "hit": false
          },
          {
            "score": 0.7852892875671387,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.7837902903556824,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.7720806002616882,
            "answer": "regions",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7837903201580048
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8980274200439453,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7686136364936829,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7569936513900757,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7323905229568481,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7201407551765442,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.7111966609954834,
            "answer": "districts",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8980274498462677
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.792711615562439,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7225058078765869,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7199321985244751,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7105423212051392,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7003626823425293,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.6679783463478088,
            "answer": "firefighters",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7927115857601166
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.863684356212616,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.8535867929458618,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.8085450530052185,
            "answer": "recession",
            "hit": false
          },
          {
            "score": 0.7854471206665039,
            "answer": "gdp",
            "hit": false
          },
          {
            "score": 0.7753674983978271,
            "answer": "sector",
            "hit": false
          },
          {
            "score": 0.7666537165641785,
            "answer": "economically",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8636843860149384
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.7956475019454956,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.7861977815628052,
            "answer": "renewable",
            "hit": false
          },
          {
            "score": 0.7594984769821167,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.7467584013938904,
            "answer": "gas",
            "hit": false
          },
          {
            "score": 0.7402554750442505,
            "answer": "utilities",
            "hit": false
          },
          {
            "score": 0.7391366958618164,
            "answer": "biomass",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7099305689334869
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.7693653702735901,
            "answer": "enter",
            "hit": false
          },
          {
            "score": 0.7517383694648743,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.743661105632782,
            "answer": "entering",
            "hit": false
          },
          {
            "score": 0.7215186953544617,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.6991620063781738,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.691917896270752,
            "answer": "registration",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7517383396625519
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.9176117181777954,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.7615669965744019,
            "answer": "centers",
            "hit": false
          },
          {
            "score": 0.7584322690963745,
            "answer": "plant",
            "hit": false
          },
          {
            "score": 0.7348446846008301,
            "answer": "center",
            "hit": false
          },
          {
            "score": 0.7321137189865112,
            "answer": "complexes",
            "hit": false
          },
          {
            "score": 0.7274997234344482,
            "answer": "labs",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.917611688375473
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.8536560535430908,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.8366276025772095,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.8319447636604309,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.8213033676147461,
            "answer": "friends",
            "hit": false
          },
          {
            "score": 0.8015005588531494,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.7851806282997131,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8366276025772095
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.809510350227356,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7284544706344604,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.7241860628128052,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.7105905413627625,
            "answer": "longest",
            "hit": false
          },
          {
            "score": 0.7049700021743774,
            "answer": "record",
            "hit": false
          },
          {
            "score": 0.7033664584159851,
            "answer": "heritage",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.809510350227356
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.898750901222229,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.8260615468025208,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.812609076499939,
            "answer": "sector",
            "hit": false
          },
          {
            "score": 0.8059273958206177,
            "answer": "sectors",
            "hit": false
          },
          {
            "score": 0.767667293548584,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.7672706246376038,
            "answer": "marketplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8987509310245514
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.8980813026428223,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7590624094009399,
            "answer": "books",
            "hit": false
          },
          {
            "score": 0.7588481903076172,
            "answer": "classrooms",
            "hit": false
          },
          {
            "score": 0.7435502409934998,
            "answer": "museum",
            "hit": false
          },
          {
            "score": 0.7216667532920837,
            "answer": "archives",
            "hit": false
          },
          {
            "score": 0.7168232798576355,
            "answer": "manuscripts",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8980813324451447
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7991636991500854,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.7171705961227417,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.7148528099060059,
            "answer": "experiences",
            "hit": false
          },
          {
            "score": 0.7039854526519775,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7025957107543945,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.7019518613815308,
            "answer": "happiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7991636991500854
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8682687282562256,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7745039463043213,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7584654688835144,
            "answer": "defeat",
            "hit": false
          },
          {
            "score": 0.7573660016059875,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7507721185684204,
            "answer": "defeats",
            "hit": false
          },
          {
            "score": 0.7291498184204102,
            "answer": "lose",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8682686984539032
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.8128577470779419,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.7550355792045593,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.6979363560676575,
            "answer": "cpu",
            "hit": false
          },
          {
            "score": 0.6922293901443481,
            "answer": "legacy",
            "hit": false
          },
          {
            "score": 0.6834795475006104,
            "answer": "brain",
            "hit": false
          },
          {
            "score": 0.6818122267723083,
            "answer": "disk",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8128577768802643
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8533607721328735,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.8415921926498413,
            "answer": "chance",
            "hit": false
          },
          {
            "score": 0.7167652249336243,
            "answer": "advantage",
            "hit": false
          },
          {
            "score": 0.7143824100494385,
            "answer": "eager",
            "hit": false
          },
          {
            "score": 0.7054885625839233,
            "answer": "talents",
            "hit": false
          },
          {
            "score": 0.7048241496086121,
            "answer": "able",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8533608019351959
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8963876366615295,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7544581294059753,
            "answer": "laws",
            "hit": false
          },
          {
            "score": 0.7537344694137573,
            "answer": "regulations",
            "hit": false
          },
          {
            "score": 0.7479593753814697,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.7438393235206604,
            "answer": "doctrine",
            "hit": false
          },
          {
            "score": 0.7385271191596985,
            "answer": "guidelines",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8963876664638519
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.8596993684768677,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7885733842849731,
            "answer": "land",
            "hit": false
          },
          {
            "score": 0.7615442276000977,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.7582826018333435,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7542542219161987,
            "answer": "buildings",
            "hit": false
          },
          {
            "score": 0.7513645887374878,
            "answer": "parcel",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8596993982791901
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8486977815628052,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7774883508682251,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.7616980671882629,
            "answer": "blame",
            "hit": false
          },
          {
            "score": 0.7449010014533997,
            "answer": "burden",
            "hit": false
          },
          {
            "score": 0.7448620796203613,
            "answer": "accountable",
            "hit": false
          },
          {
            "score": 0.7308182716369629,
            "answer": "accountability",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.84869784116745
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7295072674751282,
            "answer": "encryption",
            "hit": false
          },
          {
            "score": 0.7233895063400269,
            "answer": "guards",
            "hit": false
          },
          {
            "score": 0.7159040570259094,
            "answer": "forces",
            "hit": false
          },
          {
            "score": 0.7072594165802002,
            "answer": "cyber",
            "hit": false
          },
          {
            "score": 0.704866886138916,
            "answer": "threats",
            "hit": false
          },
          {
            "score": 0.703616738319397,
            "answer": "airports",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 1307,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5747720748186111
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.7187889814376831,
            "answer": "finale",
            "hit": false
          },
          {
            "score": 0.7001026272773743,
            "answer": "installment",
            "hit": false
          },
          {
            "score": 0.6994613409042358,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.6948579549789429,
            "answer": "contests",
            "hit": false
          },
          {
            "score": 0.6835834383964539,
            "answer": "string",
            "hit": false
          },
          {
            "score": 0.6789408922195435,
            "answer": "mini",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9786475598812103
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8634492754936218,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.8153362274169922,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7558677196502686,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7493630051612854,
            "answer": "civilization",
            "hit": false
          },
          {
            "score": 0.7370244264602661,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.7369276285171509,
            "answer": "socially",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8634492754936218
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.8454142808914185,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.8353890180587769,
            "answer": "mammals",
            "hit": false
          },
          {
            "score": 0.815599262714386,
            "answer": "habitat",
            "hit": false
          },
          {
            "score": 0.8017967343330383,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.7952448129653931,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.7877480983734131,
            "answer": "populations",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9818488657474518
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.8882226347923279,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.832770049571991,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.7988116145133972,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.7603909373283386,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7508535981178284,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7471978664398193,
            "answer": "storyline",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8882226645946503
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.8663639426231384,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.781216025352478,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.7734694480895996,
            "answer": "plan",
            "hit": false
          },
          {
            "score": 0.7678800225257874,
            "answer": "initiatives",
            "hit": false
          },
          {
            "score": 0.7587161064147949,
            "answer": "approach",
            "hit": false
          },
          {
            "score": 0.7585294246673584,
            "answer": "tactics",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.866363912820816
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.8724939823150635,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.8001099824905396,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7564590573310852,
            "answer": "achievements",
            "hit": false
          },
          {
            "score": 0.7392500042915344,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.7303237915039062,
            "answer": "achievement",
            "hit": false
          },
          {
            "score": 0.723257303237915,
            "answer": "accomplishment",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8724939525127411
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.9326964020729065,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.824590802192688,
            "answer": "innovations",
            "hit": false
          },
          {
            "score": 0.7945131659507751,
            "answer": "systems",
            "hit": false
          },
          {
            "score": 0.7802982330322266,
            "answer": "innovation",
            "hit": false
          },
          {
            "score": 0.7782013416290283,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7767999768257141,
            "answer": "solutions",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9326964020729065
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.9113253951072693,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.8677992820739746,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.8175269961357117,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7945218682289124,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7730926275253296,
            "answer": "reasoning",
            "hit": false
          },
          {
            "score": 0.7714027166366577,
            "answer": "theorem",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9113253951072693
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.7921614646911621,
            "answer": "professor",
            "hit": false
          },
          {
            "score": 0.7692423462867737,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.767047643661499,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7619672417640686,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7513249516487122,
            "answer": "doctoral",
            "hit": false
          },
          {
            "score": 0.7510576248168945,
            "answer": "phd",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.767047643661499
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8512171506881714,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.847705602645874,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.8305507302284241,
            "answer": "myriad",
            "hit": false
          },
          {
            "score": 0.8047794103622437,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.803693413734436,
            "answer": "array",
            "hit": false
          },
          {
            "score": 0.7990511655807495,
            "answer": "numerous",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6905083954334259
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.896600604057312,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.8769403696060181,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.8645294308662415,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8560329675674438,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8422768712043762,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8330413103103638,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7868864238262177
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.8644775152206421,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.8609464168548584,
            "answer": "man",
            "hit": false
          },
          {
            "score": 0.7970441579818726,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.7884414792060852,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7867060303688049,
            "answer": "boy",
            "hit": false
          },
          {
            "score": 0.7854645252227783,
            "answer": "women",
            "hit": true
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7854645252227783
      }
    ],
    "result": {
      "cnt_questions_correct": 29,
      "cnt_questions_total": 44,
      "accuracy": 0.6590909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4e1ad07f-cea5-4e02-9eec-58a3a68c6d4e",
      "timestamp": "2025-05-18T13:34:03.526850"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8876253366470337,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.781451940536499,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7579440474510193,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7417036294937134,
            "answer": "simpler",
            "hit": false
          },
          {
            "score": 0.7215278148651123,
            "answer": "richer",
            "hit": false
          },
          {
            "score": 0.7197632789611816,
            "answer": "affordable",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8876253962516785
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.8851121664047241,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.8046488761901855,
            "answer": "glad",
            "hit": false
          },
          {
            "score": 0.7637726664543152,
            "answer": "satisfied",
            "hit": false
          },
          {
            "score": 0.7559816241264343,
            "answer": "better",
            "hit": false
          },
          {
            "score": 0.7538188695907593,
            "answer": "disappointed",
            "hit": false
          },
          {
            "score": 0.7516070604324341,
            "answer": "thrilled",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8851121664047241
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.9102115631103516,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.8270397186279297,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7973681092262268,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7750173807144165,
            "answer": "solid",
            "hit": false
          },
          {
            "score": 0.7745961546897888,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7743040919303894,
            "answer": "strengthened",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9102115333080292
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.921851396560669,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.8610504865646362,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.8155661821365356,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.8139005899429321,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.8052678108215332,
            "answer": "softer",
            "hit": false
          },
          {
            "score": 0.7952276468276978,
            "answer": "weakness",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.921851396560669
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2d74a5d1-57af-4b77-b9ea-f38c434ee886",
      "timestamp": "2025-05-18T13:34:03.662854"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.8557840585708618,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7190546989440918,
            "answer": "worst",
            "hit": false
          },
          {
            "score": 0.7148047089576721,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7023284435272217,
            "answer": "easiest",
            "hit": false
          },
          {
            "score": 0.6969158053398132,
            "answer": "biggest",
            "hit": false
          },
          {
            "score": 0.6956743001937866,
            "answer": "fastest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8557840883731842
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.8526219129562378,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7650307416915894,
            "answer": "solid",
            "hit": false
          },
          {
            "score": 0.7457334399223328,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7395051717758179,
            "answer": "best",
            "hit": false
          },
          {
            "score": 0.7316431999206543,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7215821743011475,
            "answer": "greatest",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8526218831539154
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 2,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2f201b45-6779-4fe4-a5f3-d9e938a717a2",
      "timestamp": "2025-05-18T13:34:03.673407"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.9247140884399414,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.8238992094993591,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8121193647384644,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8033804297447205,
            "answer": "rejects",
            "hit": false
          },
          {
            "score": 0.7847976088523865,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7708530426025391,
            "answer": "agrees",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9247140288352966
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8730884790420532,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.797878086566925,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.777954638004303,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7680160999298096,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7629903554916382,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7593752145767212,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8730884790420532
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8860260248184204,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8446550369262695,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7849552631378174,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7715011835098267,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7468538880348206,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.7437981367111206,
            "answer": "rejects",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8860260844230652
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9321085214614868,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8664373755455017,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8595553636550903,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8548803925514221,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.8363487720489502,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8163293600082397,
            "answer": "enabling",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9321085810661316
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.845223069190979,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.827282726764679,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8010787963867188,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7632771134376526,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7530061602592468,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7327979207038879,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8452230989933014
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9066922068595886,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8730016946792603,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8373900651931763,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7636525630950928,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7577836513519287,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7534860968589783,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9066922068595886
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.9171842336654663,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8424983620643616,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8390836119651794,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7846096158027649,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7703259587287903,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.7614726424217224,
            "answer": "refuses",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9171842038631439
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8924223184585571,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.8671634793281555,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8239498138427734,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7831003069877625,
            "answer": "prevent",
            "hit": false
          },
          {
            "score": 0.7788017988204956,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7752935886383057,
            "answer": "minimize",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8924223482608795
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.9018330574035645,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.864071249961853,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8603792190551758,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7506213188171387,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7362737655639648,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7359344959259033,
            "answer": "grows",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9018331468105316
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8378702998161316,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8014655709266663,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.784990131855011,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.7789265513420105,
            "answer": "convinced",
            "hit": false
          },
          {
            "score": 0.772550642490387,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7711490392684937,
            "answer": "say",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.837870329618454
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8682076930999756,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8336222767829895,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7897158861160278,
            "answer": "recommends",
            "hit": false
          },
          {
            "score": 0.7757769823074341,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7653806209564209,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7609069347381592,
            "answer": "recommend",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8682076930999756
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9441474080085754,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8837275505065918,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.879351019859314,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8758801221847534,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8560230135917664,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.855218768119812,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9441474378108978
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8773115873336792,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8359177708625793,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8200637698173523,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.7344393730163574,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7308247685432434,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.70941561460495,
            "answer": "refers",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8773116171360016
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9349130392074585,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8534347414970398,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8201819062232971,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7624782919883728,
            "answer": "will",
            "hit": false
          },
          {
            "score": 0.7580324411392212,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7564369440078735,
            "answer": "intends",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9349130690097809
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9320125579833984,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8659424185752869,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8501257300376892,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7837610840797424,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7741715908050537,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7660431861877441,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.932012528181076
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8842324614524841,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8463389873504639,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8388933539390564,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8133301138877869,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.8133004903793335,
            "answer": "defines",
            "hit": false
          },
          {
            "score": 0.7693256139755249,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8842324316501617
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8447552919387817,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.821171760559082,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.817593514919281,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7825905680656433,
            "answer": "builds",
            "hit": false
          },
          {
            "score": 0.769863486289978,
            "answer": "build",
            "hit": false
          },
          {
            "score": 0.7684417963027954,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8447552919387817
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.9349780678749084,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8956627249717712,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.894666314125061,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8552617430686951,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.8329148292541504,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8291120529174805,
            "answer": "helps",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9349780380725861
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.8671926856040955,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.859963059425354,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8373287916183472,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.77994704246521,
            "answer": "loves",
            "hit": false
          },
          {
            "score": 0.7638863921165466,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7552350759506226,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8671927154064178
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.9055245518684387,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.8855079412460327,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7919634580612183,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.7819391489028931,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7672187685966492,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7488043308258057,
            "answer": "imperative",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9055246114730835
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.8824803233146667,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.8369908928871155,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7672922611236572,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7490571737289429,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7467703819274902,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7418111562728882,
            "answer": "operates",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.882480263710022
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8456571698188782,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8326658010482788,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.7952162027359009,
            "answer": "illustrates",
            "hit": false
          },
          {
            "score": 0.7918787002563477,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7887946367263794,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7884373664855957,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8326658308506012
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.841440737247467,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7937785387039185,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7172906994819641,
            "answer": "goes",
            "hit": false
          },
          {
            "score": 0.7113075256347656,
            "answer": "lays",
            "hit": false
          },
          {
            "score": 0.7105191946029663,
            "answer": "comes",
            "hit": false
          },
          {
            "score": 0.7099683284759521,
            "answer": "following",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8414407968521118
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9030976891517639,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8064264059066772,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7982227206230164,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7888301610946655,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7880839705467224,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7697657942771912,
            "answer": "goes",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9030976593494415
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.9006832838058472,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8384363651275635,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7656298875808716,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.758423924446106,
            "answer": "sounds",
            "hit": false
          },
          {
            "score": 0.7467651963233948,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7439084649085999,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9006832838058472
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.9077600240707397,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8469181060791016,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8206006288528442,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7561010122299194,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7488322257995605,
            "answer": "recognizes",
            "hit": false
          },
          {
            "score": 0.7450907230377197,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9077600538730621
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8812925219535828,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8612887859344482,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8410767316818237,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8276019096374512,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.7881801128387451,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7801119685173035,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8812925219535828
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.9007368683815002,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.8672570586204529,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7862898707389832,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7847014665603638,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7802292108535767,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7724966406822205,
            "answer": "including",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.900736927986145
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9315856099128723,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7957735061645508,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7876997590065002,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7803992629051208,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7737632989883423,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7692122459411621,
            "answer": "focuses",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9315856099128723
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8437868356704712,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.8038166761398315,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.7985783815383911,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7973133325576782,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7700425982475281,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7474774122238159,
            "answer": "taught",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8437868356704712
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.8654671907424927,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.842698335647583,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8201333284378052,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8053858876228333,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7690770626068115,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7528780698776245,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654671609401703
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9186694622039795,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8579033613204956,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.806251585483551,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7879886031150818,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7705316543579102,
            "answer": "arise",
            "hit": false
          },
          {
            "score": 0.7633270025253296,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9186694920063019
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8946605324745178,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.830194354057312,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.7766441106796265,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7511817216873169,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.7460376024246216,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7436912655830383,
            "answer": "uses",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8946605324745178
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.8873009085655212,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.8788750171661377,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.8219977617263794,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7840044498443604,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.779291570186615,
            "answer": "deter",
            "hit": false
          },
          {
            "score": 0.7658196687698364,
            "answer": "avoid",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8873009085655212
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9065226912498474,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8747722506523132,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7736262679100037,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7655129432678223,
            "answer": "emphasizes",
            "hit": false
          },
          {
            "score": 0.7572108507156372,
            "answer": "aims",
            "hit": false
          },
          {
            "score": 0.7418802976608276,
            "answer": "encourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9065227210521698
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.9080259799957275,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.8606289029121399,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.852989137172699,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.8029698133468628,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.7966737151145935,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.7909855246543884,
            "answer": "shield",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9080259501934052
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9428564310073853,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8741604089736938,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8529549837112427,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.8472026586532593,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8454316258430481,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8335626721382141,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.94285649061203
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9300367832183838,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8354933261871338,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8164944648742676,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7973363995552063,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7774876952171326,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.771170437335968,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.930036723613739
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9197366833686829,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8957400918006897,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8394502401351929,
            "answer": "lowers",
            "hit": false
          },
          {
            "score": 0.8102942109107971,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8045465350151062,
            "answer": "minimize",
            "hit": false
          },
          {
            "score": 0.7902542352676392,
            "answer": "reduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9197366833686829
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.9034292101860046,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.883225679397583,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7838135957717896,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7773856520652771,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7772900462150574,
            "answer": "defines",
            "hit": false
          },
          {
            "score": 0.7550092339515686,
            "answer": "mentions",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9034292101860046
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.9040687084197998,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.875602662563324,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8301618099212646,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.7764360308647156,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.765661895275116,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7547239065170288,
            "answer": "retains",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9040686786174774
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.8623572587966919,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.8306189179420471,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.8110244870185852,
            "answer": "reminds",
            "hit": false
          },
          {
            "score": 0.8072031736373901,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.7879962921142578,
            "answer": "forget",
            "hit": false
          },
          {
            "score": 0.772405743598938,
            "answer": "reminded",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8623572885990143
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8957076072692871,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.8430806398391724,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.822529673576355,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7764415740966797,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7707293033599854,
            "answer": "reflects",
            "hit": false
          },
          {
            "score": 0.7698647975921631,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8957075774669647
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9401993155479431,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.8571993112564087,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8265566229820251,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.8080951571464539,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.794734001159668,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7807566523551941,
            "answer": "applies",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9401992857456207
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.9003595113754272,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8248516917228699,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8214433789253235,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7867449522018433,
            "answer": "looks",
            "hit": false
          },
          {
            "score": 0.7828481197357178,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.7810747623443604,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.900359570980072
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.9225530624389648,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.8557949066162109,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.8479938507080078,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7484817504882812,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.714627742767334,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7114405632019043,
            "answer": "goes",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9225530326366425
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.9162425398826599,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8374133706092834,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8300198912620544,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.8241258859634399,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.814275860786438,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.7874033451080322,
            "answer": "appears",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9162425696849823
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8972660303115845,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8356111645698547,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8107156753540039,
            "answer": "reminds",
            "hit": false
          },
          {
            "score": 0.7982685565948486,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7954105138778687,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7731239795684814,
            "answer": "asks",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8972660303115845
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.883217453956604,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.8073597550392151,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.803312361240387,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8000571727752686,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7984461188316345,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7954738140106201,
            "answer": "realizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8832174837589264
      }
    ],
    "result": {
      "cnt_questions_correct": 48,
      "cnt_questions_total": 49,
      "accuracy": 0.9795918367346939
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "80937d65-f2b5-4a19-8543-0a315a8962b4",
      "timestamp": "2025-05-18T13:34:03.678737"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9423086047172546,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.8777545094490051,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8560789823532104,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.8050511479377747,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7879747152328491,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7434729337692261,
            "answer": "achievement",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9423085749149323
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7873506546020508,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7594767808914185,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.7580155730247498,
            "answer": "bringing",
            "hit": false
          },
          {
            "score": 0.7350644469261169,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7246816158294678,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7228276133537292,
            "answer": "expanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7594768106937408
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.9157724380493164,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.8569701910018921,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8537495136260986,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8432685136795044,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8267346620559692,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8109403848648071,
            "answer": "requiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9157724380493164
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8556821346282959,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.8346120119094849,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7799255847930908,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7598397731781006,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7321228981018066,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7132983803749084,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556821346282959
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.9164333343505859,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.890518307685852,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8251357674598694,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7578304409980774,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7232706546783447,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7217554450035095,
            "answer": "accepting",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9164333045482635
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.9149409532546997,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.8653636574745178,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.836407482624054,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7941640019416809,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7719560861587524,
            "answer": "answering",
            "hit": false
          },
          {
            "score": 0.7674338817596436,
            "answer": "telling",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9149409830570221
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.9372636079788208,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8589463233947754,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.7738415598869324,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7569539546966553,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7563759684562683,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7458598017692566,
            "answer": "invited",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9372636079788208
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.9278058409690857,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.8452855348587036,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7956620454788208,
            "answer": "prevent",
            "hit": false
          },
          {
            "score": 0.7946425676345825,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7925963401794434,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7879761457443237,
            "answer": "minimize",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9278058111667633
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.9300336241722107,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.87098228931427,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8293379545211792,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7496873140335083,
            "answer": "increasingly",
            "hit": false
          },
          {
            "score": 0.7185648679733276,
            "answer": "emerged",
            "hit": false
          },
          {
            "score": 0.7088144421577454,
            "answer": "making",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9300336837768555
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8243457674980164,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.8050591349601746,
            "answer": "convinced",
            "hit": false
          },
          {
            "score": 0.8027999401092529,
            "answer": "say",
            "hit": false
          },
          {
            "score": 0.7964967489242554,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7924419641494751,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.768673300743103,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8243457674980164
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.8741835951805115,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.7834538221359253,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7768164277076721,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7703143954277039,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7586911916732788,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.748009204864502,
            "answer": "assessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8741835653781891
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8633919954299927,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8531481027603149,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7938241958618164,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.705416202545166,
            "answer": "spreading",
            "hit": false
          },
          {
            "score": 0.6847344040870667,
            "answer": "contents",
            "hit": false
          },
          {
            "score": 0.6832908391952515,
            "answer": "producing",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8633919656276703
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.888005256652832,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.8819091320037842,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8720083236694336,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7521249651908875,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7356992959976196,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.7349358201026917,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8880053460597992
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.9492946267127991,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.85971999168396,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.8296197652816772,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7890200018882751,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7550625801086426,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7524142861366272,
            "answer": "generate",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9492946267127991
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8841413259506226,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.8133680820465088,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7943004369735718,
            "answer": "build",
            "hit": false
          },
          {
            "score": 0.7823508381843567,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7802413105964661,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7707200050354004,
            "answer": "establish",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8841413855552673
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8625446557998657,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8430539965629578,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.812679648399353,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7781650424003601,
            "answer": "inviting",
            "hit": false
          },
          {
            "score": 0.7777879238128662,
            "answer": "urging",
            "hit": false
          },
          {
            "score": 0.7768317461013794,
            "answer": "promoting",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8625446259975433
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.9278817772865295,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.8548252582550049,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7968557476997375,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7866723537445068,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7649100422859192,
            "answer": "relaxing",
            "hit": false
          },
          {
            "score": 0.7637037038803101,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9278818070888519
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.9400067329406738,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.8201231956481934,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.8177957534790039,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7963659167289734,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7691360116004944,
            "answer": "assured",
            "hit": false
          },
          {
            "score": 0.7565282583236694,
            "answer": "safeguard",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9400067627429962
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.9392961859703064,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8530464172363281,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.78504478931427,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7625303268432617,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7432224750518799,
            "answer": "forge",
            "hit": false
          },
          {
            "score": 0.7412327527999878,
            "answer": "build",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9392961859703064
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.8475233316421509,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.8145603537559509,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7718769311904907,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7654593586921692,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7088589668273926,
            "answer": "there",
            "hit": false
          },
          {
            "score": 0.7060034871101379,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 82,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6432609260082245
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.8676055669784546,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.8143150806427002,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.798694372177124,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7863388061523438,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.77550208568573,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7560626864433289,
            "answer": "hoping",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8676055371761322
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.8095012903213501,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7622188329696655,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.7590678930282593,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7124503254890442,
            "answer": "setting",
            "hit": false
          },
          {
            "score": 0.6872518062591553,
            "answer": "adhere",
            "hit": false
          },
          {
            "score": 0.6829156279563904,
            "answer": "set",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7622188031673431
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8473866581916809,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.8461241126060486,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.819227397441864,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.783209502696991,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7749897837638855,
            "answer": "going",
            "hit": false
          },
          {
            "score": 0.7709280252456665,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8473866879940033
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.9193553328514099,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8327679634094238,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8068715333938599,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7670706510543823,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.754875659942627,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7505966424942017,
            "answer": "identification",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9193553030490875
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.9378483891487122,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.8651068210601807,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8359727263450623,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8245035409927368,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8049355745315552,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7821301221847534,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9378483891487122
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.892434298992157,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.8234986662864685,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.815012514591217,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.7546948790550232,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7512655854225159,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7421379089355469,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8150124847888947
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.863984227180481,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7831674814224243,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7522282004356384,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.741119384765625,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7407864928245544,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7373349070549011,
            "answer": "included",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7831674516201019
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.8574745059013367,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.815920352935791,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7749037742614746,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7669146060943604,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.7497193813323975,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.7492131590843201,
            "answer": "taught",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8574745357036591
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.9199973940849304,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.8571217060089111,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.8277981281280518,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7667481899261475,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7608907222747803,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7388385534286499,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9199973940849304
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9148038029670715,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8327773213386536,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7767263650894165,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7714235782623291,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7705023884773254,
            "answer": "retaining",
            "hit": false
          },
          {
            "score": 0.7687451839447021,
            "answer": "keeping",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9148038029670715
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8777501583099365,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.7875360250473022,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7649427652359009,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7430148720741272,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7278751134872437,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7217170000076294,
            "answer": "handle",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8777501583099365
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8468849658966064,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.8384305834770203,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8293731212615967,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.7605965733528137,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.755683422088623,
            "answer": "functioning",
            "hit": false
          },
          {
            "score": 0.7205688953399658,
            "answer": "operations",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8293731212615967
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.9175877571105957,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.8963289260864258,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8558949828147888,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7343388199806213,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7311239838600159,
            "answer": "conducting",
            "hit": false
          },
          {
            "score": 0.7289786338806152,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9175878167152405
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.9365684986114502,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.8336392641067505,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8107318878173828,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7874495983123779,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.7841175198554993,
            "answer": "avoid",
            "hit": false
          },
          {
            "score": 0.7838547229766846,
            "answer": "deter",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9365685284137726
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9419863820075989,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8232911825180054,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7624877691268921,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7465152740478516,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7450464963912964,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7424383163452148,
            "answer": "emphasizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9419864118099213
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.9239370822906494,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.877061128616333,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.8283432126045227,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.8124061822891235,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.8099159002304077,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.809208869934082,
            "answer": "shielding",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9239371120929718
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.9514928460121155,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.8596329092979431,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8491652011871338,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7985783219337463,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7941912412643433,
            "answer": "giving",
            "hit": false
          },
          {
            "score": 0.7853896617889404,
            "answer": "delivering",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9514928758144379
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.9008390307426453,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.8561863899230957,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8512555360794067,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7633609771728516,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7573716640472412,
            "answer": "giving",
            "hit": false
          },
          {
            "score": 0.7509124279022217,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9008390307426453
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.9589753746986389,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8519432544708252,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8368182182312012,
            "answer": "lowering",
            "hit": false
          },
          {
            "score": 0.8344593048095703,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8318178653717041,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8239130973815918,
            "answer": "minimize",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9589753746986389
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8783283233642578,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8156154155731201,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7442336678504944,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7432381510734558,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7427200078964233,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7399790287017822,
            "answer": "mentioning",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7389141917228699
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8957010507583618,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8685356378555298,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7861192226409912,
            "answer": "keeping",
            "hit": false
          },
          {
            "score": 0.7750053405761719,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.769733190536499,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7639674544334412,
            "answer": "stay",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7333649098873138
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.8909088373184204,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.8237754106521606,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.8104864358901978,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.8017141819000244,
            "answer": "forgetting",
            "hit": false
          },
          {
            "score": 0.7997852563858032,
            "answer": "forget",
            "hit": false
          },
          {
            "score": 0.7766063213348389,
            "answer": "reminded",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8909088671207428
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.8706156611442566,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.8528256416320801,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.825560450553894,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7281715869903564,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7231877446174622,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7131996154785156,
            "answer": "reflect",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870615690946579
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.9138119220733643,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.8849170207977295,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8549824953079224,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.7638223171234131,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7470874786376953,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.7407950162887573,
            "answer": "needed",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.913811981678009
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8369046449661255,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8251097798347473,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.796682596206665,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7698175311088562,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7603881359100342,
            "answer": "quite",
            "hit": false
          },
          {
            "score": 0.7590944766998291,
            "answer": "appears",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7698175311088562
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.8983097076416016,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.8597229719161987,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.7820359468460083,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.7567132115364075,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7412906885147095,
            "answer": "staring",
            "hit": false
          },
          {
            "score": 0.7263457179069519,
            "answer": "standing",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8983096778392792
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8824166655540466,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8553014993667603,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8244466185569763,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.7736642360687256,
            "answer": "devote",
            "hit": false
          },
          {
            "score": 0.7711009979248047,
            "answer": "wasting",
            "hit": false
          },
          {
            "score": 0.7404180765151978,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8244467079639435
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8996725082397461,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8891671895980835,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8576847314834595,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8292540907859802,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.7818583250045776,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7699161767959595,
            "answer": "educate",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8996724784374237
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.9129077792167664,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.8142199516296387,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8088120222091675,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7942206859588623,
            "answer": "talking",
            "hit": false
          },
          {
            "score": 0.7658495306968689,
            "answer": "say",
            "hit": false
          },
          {
            "score": 0.7632763385772705,
            "answer": "ask",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.912907749414444
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8225666284561157,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8221498727798462,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.819908857345581,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.8168148994445801,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8070307970046997,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8013964891433716,
            "answer": "realize",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8199089169502258
      }
    ],
    "result": {
      "cnt_questions_correct": 39,
      "cnt_questions_total": 50,
      "accuracy": 0.78
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c6c33784-e9a1-4609-b3f0-6dd655ab3708",
      "timestamp": "2025-05-18T13:34:03.820263"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8982831239700317,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8376180529594421,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.829876720905304,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7841591238975525,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7839170694351196,
            "answer": "rejected",
            "hit": false
          },
          {
            "score": 0.766581654548645,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.898283064365387
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.9236582517623901,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.8878510594367981,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8618988394737244,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.8469732999801636,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.793197512626648,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7559869289398193,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9236582517623901
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.800804853439331,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7725198864936829,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7407812476158142,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7311431765556335,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7289596199989319,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7155947685241699,
            "answer": "included",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7725198864936829
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8387336134910583,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.8314054012298584,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8178360462188721,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8038488626480103,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7776330709457397,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.731142520904541,
            "answer": "objected",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8314053416252136
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8674565553665161,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8654579520225525,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8470702171325684,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8388838768005371,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.8367820978164673,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8011451363563538,
            "answer": "enabling",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654579222202301
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9020381569862366,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8523397445678711,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8416008949279785,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7651756405830383,
            "answer": "confirmed",
            "hit": false
          },
          {
            "score": 0.7625265121459961,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.761631190776825,
            "answer": "announcement",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.902038186788559
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8805904388427734,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8217514157295227,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7886171340942383,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7465431690216064,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7366905212402344,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7296766042709351,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.880590409040451
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9352371096611023,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8569050431251526,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.8286488056182861,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7546233534812927,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7499966621398926,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7281607389450073,
            "answer": "eligible",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9352371394634247
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.9133496284484863,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8822861313819885,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8341964483261108,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7881027460098267,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7750541567802429,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.763595700263977,
            "answer": "begged",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9133495986461639
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.9044082164764404,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8968441486358643,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.7758517861366272,
            "answer": "invited",
            "hit": false
          },
          {
            "score": 0.7729302048683167,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7723667621612549,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.758071780204773,
            "answer": "skipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.904408186674118
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8936688899993896,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8666142225265503,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8098361492156982,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7627184391021729,
            "answer": "emerged",
            "hit": false
          },
          {
            "score": 0.7358741164207458,
            "answer": "transformed",
            "hit": false
          },
          {
            "score": 0.7324641942977905,
            "answer": "regarded",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8936688601970673
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8489301800727844,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8186142444610596,
            "answer": "convinced",
            "hit": false
          },
          {
            "score": 0.8085547685623169,
            "answer": "say",
            "hit": false
          },
          {
            "score": 0.7879096269607544,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7870824337005615,
            "answer": "thought",
            "hit": false
          },
          {
            "score": 0.7804362177848816,
            "answer": "think",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489301800727844
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8595000505447388,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.832085132598877,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7843242883682251,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7605441808700562,
            "answer": "discussed",
            "hit": false
          },
          {
            "score": 0.7555913925170898,
            "answer": "recommended",
            "hit": false
          },
          {
            "score": 0.7472542524337769,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8320851624011993
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9043745398521423,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8789793252944946,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8476551175117493,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7529915571212769,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.7462544441223145,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7410509586334229,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9043745398521423
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.9152195453643799,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8792327642440796,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8253880739212036,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7664881944656372,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7520269751548767,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7478482127189636,
            "answer": "generated",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9152196049690247
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8702424764633179,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8415573239326477,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8390417098999023,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.7706547975540161,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7667012214660645,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7626063823699951,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8390417397022247
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8487927913665771,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8467044830322266,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8012123107910156,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.792495846748352,
            "answer": "characterized",
            "hit": false
          },
          {
            "score": 0.7561872005462646,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7540119886398315,
            "answer": "termed",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.846704512834549
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8752791285514832,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8320226669311523,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7805290818214417,
            "answer": "build",
            "hit": false
          },
          {
            "score": 0.7722929120063782,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.7697898745536804,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7695835828781128,
            "answer": "established",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8752791881561279
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.8611588478088379,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.8572514057159424,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.8002755045890808,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.7960706949234009,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.7787004709243774,
            "answer": "found",
            "hit": false
          },
          {
            "score": 0.7727660536766052,
            "answer": "uncovered",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8572514057159424
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.9011706709861755,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.9005863070487976,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8030056357383728,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7676265239715576,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7624954581260681,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7533684968948364,
            "answer": "fun",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9011707007884979
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8856286406517029,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.8510289788246155,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.8159394860267639,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.8152797818183899,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7989771962165833,
            "answer": "assured",
            "hit": false
          },
          {
            "score": 0.7594262361526489,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8510289788246155
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8945649862289429,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8786950707435608,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7818963527679443,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7517940998077393,
            "answer": "formed",
            "hit": false
          },
          {
            "score": 0.7472866177558899,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7254471778869629,
            "answer": "establishment",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8945649564266205
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8589025735855103,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.8263402581214905,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8129622936248779,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.806681752204895,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7688851356506348,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7478030920028687,
            "answer": "predicting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8263402879238129
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8542205095291138,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7844473719596863,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7654958367347717,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6997888088226318,
            "answer": "complied",
            "hit": false
          },
          {
            "score": 0.6950053572654724,
            "answer": "set",
            "hit": false
          },
          {
            "score": 0.6944841742515564,
            "answer": "tracked",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8542205095291138
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.9206873178482056,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8195225596427917,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.8065733909606934,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7612932920455933,
            "answer": "sounded",
            "hit": false
          },
          {
            "score": 0.7585632801055908,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.757818877696991,
            "answer": "listen",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9206872880458832
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.887059211730957,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.8551916480064392,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8049906492233276,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7654455900192261,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7428092360496521,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7345526814460754,
            "answer": "detect",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8870591819286346
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8900095224380493,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8846067190170288,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8200450539588928,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.7973964214324951,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7873005867004395,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7781029343605042,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8900094926357269
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.92262864112854,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.8297074437141418,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.800652027130127,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7683570981025696,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7598576545715332,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7576192617416382,
            "answer": "featured",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9226286709308624
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9306195974349976,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8884488344192505,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8074023723602295,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.7990953922271729,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.788737416267395,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.7797833681106567,
            "answer": "launched",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.93061962723732
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8619389533996582,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7869776487350464,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.786637544631958,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7770265340805054,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7645226716995239,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7634003162384033,
            "answer": "involved",
            "hit": true
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7634003162384033
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8379096984863281,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7588472962379456,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.7532545328140259,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.74574875831604,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.7415457963943481,
            "answer": "retrieved",
            "hit": false
          },
          {
            "score": 0.7412828207015991,
            "answer": "searched",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7174942493438721
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8894350528717041,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8832879662513733,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.826505720615387,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7811030149459839,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7553689479827881,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7368035912513733,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8894350528717041
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8415251970291138,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.832360029220581,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7748975157737732,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7364790439605713,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.7327548265457153,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7316288352012634,
            "answer": "handle",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8415251970291138
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.9035982489585876,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8795885443687439,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8252017498016357,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.8092432022094727,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.7686083316802979,
            "answer": "bride",
            "hit": false
          },
          {
            "score": 0.7654896974563599,
            "answer": "marriages",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.90359827876091
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9396572113037109,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.883661150932312,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.863802433013916,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7247209548950195,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.7232224345207214,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7229402661323547,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9396572113037109
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9111456274986267,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8810657858848572,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8473408818244934,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8103576898574829,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7816950082778931,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7668523192405701,
            "answer": "supplied",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9111456274986267
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8688520193099976,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7978569269180298,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7954354286193848,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7497343420982361,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7477473020553589,
            "answer": "printed",
            "hit": false
          },
          {
            "score": 0.7457475662231445,
            "answer": "released",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8688519895076752
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8994746208190918,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.859502911567688,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8512512445449829,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7891659736633301,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7853590846061707,
            "answer": "awarded",
            "hit": false
          },
          {
            "score": 0.7655236124992371,
            "answer": "offered",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8994745910167694
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.9071508646011353,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8650568127632141,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8310590982437134,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8141825795173645,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8137654662132263,
            "answer": "minimize",
            "hit": false
          },
          {
            "score": 0.8112682104110718,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8650568127632141
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.9207077622413635,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.831436276435852,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7712178230285645,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7586047649383545,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7533213496208191,
            "answer": "mentioned",
            "hit": false
          },
          {
            "score": 0.7501224279403687,
            "answer": "coined",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9207077920436859
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8170467615127563,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7970193028450012,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7450433373451233,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7426165342330933,
            "answer": "reflected",
            "hit": false
          },
          {
            "score": 0.7356733083724976,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.7315108180046082,
            "answer": "pertaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7450433373451233
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.9256001114845276,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.865443766117096,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8102893829345703,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7624879479408264,
            "answer": "kept",
            "hit": false
          },
          {
            "score": 0.7559980750083923,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.7519727945327759,
            "answer": "still",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9256000816822052
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8830723762512207,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8805176615715027,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8573670387268066,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.8444779515266418,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8054920434951782,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7457060813903809,
            "answer": "successor",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8830723762512207
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.875251054763794,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8684836626052856,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8684111833572388,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.7618137001991272,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.7495450973510742,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7413697838783264,
            "answer": "allow",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8684112131595612
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8631490468978882,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8452973365783691,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8036062717437744,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7815569639205933,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7804341316223145,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7701925039291382,
            "answer": "quite",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631490468978882
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9314485788345337,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8793802857398987,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8259137868881226,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7395806312561035,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7370243072509766,
            "answer": "delivered",
            "hit": false
          },
          {
            "score": 0.7212245464324951,
            "answer": "received",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9314486086368561
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.9245413541793823,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8580466508865356,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8010032176971436,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7647072076797485,
            "answer": "devote",
            "hit": false
          },
          {
            "score": 0.7489231824874878,
            "answer": "wasted",
            "hit": false
          },
          {
            "score": 0.7339859008789062,
            "answer": "invested",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9245413839817047
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8647428750991821,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.82084059715271,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8120071291923523,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7946421504020691,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7822839021682739,
            "answer": "knew",
            "hit": false
          },
          {
            "score": 0.7754480242729187,
            "answer": "reminded",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7946421205997467
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8741397857666016,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8226650953292847,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.821104884147644,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8018825054168701,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7958540916442871,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.794813871383667,
            "answer": "know",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8741397857666016
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.7784229516983032,
            "answer": "unity",
            "hit": false
          },
          {
            "score": 0.7471156716346741,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.7195643186569214,
            "answer": "formed",
            "hit": false
          },
          {
            "score": 0.7135063409805298,
            "answer": "solidarity",
            "hit": false
          },
          {
            "score": 0.7074023485183716,
            "answer": "together",
            "hit": false
          },
          {
            "score": 0.7005763053894043,
            "answer": "joined",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 2212,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5649241134524345
      }
    ],
    "result": {
      "cnt_questions_correct": 34,
      "cnt_questions_total": 50,
      "accuracy": 0.68
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2171b59d-c948-488c-8918-19121059a143",
      "timestamp": "2025-05-18T13:34:03.966755"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8897159099578857,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.8584591746330261,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.8119624853134155,
            "answer": "noting",
            "hit": false
          },
          {
            "score": 0.8026295900344849,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.8003748655319214,
            "answer": "said",
            "hit": false
          },
          {
            "score": 0.7724609375,
            "answer": "noted",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8897159397602081
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.908552885055542,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.860948920249939,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.8399880528450012,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8352153897285461,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8316863775253296,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.818719744682312,
            "answer": "enabling",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.908552885055542
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8081579208374023,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7941476106643677,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.763893187046051,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.7498055100440979,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.742277979850769,
            "answer": "airs",
            "hit": false
          },
          {
            "score": 0.7349511384963989,
            "answer": "featured",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7638932168483734
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8630707263946533,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8448710441589355,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8105283379554749,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7632269859313965,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.7400874495506287,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.7356222867965698,
            "answer": "requires",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8105283677577972
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.9074758291244507,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8597040176391602,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8271830081939697,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.8210557699203491,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.780890703201294,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.7593261003494263,
            "answer": "urging",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9074757993221283
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.9020016193389893,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8732132911682129,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8455167412757874,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.75674968957901,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7518562078475952,
            "answer": "grows",
            "hit": false
          },
          {
            "score": 0.7341837882995605,
            "answer": "emerges",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9020016491413116
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.7817080020904541,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7804933190345764,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.7781777381896973,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.7761425375938416,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7634329795837402,
            "answer": "convinced",
            "hit": false
          },
          {
            "score": 0.760654091835022,
            "answer": "belief",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7761425375938416
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8230936527252197,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8161650896072388,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7466449737548828,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7389639616012573,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7361887693405151,
            "answer": "looks",
            "hit": false
          },
          {
            "score": 0.7343366146087646,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8230936825275421
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9368575811386108,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.9030864834785461,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.896332859992981,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8663316965103149,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8640735745429993,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.862931489944458,
            "answer": "consisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9368575811386108
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8821060657501221,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8183645009994507,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.816283643245697,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7587524652481079,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7515095472335815,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7435107231140137,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8821060061454773
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8984074592590332,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8375940918922424,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8277953267097473,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.820927083492279,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7342740297317505,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7305237650871277,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8984074890613556
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9280074834823608,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8622474074363708,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.838451087474823,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7860721349716187,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7770693302154541,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7679946422576904,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9280074834823608
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8651623129844666,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.8406797051429749,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8186095952987671,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.8115352988243103,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7911313772201538,
            "answer": "vary",
            "hit": false
          },
          {
            "score": 0.7671368718147278,
            "answer": "regardless",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8651622831821442
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9384080767631531,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8690933585166931,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.8316043615341187,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8124290108680725,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7970247864723206,
            "answer": "defines",
            "hit": false
          },
          {
            "score": 0.7861093878746033,
            "answer": "illustrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9384080469608307
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8299704194068909,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8247461915016174,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8100666999816895,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.754033088684082,
            "answer": "builds",
            "hit": false
          },
          {
            "score": 0.7499006986618042,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7495790719985962,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8299704492092133
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8499898910522461,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8386297821998596,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.826550304889679,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8006325960159302,
            "answer": "finds",
            "hit": false
          },
          {
            "score": 0.7698039412498474,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.765107274055481,
            "answer": "reveals",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8499899208545685
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.9485578536987305,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.9146490097045898,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8795918226242065,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.8507792949676514,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.839383602142334,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8359248638153076,
            "answer": "enabled",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9485578536987305
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7518439292907715,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7435075640678406,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7249581813812256,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7209379076957703,
            "answer": "new",
            "hit": false
          },
          {
            "score": 0.720731258392334,
            "answer": "builds",
            "hit": false
          },
          {
            "score": 0.7178267240524292,
            "answer": "extends",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6880126744508743
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8780444264411926,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8344886898994446,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.820393443107605,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8200113773345947,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7971895933151245,
            "answer": "illustrates",
            "hit": false
          },
          {
            "score": 0.7964907288551331,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8780444264411926
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8848875164985657,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7934262752532959,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.780205249786377,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.766547679901123,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.7546346783638,
            "answer": "prompted",
            "hit": false
          },
          {
            "score": 0.7492728233337402,
            "answer": "triggered",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8848875164985657
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.867280125617981,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8183772563934326,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.815768301486969,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.7952827215194702,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.761612057685852,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7447942495346069,
            "answer": "goes",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8672801554203033
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8385239839553833,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7602354884147644,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.730611264705658,
            "answer": "sentencing",
            "hit": false
          },
          {
            "score": 0.7272729873657227,
            "answer": "testimony",
            "hit": false
          },
          {
            "score": 0.722695529460907,
            "answer": "proceedings",
            "hit": false
          },
          {
            "score": 0.7220032811164856,
            "answer": "hear",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7602355182170868
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8673696517944336,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8641270399093628,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8473585247993469,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.812369167804718,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7886589765548706,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7639377117156982,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8673697113990784
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8370382189750671,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7912870049476624,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7825648784637451,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7721400856971741,
            "answer": "ranging",
            "hit": false
          },
          {
            "score": 0.7637951374053955,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7621567249298096,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8370382487773895
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8256568908691406,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7629039287567139,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7458944320678711,
            "answer": "handles",
            "hit": false
          },
          {
            "score": 0.7440308928489685,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7334346175193787,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7297695279121399,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8256568610668182
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8112982511520386,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.8056958913803101,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7977832555770874,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7799292206764221,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.7782930135726929,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7590280771255493,
            "answer": "taught",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8112983107566833
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8853482604026794,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.861278235912323,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8584725856781006,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7542603015899658,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7344308495521545,
            "answer": "defeats",
            "hit": false
          },
          {
            "score": 0.7268111705780029,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8853482902050018
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8017338514328003,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.801051139831543,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.752748429775238,
            "answer": "handles",
            "hit": false
          },
          {
            "score": 0.7342647910118103,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7124680876731873,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.7116794586181641,
            "answer": "helps",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8010511696338654
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9021580219268799,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8742110133171082,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8339982628822327,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8039413690567017,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7961156368255615,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7685263156890869,
            "answer": "occurrence",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9021580219268799
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.7928166389465332,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7924712896347046,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7604658603668213,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7533743381500244,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7477264404296875,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.7063165903091431,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7928166687488556
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8962715268135071,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.861564040184021,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8576241731643677,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.759742796421051,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7572236657142639,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7289978265762329,
            "answer": "sings",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8962715566158295
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8950142860412598,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8700379133224487,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.7746164798736572,
            "answer": "emphasizes",
            "hit": false
          },
          {
            "score": 0.7555183172225952,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.7546716928482056,
            "answer": "focuses",
            "hit": false
          },
          {
            "score": 0.7505234479904175,
            "answer": "supports",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8950143754482269
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9282587170600891,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8623459935188293,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8338524103164673,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.8333237171173096,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.8250733613967896,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8232109546661377,
            "answer": "provided",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9282587468624115
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9021481871604919,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8721199035644531,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.842686653137207,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7719154357910156,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7410621643066406,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7389620542526245,
            "answer": "accepts",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9021481871604919
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9206506013870239,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8867590427398682,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.84459388256073,
            "answer": "lowers",
            "hit": false
          },
          {
            "score": 0.8125386238098145,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8009783029556274,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7972126007080078,
            "answer": "lowering",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9206506311893463
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8259047269821167,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7834567427635193,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7757627367973328,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7714415788650513,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7701864838600159,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7684283256530762,
            "answer": "cites",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8259046971797943
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8553833961486816,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8496590852737427,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8385072946548462,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.8109956383705139,
            "answer": "related",
            "hit": false
          },
          {
            "score": 0.8096038103103638,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7886736392974854,
            "answer": "relate",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8553833961486816
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7313896417617798,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7239400744438171,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.719196081161499,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.716913104057312,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.7101972103118896,
            "answer": "leaves",
            "hit": false
          },
          {
            "score": 0.7087230682373047,
            "answer": "remains",
            "hit": true
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7087230533361435
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8840197324752808,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.8743978142738342,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.8291863799095154,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.788704514503479,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7673678398132324,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7660508155822754,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8840197324752808
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9236676692962646,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.8764395713806152,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8406524062156677,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8291541337966919,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.801231861114502,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7951939105987549,
            "answer": "applies",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9236676692962646
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.818261981010437,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.774467408657074,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7659598588943481,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7615776658058167,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7506527304649353,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.7497853636741638,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.818261981010437
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8864445090293884,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.8486075401306152,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.8481642007827759,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.7792664766311646,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.762401282787323,
            "answer": "hangs",
            "hit": false
          },
          {
            "score": 0.7548739910125732,
            "answer": "staring",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8864445388317108
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.7972418069839478,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7967793345451355,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7950785756111145,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.792853832244873,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.7779948711395264,
            "answer": "budgets",
            "hit": false
          },
          {
            "score": 0.758171796798706,
            "answer": "budget",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7928538024425507
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8918197154998779,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8495123982429504,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.8404130935668945,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.8166433572769165,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8115396499633789,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8018226623535156,
            "answer": "indicating",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8918198049068451
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8577753901481628,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8436236381530762,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8393776416778564,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7897725701332092,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7865841388702393,
            "answer": "curriculum",
            "hit": false
          },
          {
            "score": 0.7762418389320374,
            "answer": "learning",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8577753901481628
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.9044586420059204,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8552916049957275,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8247599601745605,
            "answer": "reminds",
            "hit": false
          },
          {
            "score": 0.807883620262146,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7966892123222351,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7879365682601929,
            "answer": "reminded",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.904458612203598
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.7871503233909607,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7812105417251587,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.7706060409545898,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.770574688911438,
            "answer": "insight",
            "hit": false
          },
          {
            "score": 0.7373048067092896,
            "answer": "illustrates",
            "hit": false
          },
          {
            "score": 0.7352665066719055,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7706060707569122
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 47,
      "accuracy": 0.8085106382978723
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "209253a5-29f0-4dce-a8a7-82307f1ac095",
      "timestamp": "2025-05-18T13:34:04.112497"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8884446620941162,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8370193243026733,
            "answer": "said",
            "hit": false
          },
          {
            "score": 0.8276907205581665,
            "answer": "noting",
            "hit": false
          },
          {
            "score": 0.8170350790023804,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.8014606237411499,
            "answer": "noted",
            "hit": false
          },
          {
            "score": 0.7832133173942566,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8884446918964386
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.91974276304245,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7896860241889954,
            "answer": "persuaded",
            "hit": false
          },
          {
            "score": 0.7754281163215637,
            "answer": "negotiated",
            "hit": false
          },
          {
            "score": 0.7595456838607788,
            "answer": "decided",
            "hit": false
          },
          {
            "score": 0.7559260725975037,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7540960907936096,
            "answer": "signed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9197427928447723
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9007804989814758,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8515010476112366,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8388586044311523,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8142970204353333,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8128399848937988,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.7785342931747437,
            "answer": "lets",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9007804989814758
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9010137915611267,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8556607365608215,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8116132020950317,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7921456098556519,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7740302085876465,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7328237295150757,
            "answer": "disclosed",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9010137915611267
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8604570031166077,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8147612810134888,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7648099660873413,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.764244019985199,
            "answer": "featured",
            "hit": false
          },
          {
            "score": 0.7558777332305908,
            "answer": "aired",
            "hit": false
          },
          {
            "score": 0.7442651987075806,
            "answer": "appearances",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.86045703291893
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.9271154403686523,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8645057082176208,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7378629446029663,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7241346836090088,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.7237614393234253,
            "answer": "employed",
            "hit": false
          },
          {
            "score": 0.7215108871459961,
            "answer": "application",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9271154701709747
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8890829682350159,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8634893894195557,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8479965925216675,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.8228870034217834,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.808504045009613,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.7769829630851746,
            "answer": "begged",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8890830278396606
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.9240261912345886,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8953766822814941,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.7890528440475464,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7816646099090576,
            "answer": "hosted",
            "hit": false
          },
          {
            "score": 0.7666105628013611,
            "answer": "invited",
            "hit": false
          },
          {
            "score": 0.7610867023468018,
            "answer": "participating",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.924026221036911
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.9021958112716675,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8917503952980042,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8259868621826172,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.727289080619812,
            "answer": "emerged",
            "hit": false
          },
          {
            "score": 0.7204990386962891,
            "answer": "increasingly",
            "hit": false
          },
          {
            "score": 0.7158581018447876,
            "answer": "regarded",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8917503654956818
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8203321695327759,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7805647253990173,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7450270652770996,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7432807683944702,
            "answer": "contemplated",
            "hit": false
          },
          {
            "score": 0.7284209132194519,
            "answer": "discussed",
            "hit": false
          },
          {
            "score": 0.725940465927124,
            "answer": "decided",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7805647552013397
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.851667046546936,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8303897380828857,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8129725456237793,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7474948167800903,
            "answer": "retrieved",
            "hit": false
          },
          {
            "score": 0.7235396504402161,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7221854329109192,
            "answer": "produced",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8516670763492584
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8813969492912292,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8377907276153564,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8361989259719849,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8357360363006592,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7513443827629089,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7333247661590576,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8813969194889069
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.911150336265564,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8851125240325928,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8395739197731018,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8038936257362366,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7645652294158936,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7517002820968628,
            "answer": "forming",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9111503660678864
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8691233992576599,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8113152980804443,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.7987087965011597,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7855578660964966,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7636368274688721,
            "answer": "choosing",
            "hit": false
          },
          {
            "score": 0.7592304944992065,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8113152980804443
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.9104950428009033,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8813055157661438,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8370558619499207,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.809984028339386,
            "answer": "characterized",
            "hit": false
          },
          {
            "score": 0.8061779737472534,
            "answer": "termed",
            "hit": false
          },
          {
            "score": 0.7747299671173096,
            "answer": "detailing",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9104950726032257
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8884180784225464,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8273528814315796,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7690474390983582,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7472283840179443,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7406500577926636,
            "answer": "emerging",
            "hit": false
          },
          {
            "score": 0.7216107845306396,
            "answer": "producing",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8884180784225464
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.9039090871810913,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8857135772705078,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8089436888694763,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7627654075622559,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.7438482046127319,
            "answer": "formed",
            "hit": false
          },
          {
            "score": 0.7399076223373413,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9039090871810913
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7177395224571228,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7149722576141357,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.7095540761947632,
            "answer": "new",
            "hit": false
          },
          {
            "score": 0.7069063782691956,
            "answer": "proposed",
            "hit": false
          },
          {
            "score": 0.7026492953300476,
            "answer": "expanded",
            "hit": false
          },
          {
            "score": 0.7023796439170837,
            "answer": "adjacent",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 54,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6571624279022217
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8327029347419739,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8116267323493958,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7840847969055176,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.779001772403717,
            "answer": "surprised",
            "hit": false
          },
          {
            "score": 0.7628490328788757,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.7474911212921143,
            "answer": "hoped",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8116267323493958
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.9193781018257141,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8390411138534546,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.8096669316291809,
            "answer": "unable",
            "hit": false
          },
          {
            "score": 0.7984858751296997,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.7977957725524902,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.7782597541809082,
            "answer": "inability",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9193781018257141
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8255709409713745,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8123339414596558,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.8109365105628967,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7964524626731873,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.7641737461090088,
            "answer": "triggered",
            "hit": false
          },
          {
            "score": 0.7620142698287964,
            "answer": "preceding",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8255709409713745
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8577529788017273,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7598114013671875,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7491683959960938,
            "answer": "testimony",
            "hit": false
          },
          {
            "score": 0.7483927011489868,
            "answer": "sentencing",
            "hit": false
          },
          {
            "score": 0.7407181859016418,
            "answer": "meeting",
            "hit": false
          },
          {
            "score": 0.7384799718856812,
            "answer": "proceedings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7598114311695099
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8970188498497009,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8778782486915588,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.802378237247467,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.800853431224823,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7911896109580994,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.786024808883667,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8970188796520233
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8210073709487915,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.789873480796814,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7801340222358704,
            "answer": "ranging",
            "hit": false
          },
          {
            "score": 0.7627404928207397,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7441025972366333,
            "answer": "notably",
            "hit": false
          },
          {
            "score": 0.7422260046005249,
            "answer": "plus",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8210073709487915
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9249384999275208,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8873329758644104,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8286834955215454,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.8125004768371582,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.7759840488433838,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7750272750854492,
            "answer": "launching",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9249385893344879
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.7673500776290894,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7542994022369385,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7448987364768982,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7443963885307312,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.7403709292411804,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7351124286651611,
            "answer": "related",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.767350047826767
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8551855087280273,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7435870170593262,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7375425696372986,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.7243021130561829,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7129653692245483,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7101820707321167,
            "answer": "identify",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7243021130561829
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.909169614315033,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8718549013137817,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8007764220237732,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7711856961250305,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7701955437660217,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7604370713233948,
            "answer": "won",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9091695547103882
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8121500015258789,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7440962791442871,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7313598394393921,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7248140573501587,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7180627584457397,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.7158502340316772,
            "answer": "oversee",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7313598245382309
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8869245052337646,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8834352493286133,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.8181858658790588,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.8142654895782471,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.776291012763977,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7492848634719849,
            "answer": "born",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8869245648384094
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7987787127494812,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7899873852729797,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7888462543487549,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.7686989903450012,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.734629213809967,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7262701988220215,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888462841510773
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.913485050201416,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8697419166564941,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.824569821357727,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7768572568893433,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7560023069381714,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7197378873825073,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9134850800037384
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8613787889480591,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.848516583442688,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8376555442810059,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.7798593640327454,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7682825922966003,
            "answer": "advocated",
            "hit": false
          },
          {
            "score": 0.763140082359314,
            "answer": "agreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8613788485527039
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8930776715278625,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8890761137008667,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.856403112411499,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7835597991943359,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7832238078117371,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7825640439987183,
            "answer": "delivering",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8930776715278625
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8444617390632629,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.8116369247436523,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7836227416992188,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7782712578773499,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7702001333236694,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7517054080963135,
            "answer": "publications",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.770200103521347
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9192079305648804,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8450222611427307,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8114767670631409,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7675498723983765,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7426328659057617,
            "answer": "awarded",
            "hit": false
          },
          {
            "score": 0.7338013052940369,
            "answer": "recipient",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9192079305648804
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.9123625159263611,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.863860547542572,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8533670902252197,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8445947170257568,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8277365565299988,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8183591365814209,
            "answer": "lowering",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8638605773448944
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8686415553092957,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8512047529220581,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.8342186212539673,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.8181782960891724,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.798711359500885,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7910251617431641,
            "answer": "relate",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8342186510562897
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.752195417881012,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7462315559387207,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.7191379070281982,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7175596356391907,
            "answer": "only",
            "hit": false
          },
          {
            "score": 0.7106775045394897,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7089831233024597,
            "answer": "retained",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7106775045394897
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.9048313498497009,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8910217881202698,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8482033014297485,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8210533857345581,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7746151685714722,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7191069722175598,
            "answer": "installing",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9048313200473785
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.9159305691719055,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8318038582801819,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.8184657096862793,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7628532648086548,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.746395468711853,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7322155237197876,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9159305691719055
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8806101083755493,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8721718192100525,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8616348505020142,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8057155609130859,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.783236563205719,
            "answer": "mandated",
            "hit": false
          },
          {
            "score": 0.771989107131958,
            "answer": "allow",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8721718788146973
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9399518966674805,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8815442323684692,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8326808214187622,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7348552942276001,
            "answer": "delivered",
            "hit": false
          },
          {
            "score": 0.7281378507614136,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7139803767204285,
            "answer": "flew",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9399518668651581
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8149124383926392,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.8143794536590576,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7937813401222229,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.7857974767684937,
            "answer": "budgets",
            "hit": false
          },
          {
            "score": 0.7696850299835205,
            "answer": "budget",
            "hit": false
          },
          {
            "score": 0.75531005859375,
            "answer": "spent",
            "hit": true
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7553100883960724
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8894478678703308,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8318941593170166,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8304274678230286,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.7861836552619934,
            "answer": "inflicted",
            "hit": false
          },
          {
            "score": 0.7663701772689819,
            "answer": "endured",
            "hit": false
          },
          {
            "score": 0.7636922597885132,
            "answer": "severe",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8894478976726532
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8844144344329834,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.8490104079246521,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.800965428352356,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7985626459121704,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7975568175315857,
            "answer": "curriculum",
            "hit": false
          },
          {
            "score": 0.7851612567901611,
            "answer": "learning",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.884414404630661
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.862913966178894,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.8485590219497681,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8287778496742249,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8190498352050781,
            "answer": "reminded",
            "hit": false
          },
          {
            "score": 0.7836153507232666,
            "answer": "reminding",
            "hit": false
          },
          {
            "score": 0.7820922136306763,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8485589921474457
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8037209510803223,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.7904632687568665,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7670385837554932,
            "answer": "insight",
            "hit": false
          },
          {
            "score": 0.7612408995628357,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.736112654209137,
            "answer": "insights",
            "hit": false
          },
          {
            "score": 0.7341233491897583,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7612409293651581
      }
    ],
    "result": {
      "cnt_questions_correct": 31,
      "cnt_questions_total": 48,
      "accuracy": 0.6458333333333334
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "26ddbe63-d48a-4d9d-ab92-8cefa9e36e1c",
      "timestamp": "2025-05-18T13:34:04.245829"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8789750337600708,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.8416176438331604,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7778635025024414,
            "answer": "noted",
            "hit": false
          },
          {
            "score": 0.7765456438064575,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.7635756731033325,
            "answer": "said",
            "hit": false
          },
          {
            "score": 0.7583872079849243,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8789750933647156
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.860083818435669,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8164250254631042,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8088881373405457,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7808396220207214,
            "answer": "persuaded",
            "hit": false
          },
          {
            "score": 0.779323160648346,
            "answer": "convinced",
            "hit": false
          },
          {
            "score": 0.7632977962493896,
            "answer": "agreeing",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8600837886333466
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8828542828559875,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8611052632331848,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8552301526069641,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.852948784828186,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8399749398231506,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.8334416747093201,
            "answer": "lets",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.795608788728714
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.9176711440086365,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8766264915466309,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8370772004127502,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7447395920753479,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7307426333427429,
            "answer": "confirmed",
            "hit": false
          },
          {
            "score": 0.7259886860847473,
            "answer": "commenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9176711142063141
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8776366710662842,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8274414539337158,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8256301283836365,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7868548035621643,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7796388864517212,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7775382995605469,
            "answer": "appear",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8776366412639618
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8367597460746765,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8283107876777649,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.787542462348938,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7435178160667419,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7363860607147217,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7338175177574158,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8283107578754425
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.9196037650108337,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8698601722717285,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8568943738937378,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7902921438217163,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.7796213626861572,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7749083638191223,
            "answer": "instructed",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9196037948131561
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8930453658103943,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8713624477386475,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8430664539337158,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7277859449386597,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.7194990515708923,
            "answer": "was",
            "hit": false
          },
          {
            "score": 0.7178822755813599,
            "answer": "emerged",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8930453658103943
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8243032097816467,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8172644376754761,
            "answer": "insisted",
            "hit": false
          },
          {
            "score": 0.8125556707382202,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8119783401489258,
            "answer": "acknowledged",
            "hit": false
          },
          {
            "score": 0.8038332462310791,
            "answer": "argued",
            "hit": false
          },
          {
            "score": 0.8038222789764404,
            "answer": "convinced",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8243032395839691
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8549225330352783,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7944091558456421,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.7826852202415466,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.7773265242576599,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7747324109077454,
            "answer": "acknowledged",
            "hit": false
          },
          {
            "score": 0.7719162106513977,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8549225628376007
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9247016906738281,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.9088826179504395,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8938754796981812,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8938571810722351,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8811315298080444,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8467090129852295,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9247017800807953
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8545427322387695,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8397800922393799,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8272151947021484,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7817769050598145,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7692288160324097,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7381094694137573,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8545427024364471
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.9152931571006775,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.852882981300354,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8496772646903992,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7559757828712463,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.7497004270553589,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7483837008476257,
            "answer": "began",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9152931272983551
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8873331546783447,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.8618400692939758,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8543599843978882,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7400839328765869,
            "answer": "generated",
            "hit": false
          },
          {
            "score": 0.7388774156570435,
            "answer": "caused",
            "hit": false
          },
          {
            "score": 0.7308050394058228,
            "answer": "resulting",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8873331546783447
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8677063584327698,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8548673987388611,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8084828853607178,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.8051767349243164,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7990667223930359,
            "answer": "persuaded",
            "hit": false
          },
          {
            "score": 0.7753260135650635,
            "answer": "asked",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8677063584327698
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.9139212369918823,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8799859881401062,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7995662093162537,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.794408917427063,
            "answer": "characterized",
            "hit": false
          },
          {
            "score": 0.7893624305725098,
            "answer": "termed",
            "hit": false
          },
          {
            "score": 0.7792010307312012,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9139211773872375
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8131370544433594,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7784727811813354,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7551389932632446,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7151979207992554,
            "answer": "builds",
            "hit": false
          },
          {
            "score": 0.7017865180969238,
            "answer": "acquired",
            "hit": false
          },
          {
            "score": 0.7013769745826721,
            "answer": "formed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131370544433594
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8570003509521484,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8240224719047546,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8190900087356567,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.72396320104599,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7233990430831909,
            "answer": "set",
            "hit": false
          },
          {
            "score": 0.7181394100189209,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8570003807544708
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8513922691345215,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8252270221710205,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.8062018156051636,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.784492015838623,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.7820075750350952,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7695591449737549,
            "answer": "expecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8513922691345215
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.9023348689079285,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8603863716125488,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8227572441101074,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8170152902603149,
            "answer": "unable",
            "hit": false
          },
          {
            "score": 0.7936416268348694,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7600772380828857,
            "answer": "did",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9023348689079285
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.870633602142334,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8524300456047058,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7682914137840271,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.7630070447921753,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7572531700134277,
            "answer": "prompted",
            "hit": false
          },
          {
            "score": 0.7514714002609253,
            "answer": "included",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870633602142334
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.8650494813919067,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8516060709953308,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8250621557235718,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7974966764450073,
            "answer": "going",
            "hit": false
          },
          {
            "score": 0.7758680582046509,
            "answer": "done",
            "hit": false
          },
          {
            "score": 0.7554978132247925,
            "answer": "know",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8516060709953308
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8937454223632812,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8439176678657532,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7713046073913574,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7281984090805054,
            "answer": "uttered",
            "hit": false
          },
          {
            "score": 0.7218720316886902,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.7215478420257568,
            "answer": "hearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8937453925609589
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.9122124314308167,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.8414536118507385,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.8275755047798157,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8096050024032593,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.806293249130249,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7975658178329468,
            "answer": "consist",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.912212461233139
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8432602882385254,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.8075041770935059,
            "answer": "plans",
            "hit": false
          },
          {
            "score": 0.7979971170425415,
            "answer": "decided",
            "hit": false
          },
          {
            "score": 0.7940011024475098,
            "answer": "planned",
            "hit": false
          },
          {
            "score": 0.7876495718955994,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.779228150844574,
            "answer": "pledged",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7515571713447571
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8703347444534302,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8410634398460388,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8267424702644348,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.776511549949646,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.764636754989624,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.761215090751648,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870334804058075
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8709676265716553,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7978808879852295,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7825002074241638,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7591711282730103,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.7588798999786377,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.758742094039917,
            "answer": "involved",
            "hit": true
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.758742094039917
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8785410523414612,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8565067052841187,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8386911153793335,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7673859000205994,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7373828291893005,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.7371824979782104,
            "answer": "dies",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.878541111946106
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8569562435150146,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7591301202774048,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7305616140365601,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7282642126083374,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.7226403951644897,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7161400318145752,
            "answer": "handles",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8569563031196594
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.8714450001716614,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8594264388084412,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8499423265457153,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.7573407292366028,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.7558925151824951,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7326611876487732,
            "answer": "observed",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8499422967433929
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8698044419288635,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.8316943049430847,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7699902057647705,
            "answer": "located",
            "hit": false
          },
          {
            "score": 0.7628015279769897,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.7504844665527344,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7382766008377075,
            "answer": "operating",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8698044717311859
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9319203495979309,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8775534629821777,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8427993655204773,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7380924820899963,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.7221763134002686,
            "answer": "underwent",
            "hit": false
          },
          {
            "score": 0.7219285368919373,
            "answer": "played",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9319203197956085
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8625526428222656,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8513007164001465,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8423209190368652,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8087007403373718,
            "answer": "advocated",
            "hit": false
          },
          {
            "score": 0.7830560207366943,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.778429388999939,
            "answer": "recommended",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8513007164001465
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8680002689361572,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8543674945831299,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8508070111274719,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8366769552230835,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.775428295135498,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7718883752822876,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8508070111274719
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9099885821342468,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8687418699264526,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.855869472026825,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.777977705001831,
            "answer": "awarded",
            "hit": false
          },
          {
            "score": 0.7734301090240479,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7599189281463623,
            "answer": "collected",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9099885523319244
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8631551265716553,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8264483213424683,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8107408285140991,
            "answer": "coined",
            "hit": false
          },
          {
            "score": 0.7788516283035278,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7754979133605957,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7718580961227417,
            "answer": "referring",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631551265716553
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8014392256736755,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7975965738296509,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7798653244972229,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7734880447387695,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7677847743034363,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.7590644359588623,
            "answer": "relation",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798652946949005
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8897294998168945,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8404785394668579,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7771977186203003,
            "answer": "still",
            "hit": false
          },
          {
            "score": 0.7574577927589417,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7487260699272156,
            "answer": "was",
            "hit": false
          },
          {
            "score": 0.7340203523635864,
            "answer": "been",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8897295296192169
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8795545101165771,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8247839212417603,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8209612965583801,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7615427374839783,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7274819612503052,
            "answer": "resigned",
            "hit": false
          },
          {
            "score": 0.72562575340271,
            "answer": "appointed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8795544505119324
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8691899180412292,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.837053656578064,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.8227586150169373,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7292736768722534,
            "answer": "amounted",
            "hit": false
          },
          {
            "score": 0.7212002277374268,
            "answer": "marked",
            "hit": false
          },
          {
            "score": 0.7127525210380554,
            "answer": "reflects",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8691899478435516
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8914892077445984,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.8784923553466797,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8669748306274414,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.769051194190979,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7541422843933105,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.7474751472473145,
            "answer": "allows",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8914892375469208
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.900588870048523,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8506815433502197,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8399417400360107,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7974756956100464,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7819327116012573,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7682326436042786,
            "answer": "evidently",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.900588870048523
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.9159220457077026,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.8732998371124268,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8699744343757629,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7374680042266846,
            "answer": "delivered",
            "hit": false
          },
          {
            "score": 0.7333385944366455,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7270177602767944,
            "answer": "brought",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9159220457077026
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.9316843152046204,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8562992215156555,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.7627344131469727,
            "answer": "devoted",
            "hit": false
          },
          {
            "score": 0.7486268877983093,
            "answer": "wasted",
            "hit": false
          },
          {
            "score": 0.7475398182868958,
            "answer": "devote",
            "hit": false
          },
          {
            "score": 0.7338837385177612,
            "answer": "spending",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9316843748092651
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.886298418045044,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8710691332817078,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.8459504246711731,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8454127311706543,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8411329388618469,
            "answer": "indicated",
            "hit": false
          },
          {
            "score": 0.816969633102417,
            "answer": "indicate",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.886298418045044
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.9020258784294128,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8433696627616882,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8305551409721375,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7705104947090149,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7627846002578735,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7624992728233337,
            "answer": "quoted",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9020259082317352
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 46,
      "accuracy": 0.8043478260869565
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f7f67447-ffbe-4607-9d05-382371aa4436",
      "timestamp": "2025-05-18T13:34:04.383980"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.8126398324966431,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.7104171514511108,
            "answer": "brutal",
            "hit": false
          },
          {
            "score": 0.6744709014892578,
            "answer": "vengeance",
            "hit": false
          },
          {
            "score": 0.6679511070251465,
            "answer": "greedy",
            "hit": false
          },
          {
            "score": 0.6676198244094849,
            "answer": "relentless",
            "hit": false
          },
          {
            "score": 0.6674965620040894,
            "answer": "mercy",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 4650,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5366857722401619
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7913029193878174,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.7046219110488892,
            "answer": "elaine",
            "hit": false
          },
          {
            "score": 0.7028090953826904,
            "answer": "deborah",
            "hit": false
          },
          {
            "score": 0.7020399570465088,
            "answer": "peggy",
            "hit": false
          },
          {
            "score": 0.7004647850990295,
            "answer": "dorothy",
            "hit": false
          },
          {
            "score": 0.7000204920768738,
            "answer": "esther",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 8898,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5035991000477225
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "47f775d7-d094-46e1-b4a6-3a1985b0659f",
      "timestamp": "2025-05-18T13:34:04.514819"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.8774702548980713,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.7873966693878174,
            "answer": "trying",
            "hit": false
          },
          {
            "score": 0.7745303511619568,
            "answer": "attempting",
            "hit": false
          },
          {
            "score": 0.7651766538619995,
            "answer": "forced",
            "hit": false
          },
          {
            "score": 0.7583946585655212,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.7574707269668579,
            "answer": "compelled",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8774702548980713
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8605886697769165,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.7563364505767822,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7539165616035461,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.7478916645050049,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.746444821357727,
            "answer": "unsafe",
            "hit": false
          },
          {
            "score": 0.7455670237541199,
            "answer": "appropriate",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8605886399745941
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8629438877105713,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8164358139038086,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.8036202788352966,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.7978009581565857,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7840781211853027,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.7755720615386963,
            "answer": "damaged",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7978009581565857
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.7790193557739258,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.7524360418319702,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.7322009801864624,
            "answer": "availability",
            "hit": false
          },
          {
            "score": 0.7148871421813965,
            "answer": "scarce",
            "hit": false
          },
          {
            "score": 0.7120389938354492,
            "answer": "accessed",
            "hit": false
          },
          {
            "score": 0.7040077447891235,
            "answer": "inaccessible",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7790193557739258
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.880264937877655,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.8007768392562866,
            "answer": "concerned",
            "hit": false
          },
          {
            "score": 0.7683005928993225,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.7561547756195068,
            "answer": "alarmed",
            "hit": false
          },
          {
            "score": 0.7491687536239624,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7470009922981262,
            "answer": "understand",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8802649974822998
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7409067749977112,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7406260967254639,
            "answer": "some",
            "hit": false
          },
          {
            "score": 0.7374249696731567,
            "answer": "these",
            "hit": false
          },
          {
            "score": 0.7336592674255371,
            "answer": "particular",
            "hit": false
          },
          {
            "score": 0.7293684482574463,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7292327284812927,
            "answer": "all",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 88,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6642184108495712
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.8466557264328003,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.8296194076538086,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.8281219005584717,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.8092845678329468,
            "answer": "alter",
            "hit": false
          },
          {
            "score": 0.7742854356765747,
            "answer": "altering",
            "hit": false
          },
          {
            "score": 0.7593415379524231,
            "answer": "reversed",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6848618537187576
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8470684289932251,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.7753199934959412,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.7741576433181763,
            "answer": "relaxed",
            "hit": false
          },
          {
            "score": 0.7509961128234863,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7418282628059387,
            "answer": "awkward",
            "hit": false
          },
          {
            "score": 0.7247209548950195,
            "answer": "confident",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8470684289932251
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.7243894934654236,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.703797459602356,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.7025476694107056,
            "answer": "fearful",
            "hit": false
          },
          {
            "score": 0.7022219896316528,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6993549466133118,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.6957242488861084,
            "answer": "aware",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7037975043058395
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8283100128173828,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.8075215220451355,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7674967050552368,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7451140284538269,
            "answer": "hired",
            "hit": false
          },
          {
            "score": 0.7364472150802612,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.7165311574935913,
            "answer": "employment",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7364472448825836
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.8281343579292297,
            "answer": "likely",
            "hit": false
          },
          {
            "score": 0.8028684854507446,
            "answer": "slated",
            "hit": false
          },
          {
            "score": 0.7972864508628845,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.78889000415802,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.7873609066009521,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7866542339324951,
            "answer": "scheduled",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 95,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6552048921585083
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.8560200929641724,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.8152890205383301,
            "answer": "finish",
            "hit": false
          },
          {
            "score": 0.779043436050415,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.7614344954490662,
            "answer": "tied",
            "hit": false
          },
          {
            "score": 0.7368769645690918,
            "answer": "scored",
            "hit": false
          },
          {
            "score": 0.7341159582138062,
            "answer": "eighth",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6891359090805054
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.827996015548706,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.8031264543533325,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.8004318475723267,
            "answer": "grateful",
            "hit": false
          },
          {
            "score": 0.7732281684875488,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.770093560218811,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.7470946907997131,
            "answer": "glad",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7700935900211334
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.8437943458557129,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.8411002159118652,
            "answer": "glad",
            "hit": false
          },
          {
            "score": 0.8102616667747498,
            "answer": "disappointed",
            "hit": false
          },
          {
            "score": 0.7986979484558105,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7937097549438477,
            "answer": "pleased",
            "hit": false
          },
          {
            "score": 0.7915558815002441,
            "answer": "thankful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8437943756580353
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.810786247253418,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7795885801315308,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.7767575979232788,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7668794989585876,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.736167311668396,
            "answer": "unknown",
            "hit": false
          },
          {
            "score": 0.7275698184967041,
            "answer": "referred",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7795886099338531
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7790119647979736,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.7629314661026001,
            "answer": "unknown",
            "hit": true
          },
          {
            "score": 0.7436450719833374,
            "answer": "dubbed",
            "hit": false
          },
          {
            "score": 0.730063796043396,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7259002923965454,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7168521881103516,
            "answer": "described",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7629314363002777
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8254515528678894,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7672812342643738,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7493482232093811,
            "answer": "legally",
            "hit": false
          },
          {
            "score": 0.7454346418380737,
            "answer": "unconstitutional",
            "hit": false
          },
          {
            "score": 0.7450239062309265,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7449136972427368,
            "answer": "unauthorized",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8254515528678894
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.8513803482055664,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.8403868079185486,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.8092536926269531,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.8069896697998047,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7898416519165039,
            "answer": "owed",
            "hit": false
          },
          {
            "score": 0.7250876426696777,
            "answer": "owes",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8069897294044495
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.845575213432312,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.8063607215881348,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7770432829856873,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.763918399810791,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.7626696825027466,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7619892358779907,
            "answer": "strange",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8455752730369568
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.7748472690582275,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.744469404220581,
            "answer": "controversial",
            "hit": false
          },
          {
            "score": 0.7393652200698853,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.7383467555046082,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7201371192932129,
            "answer": "favorite",
            "hit": false
          },
          {
            "score": 0.7199640274047852,
            "answer": "influential",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7748472690582275
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.7885854244232178,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7566197514533997,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.7409691214561462,
            "answer": "unpleasant",
            "hit": false
          },
          {
            "score": 0.739113450050354,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.7332742810249329,
            "answer": "bizarre",
            "hit": false
          },
          {
            "score": 0.7328352928161621,
            "answer": "inconsistent",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7885854244232178
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.7891680598258972,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.787682056427002,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7856054306030273,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.7562235593795776,
            "answer": "released",
            "hit": false
          },
          {
            "score": 0.7504810094833374,
            "answer": "reprinted",
            "hit": false
          },
          {
            "score": 0.7459729909896851,
            "answer": "article",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7856054306030273
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8437786102294922,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7507979869842529,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7473200559616089,
            "answer": "appropriate",
            "hit": false
          },
          {
            "score": 0.7467954754829407,
            "answer": "adequate",
            "hit": false
          },
          {
            "score": 0.7452748417854309,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7439706325531006,
            "answer": "absurd",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8437785506248474
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.8363543152809143,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.8330904245376587,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7934308648109436,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.7889543175697327,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7664647698402405,
            "answer": "stemming",
            "hit": false
          },
          {
            "score": 0.757221519947052,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8363543152809143
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8260073065757751,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.7758744955062866,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.7388623952865601,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7281947135925293,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7259149551391602,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.7216620445251465,
            "answer": "credible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8260072469711304
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.812032163143158,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7962835431098938,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.777732253074646,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7465934157371521,
            "answer": "certain",
            "hit": false
          },
          {
            "score": 0.7423757314682007,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7387471199035645,
            "answer": "unspecified",
            "hit": true
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7387471050024033
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.788422703742981,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.781524658203125,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7295556664466858,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7229249477386475,
            "answer": "disastrous",
            "hit": false
          },
          {
            "score": 0.7159540057182312,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.7152667045593262,
            "answer": "successfully",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7884226739406586
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.8066244125366211,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.7873878479003906,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.7868388891220093,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.7842990159988403,
            "answer": "use",
            "hit": false
          },
          {
            "score": 0.745535135269165,
            "answer": "intended",
            "hit": false
          },
          {
            "score": 0.7114884853363037,
            "answer": "relied",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7048083692789078
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7378126382827759,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7172484397888184,
            "answer": "normal",
            "hit": false
          },
          {
            "score": 0.7164807319641113,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7110744118690491,
            "answer": "rather",
            "hit": false
          },
          {
            "score": 0.7108184099197388,
            "answer": "predictable",
            "hit": false
          },
          {
            "score": 0.701774537563324,
            "answer": "mundane",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6527299731969833
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.8086807727813721,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.8063278198242188,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.7969814538955688,
            "answer": "tried",
            "hit": false
          },
          {
            "score": 0.7932432889938354,
            "answer": "refused",
            "hit": false
          },
          {
            "score": 0.7896161079406738,
            "answer": "did",
            "hit": false
          },
          {
            "score": 0.7866967916488647,
            "answer": "decided",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 1057,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.597704716026783
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 30,
      "accuracy": 0.4666666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "341136e1-cedb-4661-9ca7-11ad187d9772",
      "timestamp": "2025-05-18T13:34:04.525707"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7258994579315186,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7248297929763794,
            "answer": "reported",
            "hit": false
          },
          {
            "score": 0.7232056856155396,
            "answer": "noted",
            "hit": false
          },
          {
            "score": 0.7228604555130005,
            "answer": "citing",
            "hit": false
          },
          {
            "score": 0.7196290493011475,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7158423662185669,
            "answer": "indicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 231,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6124395728111267
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.8262096643447876,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.7418939471244812,
            "answer": "accurately",
            "hit": false
          },
          {
            "score": 0.7334994077682495,
            "answer": "exact",
            "hit": false
          },
          {
            "score": 0.7313011288642883,
            "answer": "approximate",
            "hit": false
          },
          {
            "score": 0.7271235585212708,
            "answer": "even",
            "hit": false
          },
          {
            "score": 0.723841667175293,
            "answer": "merely",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8262096345424652
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.7777407169342041,
            "answer": "extra",
            "hit": false
          },
          {
            "score": 0.7303926944732666,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7227487564086914,
            "answer": "approximately",
            "hit": false
          },
          {
            "score": 0.7164756655693054,
            "answer": "more",
            "hit": false
          },
          {
            "score": 0.7147722244262695,
            "answer": "excess",
            "hit": false
          },
          {
            "score": 0.6954811811447144,
            "answer": "already",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.67628113925457
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8144898414611816,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.8092830181121826,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7708594799041748,
            "answer": "apparently",
            "hit": true
          },
          {
            "score": 0.7388519048690796,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7199062705039978,
            "answer": "clear",
            "hit": false
          },
          {
            "score": 0.7193464636802673,
            "answer": "perceived",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7708595097064972
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.8790497779846191,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8699571490287781,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8286647796630859,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.7943597435951233,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.7826699018478394,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.7794308662414551,
            "answer": "fabulous",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8286647796630859
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.826816976070404,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.8133443593978882,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.8067570924758911,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.7800930738449097,
            "answer": "essential",
            "hit": false
          },
          {
            "score": 0.7636229395866394,
            "answer": "important",
            "hit": false
          },
          {
            "score": 0.7613611221313477,
            "answer": "key",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8268169462680817
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.8428536653518677,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.8186280131340027,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7933561205863953,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.7512874603271484,
            "answer": "heritage",
            "hit": false
          },
          {
            "score": 0.7388815879821777,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.7360519170761108,
            "answer": "socio",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8428536653518677
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8346230387687683,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.8337714076042175,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.8009892702102661,
            "answer": "persuaded",
            "hit": false
          },
          {
            "score": 0.793175220489502,
            "answer": "wanted",
            "hit": false
          },
          {
            "score": 0.7861597537994385,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7759606242179871,
            "answer": "decides",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 561,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.604278177022934
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.8430910110473633,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7725353240966797,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.7599100470542908,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7478820085525513,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7471796274185181,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.739181399345398,
            "answer": "varied",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8430909812450409
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8384497761726379,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7544384598731995,
            "answer": "multimedia",
            "hit": false
          },
          {
            "score": 0.7485498785972595,
            "answer": "formats",
            "hit": false
          },
          {
            "score": 0.7403437495231628,
            "answer": "analog",
            "hit": false
          },
          {
            "score": 0.7266936302185059,
            "answer": "analogue",
            "hit": false
          },
          {
            "score": 0.7264877557754517,
            "answer": "electronic",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8384498059749603
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7709113359451294,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7512316107749939,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7449567914009094,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.7217543125152588,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.7171427011489868,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7123982310295105,
            "answer": "responsive",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7449568212032318
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.8160960674285889,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.8062549233436584,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.7733587622642517,
            "answer": "pollution",
            "hit": false
          },
          {
            "score": 0.7617451548576355,
            "answer": "ecology",
            "hit": false
          },
          {
            "score": 0.7615745067596436,
            "answer": "eco",
            "hit": false
          },
          {
            "score": 0.76115882396698,
            "answer": "epa",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8160960376262665
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.7594394683837891,
            "answer": "thorough",
            "hit": false
          },
          {
            "score": 0.7542466521263123,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.7422337532043457,
            "answer": "expertise",
            "hit": false
          },
          {
            "score": 0.7227796912193298,
            "answer": "rigorous",
            "hit": false
          },
          {
            "score": 0.7196310758590698,
            "answer": "comprehensive",
            "hit": false
          },
          {
            "score": 0.7160901427268982,
            "answer": "expansive",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7542466521263123
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.8436547517776489,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7960954904556274,
            "answer": "legendary",
            "hit": false
          },
          {
            "score": 0.7892379760742188,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7832987904548645,
            "answer": "iconic",
            "hit": false
          },
          {
            "score": 0.7786073684692383,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.772942841053009,
            "answer": "renowned",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7892380058765411
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.788562536239624,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.7775521874427795,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7444782257080078,
            "answer": "banking",
            "hit": false
          },
          {
            "score": 0.7343814373016357,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7299599647521973,
            "answer": "fiscal",
            "hit": false
          },
          {
            "score": 0.7183219194412231,
            "answer": "debt",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7885625660419464
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8697062730789185,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.8206619620323181,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7810232043266296,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.7568994760513306,
            "answer": "globe",
            "hit": false
          },
          {
            "score": 0.7493330836296082,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.7431161999702454,
            "answer": "markets",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8697062432765961
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.7704569697380066,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.7634570598602295,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.7222375869750977,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.6975005865097046,
            "answer": "artifacts",
            "hit": false
          },
          {
            "score": 0.6930372714996338,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.692406177520752,
            "answer": "histories",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7634570598602295
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8529214859008789,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.8490086197853088,
            "answer": "big",
            "hit": false
          },
          {
            "score": 0.8399152159690857,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.8162118792533875,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.8075551390647888,
            "answer": "tremendous",
            "hit": false
          },
          {
            "score": 0.8061087131500244,
            "answer": "immense",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7505751848220825
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.7831905484199524,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7131311297416687,
            "answer": "swift",
            "hit": false
          },
          {
            "score": 0.7127776145935059,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.7040103673934937,
            "answer": "instant",
            "hit": false
          },
          {
            "score": 0.6969455480575562,
            "answer": "urgent",
            "hit": false
          },
          {
            "score": 0.6951772570610046,
            "answer": "any",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7831905782222748
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.8268886804580688,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.8160449266433716,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.7996943593025208,
            "answer": "essential",
            "hit": false
          },
          {
            "score": 0.7846581339836121,
            "answer": "imperative",
            "hit": false
          },
          {
            "score": 0.7739302515983582,
            "answer": "critical",
            "hit": false
          },
          {
            "score": 0.7732396721839905,
            "answer": "integral",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.767390787601471
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.8848013877868652,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8410192728042603,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.8124118447303772,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.8114194869995117,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.789370059967041,
            "answer": "growing",
            "hit": false
          },
          {
            "score": 0.7835652828216553,
            "answer": "rising",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7474073022603989
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.8398051857948303,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.7846879363059998,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7731716632843018,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.7024933099746704,
            "answer": "audit",
            "hit": false
          },
          {
            "score": 0.6851913928985596,
            "answer": "independently",
            "hit": false
          },
          {
            "score": 0.6851271986961365,
            "answer": "properly",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8398052155971527
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.8152981996536255,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7337507605552673,
            "answer": "foreign",
            "hit": false
          },
          {
            "score": 0.731021523475647,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.7158951759338379,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7154648900032043,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7140322327613831,
            "answer": "globally",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8152982294559479
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.7952255010604858,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7706679105758667,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7503218650817871,
            "answer": "litigation",
            "hit": false
          },
          {
            "score": 0.737411618232727,
            "answer": "attorneys",
            "hit": false
          },
          {
            "score": 0.7262260913848877,
            "answer": "counsel",
            "hit": false
          },
          {
            "score": 0.7187281847000122,
            "answer": "constitutional",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7952255308628082
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.845097541809082,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7706589698791504,
            "answer": "physically",
            "hit": false
          },
          {
            "score": 0.7660462260246277,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.7609632015228271,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7448267340660095,
            "answer": "physical",
            "hit": false
          },
          {
            "score": 0.7281936407089233,
            "answer": "emotionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.845097541809082
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.8172369599342346,
            "answer": "really",
            "hit": false
          },
          {
            "score": 0.8148303627967834,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.797812819480896,
            "answer": "pretty",
            "hit": false
          },
          {
            "score": 0.7976372838020325,
            "answer": "good",
            "hit": false
          },
          {
            "score": 0.795280933380127,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.7917758822441101,
            "answer": "fantastic",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7952809035778046
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.7847612500190735,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.7847519516944885,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.7667639255523682,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7665432095527649,
            "answer": "clear",
            "hit": false
          },
          {
            "score": 0.7606858015060425,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.7597230076789856,
            "answer": "obviously",
            "hit": true
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.759723037481308
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8451063632965088,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.7577868700027466,
            "answer": "mental",
            "hit": false
          },
          {
            "score": 0.735569417476654,
            "answer": "mentally",
            "hit": false
          },
          {
            "score": 0.7248120307922363,
            "answer": "conditioning",
            "hit": false
          },
          {
            "score": 0.7145860195159912,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.7128312587738037,
            "answer": "psychological",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8451063632965088
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.8365864753723145,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.8295229077339172,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.7888957262039185,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7825122475624084,
            "answer": "electoral",
            "hit": false
          },
          {
            "score": 0.7792385816574097,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.767969012260437,
            "answer": "politician",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8365864753723145
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7391148805618286,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7210921049118042,
            "answer": "useful",
            "hit": false
          },
          {
            "score": 0.7162039279937744,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.7129343748092651,
            "answer": "simple",
            "hit": false
          },
          {
            "score": 0.7099370956420898,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7062557935714722,
            "answer": "economical",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 695,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.60330730676651
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8175035715103149,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.8121551871299744,
            "answer": "last",
            "hit": false
          },
          {
            "score": 0.7788423299789429,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7720784544944763,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.7535791993141174,
            "answer": "past",
            "hit": false
          },
          {
            "score": 0.7422555088996887,
            "answer": "previously",
            "hit": true
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422555238008499
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7772599458694458,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.751578688621521,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.736491858959198,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.720746636390686,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.7096797227859497,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.7033263444900513,
            "answer": "often",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7772599160671234
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.8118628263473511,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.7672830820083618,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7573911547660828,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7198266983032227,
            "answer": "minor",
            "hit": false
          },
          {
            "score": 0.7138521075248718,
            "answer": "lightly",
            "hit": false
          },
          {
            "score": 0.7098248600959778,
            "answer": "clearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8118628561496735
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8877471685409546,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.8661136031150818,
            "answer": "sex",
            "hit": false
          },
          {
            "score": 0.8226013779640198,
            "answer": "intercourse",
            "hit": false
          },
          {
            "score": 0.7919497489929199,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7918481230735779,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7684242725372314,
            "answer": "heterosexual",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8877471387386322
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.8957793116569519,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.8112773895263672,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7773392796516418,
            "answer": "tremendous",
            "hit": false
          },
          {
            "score": 0.775873601436615,
            "answer": "huge",
            "hit": false
          },
          {
            "score": 0.7579377889633179,
            "answer": "major",
            "hit": false
          },
          {
            "score": 0.7570064067840576,
            "answer": "enormous",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.746794655919075
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7822598814964294,
            "answer": "identical",
            "hit": false
          },
          {
            "score": 0.7577766180038452,
            "answer": "differently",
            "hit": false
          },
          {
            "score": 0.7506152391433716,
            "answer": "different",
            "hit": false
          },
          {
            "score": 0.7458284497261047,
            "answer": "same",
            "hit": false
          },
          {
            "score": 0.7333661913871765,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7276922464370728,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 404,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6146020442247391
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.8224636316299438,
            "answer": "solid",
            "hit": false
          },
          {
            "score": 0.7970240116119385,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.7942838668823242,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7942262291908264,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7698534727096558,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7686136960983276,
            "answer": "strongly",
            "hit": true
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.76861372590065
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.802288830280304,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7816752195358276,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7698254585266113,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.7684363126754761,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7659910321235657,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.7654868364334106,
            "answer": "resulting",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.802288830280304
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.7987771034240723,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.777292013168335,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.7392734885215759,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.7334216833114624,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7239497900009155,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7212222218513489,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.777292013168335
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.8063178658485413,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.7886879444122314,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7257654070854187,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7215288877487183,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.7111304998397827,
            "answer": "mainstream",
            "hit": false
          },
          {
            "score": 0.7037988305091858,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8063178360462189
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.7891820669174194,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.7613248825073242,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.755652904510498,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7510635852813721,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.7284929752349854,
            "answer": "usual",
            "hit": false
          },
          {
            "score": 0.7254054546356201,
            "answer": "decidedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7891820669174194
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.869686484336853,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.7966076731681824,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.7642895579338074,
            "answer": "innovative",
            "hit": false
          },
          {
            "score": 0.7558106780052185,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.7460658550262451,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.7390207052230835,
            "answer": "diverse",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8696864545345306
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.7116583585739136,
            "answer": "remotely",
            "hit": false
          },
          {
            "score": 0.7088103294372559,
            "answer": "essentially",
            "hit": false
          },
          {
            "score": 0.7034374475479126,
            "answer": "securely",
            "hit": false
          },
          {
            "score": 0.6917864084243774,
            "answer": "simulate",
            "hit": false
          },
          {
            "score": 0.6910017728805542,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.6884996891021729,
            "answer": "simulation",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6779610365629196
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.87270587682724,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.7580002546310425,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.7527289390563965,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7515978217124939,
            "answer": "graphics",
            "hit": false
          },
          {
            "score": 0.7504101991653442,
            "answer": "imagery",
            "hit": false
          },
          {
            "score": 0.7500753402709961,
            "answer": "textures",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8727059066295624
      }
    ],
    "result": {
      "cnt_questions_correct": 23,
      "cnt_questions_total": 44,
      "accuracy": 0.5227272727272727
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ec723b94-82e3-40d7-8270-6b0acd0bdd79",
      "timestamp": "2025-05-18T13:34:04.607685"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7905668616294861,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7643594145774841,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7404578924179077,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7306177616119385,
            "answer": "inform",
            "hit": false
          },
          {
            "score": 0.7240210771560669,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7194708585739136,
            "answer": "informed",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6979891508817673
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.761900782585144,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7460327744483948,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7163494229316711,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6845044493675232,
            "answer": "simplicity",
            "hit": false
          },
          {
            "score": 0.6830747127532959,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.6806201338768005,
            "answer": "necessity",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7619008421897888
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7668809294700623,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7070348262786865,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.6879055500030518,
            "answer": "effect",
            "hit": false
          },
          {
            "score": 0.6806803941726685,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.6801810264587402,
            "answer": "potent",
            "hit": false
          },
          {
            "score": 0.6799164414405823,
            "answer": "method",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7668809592723846
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.8148683309555054,
            "answer": "glad",
            "hit": false
          },
          {
            "score": 0.7934293746948242,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7876852750778198,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.7844852209091187,
            "answer": "pleased",
            "hit": false
          },
          {
            "score": 0.7680197358131409,
            "answer": "excited",
            "hit": false
          },
          {
            "score": 0.7623215913772583,
            "answer": "joy",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.747953787446022
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7934673428535461,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.7470822930335999,
            "answer": "insane",
            "hit": false
          },
          {
            "score": 0.7456668615341187,
            "answer": "rage",
            "hit": false
          },
          {
            "score": 0.7444921731948853,
            "answer": "hell",
            "hit": false
          },
          {
            "score": 0.7414352893829346,
            "answer": "anger",
            "hit": false
          },
          {
            "score": 0.7405363917350769,
            "answer": "fury",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.729731023311615
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.8229994773864746,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7817586660385132,
            "answer": "tragic",
            "hit": false
          },
          {
            "score": 0.7769969701766968,
            "answer": "shame",
            "hit": false
          },
          {
            "score": 0.7768051624298096,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.7536588311195374,
            "answer": "irony",
            "hit": false
          },
          {
            "score": 0.7520531415939331,
            "answer": "melancholy",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8229994773864746
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.8031102418899536,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7558383941650391,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7184435725212097,
            "answer": "minor",
            "hit": false
          },
          {
            "score": 0.7172815799713135,
            "answer": "severity",
            "hit": false
          },
          {
            "score": 0.7119598388671875,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.7093058824539185,
            "answer": "profound",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.803110271692276
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.8444284200668335,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.8083755970001221,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7977170944213867,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7729580402374268,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7470396161079407,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.7208537459373474,
            "answer": "strong",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8444284498691559
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 8,
      "accuracy": 0.625
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "82e329aa-2e08-4617-a8a0-a5a6cd1aeb83",
      "timestamp": "2025-05-18T13:34:04.731751"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8248594999313354,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8083423376083374,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.7861824035644531,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.755403995513916,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7219434976577759,
            "answer": "rejecting",
            "hit": false
          },
          {
            "score": 0.7199684977531433,
            "answer": "acceptable",
            "hit": true
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7199684679508209
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.842592716217041,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8023120760917664,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.7930840849876404,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7832871079444885,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7776777148246765,
            "answer": "adapt",
            "hit": false
          },
          {
            "score": 0.748834490776062,
            "answer": "changing",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7221046984195709
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.7684389352798462,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7678905129432678,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7214288711547852,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.718704342842102,
            "answer": "cheap",
            "hit": false
          },
          {
            "score": 0.7181519865989685,
            "answer": "costly",
            "hit": false
          },
          {
            "score": 0.7124930620193481,
            "answer": "anymore",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7678905129432678
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.8130735754966736,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7795276641845703,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7624213099479675,
            "answer": "recommend",
            "hit": false
          },
          {
            "score": 0.7380958199501038,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7242359519004822,
            "answer": "recommended",
            "hit": false
          },
          {
            "score": 0.7214792966842651,
            "answer": "propose",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 5582,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.539903711527586
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.8448660373687744,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8154045343399048,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.8140311241149902,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.7943501472473145,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.774239182472229,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7694348692893982,
            "answer": "fun",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8140310943126678
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.852470874786377,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8049837350845337,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7869271636009216,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7655786871910095,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.7556920647621155,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7376505136489868,
            "answer": "identification",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7655786871910095
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8421792387962341,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.8024565577507019,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7495485544204712,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.7429755330085754,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.7255399227142334,
            "answer": "estimate",
            "hit": false
          },
          {
            "score": 0.7179831266403198,
            "answer": "likely",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6762519627809525
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8771234750747681,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8660896420478821,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.8573060631752014,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8061030507087708,
            "answer": "dependent",
            "hit": false
          },
          {
            "score": 0.7783329486846924,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.7747474908828735,
            "answer": "reliance",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7622357606887817
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8453122973442078,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.8369803428649902,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.7128734588623047,
            "answer": "extend",
            "hit": false
          },
          {
            "score": 0.7081202268600464,
            "answer": "expired",
            "hit": false
          },
          {
            "score": 0.6979681849479675,
            "answer": "extension",
            "hit": false
          },
          {
            "score": 0.6935428977012634,
            "answer": "terminate",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6410927027463913
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.7882338166236877,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7827693223953247,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.7686873078346252,
            "answer": "sustainable",
            "hit": true
          },
          {
            "score": 0.7323769927024841,
            "answer": "sufficient",
            "hit": false
          },
          {
            "score": 0.7317756414413452,
            "answer": "maintain",
            "hit": false
          },
          {
            "score": 0.7273815274238586,
            "answer": "stable",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.76868736743927
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.861463189125061,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8203915953636169,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8084666728973389,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7880005836486816,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.749600350856781,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.7395912408828735,
            "answer": "differs",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7066190391778946
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "64ab2980-0673-43cd-9a1e-79821c124d94",
      "timestamp": "2025-05-18T13:34:04.750568"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.7786991596221924,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7772494554519653,
            "answer": "convinced",
            "hit": false
          },
          {
            "score": 0.768456220626831,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.7665755748748779,
            "answer": "say",
            "hit": false
          },
          {
            "score": 0.7628160715103149,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7593114376068115,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7043625861406326
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8133017420768738,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.7553626298904419,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.7150979042053223,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7024683952331543,
            "answer": "editing",
            "hit": false
          },
          {
            "score": 0.6985961198806763,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.695268988609314,
            "answer": "listener",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7553626894950867
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8233473300933838,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.789086103439331,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.7624143362045288,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.7201154232025146,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.718664824962616,
            "answer": "eat",
            "hit": false
          },
          {
            "score": 0.6917983293533325,
            "answer": "eating",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 177,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6129948124289513
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7535651922225952,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.7461432218551636,
            "answer": "argued",
            "hit": false
          },
          {
            "score": 0.7020193338394165,
            "answer": "arguing",
            "hit": false
          },
          {
            "score": 0.7004120349884033,
            "answer": "claim",
            "hit": false
          },
          {
            "score": 0.6976522207260132,
            "answer": "claiming",
            "hit": false
          },
          {
            "score": 0.693805456161499,
            "answer": "argues",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.664337769150734
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8285810947418213,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.7554280161857605,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.721940279006958,
            "answer": "defense",
            "hit": false
          },
          {
            "score": 0.714809000492096,
            "answer": "opponent",
            "hit": false
          },
          {
            "score": 0.7137720584869385,
            "answer": "protector",
            "hit": false
          },
          {
            "score": 0.7114580869674683,
            "answer": "defender",
            "hit": true
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7114580720663071
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.8160474300384521,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7941442131996155,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7687602043151855,
            "answer": "build",
            "hit": false
          },
          {
            "score": 0.7682152390480042,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7634434103965759,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7348366975784302,
            "answer": "establish",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.712759718298912
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8700460195541382,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8340676426887512,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.7829806804656982,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7701046466827393,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7564615607261658,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.7511194944381714,
            "answer": "assess",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 1440,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5644926130771637
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8562912344932556,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8195112347602844,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.762190580368042,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6947069764137268,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.6945274472236633,
            "answer": "adventure",
            "hit": false
          },
          {
            "score": 0.6893313527107239,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 229,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6072629392147064
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7776254415512085,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7539980411529541,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7175375819206238,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6779639720916748,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.654569149017334,
            "answer": "set",
            "hit": false
          },
          {
            "score": 0.6484211683273315,
            "answer": "deviation",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6779639720916748
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8322949409484863,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.7943503856658936,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.784526526927948,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.7500767111778259,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.7301729917526245,
            "answer": "ambiguous",
            "hit": false
          },
          {
            "score": 0.7035341858863831,
            "answer": "meanings",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 74,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6468403190374374
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.8466145992279053,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.820336103439331,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.766818642616272,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.7384049892425537,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7292981147766113,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.719322919845581,
            "answer": "microphone",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7668186724185944
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.8494524955749512,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8184748888015747,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.8115736246109009,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7331836223602295,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7232473492622375,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7220571041107178,
            "answer": "loser",
            "hit": true
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7220570743083954
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8235929012298584,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7731554508209229,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.763388991355896,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7367050647735596,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7123443484306335,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.701408863067627,
            "answer": "handle",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7123443782329559
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.8566756248474121,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.7918901443481445,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7333346009254456,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7073460817337036,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.6815225481987,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6617032289505005,
            "answer": "witnessed",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3868,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5417511090636253
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8638715744018555,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8515427112579346,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.8019168376922607,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7253535985946655,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7207823991775513,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7149909734725952,
            "answer": "coordinate",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.851542741060257
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.8557913899421692,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8520077466964722,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8488781452178955,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7646666765213013,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.7496536374092102,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7283152341842651,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7646667063236237
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8887092471122742,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.7891818881034851,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7580065727233887,
            "answer": "gospel",
            "hit": false
          },
          {
            "score": 0.7547640800476074,
            "answer": "believer",
            "hit": false
          },
          {
            "score": 0.7514636516571045,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.7474550008773804,
            "answer": "sermon",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7891818881034851
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8697407841682434,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7988460063934326,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7412981390953064,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7163249254226685,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7092024087905884,
            "answer": "stimulate",
            "hit": false
          },
          {
            "score": 0.7025371193885803,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6867869049310684
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.8549436330795288,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8211108446121216,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8117603659629822,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7715887427330017,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7622262239456177,
            "answer": "offer",
            "hit": false
          },
          {
            "score": 0.7433549165725708,
            "answer": "offering",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7119141519069672
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8158015012741089,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.8079324960708618,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.8060948848724365,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7929680347442627,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7520368695259094,
            "answer": "editor",
            "hit": false
          },
          {
            "score": 0.7150882482528687,
            "answer": "unpublished",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8079325258731842
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8348605632781982,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.821340799331665,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.817333459854126,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7750635743141174,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7531285881996155,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.7284138798713684,
            "answer": "eligible",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 501,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5801354497671127
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8436353802680969,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.809525728225708,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.7992824912071228,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7901065945625305,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.7380618453025818,
            "answer": "talk",
            "hit": false
          },
          {
            "score": 0.7116885185241699,
            "answer": "speakers",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7108244299888611
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8669027090072632,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8545893430709839,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8507899045944214,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8201701641082764,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.7956331968307495,
            "answer": "tutor",
            "hit": false
          },
          {
            "score": 0.7821850776672363,
            "answer": "teacher",
            "hit": true
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7821850478649139
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8381693363189697,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.7855583429336548,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.7409427165985107,
            "answer": "read",
            "hit": false
          },
          {
            "score": 0.73774254322052,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7349595427513123,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.7313072681427002,
            "answer": "reader",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 142,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6220761686563492
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c785ba43-615a-46ba-a80a-7031f0883db6",
      "timestamp": "2025-05-18T13:34:04.778979"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.863433837890625,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8522613048553467,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.773604154586792,
            "answer": "criticized",
            "hit": false
          },
          {
            "score": 0.7630501985549927,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.7476832270622253,
            "answer": "blamed",
            "hit": false
          },
          {
            "score": 0.742027997970581,
            "answer": "accusations",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7630501985549927
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8427149057388306,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.7810752987861633,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.7462483048439026,
            "answer": "appreciate",
            "hit": false
          },
          {
            "score": 0.7329801917076111,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.7259045839309692,
            "answer": "dedication",
            "hit": false
          },
          {
            "score": 0.7257862091064453,
            "answer": "amazed",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7810752689838409
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8453441262245178,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.7787819504737854,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.7695488929748535,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7662625312805176,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.7579999566078186,
            "answer": "cpu",
            "hit": false
          },
          {
            "score": 0.7519435882568359,
            "answer": "calculations",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8453441262245178
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.861385703086853,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8476050496101379,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8455306887626648,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7592766880989075,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7541971206665039,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7495611906051636,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7541971504688263
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8660368323326111,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8617204427719116,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.8434568047523499,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.7886492013931274,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.7554702758789062,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.6935555934906006,
            "answer": "stating",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8434568047523499
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8797985315322876,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8314203023910522,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7813116312026978,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7738329172134399,
            "answer": "assess",
            "hit": false
          },
          {
            "score": 0.7650848627090454,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7640621066093445,
            "answer": "unclear",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 70,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6633079200983047
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8784869909286499,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8517532348632812,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.7940247058868408,
            "answer": "review",
            "hit": false
          },
          {
            "score": 0.7939196825027466,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.7872796058654785,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7680454850196838,
            "answer": "assess",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7650462985038757
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8638835549354553,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8307546973228455,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.7442140579223633,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7346506118774414,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7180473208427429,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.7102210521697998,
            "answer": "adventure",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7180473357439041
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.7959461808204651,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.7896669507026672,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.7394883632659912,
            "answer": "suppose",
            "hit": false
          },
          {
            "score": 0.7288641929626465,
            "answer": "wonder",
            "hit": false
          },
          {
            "score": 0.7274954915046692,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.7235769629478455,
            "answer": "knowing",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 418,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6191750839352608
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8358755707740784,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7749612331390381,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.7635159492492676,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7217984199523926,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.717854380607605,
            "answer": "spirit",
            "hit": false
          },
          {
            "score": 0.7171298265457153,
            "answer": "passion",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7635159194469452
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.8728457689285278,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.7951081395149231,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.759390652179718,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.7076090574264526,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6981582641601562,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6888331770896912,
            "answer": "adhere",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7593906223773956
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8591899871826172,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8579944968223572,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8296457529067993,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.728672981262207,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.7260416746139526,
            "answer": "inhabit",
            "hit": false
          },
          {
            "score": 0.7191402912139893,
            "answer": "vacant",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6604626476764679
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8737460374832153,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8193087577819824,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7967563271522522,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7431987524032593,
            "answer": "coordinate",
            "hit": false
          },
          {
            "score": 0.7173486351966858,
            "answer": "coordinated",
            "hit": false
          },
          {
            "score": 0.7170958518981934,
            "answer": "coordinating",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 75,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6409488469362259
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8765183091163635,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.8462748527526855,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8186593055725098,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.7882910370826721,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7606791853904724,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.7439424395561218,
            "answer": "ready",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8765183389186859
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.880776047706604,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8238221406936646,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.8220444321632385,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.7677805423736572,
            "answer": "rebuild",
            "hit": false
          },
          {
            "score": 0.76214200258255,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.7606042623519897,
            "answer": "preserve",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8220444321632385
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8364208340644836,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8063051104545593,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.7617745399475098,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.7443708777427673,
            "answer": "recovery",
            "hit": false
          },
          {
            "score": 0.7223086357116699,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.7118675708770752,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8364208936691284
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "173995aa-e7eb-4e3b-b29b-6b3acacfb35a",
      "timestamp": "2025-05-18T13:34:04.843043"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8624734878540039,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7996801733970642,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.7778794765472412,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.763681948184967,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.762660801410675,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7502793669700623,
            "answer": "achieving",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7996802031993866
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.8988073468208313,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8771566152572632,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8497428894042969,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7938556671142578,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7827812433242798,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7790762186050415,
            "answer": "accomplish",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7827812433242798
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.876093864440918,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8559606671333313,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.8167846202850342,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7969386577606201,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.775510311126709,
            "answer": "adapt",
            "hit": false
          },
          {
            "score": 0.7582821249961853,
            "answer": "changes",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8559606969356537
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8276616334915161,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7770891189575195,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7618388533592224,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7582405209541321,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7511120438575745,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7403953671455383,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7079702913761139
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.8656061291694641,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.8028066158294678,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.696209728717804,
            "answer": "integration",
            "hit": false
          },
          {
            "score": 0.6932832598686218,
            "answer": "integrate",
            "hit": false
          },
          {
            "score": 0.6923792362213135,
            "answer": "engagement",
            "hit": false
          },
          {
            "score": 0.6867091059684753,
            "answer": "positioning",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8028066456317902
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8664003014564514,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.8486286997795105,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.8408594727516174,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.786115288734436,
            "answer": "revision",
            "hit": false
          },
          {
            "score": 0.757226824760437,
            "answer": "enactment",
            "hit": false
          },
          {
            "score": 0.7477729916572571,
            "answer": "provisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8408595025539398
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8522028923034668,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.8335970640182495,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8250079154968262,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8159116506576538,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.7152352333068848,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7151710987091064,
            "answer": "announcements",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.815911591053009
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8652796149253845,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.8558082580566406,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7540042996406555,
            "answer": "resignation",
            "hit": false
          },
          {
            "score": 0.7514877915382385,
            "answer": "elected",
            "hit": false
          },
          {
            "score": 0.741243839263916,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.7387337684631348,
            "answer": "resign",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8558082282543182
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8515908718109131,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.8476848006248474,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.7452048659324646,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7174196243286133,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.6877705454826355,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.6860638856887817,
            "answer": "contact",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6877705305814743
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8763725161552429,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8339099884033203,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.83273845911026,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.7885167002677917,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7849793434143066,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.78363037109375,
            "answer": "evaluation",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8327384293079376
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8284674882888794,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.8226287364959717,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.741399884223938,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7099280953407288,
            "answer": "designate",
            "hit": false
          },
          {
            "score": 0.706814169883728,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.7014328241348267,
            "answer": "numerical",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.741399884223938
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.8636994361877441,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.802398681640625,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.7994524240493774,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.7354037761688232,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7099779844284058,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.6857908964157104,
            "answer": "guilty",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7354037910699844
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.8302536010742188,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8237656950950623,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.8103684186935425,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7771735191345215,
            "answer": "build",
            "hit": false
          },
          {
            "score": 0.7501299977302551,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7406636476516724,
            "answer": "evolve",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8237657248973846
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8354828357696533,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8088865280151367,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7723171710968018,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7180081605911255,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7176836729049683,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7146745920181274,
            "answer": "dislike",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7723171412944794
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8301258087158203,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.816307783126831,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.7907363772392273,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7476001977920532,
            "answer": "urge",
            "hit": false
          },
          {
            "score": 0.7454528212547302,
            "answer": "incentive",
            "hit": false
          },
          {
            "score": 0.7399999499320984,
            "answer": "discourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6820946633815765
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8685246109962463,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8395926356315613,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.8258571624755859,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7649397253990173,
            "answer": "compliance",
            "hit": false
          },
          {
            "score": 0.7411367893218994,
            "answer": "comply",
            "hit": false
          },
          {
            "score": 0.7350015640258789,
            "answer": "uphold",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8395926356315613
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.8625977039337158,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.814719557762146,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.8084883689880371,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.7453843355178833,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.736691951751709,
            "answer": "participation",
            "hit": false
          },
          {
            "score": 0.7304025888442993,
            "answer": "engagement",
            "hit": true
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7304026484489441
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8905272483825684,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.856364369392395,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.808545708656311,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.7976461052894592,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7957653999328613,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7588465213775635,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8085457384586334
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.8581601977348328,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8378031253814697,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.8015681505203247,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.7811082005500793,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7578459978103638,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7444236278533936,
            "answer": "fun",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8015681803226471
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8064668774604797,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7568999528884888,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.7188187837600708,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.6893155574798584,
            "answer": "delight",
            "hit": false
          },
          {
            "score": 0.6888089179992676,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6798021197319031,
            "answer": "audiences",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7188187539577484
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8851848840713501,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8395406007766724,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7714517712593079,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.769748330116272,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.745894193649292,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7298535704612732,
            "answer": "build",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7697483599185944
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8915536403656006,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.8831493854522705,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.7997493743896484,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.7389887571334839,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.7107969522476196,
            "answer": "realization",
            "hit": false
          },
          {
            "score": 0.7084033489227295,
            "answer": "meet",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7997494041919708
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8875999450683594,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8766632676124573,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.808567464351654,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8070634603500366,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.7976962327957153,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7957718372344971,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8070634603500366
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.878990888595581,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.8625714778900146,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.8433408141136169,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.8388034105300903,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7341327667236328,
            "answer": "venture",
            "hit": false
          },
          {
            "score": 0.7171181440353394,
            "answer": "expansion",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8433407843112946
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8553903698921204,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7623218297958374,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7541286945343018,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7530299425125122,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7432215213775635,
            "answer": "constitute",
            "hit": false
          },
          {
            "score": 0.7321990728378296,
            "answer": "included",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6585638225078583
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8276160955429077,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7748830914497375,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7647210359573364,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7559285163879395,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.7132595777511597,
            "answer": "handle",
            "hit": false
          },
          {
            "score": 0.7026714086532593,
            "answer": "efficiently",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7559285163879395
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8275622129440308,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.7988716959953308,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7466287612915039,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.7419428825378418,
            "answer": "sanctions",
            "hit": false
          },
          {
            "score": 0.7371362447738647,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.7185641527175903,
            "answer": "revenge",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7988717257976532
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.8468998670578003,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.7927658557891846,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.7446462512016296,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7376284003257751,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7336552143096924,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.7081562876701355,
            "answer": "emphasize",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.792765885591507
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.8844409584999084,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.8773751258850098,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8340394496917725,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8335695862770081,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.8209924101829529,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7685738205909729,
            "answer": "successor",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8844409584999084
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.8638650178909302,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8575034737586975,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8413885235786438,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.7769660353660583,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.7310114502906799,
            "answer": "need",
            "hit": false
          },
          {
            "score": 0.7285030484199524,
            "answer": "needed",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7769660651683807
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 30,
      "accuracy": 0.03333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "26a07191-f9d9-46b6-b413-f125a8f9ba8d",
      "timestamp": "2025-05-18T13:34:04.881439"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8702757358551025,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.791728138923645,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7680935859680176,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7670578956604004,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7555599212646484,
            "answer": "cyprus",
            "hit": false
          },
          {
            "score": 0.7520343661308289,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8702757358551025
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8776112794876099,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8659363389015198,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.7969202399253845,
            "answer": "sunni",
            "hit": false
          },
          {
            "score": 0.7845837473869324,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7824483513832092,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7804056406021118,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8659363687038422
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.9397276043891907,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8476384878158569,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.8172224760055542,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8109167814254761,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.8082956671714783,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.794310450553894,
            "answer": "singapore",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9397276043891907
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.9313443899154663,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.8435318470001221,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.8375468850135803,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7905663847923279,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.7898013591766357,
            "answer": "zhang",
            "hit": false
          },
          {
            "score": 0.7852982878684998,
            "answer": "jiang",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9313443601131439
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.9214695692062378,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.8301725387573242,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8246217966079712,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.8073390126228333,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.799973726272583,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7944326400756836,
            "answer": "germans",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.921469509601593
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7888553142547607,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.7507559657096863,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7454557418823242,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7315236330032349,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7271185517311096,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.7255575656890869,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888553142547607
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8347445726394653,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.8323976993560791,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.8156092166900635,
            "answer": "europe",
            "hit": false
          },
          {
            "score": 0.8023605942726135,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.801528811454773,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7952213883399963,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8347445726394653
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.9389318227767944,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.870478093624115,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.856884241104126,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8525322675704956,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8502792716026306,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.8420087099075317,
            "answer": "bulgaria",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9389318525791168
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.9255550503730774,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8293390274047852,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8186078667640686,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7929482460021973,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7858310341835022,
            "answer": "yemen",
            "hit": false
          },
          {
            "score": 0.7801880240440369,
            "answer": "arab",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9255550503730774
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8500630259513855,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8071660995483398,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7939063906669617,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7705526947975159,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7676383256912231,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.759477972984314,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8500630259513855
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.9269803762435913,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8587055802345276,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8230579495429993,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.8195576071739197,
            "answer": "iran",
            "hit": false
          },
          {
            "score": 0.8163041472434998,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.8035771250724792,
            "answer": "israel",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9269803464412689
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.9295293688774109,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.8479217886924744,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.8241442441940308,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7904835939407349,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.7718051075935364,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7579002380371094,
            "answer": "scotland",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9295293688774109
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.918175995349884,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.8698884844779968,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8448054790496826,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.8212113380432129,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7941938638687134,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7855918407440186,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9181760251522064
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7840306758880615,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.7514698505401611,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.7388533353805542,
            "answer": "pei",
            "hit": false
          },
          {
            "score": 0.7225215435028076,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.717816948890686,
            "answer": "brunswick",
            "hit": false
          },
          {
            "score": 0.6943475008010864,
            "answer": "queens",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7840306758880615
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8701615333557129,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.7803874015808105,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7668606042861938,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7660219073295593,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7648621797561646,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7646228671073914,
            "answer": "brazil",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8701615631580353
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.9214604496955872,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.8367111682891846,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.8226262927055359,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.8109522461891174,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.790795087814331,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.7906222939491272,
            "answer": "morocco",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9214604794979095
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.936753511428833,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.8954031467437744,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.774459958076477,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7728244066238403,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7685093283653259,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.7541862726211548,
            "answer": "ang",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9367535412311554
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.9599337577819824,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.893873929977417,
            "answer": "ukraine",
            "hit": false
          },
          {
            "score": 0.8692429065704346,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.8188693523406982,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.8173143863677979,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8121069669723511,
            "answer": "putin",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9599338471889496
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.9029855132102966,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8348401784896851,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8290360569953918,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8286569714546204,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7914640307426453,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7869302034378052,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9029855132102966
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.8786053657531738,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.8326594829559326,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.8225584030151367,
            "answer": "pei",
            "hit": false
          },
          {
            "score": 0.816572904586792,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.8120786547660828,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.8069630861282349,
            "answer": "alberta",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8786053657531738
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.9187666773796082,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.821799099445343,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.8093435764312744,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7990958094596863,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7955355048179626,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7890685200691223,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9187666773796082
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.8892909288406372,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7727614641189575,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7702488899230957,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7676466107368469,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7653418779373169,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7546814680099487,
            "answer": "romania",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8892908990383148
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.8351303935050964,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.8168073892593384,
            "answer": "cruz",
            "hit": false
          },
          {
            "score": 0.8167978525161743,
            "answer": "perez",
            "hit": false
          },
          {
            "score": 0.8153112530708313,
            "answer": "salvador",
            "hit": false
          },
          {
            "score": 0.8127745389938354,
            "answer": "francisco",
            "hit": false
          },
          {
            "score": 0.8118418455123901,
            "answer": "flores",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8351304531097412
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.9299725890159607,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8693912029266357,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8626835346221924,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.8488038778305054,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8480303883552551,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8129949569702148,
            "answer": "norwegian",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9299725890159607
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.9451576471328735,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.8705615997314453,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8391202688217163,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7828988432884216,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7720799446105957,
            "answer": "israel",
            "hit": false
          },
          {
            "score": 0.7669718861579895,
            "answer": "pakistan",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9451577067375183
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.9457945227622986,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.8572045564651489,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7939813137054443,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.7734315991401672,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7660280466079712,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7607681155204773,
            "answer": "china",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.945794552564621
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8783400654792786,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.8341823220252991,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8202534317970276,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.8002740144729614,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7910126447677612,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7892310619354248,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.878340095281601
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.9245268106460571,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.8345037698745728,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8327701091766357,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.8260022401809692,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.8141239881515503,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7931556701660156,
            "answer": "bulgaria",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9245268106460571
      }
    ],
    "result": {
      "cnt_questions_correct": 27,
      "cnt_questions_total": 28,
      "accuracy": 0.9642857142857143
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1ca0533a-bb6f-43d1-8b40-96315547ddcf",
      "timestamp": "2025-05-18T13:34:04.959434"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8709381222724915,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.857825756072998,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8194899559020996,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7774975299835205,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7717241048812866,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7669230103492737,
            "answer": "brazilian",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8709381222724915
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.873157799243927,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.8084518313407898,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.8009331226348877,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.790355384349823,
            "answer": "queensland",
            "hit": false
          },
          {
            "score": 0.7872279286384583,
            "answer": "nsw",
            "hit": false
          },
          {
            "score": 0.7862715721130371,
            "answer": "melbourne",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 8,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7687470018863678
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8643883466720581,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8449318408966064,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7972264289855957,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.78437340259552,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7707199454307556,
            "answer": "romanian",
            "hit": false
          },
          {
            "score": 0.7698301672935486,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8449319005012512
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8800418972969055,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8607312440872192,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.8427356481552124,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7813217639923096,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.7718093395233154,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.763197124004364,
            "answer": "argentine",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 1,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8607312440872192
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8599073886871338,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7956947684288025,
            "answer": "quebec",
            "hit": false
          },
          {
            "score": 0.7901376485824585,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.7756960988044739,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.7647144794464111,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7501543760299683,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7647144496440887
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8683440685272217,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7855780124664307,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7817587852478027,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7600066661834717,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.7546636462211609,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.751980721950531,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8683440387248993
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8836002349853516,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.785340428352356,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.777212917804718,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7749364376068115,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7564879655838013,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7558904886245728,
            "answer": "ecuador",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8836002349853516
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8622535467147827,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.8327583074569702,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.77145916223526,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7467643618583679,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7457528710365295,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.7434855699539185,
            "answer": "castro",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8327582776546478
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8141924142837524,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7993932962417603,
            "answer": "turkish",
            "hit": true
          },
          {
            "score": 0.7755357027053833,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7630796432495117,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7584528923034668,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7584450244903564,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8141924142837524
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8932655453681946,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8653137683868408,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7810698747634888,
            "answer": "arab",
            "hit": false
          },
          {
            "score": 0.7788288593292236,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.7594860196113586,
            "answer": "saudi",
            "hit": false
          },
          {
            "score": 0.7572343349456787,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653137683868408
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.85108482837677,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7882543802261353,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7615611553192139,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7530519962310791,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.7512050867080688,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7356834411621094,
            "answer": "dominican",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.85108482837677
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8761552572250366,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8406029939651489,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8308703899383545,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.818965494632721,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.7545863389968872,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.7531300187110901,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 3,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.818965494632721
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8189375996589661,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8147597908973694,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7788807153701782,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7476645708084106,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.7459444999694824,
            "answer": "kurdish",
            "hit": true
          },
          {
            "score": 0.7448287606239319,
            "answer": "war",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8189375698566437
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8582831621170044,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.847592830657959,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.8204218149185181,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.8202123641967773,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8161826729774475,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.8120648860931396,
            "answer": "jewish",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8475928008556366
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7778959274291992,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7272181510925293,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7001376748085022,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6856774687767029,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.6851907968521118,
            "answer": "arabian",
            "hit": false
          },
          {
            "score": 0.6751207709312439,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7778959572315216
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8496948480606079,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7719204425811768,
            "answer": "saudi",
            "hit": false
          },
          {
            "score": 0.7616514563560486,
            "answer": "qatar",
            "hit": false
          },
          {
            "score": 0.7480887174606323,
            "answer": "arabian",
            "hit": false
          },
          {
            "score": 0.7463400363922119,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.735667884349823,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8496948480606079
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8191313147544861,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7689129114151001,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7571393251419067,
            "answer": "arabs",
            "hit": false
          },
          {
            "score": 0.7499463558197021,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7461704015731812,
            "answer": "arab",
            "hit": false
          },
          {
            "score": 0.7451467514038086,
            "answer": "palestinian",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8191313147544861
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.855019748210907,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7808187007904053,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7632627487182617,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.7621568441390991,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7494396567344666,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.7443552017211914,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8550197184085846
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8576900959014893,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.7957346439361572,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7874172925949097,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7811381816864014,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7707993984222412,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7653500437736511,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7957346737384796
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8654731512069702,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8634257912635803,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8137874603271484,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8069186806678772,
            "answer": "lebanese",
            "hit": false
          },
          {
            "score": 0.7874385118484497,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.7859385013580322,
            "answer": "arab",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8634257614612579
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.8275803923606873,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.7855700254440308,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7732794880867004,
            "answer": "mainland",
            "hit": false
          },
          {
            "score": 0.772336483001709,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7637925148010254,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7617555856704712,
            "answer": "vietnamese",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8275803625583649
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7513988018035889,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7482947707176208,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7098046541213989,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.688249945640564,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6874708533287048,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.677828848361969,
            "answer": "america",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7513988316059113
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8647708892822266,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7914352416992188,
            "answer": "latin",
            "hit": false
          },
          {
            "score": 0.7685148119926453,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7641903758049011,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7639157772064209,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7638136148452759,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.864770919084549
      }
    ],
    "result": {
      "cnt_questions_correct": 13,
      "cnt_questions_total": 23,
      "accuracy": 0.5652173913043478
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "94441793-3e2b-4e51-95bf-14b0507892ef",
      "timestamp": "2025-05-18T13:34:05.034657"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8279464244842529,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7527824640274048,
            "answer": "tub",
            "hit": false
          },
          {
            "score": 0.7523804903030396,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.7401446104049683,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.734637439250946,
            "answer": "bedroom",
            "hit": false
          },
          {
            "score": 0.7178141474723816,
            "answer": "bedrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 286,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6023945733904839
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8672502636909485,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8293007016181946,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.8071310520172119,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7983415126800537,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7897540926933289,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7751327157020569,
            "answer": "devon",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8672502636909485
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8414837718009949,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.833342432975769,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8250037431716919,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.8169263005256653,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.8078439831733704,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7987134456634521,
            "answer": "cornwall",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8414837419986725
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8622146844863892,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8061526417732239,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.8023391366004944,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7990953326225281,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7776637077331543,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7748708128929138,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8622147142887115
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.9290056228637695,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8022807240486145,
            "answer": "leicester",
            "hit": false
          },
          {
            "score": 0.7978610396385193,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7969784736633301,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7911899089813232,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7834020853042603,
            "answer": "newcastle",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9290056526660919
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.8481871485710144,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.8444687724113464,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.8354266881942749,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.823137640953064,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.8201580047607422,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8188809156417847,
            "answer": "cornwall",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7596733570098877
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.881161093711853,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8007248640060425,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7983794212341309,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7905566096305847,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7876104712486267,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7875527143478394,
            "answer": "nottingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.881161093711853
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7395207285881042,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7147722244262695,
            "answer": "williams",
            "hit": false
          },
          {
            "score": 0.7119336128234863,
            "answer": "davis",
            "hit": false
          },
          {
            "score": 0.710515022277832,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7097006440162659,
            "answer": "compton",
            "hit": false
          },
          {
            "score": 0.7014023065567017,
            "answer": "greene",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6863584816455841
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.854222297668457,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.8494206666946411,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.82722008228302,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8172311186790466,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.8141180276870728,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7961156368255615,
            "answer": "hampshire",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8272200524806976
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4688dc4e-e142-4bd0-8534-20a6f9f7dc28",
      "timestamp": "2025-05-18T13:34:05.090939"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7786260843276978,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7448577880859375,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7442273497581482,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7321345210075378,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7259892225265503,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7258216738700867,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7786260843276978
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7686300277709961,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7649785280227661,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.753360390663147,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.7299413681030273,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7198327779769897,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7085891366004944,
            "answer": "polish",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7533603608608246
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.8197317719459534,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7670426368713379,
            "answer": "queensland",
            "hit": false
          },
          {
            "score": 0.7662209272384644,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.7651035189628601,
            "answer": "adelaide",
            "hit": false
          },
          {
            "score": 0.7633779644966125,
            "answer": "brisbane",
            "hit": false
          },
          {
            "score": 0.7597662806510925,
            "answer": "melbourne",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6517815142869949
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7374003529548645,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7291005253791809,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7089066505432129,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6956113576889038,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.694559633731842,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6936994791030884,
            "answer": "hungarian",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7089066356420517
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7921706438064575,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7251832485198975,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7234612107276917,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7230682969093323,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7174210548400879,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7166962623596191,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.682877391576767
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8685951828956604,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.8551284074783325,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8468576073646545,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.8160574436187744,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7694122791290283,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7690123319625854,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8468576669692993
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7772260904312134,
            "answer": "inning",
            "hit": false
          },
          {
            "score": 0.7048325538635254,
            "answer": "batter",
            "hit": false
          },
          {
            "score": 0.703220009803772,
            "answer": "hits",
            "hit": false
          },
          {
            "score": 0.6890929937362671,
            "answer": "outs",
            "hit": false
          },
          {
            "score": 0.6858519315719604,
            "answer": "fielder",
            "hit": false
          },
          {
            "score": 0.6850362420082092,
            "answer": "pointer",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 47,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6425425857305527
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7411229610443115,
            "answer": "welsh",
            "hit": false
          },
          {
            "score": 0.7297134399414062,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7239229679107666,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.7158613204956055,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7155160903930664,
            "answer": "fraser",
            "hit": false
          },
          {
            "score": 0.7142385244369507,
            "answer": "australian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7239229530096054
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7483375072479248,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7348135709762573,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7124607563018799,
            "answer": "romanian",
            "hit": false
          },
          {
            "score": 0.7120140790939331,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7104339003562927,
            "answer": "czech",
            "hit": false
          },
          {
            "score": 0.7032122015953064,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7483375519514084
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7399548292160034,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7188799381256104,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7142927646636963,
            "answer": "planets",
            "hit": false
          },
          {
            "score": 0.7084882855415344,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7062331438064575,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7023254036903381,
            "answer": "swiss",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7399548590183258
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.7978594303131104,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.792252779006958,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.7848336696624756,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7782677412033081,
            "answer": "ukrainian",
            "hit": false
          },
          {
            "score": 0.7770950794219971,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7755101919174194,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.792252779006958
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7374171614646912,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7242151498794556,
            "answer": "dakota",
            "hit": false
          },
          {
            "score": 0.7237613201141357,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7235147953033447,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7011784315109253,
            "answer": "norfolk",
            "hit": false
          },
          {
            "score": 0.6995394229888916,
            "answer": "roosevelt",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7235148251056671
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7186223268508911,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.7171833515167236,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7150998711585999,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7040082216262817,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7036989331245422,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7007652521133423,
            "answer": "welsh",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6769101023674011
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7781776785850525,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7471212148666382,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.7294161319732666,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7266897559165955,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7221591472625732,
            "answer": "czech",
            "hit": false
          },
          {
            "score": 0.7214158773422241,
            "answer": "marxist",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7781777083873749
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7090742588043213,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7048051953315735,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7044838666915894,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.7020286917686462,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7009074091911316,
            "answer": "ellis",
            "hit": false
          },
          {
            "score": 0.6994237899780273,
            "answer": "shepherd",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7044838815927505
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7293930053710938,
            "answer": "bedford",
            "hit": false
          },
          {
            "score": 0.7152024507522583,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7140690088272095,
            "answer": "auburn",
            "hit": false
          },
          {
            "score": 0.711258053779602,
            "answer": "bradford",
            "hit": false
          },
          {
            "score": 0.7101607322692871,
            "answer": "alabama",
            "hit": false
          },
          {
            "score": 0.7011104822158813,
            "answer": "somerset",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6649641245603561
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7423593997955322,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7418944835662842,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7169785499572754,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.715861439704895,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7091878056526184,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7075263261795044,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7418944984674454
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7824941873550415,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7424982190132141,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7398739457130432,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7358593940734863,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7231159806251526,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7210122346878052,
            "answer": "wartime",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7231159955263138
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7589911222457886,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7550377249717712,
            "answer": "schneider",
            "hit": false
          },
          {
            "score": 0.7488675117492676,
            "answer": "hoffman",
            "hit": false
          },
          {
            "score": 0.7452920079231262,
            "answer": "roth",
            "hit": false
          },
          {
            "score": 0.73885178565979,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7385827898979187,
            "answer": "ludwig",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.758991152048111
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 19,
      "accuracy": 0.3684210526315789
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "644e0b04-040d-4ba9-9fd0-64f27e805d78",
      "timestamp": "2025-05-18T13:34:05.112471"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8556860089302063,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7902848124504089,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7541825771331787,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7482734322547913,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7318722009658813,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.7214925289154053,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556860089302063
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7574182152748108,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.704633355140686,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.69951331615448,
            "answer": "patriarch",
            "hit": false
          },
          {
            "score": 0.6951942443847656,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.6938292980194092,
            "answer": "ruler",
            "hit": false
          },
          {
            "score": 0.6906791925430298,
            "answer": "deity",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6951942294836044
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7298386096954346,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.7210354208946228,
            "answer": "rochester",
            "hit": false
          },
          {
            "score": 0.7137303948402405,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.7115273475646973,
            "answer": "ohio",
            "hit": false
          },
          {
            "score": 0.7076828479766846,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.7010790109634399,
            "answer": "dayton",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 952,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5620754994452
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7334892749786377,
            "answer": "giovanni",
            "hit": false
          },
          {
            "score": 0.7277621030807495,
            "answer": "antonio",
            "hit": false
          },
          {
            "score": 0.7154495716094971,
            "answer": "tre",
            "hit": false
          },
          {
            "score": 0.709750771522522,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.7086489796638489,
            "answer": "carlo",
            "hit": false
          },
          {
            "score": 0.7066837549209595,
            "answer": "philosopher",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7097507417201996
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7264710068702698,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6915512681007385,
            "answer": "inventor",
            "hit": true
          },
          {
            "score": 0.6875488758087158,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6824674010276794,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6784056425094604,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6699234247207642,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6915512681007385
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.8166667222976685,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.8069957494735718,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7712468504905701,
            "answer": "inventor",
            "hit": false
          },
          {
            "score": 0.7409877777099609,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.7388216257095337,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7335470914840698,
            "answer": "scientist",
            "hit": true
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8166667222976685
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.8217757940292358,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.8203896880149841,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7735154032707214,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7508972883224487,
            "answer": "dictator",
            "hit": true
          },
          {
            "score": 0.7476252317428589,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7474451065063477,
            "answer": "philosopher",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7508972585201263
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.755100667476654,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7144007086753845,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7103695273399353,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6948071718215942,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6940655708312988,
            "answer": "commentator",
            "hit": false
          },
          {
            "score": 0.6924781799316406,
            "answer": "fraser",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7551006376743317
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7908995151519775,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7400749921798706,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7116483449935913,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7108595371246338,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7102379202842712,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.7074191570281982,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7908995449542999
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7136335968971252,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7050645351409912,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7016591429710388,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7013429403305054,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7003384232521057,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6925843954086304,
            "answer": "dakota",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 322,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.593223363161087
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7334321737289429,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6766778230667114,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6709839701652527,
            "answer": "entrepreneur",
            "hit": false
          },
          {
            "score": 0.6670299768447876,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.6641572713851929,
            "answer": "richardson",
            "hit": false
          },
          {
            "score": 0.6633487939834595,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7334321588277817
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.805260419845581,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.77858966588974,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7583985924720764,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.740374743938446,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7400046586990356,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.7223211526870728,
            "answer": "lenin",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.805260419845581
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7035515308380127,
            "answer": "walter",
            "hit": false
          },
          {
            "score": 0.7013914585113525,
            "answer": "smith",
            "hit": false
          },
          {
            "score": 0.6999500393867493,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6943241357803345,
            "answer": "bennett",
            "hit": false
          },
          {
            "score": 0.6941549181938171,
            "answer": "bailey",
            "hit": false
          },
          {
            "score": 0.6915088891983032,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6684622466564178
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.762176513671875,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.7464603185653687,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.7434185147285461,
            "answer": "isaac",
            "hit": false
          },
          {
            "score": 0.7400823831558228,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7327182292938232,
            "answer": "solomon",
            "hit": false
          },
          {
            "score": 0.7175073027610779,
            "answer": "preacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.762176513671875
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7850850820541382,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7346048355102539,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.725794792175293,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7193364500999451,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7120561599731445,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.7096822261810303,
            "answer": "nobility",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6955310702323914
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8156018257141113,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7457555532455444,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7417134642601013,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7382062673568726,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7357548475265503,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7208569049835205,
            "answer": "aristotle",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8156018257141113
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.750023365020752,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7385454177856445,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7272569537162781,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.7105544805526733,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.7068930864334106,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7012085914611816,
            "answer": "wartime",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 208,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.608918622136116
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7527281045913696,
            "answer": "schneider",
            "hit": false
          },
          {
            "score": 0.7515207529067993,
            "answer": "hoffman",
            "hit": false
          },
          {
            "score": 0.7421910762786865,
            "answer": "franz",
            "hit": false
          },
          {
            "score": 0.7406790256500244,
            "answer": "schmidt",
            "hit": false
          },
          {
            "score": 0.7394596338272095,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.7330074906349182,
            "answer": "fischer",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7048679292201996
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 18,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b8a9cd0b-d590-4c57-8075-bd4930c094f3",
      "timestamp": "2025-05-18T13:34:05.160074"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8018981218338013,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7930689454078674,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7793362140655518,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7424367070198059,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7409119606018066,
            "answer": "creature",
            "hit": false
          },
          {
            "score": 0.7261066436767578,
            "answer": "calf",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7253178805112839
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8048721551895142,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7358976006507874,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7275281548500061,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7248983383178711,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7236290574073792,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7118279933929443,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8048721849918365
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7761397361755371,
            "answer": "erie",
            "hit": false
          },
          {
            "score": 0.7670034766197205,
            "answer": "rochester",
            "hit": false
          },
          {
            "score": 0.7636725306510925,
            "answer": "pittsburgh",
            "hit": false
          },
          {
            "score": 0.7551608681678772,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.7415104508399963,
            "answer": "syracuse",
            "hit": false
          },
          {
            "score": 0.738943338394165,
            "answer": "denver",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 130,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6252989619970322
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8546489477157593,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.8467776775360107,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.809014081954956,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7693401575088501,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7641355991363525,
            "answer": "newborn",
            "hit": false
          },
          {
            "score": 0.761945903301239,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7476547658443451
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.8580740094184875,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.8142070174217224,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.8114028573036194,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7982367277145386,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7926509976387024,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.78816157579422,
            "answer": "sheep",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 252,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6192413792014122
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8168503642082214,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7662022113800049,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7321093082427979,
            "answer": "newborn",
            "hit": false
          },
          {
            "score": 0.7313764095306396,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7266491651535034,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7249826192855835,
            "answer": "puppy",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8168503642082214
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8184689283370972,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.812264621257782,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.8047655820846558,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7884600162506104,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.77471524477005,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7663517594337463,
            "answer": "cat",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7005181014537811
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8223953247070312,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.8034437894821167,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.8025646209716797,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7302626371383667,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7173495292663574,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6891557574272156,
            "answer": "secure",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6690818071365356
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8103624582290649,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7771161794662476,
            "answer": "pup",
            "hit": true
          },
          {
            "score": 0.7694474458694458,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7671275734901428,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7467660903930664,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7460116147994995,
            "answer": "cub",
            "hit": true
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7460116446018219
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7528634667396545,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.7501271963119507,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7252108454704285,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6951417922973633,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.6923891305923462,
            "answer": "lily",
            "hit": false
          },
          {
            "score": 0.6848585605621338,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7501272261142731
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.866709291934967,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.8056454658508301,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.789777398109436,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7850664854049683,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.773064136505127,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.768785834312439,
            "answer": "turtle",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7850664854049683
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 11,
      "accuracy": 0.18181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8508ecfd-1926-4223-a98b-52fb068335ce",
      "timestamp": "2025-05-18T13:34:05.203961"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.6748188734054565,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6677771806716919,
            "answer": "chronicle",
            "hit": false
          },
          {
            "score": 0.6667453646659851,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6665140390396118,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.6626070737838745,
            "answer": "cherry",
            "hit": false
          },
          {
            "score": 0.6600538492202759,
            "answer": "lil",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6511910557746887
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7900975346565247,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7541084289550781,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7419556379318237,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7415264844894409,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7292696833610535,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.7140147089958191,
            "answer": "hop",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6590374708175659
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7723466157913208,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7639392018318176,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.7540140151977539,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7123945951461792,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.6891412734985352,
            "answer": "aura",
            "hit": false
          },
          {
            "score": 0.6874932050704956,
            "answer": "secure",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 749,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5815153270959854
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7891989946365356,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7810333371162415,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7424750328063965,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6991140246391296,
            "answer": "creature",
            "hit": false
          },
          {
            "score": 0.6933614015579224,
            "answer": "chatter",
            "hit": false
          },
          {
            "score": 0.6908056139945984,
            "answer": "mammals",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 4834,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5369153954088688
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b9453b8f-9d74-4a20-9599-1bbfcbc5b89a",
      "timestamp": "2025-05-18T13:34:05.230651"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8012145161628723,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7896838784217834,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7520439028739929,
            "answer": "creature",
            "hit": false
          },
          {
            "score": 0.7476810812950134,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7433037757873535,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7356166839599609,
            "answer": "monkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 47,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5354219079017639
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8394529819488525,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.7682445049285889,
            "answer": "batting",
            "hit": false
          },
          {
            "score": 0.7611560225486755,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7241459488868713,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7147886753082275,
            "answer": "fielder",
            "hit": false
          },
          {
            "score": 0.7146565914154053,
            "answer": "balls",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6578705012798309
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7441284656524658,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7271362543106079,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7202527523040771,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7152696847915649,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.70815110206604,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6981663703918457,
            "answer": "bearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7081510573625565
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.8340489864349365,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8336183428764343,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8129960894584656,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.8050118684768677,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7985252141952515,
            "answer": "pasture",
            "hit": false
          },
          {
            "score": 0.785424530506134,
            "answer": "sheep",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7379281520843506
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7851642370223999,
            "answer": "odi",
            "hit": false
          },
          {
            "score": 0.7695350646972656,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7323811054229736,
            "answer": "ashes",
            "hit": false
          },
          {
            "score": 0.7212663888931274,
            "answer": "icc",
            "hit": false
          },
          {
            "score": 0.7179967164993286,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7094180583953857,
            "answer": "hockey",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6839140802621841
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7115784287452698,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6989738941192627,
            "answer": "wheeler",
            "hit": false
          },
          {
            "score": 0.6904847025871277,
            "answer": "nichols",
            "hit": false
          },
          {
            "score": 0.6886328458786011,
            "answer": "graves",
            "hit": false
          },
          {
            "score": 0.6879908442497253,
            "answer": "chapman",
            "hit": false
          },
          {
            "score": 0.6818827390670776,
            "answer": "hale",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7115784585475922
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8153810501098633,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7684534788131714,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7270586490631104,
            "answer": "goose",
            "hit": false
          },
          {
            "score": 0.7265931367874146,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.725847065448761,
            "answer": "bird",
            "hit": false
          },
          {
            "score": 0.7233208417892456,
            "answer": "den",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6887316256761551
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8003540635108948,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7826349139213562,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7730333209037781,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7690812945365906,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7545222043991089,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7299508452415466,
            "answer": "flight",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7730333507061005
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7827633023262024,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.7718081474304199,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.7702956199645996,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.7102841138839722,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6995147466659546,
            "answer": "anchors",
            "hit": false
          },
          {
            "score": 0.6919509172439575,
            "answer": "beck",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6519199311733246
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.8849115371704102,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.8242173194885254,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.8238941431045532,
            "answer": "larvae",
            "hit": false
          },
          {
            "score": 0.8084426522254944,
            "answer": "moth",
            "hit": false
          },
          {
            "score": 0.8068560361862183,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.8028802871704102,
            "answer": "pest",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242173194885254
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7678500413894653,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7349216938018799,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.726439356803894,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7104851603507996,
            "answer": "spies",
            "hit": false
          },
          {
            "score": 0.6948445439338684,
            "answer": "cavern",
            "hit": false
          },
          {
            "score": 0.6892467737197876,
            "answer": "gland",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6480629146099091
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7945314645767212,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7852209806442261,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7805955410003662,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7526950836181641,
            "answer": "snake",
            "hit": false
          },
          {
            "score": 0.7417656183242798,
            "answer": "frog",
            "hit": false
          },
          {
            "score": 0.7386798858642578,
            "answer": "owl",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6823808699846268
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7716156244277954,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7533209323883057,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7508379817008972,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.722528338432312,
            "answer": "keyboard",
            "hit": false
          },
          {
            "score": 0.71839839220047,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7028478384017944,
            "answer": "rats",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.750838041305542
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8227157592773438,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.7857399582862854,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7803877592086792,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7800811529159546,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7363616824150085,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7275617718696594,
            "answer": "mice",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7800812125205994
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7103341221809387,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7027671337127686,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6880004405975342,
            "answer": "piper",
            "hit": false
          },
          {
            "score": 0.6867538690567017,
            "answer": "crystal",
            "hit": false
          },
          {
            "score": 0.686636745929718,
            "answer": "holly",
            "hit": false
          },
          {
            "score": 0.6786989569664001,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7027671039104462
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7421036958694458,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.7292770147323608,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7161182165145874,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.707335352897644,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6879330277442932,
            "answer": "tee",
            "hit": false
          },
          {
            "score": 0.6857904195785522,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7161182165145874
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8491790890693665,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7916120290756226,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7778882384300232,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7766854166984558,
            "answer": "reef",
            "hit": false
          },
          {
            "score": 0.7646399736404419,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7604483962059021,
            "answer": "turtle",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7232982218265533
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.729351282119751,
            "answer": "werner",
            "hit": false
          },
          {
            "score": 0.7238981127738953,
            "answer": "franz",
            "hit": false
          },
          {
            "score": 0.7233026623725891,
            "answer": "fritz",
            "hit": false
          },
          {
            "score": 0.7223669290542603,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7214703559875488,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7199966907501221,
            "answer": "schmidt",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7074673920869827
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 18,
      "accuracy": 0.16666666666666666
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f5b9be0e-ac2a-4252-9cd9-5b908218440d",
      "timestamp": "2025-05-18T13:34:05.243680"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7987123727798462,
            "answer": "ants",
            "hit": false
          },
          {
            "score": 0.7963719367980957,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.790298581123352,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7494343519210815,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7452411651611328,
            "answer": "insect",
            "hit": false
          },
          {
            "score": 0.736151397228241,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7902986109256744
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7759149670600891,
            "answer": "iphone",
            "hit": false
          },
          {
            "score": 0.7618184089660645,
            "answer": "ipod",
            "hit": false
          },
          {
            "score": 0.7574885487556458,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7555626630783081,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7535482048988342,
            "answer": "ipad",
            "hit": false
          },
          {
            "score": 0.7399518489837646,
            "answer": "dell",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.697482630610466
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7991652488708496,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7714133858680725,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7712032198905945,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7644914388656616,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7254719734191895,
            "answer": "urine",
            "hit": false
          },
          {
            "score": 0.7186760902404785,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7714134454727173
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.8230942487716675,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7872528433799744,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7846965789794922,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7845481634140015,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7707695960998535,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7660693526268005,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.71397864818573
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7894112467765808,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7740326523780823,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7692410945892334,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7585700750350952,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7499082088470459,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7385157346725464,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5624366663396358
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7809591889381409,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7771064639091492,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7491358518600464,
            "answer": "pine",
            "hit": false
          },
          {
            "score": 0.743736982345581,
            "answer": "gray",
            "hit": false
          },
          {
            "score": 0.7393821477890015,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.72679603099823,
            "answer": "berry",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7393821626901627
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8276987075805664,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8127601742744446,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.800745964050293,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.7922103404998779,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7890706658363342,
            "answer": "colored",
            "hit": false
          },
          {
            "score": 0.7812719941139221,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8276987075805664
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8206693530082703,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7934126853942871,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7927481532096863,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7467024326324463,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7420644164085388,
            "answer": "dark",
            "hit": false
          },
          {
            "score": 0.7277764678001404,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7927481830120087
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7784453630447388,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.773928165435791,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7233918905258179,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.7223674058914185,
            "answer": "mining",
            "hit": false
          },
          {
            "score": 0.721178412437439,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7191289663314819,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7784453928470612
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7940315008163452,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7792984247207642,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7540879845619202,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7359405159950256,
            "answer": "colored",
            "hit": false
          },
          {
            "score": 0.7358338832855225,
            "answer": "tea",
            "hit": false
          },
          {
            "score": 0.732491672039032,
            "answer": "starbucks",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7792984247207642
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.8425658941268921,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8146324157714844,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.8046784400939941,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7917181253433228,
            "answer": "colored",
            "hit": false
          },
          {
            "score": 0.7889499664306641,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.7695571780204773,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8425659537315369
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7643078565597534,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7546660900115967,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7237520813941956,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7213598489761353,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7182286977767944,
            "answer": "gray",
            "hit": false
          },
          {
            "score": 0.7128769159317017,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7546661794185638
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.840425968170166,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7745647430419922,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7549743056297302,
            "answer": "drawer",
            "hit": false
          },
          {
            "score": 0.7454582452774048,
            "answer": "closet",
            "hit": false
          },
          {
            "score": 0.7431327104568481,
            "answer": "tray",
            "hit": false
          },
          {
            "score": 0.7411468625068665,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7745647132396698
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.8023408651351929,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7870404720306396,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7821340560913086,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7626367807388306,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7592112421989441,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7586496472358704,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7067500203847885
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.8391878008842468,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.8038891553878784,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7778764963150024,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7675464153289795,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7670407891273499,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7638287544250488,
            "answer": "wine",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7675464451313019
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.8045549392700195,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7852751016616821,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7671416401863098,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7568705081939697,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7481134533882141,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7442635297775269,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7442635595798492
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7867919206619263,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7798492312431335,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7622789144515991,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.7618098258972168,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7549319267272949,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.7453618049621582,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6874252706766129
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7971197366714478,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7654536366462708,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.7591737508773804,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7548785209655762,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7474738955497742,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7380051016807556,
            "answer": "colored",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7971197962760925
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.8429911136627197,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7843475937843323,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7662558555603027,
            "answer": "printed",
            "hit": false
          },
          {
            "score": 0.7635104060173035,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7588667273521423,
            "answer": "papers",
            "hit": false
          },
          {
            "score": 0.7424924373626709,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8429911136627197
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.8374561667442322,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.8306765556335449,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7910226583480835,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7621605396270752,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7561441659927368,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7498199939727783,
            "answer": "colored",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.837456226348877
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8131245374679565,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.8049905896186829,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7967559099197388,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.790207028388977,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7677861452102661,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7642025947570801,
            "answer": "onion",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 10823,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5066657685674727
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7598265409469604,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7591341733932495,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7282476425170898,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.719169557094574,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7132272720336914,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7022643685340881,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7591341733932495
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.8256564736366272,
            "answer": "climbed",
            "hit": false
          },
          {
            "score": 0.8087329864501953,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.8069650530815125,
            "answer": "dipped",
            "hit": false
          },
          {
            "score": 0.7975809574127197,
            "answer": "jumped",
            "hit": false
          },
          {
            "score": 0.7814648151397705,
            "answer": "plunged",
            "hit": false
          },
          {
            "score": 0.7722994089126587,
            "answer": "white",
            "hit": true
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7374576926231384
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7873563170433044,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7715028524398804,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7338686585426331,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.712537944316864,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7122997045516968,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7081355452537537,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7122996896505356
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7917704582214355,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7870961427688599,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7576818466186523,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7337692975997925,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.725489616394043,
            "answer": "colored",
            "hit": false
          },
          {
            "score": 0.7132885456085205,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7917705178260803
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7918878793716431,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7912389039993286,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.788384735584259,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7582504749298096,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7536085844039917,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7533643245697021,
            "answer": "seas",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7912389039993286
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8049156069755554,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.8016362190246582,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.7844308018684387,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.780608594417572,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.764573335647583,
            "answer": "skies",
            "hit": false
          },
          {
            "score": 0.7504152655601501,
            "answer": "colored",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8016362488269806
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7971916198730469,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7726427316665649,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7521749138832092,
            "answer": "rain",
            "hit": false
          },
          {
            "score": 0.7460899353027344,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7438979148864746,
            "answer": "fog",
            "hit": false
          },
          {
            "score": 0.7322314977645874,
            "answer": "icy",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7971916496753693
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.7805734872817993,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7676876783370972,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7546981573104858,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7252581119537354,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7033933401107788,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.702210009098053,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7546981573104858
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8207191228866577,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.8020064234733582,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7643189430236816,
            "answer": "colored",
            "hit": false
          },
          {
            "score": 0.7515259981155396,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7438006401062012,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7425215840339661,
            "answer": "cocoa",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8207191526889801
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7722327709197998,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.762921154499054,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7519973516464233,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.718339204788208,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7168323993682861,
            "answer": "herald",
            "hit": false
          },
          {
            "score": 0.6962711811065674,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6962711960077286
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7625336050987244,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7587491869926453,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.729087233543396,
            "answer": "darling",
            "hit": false
          },
          {
            "score": 0.7273811101913452,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7229089736938477,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.715495228767395,
            "answer": "victorian",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7587492167949677
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.8094860315322876,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7948415875434875,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7689173221588135,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7513753771781921,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7420364618301392,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7366569638252258,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7948416173458099
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.8123977184295654,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7983334064483643,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7913642525672913,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7908998727798462,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7644622325897217,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.761422872543335,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.790899932384491
      }
    ],
    "result": {
      "cnt_questions_correct": 12,
      "cnt_questions_total": 34,
      "accuracy": 0.35294117647058826
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "22b26da9-c45d-44d5-a3b2-3c3e7f880d34",
      "timestamp": "2025-05-18T13:34:05.290410"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.9506438374519348,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.8325906991958618,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.8136715888977051,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.7898168563842773,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.7705525159835815,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7694796323776245,
            "answer": "filmmaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9506438672542572
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.9600499272346497,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.8644382357597351,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.8435221910476685,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.8341240882873535,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8225401639938354,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.817397952079773,
            "answer": "grandmother",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9600499272346497
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.926622211933136,
            "answer": "sister",
            "hit": true
          },
          {
            "score": 0.9062745571136475,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.8996466398239136,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8957833051681519,
            "answer": "son",
            "hit": false
          },
          {
            "score": 0.8877493739128113,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.887616753578186,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9266222417354584
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.7196347713470459,
            "answer": "pierce",
            "hit": false
          },
          {
            "score": 0.7064948678016663,
            "answer": "wiley",
            "hit": false
          },
          {
            "score": 0.704745352268219,
            "answer": "hart",
            "hit": false
          },
          {
            "score": 0.7019635438919067,
            "answer": "hunter",
            "hit": false
          },
          {
            "score": 0.7000159621238708,
            "answer": "bailey",
            "hit": false
          },
          {
            "score": 0.6996113061904907,
            "answer": "barton",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 4761,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5345747321844101
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.7274358868598938,
            "answer": "cow",
            "hit": true
          },
          {
            "score": 0.7113919258117676,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.7016159296035767,
            "answer": "bear",
            "hit": false
          },
          {
            "score": 0.6998943090438843,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.6962858438491821,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.6958414316177368,
            "answer": "goat",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7274358868598938
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.9098502397537231,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.8868491649627686,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8688738942146301,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8674936890602112,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8516634702682495,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8496561050415039,
            "answer": "mum",
            "hit": true
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9098502695560455
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7271565198898315,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.7227134704589844,
            "answer": "acc",
            "hit": false
          },
          {
            "score": 0.7167210578918457,
            "answer": "stanford",
            "hit": false
          },
          {
            "score": 0.7125638127326965,
            "answer": "maryland",
            "hit": false
          },
          {
            "score": 0.7117499113082886,
            "answer": "pitt",
            "hit": false
          },
          {
            "score": 0.70720374584198,
            "answer": "duchess",
            "hit": true
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7072037309408188
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.953702449798584,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.9277603030204773,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.9084276556968689,
            "answer": "son",
            "hit": false
          },
          {
            "score": 0.8997911214828491,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8965809345245361,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.8930191993713379,
            "answer": "niece",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.953702449798584
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.8288965225219727,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.8205245733261108,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7923634052276611,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.7840877771377563,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7767949104309082,
            "answer": "scripture",
            "hit": false
          },
          {
            "score": 0.7737542390823364,
            "answer": "bible",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7092426866292953
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.9128262996673584,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8798941373825073,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.8672779202461243,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8631373643875122,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8593040704727173,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8512237071990967,
            "answer": "father",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9128262996673584
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.8556654453277588,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7647563219070435,
            "answer": "wedding",
            "hit": false
          },
          {
            "score": 0.7235654592514038,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7085456848144531,
            "answer": "maid",
            "hit": false
          },
          {
            "score": 0.7083147168159485,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7074393033981323,
            "answer": "weddings",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556654751300812
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8975353240966797,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.8859869837760925,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8824785351753235,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8438209891319275,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8366832733154297,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.8326456546783447,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8975353837013245
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7968558073043823,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.7464419603347778,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.7328630685806274,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.7310700416564941,
            "answer": "jackson",
            "hit": false
          },
          {
            "score": 0.7211068868637085,
            "answer": "prince",
            "hit": false
          },
          {
            "score": 0.7162607908248901,
            "answer": "greene",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7968557775020599
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.9357240796089172,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.8519060611724854,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.8293073177337646,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.8211753964424133,
            "answer": "boy",
            "hit": false
          },
          {
            "score": 0.7678359746932983,
            "answer": "robber",
            "hit": false
          },
          {
            "score": 0.766814112663269,
            "answer": "person",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9357240498065948
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9374613761901855,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.9044951796531677,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8899858593940735,
            "answer": "son",
            "hit": false
          },
          {
            "score": 0.8890370726585388,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.8827904462814331,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.8781496286392212,
            "answer": "grandson",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9374613761901855
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8139541149139404,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.7337380647659302,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.7095302939414978,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7053985595703125,
            "answer": "king",
            "hit": false
          },
          {
            "score": 0.705280065536499,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.7008271813392639,
            "answer": "duchess",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8139541447162628
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.973552405834198,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.9387040138244629,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.9187832474708557,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8932509422302246,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8858962655067444,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8857970833778381,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9735523462295532
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.9403440356254578,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.9119119644165039,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.9033185243606567,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8984631896018982,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.8876593112945557,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.885796308517456,
            "answer": "father",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9403440654277802
      }
    ],
    "result": {
      "cnt_questions_correct": 15,
      "cnt_questions_total": 18,
      "accuracy": 0.8333333333333334
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d0affef7-593a-4a96-976f-d147b8464199",
      "timestamp": "2025-05-18T13:34:05.411018"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7594032883644104,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.7518730759620667,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.7492280602455139,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.7243695259094238,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.723789393901825,
            "answer": "gases",
            "hit": false
          },
          {
            "score": 0.7202168703079224,
            "answer": "aura",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5913905128836632
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8935985565185547,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.80149245262146,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.793618381023407,
            "answer": "backpack",
            "hit": false
          },
          {
            "score": 0.7664583325386047,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.7541955709457397,
            "answer": "bin",
            "hit": false
          },
          {
            "score": 0.7530702948570251,
            "answer": "wallet",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.660040482878685
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.8012955188751221,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.7468051910400391,
            "answer": "bald",
            "hit": false
          },
          {
            "score": 0.7381218671798706,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.7271032333374023,
            "answer": "curly",
            "hit": false
          },
          {
            "score": 0.726164698600769,
            "answer": "wig",
            "hit": false
          },
          {
            "score": 0.7176828384399414,
            "answer": "blond",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8012955486774445
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.8287074565887451,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.7562426328659058,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.7466551661491394,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7361406683921814,
            "answer": "bones",
            "hit": true
          },
          {
            "score": 0.7126515507698059,
            "answer": "muscles",
            "hit": false
          },
          {
            "score": 0.7094318270683289,
            "answer": "bodily",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.662568673491478
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.8245897889137268,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.783225417137146,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.7559247016906738,
            "answer": "jeans",
            "hit": false
          },
          {
            "score": 0.7489609718322754,
            "answer": "shoe",
            "hit": false
          },
          {
            "score": 0.7416194677352905,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7341011762619019,
            "answer": "trousers",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7151630818843842
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8994404077529907,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.8168501853942871,
            "answer": "jug",
            "hit": false
          },
          {
            "score": 0.8045132160186768,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.7777410745620728,
            "answer": "cans",
            "hit": false
          },
          {
            "score": 0.7760887145996094,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.7682372331619263,
            "answer": "beer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8045132756233215
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8731915354728699,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.6993773579597473,
            "answer": "pac",
            "hit": false
          },
          {
            "score": 0.6958215236663818,
            "answer": "acc",
            "hit": false
          },
          {
            "score": 0.6951513886451721,
            "answer": "ncaa",
            "hit": false
          },
          {
            "score": 0.6897439956665039,
            "answer": "noodles",
            "hit": false
          },
          {
            "score": 0.6851930618286133,
            "answer": "odi",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6481060832738876
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.74466872215271,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7422722578048706,
            "answer": "brew",
            "hit": false
          },
          {
            "score": 0.7402600049972534,
            "answer": "gin",
            "hit": false
          },
          {
            "score": 0.7363162040710449,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.736126184463501,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7192689776420593,
            "answer": "drink",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 54,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6560818552970886
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7423614263534546,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.7078300714492798,
            "answer": "hallway",
            "hit": false
          },
          {
            "score": 0.7051225900650024,
            "answer": "drawer",
            "hit": false
          },
          {
            "score": 0.6996186971664429,
            "answer": "cabinets",
            "hit": false
          },
          {
            "score": 0.6994333267211914,
            "answer": "doorway",
            "hit": false
          },
          {
            "score": 0.6972061395645142,
            "answer": "kitchen",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 479,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5405284725129604
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7149105072021484,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7110768556594849,
            "answer": "golden",
            "hit": false
          },
          {
            "score": 0.7023780345916748,
            "answer": "wolf",
            "hit": false
          },
          {
            "score": 0.6963122487068176,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.6962919235229492,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.6875737905502319,
            "answer": "pearl",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 3080,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5369781479239464
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.9067356586456299,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.748909592628479,
            "answer": "banner",
            "hit": false
          },
          {
            "score": 0.6935052275657654,
            "answer": "jersey",
            "hit": false
          },
          {
            "score": 0.6892342567443848,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6837794780731201,
            "answer": "colors",
            "hit": false
          },
          {
            "score": 0.6761341094970703,
            "answer": "helmet",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 105,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6220004484057426
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8527423739433289,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.8209930062294006,
            "answer": "apartment",
            "hit": false
          },
          {
            "score": 0.8083014488220215,
            "answer": "bedroom",
            "hit": false
          },
          {
            "score": 0.7920615673065186,
            "answer": "residence",
            "hit": false
          },
          {
            "score": 0.7843936085700989,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.7807350158691406,
            "answer": "homes",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 77,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6696214228868484
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7009760141372681,
            "answer": "funk",
            "hit": false
          },
          {
            "score": 0.6923359036445618,
            "answer": "acoustic",
            "hit": false
          },
          {
            "score": 0.6846717000007629,
            "answer": "rock",
            "hit": false
          },
          {
            "score": 0.6815048456192017,
            "answer": "batter",
            "hit": false
          },
          {
            "score": 0.6807605028152466,
            "answer": "groove",
            "hit": false
          },
          {
            "score": 0.6769613027572632,
            "answer": "guitar",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5840642675757408
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7861805558204651,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7845337986946106,
            "answer": "grass",
            "hit": true
          },
          {
            "score": 0.7483309507369995,
            "answer": "driveway",
            "hit": false
          },
          {
            "score": 0.7457008361816406,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.7451376914978027,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7396936416625977,
            "answer": "weeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7845337986946106
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8864179253578186,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.7783567905426025,
            "answer": "prism",
            "hit": false
          },
          {
            "score": 0.7780603766441345,
            "answer": "aperture",
            "hit": false
          },
          {
            "score": 0.7739891409873962,
            "answer": "optics",
            "hit": false
          },
          {
            "score": 0.7557294368743896,
            "answer": "optic",
            "hit": false
          },
          {
            "score": 0.735060453414917,
            "answer": "camera",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6800052672624588
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.801729679107666,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7262924909591675,
            "answer": "prism",
            "hit": false
          },
          {
            "score": 0.7026103734970093,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6952055096626282,
            "answer": "lens",
            "hit": false
          },
          {
            "score": 0.6901227831840515,
            "answer": "window",
            "hit": false
          },
          {
            "score": 0.6894164085388184,
            "answer": "reflection",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7026104032993317
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.8429287672042847,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7942909002304077,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.790549635887146,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.7803868651390076,
            "answer": "fund",
            "hit": false
          },
          {
            "score": 0.7493929862976074,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.7217625379562378,
            "answer": "sums",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 451,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6029203236103058
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8627405166625977,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.8599817156791687,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.7925105690956116,
            "answer": "reef",
            "hit": false
          },
          {
            "score": 0.7765505909919739,
            "answer": "coral",
            "hit": false
          },
          {
            "score": 0.775044322013855,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7625764608383179,
            "answer": "waters",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7542537450790405
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.8021280765533447,
            "answer": "chocolate",
            "hit": false
          },
          {
            "score": 0.80061936378479,
            "answer": "baking",
            "hit": false
          },
          {
            "score": 0.799853503704071,
            "answer": "cheese",
            "hit": false
          },
          {
            "score": 0.781793475151062,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7796010971069336,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.7784574031829834,
            "answer": "pasta",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7386818081140518
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.8220807313919067,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.7617439031600952,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7225280404090881,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7158627510070801,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.7001565098762512,
            "answer": "profits",
            "hit": false
          },
          {
            "score": 0.6829862594604492,
            "answer": "tax",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6116775050759315
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.8763466477394104,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7652643322944641,
            "answer": "medication",
            "hit": false
          },
          {
            "score": 0.7631362080574036,
            "answer": "prescription",
            "hit": false
          },
          {
            "score": 0.7464596629142761,
            "answer": "medications",
            "hit": false
          },
          {
            "score": 0.745845377445221,
            "answer": "drugs",
            "hit": false
          },
          {
            "score": 0.7456570863723755,
            "answer": "drug",
            "hit": true
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6637503653764725
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.8194904327392578,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7964343428611755,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7903870940208435,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.7892218828201294,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7835598587989807,
            "answer": "resin",
            "hit": false
          },
          {
            "score": 0.779607355594635,
            "answer": "aluminum",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7661053240299225
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8561503887176514,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.8224683403968811,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7979912161827087,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7873410582542419,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7558214664459229,
            "answer": "coastal",
            "hit": false
          },
          {
            "score": 0.7436349987983704,
            "answer": "coral",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7401059865951538
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7660506963729858,
            "answer": "tray",
            "hit": false
          },
          {
            "score": 0.7549079060554504,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.7546055912971497,
            "answer": "tub",
            "hit": false
          },
          {
            "score": 0.7438347935676575,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.7429530620574951,
            "answer": "jug",
            "hit": false
          },
          {
            "score": 0.7388827800750732,
            "answer": "cups",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 368,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6006456762552261
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8337806463241577,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.7192095518112183,
            "answer": "tray",
            "hit": false
          },
          {
            "score": 0.6918970346450806,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.6859390735626221,
            "answer": "floor",
            "hit": false
          },
          {
            "score": 0.6839088797569275,
            "answer": "stool",
            "hit": false
          },
          {
            "score": 0.6828014254570007,
            "answer": "sofa",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 421,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5492467284202576
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.8165463209152222,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.7691265344619751,
            "answer": "costume",
            "hit": false
          },
          {
            "score": 0.7469974160194397,
            "answer": "beard",
            "hit": false
          },
          {
            "score": 0.7469244003295898,
            "answer": "scarf",
            "hit": false
          },
          {
            "score": 0.7400502562522888,
            "answer": "gown",
            "hit": false
          },
          {
            "score": 0.7353456020355225,
            "answer": "dress",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8165462613105774
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.9149695634841919,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.8425929546356201,
            "answer": "grape",
            "hit": true
          },
          {
            "score": 0.8266964554786682,
            "answer": "grapes",
            "hit": true
          },
          {
            "score": 0.796926736831665,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7893340587615967,
            "answer": "tasting",
            "hit": false
          },
          {
            "score": 0.7856565713882446,
            "answer": "whiskey",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8266964554786682
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.8177263736724854,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.7347191572189331,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.733517050743103,
            "answer": "cord",
            "hit": false
          },
          {
            "score": 0.7269115447998047,
            "answer": "electrical",
            "hit": false
          },
          {
            "score": 0.7216957807540894,
            "answer": "cables",
            "hit": false
          },
          {
            "score": 0.715141236782074,
            "answer": "cords",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6997286677360535
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 28,
      "accuracy": 0.07142857142857142
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "64d7cd19-cceb-482a-882b-6610f2d7e4be",
      "timestamp": "2025-05-18T13:34:05.457548"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.8985308408737183,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.8170837759971619,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7962008714675903,
            "answer": "goose",
            "hit": false
          },
          {
            "score": 0.7801427841186523,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7771437168121338,
            "answer": "wildlife",
            "hit": false
          },
          {
            "score": 0.7704992294311523,
            "answer": "insect",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7419660538434982
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8321614265441895,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.8255878686904907,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.8191201686859131,
            "answer": "knee",
            "hit": false
          },
          {
            "score": 0.8055253028869629,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7649754285812378,
            "answer": "leg",
            "hit": false
          },
          {
            "score": 0.7649050354957581,
            "answer": "rib",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6648078560829163
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.8774204254150391,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.8637062907218933,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.8386831283569336,
            "answer": "suv",
            "hit": false
          },
          {
            "score": 0.8051155805587769,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.8038104176521301,
            "answer": "sedan",
            "hit": false
          },
          {
            "score": 0.803238034248352,
            "answer": "mercedes",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6716151386499405
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8823022842407227,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8479946851730347,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8443563580513,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.8277761936187744,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.8212969303131104,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.816999077796936,
            "answer": "sheep",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8277761936187744
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.7967298030853271,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.7915624380111694,
            "answer": "evangelical",
            "hit": false
          },
          {
            "score": 0.7826509475708008,
            "answer": "baptist",
            "hit": false
          },
          {
            "score": 0.7783779501914978,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.7701576948165894,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.7659902572631836,
            "answer": "religious",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7226637303829193
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.8223680257797241,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.8133581280708313,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7800859212875366,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7724417448043823,
            "answer": "graduation",
            "hit": false
          },
          {
            "score": 0.7603162527084351,
            "answer": "prep",
            "hit": false
          },
          {
            "score": 0.7575333118438721,
            "answer": "graduating",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6921465843915939
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.8647018671035767,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.770236611366272,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.761992871761322,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7273085117340088,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7263717651367188,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7100741267204285,
            "answer": "commissioners",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6881748586893082
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8784455060958862,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8136659264564514,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.8125351667404175,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7975583076477051,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.7907080054283142,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7903115153312683,
            "answer": "goat",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8125351369380951
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7207920551300049,
            "answer": "chapman",
            "hit": false
          },
          {
            "score": 0.7177602052688599,
            "answer": "wheeler",
            "hit": false
          },
          {
            "score": 0.7118380069732666,
            "answer": "nichols",
            "hit": false
          },
          {
            "score": 0.7061251401901245,
            "answer": "anderson",
            "hit": false
          },
          {
            "score": 0.7058713436126709,
            "answer": "thompson",
            "hit": false
          },
          {
            "score": 0.7042027711868286,
            "answer": "wolf",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 12723,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4909656224772334
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8808166980743408,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7561079859733582,
            "answer": "zoo",
            "hit": false
          },
          {
            "score": 0.7551984190940857,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7413355112075806,
            "answer": "ape",
            "hit": false
          },
          {
            "score": 0.7321557402610779,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7306186556816101,
            "answer": "lion",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7321557402610779
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.8719986081123352,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.826576292514801,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7982596755027771,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.7770706415176392,
            "answer": "workers",
            "hit": false
          },
          {
            "score": 0.7470359802246094,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.7467548251152039,
            "answer": "customer",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7289145290851593
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.8627250790596008,
            "answer": "trout",
            "hit": false
          },
          {
            "score": 0.8474454879760742,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.8436865210533142,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.8223171830177307,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.8080997467041016,
            "answer": "cod",
            "hit": false
          },
          {
            "score": 0.8070443272590637,
            "answer": "carp",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 6821,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5294630285352468
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.760836124420166,
            "answer": "mls",
            "hit": false
          },
          {
            "score": 0.6862395405769348,
            "answer": "rapids",
            "hit": false
          },
          {
            "score": 0.6849503517150879,
            "answer": "thunder",
            "hit": false
          },
          {
            "score": 0.681481122970581,
            "answer": "magic",
            "hit": false
          },
          {
            "score": 0.6784694194793701,
            "answer": "nexus",
            "hit": false
          },
          {
            "score": 0.6760098338127136,
            "answer": "sol",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 134,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.608419768512249
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.8561723232269287,
            "answer": "memo",
            "hit": false
          },
          {
            "score": 0.8482528924942017,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.8002175092697144,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7899277806282043,
            "answer": "statement",
            "hit": false
          },
          {
            "score": 0.7565810680389404,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.742214560508728,
            "answer": "document",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 1402,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5641884580254555
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.724886417388916,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7061187028884888,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7049470543861389,
            "answer": "beast",
            "hit": false
          },
          {
            "score": 0.7028194665908813,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.6991989016532898,
            "answer": "beasts",
            "hit": false
          },
          {
            "score": 0.6975645422935486,
            "answer": "bear",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 459,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5872406288981438
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8831954598426819,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7649045586585999,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.7635228633880615,
            "answer": "melody",
            "hit": false
          },
          {
            "score": 0.739197850227356,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7375593185424805,
            "answer": "audience",
            "hit": true
          },
          {
            "score": 0.7245166897773743,
            "answer": "listen",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7375592887401581
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.8622207641601562,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7601873278617859,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7549129724502563,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.742258608341217,
            "answer": "founding",
            "hit": false
          },
          {
            "score": 0.7331094741821289,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.7256695032119751,
            "answer": "chair",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.59185741096735
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8593885898590088,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8534541726112366,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.8507838249206543,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.8228973746299744,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.8074131011962891,
            "answer": "artist",
            "hit": false
          },
          {
            "score": 0.8055605292320251,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7363482266664505
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.8071995973587036,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.7710649967193604,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7569807171821594,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.7534750699996948,
            "answer": "somebody",
            "hit": false
          },
          {
            "score": 0.7443699240684509,
            "answer": "anyone",
            "hit": false
          },
          {
            "score": 0.7434381246566772,
            "answer": "woman",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 126,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6380338370800018
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.898247480392456,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.8756726980209351,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.8527557849884033,
            "answer": "pictures",
            "hit": false
          },
          {
            "score": 0.8410400748252869,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7840980291366577,
            "answer": "picture",
            "hit": false
          },
          {
            "score": 0.7673170566558838,
            "answer": "images",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 766,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.556053601205349
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.8694714307785034,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7956556081771851,
            "answer": "league",
            "hit": false
          },
          {
            "score": 0.7788533568382263,
            "answer": "team",
            "hit": true
          },
          {
            "score": 0.7633498907089233,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.761762261390686,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7579379081726074,
            "answer": "club",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7788533866405487
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8108930587768555,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.8056768178939819,
            "answer": "cop",
            "hit": false
          },
          {
            "score": 0.7895015478134155,
            "answer": "sergeant",
            "hit": false
          },
          {
            "score": 0.7833378314971924,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7803357839584351,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7728615999221802,
            "answer": "soldier",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8108930587768555
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7536347508430481,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.7349732518196106,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.7296602725982666,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7208364009857178,
            "answer": "cabinet",
            "hit": false
          },
          {
            "score": 0.7193777561187744,
            "answer": "ministers",
            "hit": false
          },
          {
            "score": 0.70628821849823,
            "answer": "ministry",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 541,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5713780447840691
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8408875465393066,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.821921169757843,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.805120587348938,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7991448640823364,
            "answer": "democrat",
            "hit": false
          },
          {
            "score": 0.7853063344955444,
            "answer": "governor",
            "hit": false
          },
          {
            "score": 0.7681298851966858,
            "answer": "republican",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.805120587348938
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.8537701368331909,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.8400119543075562,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.8367224931716919,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.8331985473632812,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.8274702429771423,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.8234528303146362,
            "answer": "livestock",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7300348877906799
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8934439420700073,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.8167070150375366,
            "answer": "regiment",
            "hit": false
          },
          {
            "score": 0.8075294494628906,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.8070279955863953,
            "answer": "battalion",
            "hit": false
          },
          {
            "score": 0.8035969138145447,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.7892684936523438,
            "answer": "comrades",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.807529479265213
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.7756195664405823,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.775274395942688,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7510147094726562,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.750863790512085,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.747341513633728,
            "answer": "inheritance",
            "hit": false
          },
          {
            "score": 0.744216799736023,
            "answer": "couples",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.612393818795681
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7780095338821411,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7727395296096802,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7579215168952942,
            "answer": "districts",
            "hit": false
          },
          {
            "score": 0.7553630471229553,
            "answer": "legislature",
            "hit": false
          },
          {
            "score": 0.7383545637130737,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.7320157885551453,
            "answer": "federal",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7271218597888947
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8712530136108398,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.8351423740386963,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.8281680345535278,
            "answer": "school",
            "hit": true
          },
          {
            "score": 0.8081101179122925,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.8074456453323364,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.7984750270843506,
            "answer": "teacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6798879355192184
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.8998661041259766,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7842839360237122,
            "answer": "bushes",
            "hit": false
          },
          {
            "score": 0.7676858901977539,
            "answer": "canopy",
            "hit": false
          },
          {
            "score": 0.7455999851226807,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.7393429279327393,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7330755591392517,
            "answer": "lawn",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 214,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.628049448132515
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.7506822347640991,
            "answer": "stone",
            "hit": false
          },
          {
            "score": 0.7370688319206238,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7355606555938721,
            "answer": "wagner",
            "hit": false
          },
          {
            "score": 0.7351241707801819,
            "answer": "becker",
            "hit": false
          },
          {
            "score": 0.7344309091567993,
            "answer": "hoffman",
            "hit": false
          },
          {
            "score": 0.7333202362060547,
            "answer": "schneider",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 1454,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5628238245844841
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.8075931668281555,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.7675373554229736,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7617683410644531,
            "answer": "verb",
            "hit": false
          },
          {
            "score": 0.7382615804672241,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.7358613014221191,
            "answer": "noun",
            "hit": false
          },
          {
            "score": 0.7200437188148499,
            "answer": "meaning",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6393210887908936
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f9b12735-c995-4ba3-9e80-d519c2b23707",
      "timestamp": "2025-05-18T13:34:05.534246"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.8378174304962158,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.7450433969497681,
            "answer": "van",
            "hit": false
          },
          {
            "score": 0.7449835538864136,
            "answer": "taxi",
            "hit": false
          },
          {
            "score": 0.744457483291626,
            "answer": "train",
            "hit": false
          },
          {
            "score": 0.7441869974136353,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.7223566770553589,
            "answer": "cab",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6034797057509422
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.7810811996459961,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.7118878364562988,
            "answer": "unicode",
            "hit": false
          },
          {
            "score": 0.711596667766571,
            "answer": "integer",
            "hit": false
          },
          {
            "score": 0.704295814037323,
            "answer": "pixel",
            "hit": false
          },
          {
            "score": 0.7015719413757324,
            "answer": "node",
            "hit": false
          },
          {
            "score": 0.6976957321166992,
            "answer": "domains",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 729,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5810478627681732
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.7003377079963684,
            "answer": "scrub",
            "hit": false
          },
          {
            "score": 0.6903619766235352,
            "answer": "scrape",
            "hit": false
          },
          {
            "score": 0.6848589181900024,
            "answer": "searched",
            "hit": false
          },
          {
            "score": 0.684058427810669,
            "answer": "searching",
            "hit": false
          },
          {
            "score": 0.6828666925430298,
            "answer": "curl",
            "hit": false
          },
          {
            "score": 0.6772719621658325,
            "answer": "dig",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 48,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6404626220464706
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.7662461996078491,
            "answer": "currency",
            "hit": false
          },
          {
            "score": 0.7519738674163818,
            "answer": "euro",
            "hit": false
          },
          {
            "score": 0.7436996102333069,
            "answer": "rand",
            "hit": false
          },
          {
            "score": 0.7292028665542603,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6817923188209534,
            "answer": "prices",
            "hit": false
          },
          {
            "score": 0.6801362037658691,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6725521236658096
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "54314213-6fb4-49fc-abdf-a6a13423064c",
      "timestamp": "2025-05-18T13:34:05.627715"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.9037668108940125,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8436896204948425,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.8381044864654541,
            "answer": "pleased",
            "hit": false
          },
          {
            "score": 0.8120498657226562,
            "answer": "proud",
            "hit": false
          },
          {
            "score": 0.8082060813903809,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.7906242609024048,
            "answer": "happy",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6025402694940567
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8248122930526733,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.8122670650482178,
            "answer": "apartment",
            "hit": false
          },
          {
            "score": 0.8120800256729126,
            "answer": "bedroom",
            "hit": false
          },
          {
            "score": 0.7913460731506348,
            "answer": "residence",
            "hit": false
          },
          {
            "score": 0.7821825742721558,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.7605152130126953,
            "answer": "homes",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 2023,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5564507693052292
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7962765693664551,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.7807760238647461,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7666596174240112,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7659369707107544,
            "answer": "canyon",
            "hit": false
          },
          {
            "score": 0.727859377861023,
            "answer": "springs",
            "hit": false
          },
          {
            "score": 0.7260898351669312,
            "answer": "valley",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 413,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5520964562892914
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.8321533203125,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7977831363677979,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.7938015460968018,
            "answer": "ache",
            "hit": false
          },
          {
            "score": 0.7718625068664551,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7608955502510071,
            "answer": "anxiety",
            "hit": false
          },
          {
            "score": 0.7514457702636719,
            "answer": "trauma",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.707634836435318
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.7592425346374512,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.7336649894714355,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7254612445831299,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.709385335445404,
            "answer": "saddle",
            "hit": false
          },
          {
            "score": 0.7009571194648743,
            "answer": "dog",
            "hit": false
          },
          {
            "score": 0.7002936601638794,
            "answer": "cow",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7592425048351288
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.8504968285560608,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.8149104714393616,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7888486981391907,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7778944969177246,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7339780330657959,
            "answer": "coastal",
            "hit": false
          },
          {
            "score": 0.7270153760910034,
            "answer": "coral",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8504968285560608
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8655447363853455,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.7741039991378784,
            "answer": "soda",
            "hit": false
          },
          {
            "score": 0.7740796804428101,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.771404504776001,
            "answer": "cereal",
            "hit": false
          },
          {
            "score": 0.7713812589645386,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7711730003356934,
            "answer": "meal",
            "hit": true
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7711730301380157
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.8265346884727478,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8073657155036926,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.7980214357376099,
            "answer": "frustrated",
            "hit": false
          },
          {
            "score": 0.7838711142539978,
            "answer": "annoyed",
            "hit": false
          },
          {
            "score": 0.7703521847724915,
            "answer": "impatient",
            "hit": false
          },
          {
            "score": 0.7633959054946899,
            "answer": "exhausted",
            "hit": true
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7633958756923676
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 8,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7b5031a7-98d2-4288-bf7f-2c7f96794f42",
      "timestamp": "2025-05-18T13:34:05.637982"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.9136141538619995,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.8351324200630188,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.8316525220870972,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.763018786907196,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.7512304186820984,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.7433764338493347,
            "answer": "car",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9136141240596771
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7984052896499634,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.795979917049408,
            "answer": "fabric",
            "hit": true
          },
          {
            "score": 0.7809728384017944,
            "answer": "silk",
            "hit": false
          },
          {
            "score": 0.7659124135971069,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7588717937469482,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.753035843372345,
            "answer": "leather",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7959798872470856
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8128666281700134,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.7861475348472595,
            "answer": "billions",
            "hit": false
          },
          {
            "score": 0.7773072719573975,
            "answer": "millions",
            "hit": false
          },
          {
            "score": 0.7739489078521729,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7484942078590393,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.74720299243927,
            "answer": "tens",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 2915,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5516106858849525
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.9284777045249939,
            "answer": "son",
            "hit": false
          },
          {
            "score": 0.9107763767242432,
            "answer": "uncle",
            "hit": false
          },
          {
            "score": 0.8985880613327026,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.8921979665756226,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.8912886381149292,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8776604533195496,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8921979665756226
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.8140740394592285,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.7984015345573425,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7727994918823242,
            "answer": "assist",
            "hit": true
          },
          {
            "score": 0.7715573310852051,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.7611724138259888,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7564393281936646,
            "answer": "try",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6891283392906189
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.8131471276283264,
            "answer": "smart",
            "hit": true
          },
          {
            "score": 0.7725818753242493,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.7602341771125793,
            "answer": "intuitive",
            "hit": false
          },
          {
            "score": 0.750198483467102,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.7303709983825684,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7297317981719971,
            "answer": "efficient",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7501985132694244
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8102980256080627,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.798683762550354,
            "answer": "gem",
            "hit": true
          },
          {
            "score": 0.7356061935424805,
            "answer": "treasure",
            "hit": false
          },
          {
            "score": 0.735596239566803,
            "answer": "treasures",
            "hit": false
          },
          {
            "score": 0.7315759062767029,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7303242683410645,
            "answer": "pristine",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7986837327480316
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.850449800491333,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.8439722061157227,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.7866209149360657,
            "answer": "cemetery",
            "hit": false
          },
          {
            "score": 0.771905779838562,
            "answer": "museum",
            "hit": false
          },
          {
            "score": 0.7693310976028442,
            "answer": "statues",
            "hit": false
          },
          {
            "score": 0.7590625286102295,
            "answer": "sculpture",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7312767207622528
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7859053611755371,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.7375747561454773,
            "answer": "existing",
            "hit": false
          },
          {
            "score": 0.7368089556694031,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.7350255846977234,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.7163121700286865,
            "answer": "latest",
            "hit": false
          },
          {
            "score": 0.7112092971801758,
            "answer": "current",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.666335940361023
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.8499854803085327,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.705548882484436,
            "answer": "plan",
            "hit": false
          },
          {
            "score": 0.7023647427558899,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.6990122199058533,
            "answer": "bundle",
            "hit": true
          },
          {
            "score": 0.69266676902771,
            "answer": "bill",
            "hit": false
          },
          {
            "score": 0.6908524632453918,
            "answer": "proposal",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6521273851394653
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8722525835037231,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.8384358882904053,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.8072543740272522,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.8019771575927734,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7889471054077148,
            "answer": "train",
            "hit": false
          },
          {
            "score": 0.7392852306365967,
            "answer": "freight",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8384358882904053
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.8147837519645691,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.8130383491516113,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.8004462718963623,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.7797094583511353,
            "answer": "reasoned",
            "hit": false
          },
          {
            "score": 0.7574098706245422,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.7506197690963745,
            "answer": "logic",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7478137314319611
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.7988621592521667,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7913910150527954,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7746918201446533,
            "answer": "appropriate",
            "hit": false
          },
          {
            "score": 0.7637755870819092,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.759837806224823,
            "answer": "sensible",
            "hit": true
          },
          {
            "score": 0.7500128746032715,
            "answer": "plausible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7598377764225006
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7927329540252686,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.7885764837265015,
            "answer": "punk",
            "hit": false
          },
          {
            "score": 0.7730387449264526,
            "answer": "band",
            "hit": false
          },
          {
            "score": 0.7538697719573975,
            "answer": "pop",
            "hit": false
          },
          {
            "score": 0.7457443475723267,
            "answer": "bands",
            "hit": false
          },
          {
            "score": 0.7267034649848938,
            "answer": "jazz",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 341,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6054370552301407
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.8995665907859802,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.7845062017440796,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.7811775207519531,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.7763581275939941,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.7569651007652283,
            "answer": "cot",
            "hit": false
          },
          {
            "score": 0.7565293312072754,
            "answer": "bedroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8995666205883026
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.8193837404251099,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7788569927215576,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7483385801315308,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.7405867576599121,
            "answer": "motif",
            "hit": false
          },
          {
            "score": 0.7246325016021729,
            "answer": "philosophy",
            "hit": false
          },
          {
            "score": 0.7222402691841125,
            "answer": "approach",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6393049657344818
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3381572c-ce8d-4b66-9845-2a100d5ee8fe",
      "timestamp": "2025-05-18T13:34:05.657580"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8535687327384949,
            "answer": "before",
            "hit": true
          },
          {
            "score": 0.8213975429534912,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.8104242086410522,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.7907981872558594,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.7828834652900696,
            "answer": "last",
            "hit": false
          },
          {
            "score": 0.7695508599281311,
            "answer": "earlier",
            "hit": true
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8535687625408173
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.757899284362793,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.7271039485931396,
            "answer": "forward",
            "hit": false
          },
          {
            "score": 0.7258739471435547,
            "answer": "away",
            "hit": false
          },
          {
            "score": 0.7249545454978943,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7153711318969727,
            "answer": "back",
            "hit": false
          },
          {
            "score": 0.708450436592102,
            "answer": "out",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7578992545604706
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8489028215408325,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8155694603919983,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.7835145592689514,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.7587114572525024,
            "answer": "lesions",
            "hit": false
          },
          {
            "score": 0.7543100118637085,
            "answer": "cervical",
            "hit": false
          },
          {
            "score": 0.7438439130783081,
            "answer": "vascular",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489028215408325
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.8752703666687012,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.8035018444061279,
            "answer": "later",
            "hit": true
          },
          {
            "score": 0.7853648066520691,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.7821907997131348,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.7777488231658936,
            "answer": "then",
            "hit": false
          },
          {
            "score": 0.7776764631271362,
            "answer": "until",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.875270426273346
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8154337406158447,
            "answer": "starting",
            "hit": false
          },
          {
            "score": 0.7842918038368225,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.7785537242889404,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.7664490938186646,
            "answer": "start",
            "hit": false
          },
          {
            "score": 0.7605224847793579,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.7596760988235474,
            "answer": "end",
            "hit": true
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7596761286258698
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.8411356210708618,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.7947342395782471,
            "answer": "murdered",
            "hit": false
          },
          {
            "score": 0.7931972742080688,
            "answer": "slain",
            "hit": false
          },
          {
            "score": 0.7856218218803406,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.7728339433670044,
            "answer": "wounded",
            "hit": false
          },
          {
            "score": 0.7697682976722717,
            "answer": "killing",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7286569029092789
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8508654832839966,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7689862251281738,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7517576217651367,
            "answer": "diver",
            "hit": false
          },
          {
            "score": 0.7515570521354675,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.7440599203109741,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.7381353378295898,
            "answer": "sink",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 5475,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5327532514929771
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.8186973929405212,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.7968935370445251,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.7886582612991333,
            "answer": "drop",
            "hit": false
          },
          {
            "score": 0.7743149399757385,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.7612457275390625,
            "answer": "rise",
            "hit": true
          },
          {
            "score": 0.7569855451583862,
            "answer": "spring",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7612457275390625
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8954635858535767,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.8473485112190247,
            "answer": "third",
            "hit": false
          },
          {
            "score": 0.8377789258956909,
            "answer": "fourth",
            "hit": false
          },
          {
            "score": 0.8301350474357605,
            "answer": "fifth",
            "hit": false
          },
          {
            "score": 0.8146839737892151,
            "answer": "sixth",
            "hit": false
          },
          {
            "score": 0.7976276874542236,
            "answer": "seventh",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7884123623371124
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.8186172246932983,
            "answer": "feedback",
            "hit": false
          },
          {
            "score": 0.776335597038269,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.7051792740821838,
            "answer": "consultation",
            "hit": false
          },
          {
            "score": 0.7044649124145508,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.6968039870262146,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.6905621290206909,
            "answer": "stakeholders",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 56,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6399023681879044
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.8361190557479858,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7881145477294922,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.735079288482666,
            "answer": "perimeter",
            "hit": false
          },
          {
            "score": 0.7322483062744141,
            "answer": "front",
            "hit": false
          },
          {
            "score": 0.7203719615936279,
            "answer": "beneath",
            "hit": false
          },
          {
            "score": 0.7179736495018005,
            "answer": "corner",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8361190259456635
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.8075260519981384,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7934753894805908,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.746586799621582,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7135371565818787,
            "answer": "audit",
            "hit": false
          },
          {
            "score": 0.7134148478507996,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7072203159332275,
            "answer": "organizational",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8075260519981384
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7778729200363159,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.765170693397522,
            "answer": "eternal",
            "hit": false
          },
          {
            "score": 0.723611056804657,
            "answer": "eternity",
            "hit": false
          },
          {
            "score": 0.721664547920227,
            "answer": "mankind",
            "hit": false
          },
          {
            "score": 0.7209160923957825,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7179990410804749,
            "answer": "evil",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7778729200363159
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.8597024083137512,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8328343629837036,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.7966648936271667,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7750369906425476,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.765972912311554,
            "answer": "leased",
            "hit": false
          },
          {
            "score": 0.7593732476234436,
            "answer": "vacated",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7386387437582016
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.7833977341651917,
            "answer": "past",
            "hit": false
          },
          {
            "score": 0.7414141893386841,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7354694604873657,
            "answer": "around",
            "hit": false
          },
          {
            "score": 0.7253051996231079,
            "answer": "away",
            "hit": false
          },
          {
            "score": 0.7229430675506592,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.7105932831764221,
            "answer": "last",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 84,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6402737945318222
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.7944033145904541,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.7830820083618164,
            "answer": "recently",
            "hit": false
          },
          {
            "score": 0.7710106372833252,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7686446905136108,
            "answer": "initially",
            "hit": false
          },
          {
            "score": 0.7450876832008362,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.740939736366272,
            "answer": "also",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7710106074810028
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8136902451515198,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7478488683700562,
            "answer": "commence",
            "hit": false
          },
          {
            "score": 0.747334361076355,
            "answer": "pursue",
            "hit": false
          },
          {
            "score": 0.739753246307373,
            "answer": "initiate",
            "hit": false
          },
          {
            "score": 0.7382535338401794,
            "answer": "conclude",
            "hit": false
          },
          {
            "score": 0.7360599040985107,
            "answer": "progressing",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 372,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5473509915173054
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.853610098361969,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.8502874374389648,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.8325165510177612,
            "answer": "decline",
            "hit": false
          },
          {
            "score": 0.8161360621452332,
            "answer": "spike",
            "hit": false
          },
          {
            "score": 0.8126237988471985,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.8072234392166138,
            "answer": "increase",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6470363885164261
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.8776634931564331,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.8661597967147827,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.8250768184661865,
            "answer": "west",
            "hit": false
          },
          {
            "score": 0.8058561086654663,
            "answer": "central",
            "hit": false
          },
          {
            "score": 0.7371306419372559,
            "answer": "african",
            "hit": false
          },
          {
            "score": 0.7205195426940918,
            "answer": "southeast",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8776634931564331
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.8748012185096741,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.8438931703567505,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8322895169258118,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.7548650503158569,
            "answer": "midwest",
            "hit": false
          },
          {
            "score": 0.752100944519043,
            "answer": "central",
            "hit": false
          },
          {
            "score": 0.7484212517738342,
            "answer": "east",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8322895467281342
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.908610999584198,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.7269118428230286,
            "answer": "into",
            "hit": false
          },
          {
            "score": 0.7255707383155823,
            "answer": "direction",
            "hit": false
          },
          {
            "score": 0.7212411165237427,
            "answer": "upward",
            "hit": false
          },
          {
            "score": 0.7198219299316406,
            "answer": "downward",
            "hit": false
          },
          {
            "score": 0.7171683311462402,
            "answer": "closer",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.704232782125473
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7613244652748108,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.7417195439338684,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7326523065567017,
            "answer": "pure",
            "hit": false
          },
          {
            "score": 0.7315554618835449,
            "answer": "indeed",
            "hit": false
          },
          {
            "score": 0.7261187434196472,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7151732444763184,
            "answer": "essence",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6792520880699158
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.8801243305206299,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.8328158855438232,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.8317526578903198,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.7833199501037598,
            "answer": "central",
            "hit": false
          },
          {
            "score": 0.7354813814163208,
            "answer": "western",
            "hit": false
          },
          {
            "score": 0.7130759358406067,
            "answer": "southeast",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8801243603229523
      }
    ],
    "result": {
      "cnt_questions_correct": 10,
      "cnt_questions_total": 23,
      "accuracy": 0.43478260869565216
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9810bd1f-ee3a-4f45-8c6a-f60fe528d806",
      "timestamp": "2025-05-18T13:34:05.698195"
    }
  }
]