[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.8380789160728455,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.7798601984977722,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.7640657424926758,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.7430997490882874,
            "answer": "poems",
            "hit": false
          },
          {
            "score": 0.7411118149757385,
            "answer": "cds",
            "hit": false
          },
          {
            "score": 0.7408689260482788,
            "answer": "musicians",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8380789160728455
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.9232521057128906,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.7828131914138794,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7699356079101562,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.7687695026397705,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.7687540054321289,
            "answer": "applicant",
            "hit": false
          },
          {
            "score": 0.7616941928863525,
            "answer": "apply",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9232521653175354
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7862750291824341,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.7358824014663696,
            "answer": "distance",
            "hit": false
          },
          {
            "score": 0.735693097114563,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.7310659885406494,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7308478951454163,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.7304432988166809,
            "answer": "zones",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7862750291824341
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.8160305023193359,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.8015676736831665,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7820796370506287,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.779636025428772,
            "answer": "automobiles",
            "hit": false
          },
          {
            "score": 0.7594141960144043,
            "answer": "sedan",
            "hit": false
          },
          {
            "score": 0.7567598819732666,
            "answer": "truck",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7820796370506287
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.7962930202484131,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.762060284614563,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7607359290122986,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.7560511827468872,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.7552251815795898,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7450253963470459,
            "answer": "classrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7962930202484131
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8447203636169434,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7796310186386108,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7662567496299744,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7604302167892456,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.7590281963348389,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7554683685302734,
            "answer": "commission",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8447203934192657
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8522114753723145,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.7639244794845581,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7614896893501282,
            "answer": "suppliers",
            "hit": false
          },
          {
            "score": 0.7566424608230591,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.7529537677764893,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.751585841178894,
            "answer": "hundreds",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8522114455699921
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7562041282653809,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.7491497993469238,
            "answer": "nights",
            "hit": false
          },
          {
            "score": 0.7464990615844727,
            "answer": "mornings",
            "hit": false
          },
          {
            "score": 0.7449802160263062,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7397090792655945,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7389782667160034,
            "answer": "monday",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7562040984630585
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.864666759967804,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7816609144210815,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.7805324792861938,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.7783986926078796,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.775428831577301,
            "answer": "murder",
            "hit": false
          },
          {
            "score": 0.7553645968437195,
            "answer": "killings",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.864666759967804
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8377943634986877,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.8074122667312622,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.7743245959281921,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7687273025512695,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.765023946762085,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.7625728249549866,
            "answer": "officers",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8377943933010101
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.8032649159431458,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7827465534210205,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7763857841491699,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.763477623462677,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7584996819496155,
            "answer": "production",
            "hit": false
          },
          {
            "score": 0.7583446502685547,
            "answer": "developing",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7763857841491699
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7989605665206909,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7646352052688599,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.7646035552024841,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.7504510879516602,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7442492246627808,
            "answer": "similarities",
            "hit": false
          },
          {
            "score": 0.7412499189376831,
            "answer": "differ",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7989605069160461
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8012707233428955,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7902868986129761,
            "answer": "founder",
            "hit": false
          },
          {
            "score": 0.7874442934989929,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.782795786857605,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.7805688381195068,
            "answer": "directs",
            "hit": false
          },
          {
            "score": 0.7737686038017273,
            "answer": "coordinator",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8012707531452179
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.8041653633117676,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.7393237352371216,
            "answer": "incidents",
            "hit": false
          },
          {
            "score": 0.7252112627029419,
            "answer": "festivals",
            "hit": false
          },
          {
            "score": 0.7206095457077026,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.7174260020256042,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7147486805915833,
            "answer": "exciting",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8041653335094452
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8221473693847656,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.7387731075286865,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.736058235168457,
            "answer": "analogy",
            "hit": false
          },
          {
            "score": 0.7346007823944092,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.7317712903022766,
            "answer": "comparison",
            "hit": false
          },
          {
            "score": 0.7299447059631348,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8221473395824432
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7878726124763489,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.7367546558380127,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.732830822467804,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.7208917737007141,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.7154830694198608,
            "answer": "realities",
            "hit": false
          },
          {
            "score": 0.7150681018829346,
            "answer": "factories",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7878726124763489
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.7963660359382629,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.768085241317749,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7517426013946533,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.7309747338294983,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.7280144095420837,
            "answer": "comrades",
            "hit": false
          },
          {
            "score": 0.7274330258369446,
            "answer": "companions",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7963660359382629
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7994030714035034,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.7819205522537231,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.766875684261322,
            "answer": "religions",
            "hit": false
          },
          {
            "score": 0.763221025466919,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.7611114382743835,
            "answer": "prayed",
            "hit": false
          },
          {
            "score": 0.7602859735488892,
            "answer": "jesus",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7994030714035034
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8583729267120361,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.8121229410171509,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.7786768674850464,
            "answer": "federal",
            "hit": false
          },
          {
            "score": 0.762085497379303,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7617417573928833,
            "answer": "authorities",
            "hit": false
          },
          {
            "score": 0.7478070259094238,
            "answer": "officials",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8583729267120361
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.7566806077957153,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.745903730392456,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.729803204536438,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7245925068855286,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.7163839340209961,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7088452577590942,
            "answer": "minutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7566806375980377
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.8077563643455505,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.7602105140686035,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7462656497955322,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.7455811500549316,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7389575242996216,
            "answer": "ideals",
            "hit": false
          },
          {
            "score": 0.7370574474334717,
            "answer": "thinkers",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8077563643455505
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.8266669511795044,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.7667586207389832,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7478979229927063,
            "answer": "translations",
            "hit": false
          },
          {
            "score": 0.7347915172576904,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.7269493341445923,
            "answer": "translation",
            "hit": false
          },
          {
            "score": 0.7256002426147461,
            "answer": "vocabulary",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8266669511795044
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.8021793961524963,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.8019052147865295,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7925412058830261,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.7775698900222778,
            "answer": "attorneys",
            "hit": false
          },
          {
            "score": 0.7679394483566284,
            "answer": "statutes",
            "hit": false
          },
          {
            "score": 0.7648077607154846,
            "answer": "prosecutors",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8021793961524963
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.8169501423835754,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7454410791397095,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7365195751190186,
            "answer": "groups",
            "hit": false
          },
          {
            "score": 0.7194457650184631,
            "answer": "participates",
            "hit": false
          },
          {
            "score": 0.7184081673622131,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.7180310487747192,
            "answer": "founder",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8169501423835754
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8205249309539795,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.7807272672653198,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.7568317651748657,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.7404854893684387,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.7391409873962402,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.7359939813613892,
            "answer": "week",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8205249309539795
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.7998353838920593,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.7555201649665833,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7464741468429565,
            "answer": "morrow",
            "hit": false
          },
          {
            "score": 0.7431254386901855,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.7365700006484985,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7348614931106567,
            "answer": "mornings",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7998353838920593
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.8132379055023193,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7533160448074341,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7438265681266785,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.7351754903793335,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7319859266281128,
            "answer": "apartments",
            "hit": false
          },
          {
            "score": 0.7313525676727295,
            "answer": "documents",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8132379353046417
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.9011564254760742,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7489221692085266,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.7270572781562805,
            "answer": "phases",
            "hit": false
          },
          {
            "score": 0.7261394262313843,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.7231907844543457,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.7207887172698975,
            "answer": "decade",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.901156485080719
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.7927920818328857,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7528620958328247,
            "answer": "rookie",
            "hit": false
          },
          {
            "score": 0.7464748024940491,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7331558465957642,
            "answer": "coach",
            "hit": false
          },
          {
            "score": 0.7246561646461487,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.7234955430030823,
            "answer": "teammates",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7927921414375305
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8230389952659607,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.7616105079650879,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.7498878240585327,
            "answer": "residents",
            "hit": false
          },
          {
            "score": 0.7489147186279297,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.7461580038070679,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.740348219871521,
            "answer": "births",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8230389952659607
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.8505558967590332,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7599810361862183,
            "answer": "trouble",
            "hit": false
          },
          {
            "score": 0.7596926093101501,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.7515480518341064,
            "answer": "solution",
            "hit": false
          },
          {
            "score": 0.747714638710022,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7436403036117554,
            "answer": "dilemma",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8505558371543884
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.8124023079872131,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.7457922697067261,
            "answer": "brands",
            "hit": false
          },
          {
            "score": 0.7370158433914185,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.7364743947982788,
            "answer": "goods",
            "hit": false
          },
          {
            "score": 0.7318291664123535,
            "answer": "merchandise",
            "hit": false
          },
          {
            "score": 0.7309789657592773,
            "answer": "consumer",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8124022483825684
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.7911806106567383,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.7266733646392822,
            "answer": "policies",
            "hit": false
          },
          {
            "score": 0.7207841873168945,
            "answer": "nutrients",
            "hit": false
          },
          {
            "score": 0.7200609445571899,
            "answer": "facilities",
            "hit": false
          },
          {
            "score": 0.7190026044845581,
            "answer": "asset",
            "hit": false
          },
          {
            "score": 0.71892911195755,
            "answer": "cultural",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7911806106567383
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7918778657913208,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.7899231314659119,
            "answer": "rivera",
            "hit": false
          },
          {
            "score": 0.74251389503479,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7376028895378113,
            "answer": "hills",
            "hit": false
          },
          {
            "score": 0.7370898127555847,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7355303764343262,
            "answer": "mountains",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7918779253959656
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8021095395088196,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7876771092414856,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.7722207307815552,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7479825615882874,
            "answer": "streets",
            "hit": false
          },
          {
            "score": 0.7458767890930176,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.7436296939849854,
            "answer": "journeys",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8021095097064972
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.8070356249809265,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7211606502532959,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7195590734481812,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7110415697097778,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.708604097366333,
            "answer": "fantasies",
            "hit": false
          },
          {
            "score": 0.7073795795440674,
            "answer": "configurations",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8070356547832489
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8270968794822693,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.8177073001861572,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.7834677696228027,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.7801982164382935,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.7801604270935059,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.7445133328437805,
            "answer": "chemistry",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8270968794822693
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.8169530630111694,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7664541602134705,
            "answer": "luckily",
            "hit": false
          },
          {
            "score": 0.765165388584137,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.763458251953125,
            "answer": "fortunately",
            "hit": false
          },
          {
            "score": 0.7554388046264648,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.7508050799369812,
            "answer": "solving",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8169531226158142
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8381607532501221,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7741090059280396,
            "answer": "sang",
            "hit": false
          },
          {
            "score": 0.7661198377609253,
            "answer": "sings",
            "hit": false
          },
          {
            "score": 0.7649190425872803,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.7607414722442627,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7551001906394958,
            "answer": "albums",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8381607532501221
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.8729773759841919,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.7816751003265381,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.7637085914611816,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7590104341506958,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7583233118057251,
            "answer": "pavement",
            "hit": false
          },
          {
            "score": 0.7526668310165405,
            "answer": "avenue",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8729773759841919
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8643749952316284,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7880637049674988,
            "answer": "classrooms",
            "hit": false
          },
          {
            "score": 0.7851032018661499,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7848729491233826,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.776442289352417,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7727854251861572,
            "answer": "education",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8643749356269836
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.8318424820899963,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.7421551942825317,
            "answer": "programs",
            "hit": false
          },
          {
            "score": 0.7420670390129089,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.740139365196228,
            "answer": "technologies",
            "hit": false
          },
          {
            "score": 0.7384161353111267,
            "answer": "processes",
            "hit": false
          },
          {
            "score": 0.7376824021339417,
            "answer": "mechanisms",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8318424820899963
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.8425455093383789,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.7243989109992981,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.7148165702819824,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.7093517184257507,
            "answer": "phenomenon",
            "hit": false
          },
          {
            "score": 0.7075865864753723,
            "answer": "damn",
            "hit": false
          },
          {
            "score": 0.706552267074585,
            "answer": "aspect",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8425455391407013
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8869253993034363,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.8050752878189087,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7952654361724854,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7611847519874573,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7599529027938843,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7562382221221924,
            "answer": "hometown",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.886925458908081
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7880234122276306,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.7329436540603638,
            "answer": "consumer",
            "hit": false
          },
          {
            "score": 0.7225307822227478,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.7218002676963806,
            "answer": "programmer",
            "hit": false
          },
          {
            "score": 0.7138020396232605,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.7103307247161865,
            "answer": "patient",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.788023442029953
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.8811583518981934,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.7125956416130066,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.709279477596283,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.7080978155136108,
            "answer": "activation",
            "hit": false
          },
          {
            "score": 0.7075830698013306,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.703731894493103,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8811583518981934
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.9143287539482117,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8452514410018921,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.8156646490097046,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.8018606305122375,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7640937566757202,
            "answer": "tribe",
            "hit": false
          },
          {
            "score": 0.7630136013031006,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9143287539482117
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.8204715251922607,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.7664964199066162,
            "answer": "sites",
            "hit": false
          },
          {
            "score": 0.7639601230621338,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7525177597999573,
            "answer": "address",
            "hit": false
          },
          {
            "score": 0.7521926164627075,
            "answer": "www",
            "hit": false
          },
          {
            "score": 0.7514180541038513,
            "answer": "email",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8204714953899384
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7591705918312073,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.7455727458000183,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7453893423080444,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7437602877616882,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7428576946258545,
            "answer": "wednesday",
            "hit": false
          },
          {
            "score": 0.742552638053894,
            "answer": "monday",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7591705918312073
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7863320112228394,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7826093435287476,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7590399980545044,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7558319568634033,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.7475557327270508,
            "answer": "yearly",
            "hit": false
          },
          {
            "score": 0.7460533380508423,
            "answer": "decade",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7590400278568268
      }
    ],
    "result": {
      "cnt_questions_correct": 47,
      "cnt_questions_total": 50,
      "accuracy": 0.94
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9739ac97-e0a5-40cc-b9b0-e224d0974386",
      "timestamp": "2025-05-17T20:32:05.998054"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.7099695801734924,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.7042490243911743,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.7004877924919128,
            "answer": "compatibility",
            "hit": false
          },
          {
            "score": 0.7002864480018616,
            "answer": "accessibility",
            "hit": false
          },
          {
            "score": 0.6986145377159119,
            "answer": "functionality",
            "hit": false
          },
          {
            "score": 0.6983789205551147,
            "answer": "capability",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6929296553134918
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8255579471588135,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.7409337162971497,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.7330549955368042,
            "answer": "transactions",
            "hit": false
          },
          {
            "score": 0.7317664623260498,
            "answer": "participants",
            "hit": false
          },
          {
            "score": 0.7237294912338257,
            "answer": "programs",
            "hit": false
          },
          {
            "score": 0.7235894203186035,
            "answer": "participation",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8255579471588135
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.8264586329460144,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7432191371917725,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.726643443107605,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.7253764867782593,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.7237265706062317,
            "answer": "contractors",
            "hit": false
          },
          {
            "score": 0.7225717306137085,
            "answer": "organisations",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8264586329460144
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.9223437309265137,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.8154089450836182,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.8138734102249146,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.8096017837524414,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.7929455637931824,
            "answer": "assessment",
            "hit": false
          },
          {
            "score": 0.7897229194641113,
            "answer": "assessments",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9223437607288361
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8105935454368591,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.8064385056495667,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7798003554344177,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7705727815628052,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7667852640151978,
            "answer": "soldier",
            "hit": false
          },
          {
            "score": 0.7586672902107239,
            "answer": "marines",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8105935752391815
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.8004733324050903,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.732636570930481,
            "answer": "agency",
            "hit": false
          },
          {
            "score": 0.7268601059913635,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7243962287902832,
            "answer": "governments",
            "hit": false
          },
          {
            "score": 0.7242915630340576,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.7207586765289307,
            "answer": "agencies",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8004733026027679
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.742753267288208,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.74074387550354,
            "answer": "foundations",
            "hit": false
          },
          {
            "score": 0.7373045682907104,
            "answer": "grounds",
            "hit": false
          },
          {
            "score": 0.7347136735916138,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.731286883354187,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.7270594835281372,
            "answer": "justification",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7427532821893692
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.8377166986465454,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7818053960800171,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.7647886872291565,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.7621669769287109,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7549734115600586,
            "answer": "corporations",
            "hit": false
          },
          {
            "score": 0.7477992177009583,
            "answer": "businessman",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8377167582511902
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.7884472608566284,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7534546852111816,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.7522292733192444,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.7375941872596741,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.7283594608306885,
            "answer": "rating",
            "hit": false
          },
          {
            "score": 0.728111743927002,
            "answer": "groups",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7884472906589508
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.8077431917190552,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.776590883731842,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7641144394874573,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.7464796900749207,
            "answer": "dozen",
            "hit": false
          },
          {
            "score": 0.74275803565979,
            "answer": "nineteenth",
            "hit": false
          },
          {
            "score": 0.739154577255249,
            "answer": "twentieth",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8077432513237
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.8148407936096191,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.7634905576705933,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.7616057991981506,
            "answer": "childhood",
            "hit": false
          },
          {
            "score": 0.7566677331924438,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7546626925468445,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.7445037364959717,
            "answer": "babies",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8148407936096191
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.7558925151824951,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7529888153076172,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.751567006111145,
            "answer": "state",
            "hit": false
          },
          {
            "score": 0.7431939840316772,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7403576374053955,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.7355825304985046,
            "answer": "villages",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7558925151824951
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.8000408411026001,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7620466947555542,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7507117986679077,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.7469369173049927,
            "answer": "groups",
            "hit": false
          },
          {
            "score": 0.744364857673645,
            "answer": "forums",
            "hit": false
          },
          {
            "score": 0.7400908470153809,
            "answer": "citizens",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8000408709049225
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.8655966520309448,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.806962788105011,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.751106321811676,
            "answer": "provinces",
            "hit": false
          },
          {
            "score": 0.7482028007507324,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7438642978668213,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.733596682548523,
            "answer": "county",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8655966520309448
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.9057442545890808,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7943744659423828,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7841395735740662,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7816464304924011,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7736226320266724,
            "answer": "districts",
            "hit": false
          },
          {
            "score": 0.7684674859046936,
            "answer": "towns",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9057442545890808
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7887222766876221,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7472397685050964,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7458269596099854,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.734688401222229,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7218789458274841,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.7086567878723145,
            "answer": "officers",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7887223362922668
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.8710066676139832,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.7739977836608887,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.7723711133003235,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.7685301303863525,
            "answer": "gdp",
            "hit": false
          },
          {
            "score": 0.756280243396759,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.7533313035964966,
            "answer": "economic",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8710066378116608
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.7953406572341919,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.766867458820343,
            "answer": "environmental",
            "hit": false
          },
          {
            "score": 0.7619463205337524,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.7586115598678589,
            "answer": "reactors",
            "hit": false
          },
          {
            "score": 0.7548105716705322,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.7479516267776489,
            "answer": "minerals",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7953406572341919
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.8074889779090881,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.728553295135498,
            "answer": "registration",
            "hit": false
          },
          {
            "score": 0.7274813652038574,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7253572940826416,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.7223986983299255,
            "answer": "opening",
            "hit": false
          },
          {
            "score": 0.7199432849884033,
            "answer": "exhibitions",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8074889779090881
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.8460544347763062,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.7554711103439331,
            "answer": "programs",
            "hit": false
          },
          {
            "score": 0.7524943351745605,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.7418406009674072,
            "answer": "venues",
            "hit": false
          },
          {
            "score": 0.7414748072624207,
            "answer": "amenities",
            "hit": false
          },
          {
            "score": 0.7409026622772217,
            "answer": "laboratories",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8460544943809509
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.8137205839157104,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7959534525871277,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.7590541839599609,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.7580915689468384,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.7495144605636597,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7458328008651733,
            "answer": "parental",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8137206435203552
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8819628953933716,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7728951573371887,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.748178243637085,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.742705225944519,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.734686017036438,
            "answer": "heritage",
            "hit": false
          },
          {
            "score": 0.732541561126709,
            "answer": "geography",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.881962925195694
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.8532645106315613,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.7647616863250732,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.764371395111084,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7564064264297485,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.7484979629516602,
            "answer": "firms",
            "hit": false
          },
          {
            "score": 0.7465200424194336,
            "answer": "sectors",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8532645404338837
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.8191767334938049,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7611573934555054,
            "answer": "documents",
            "hit": false
          },
          {
            "score": 0.7471789717674255,
            "answer": "museums",
            "hit": false
          },
          {
            "score": 0.7390071749687195,
            "answer": "classrooms",
            "hit": false
          },
          {
            "score": 0.7374968528747559,
            "answer": "collections",
            "hit": false
          },
          {
            "score": 0.7336360216140747,
            "answer": "textbooks",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8191767930984497
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7574236989021301,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.7250984907150269,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7099573612213135,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.7038734555244446,
            "answer": "careers",
            "hit": false
          },
          {
            "score": 0.7020986080169678,
            "answer": "career",
            "hit": false
          },
          {
            "score": 0.7008668780326843,
            "answer": "happiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7574236989021301
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8492095470428467,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7865849137306213,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7615793347358704,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.759355366230011,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7444311380386353,
            "answer": "victories",
            "hit": false
          },
          {
            "score": 0.7425796985626221,
            "answer": "lost",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8492094874382019
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.7664685249328613,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.7501466274261475,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7429904937744141,
            "answer": "storage",
            "hit": false
          },
          {
            "score": 0.7364996671676636,
            "answer": "capacities",
            "hit": false
          },
          {
            "score": 0.7348660230636597,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.731894314289093,
            "answer": "textures",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7664685249328613
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.9074079394340515,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.7464261054992676,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.745975911617279,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.7406583428382874,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.7331876754760742,
            "answer": "advantages",
            "hit": false
          },
          {
            "score": 0.7275292873382568,
            "answer": "avenues",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9074079394340515
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8324599266052246,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7560168504714966,
            "answer": "initiatives",
            "hit": false
          },
          {
            "score": 0.7497923374176025,
            "answer": "regulations",
            "hit": false
          },
          {
            "score": 0.7471318244934082,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.7464977502822876,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.7453416585922241,
            "answer": "reforms",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8324599266052246
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.745241641998291,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7410733103752136,
            "answer": "buildings",
            "hit": false
          },
          {
            "score": 0.7349538803100586,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.7338809370994568,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.7313251495361328,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.7302275896072388,
            "answer": "belongings",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7452416718006134
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8028494715690613,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7574485540390015,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7560561299324036,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.7377334833145142,
            "answer": "statements",
            "hit": false
          },
          {
            "score": 0.7376360297203064,
            "answer": "policies",
            "hit": false
          },
          {
            "score": 0.7342796325683594,
            "answer": "freedoms",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.802849531173706
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7898123264312744,
            "answer": "police",
            "hit": false
          },
          {
            "score": 0.7663830518722534,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.7584593296051025,
            "answer": "investigators",
            "hit": false
          },
          {
            "score": 0.7547671794891357,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7539286017417908,
            "answer": "hundreds",
            "hit": false
          },
          {
            "score": 0.751407265663147,
            "answer": "encryption",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 169,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7131288349628448
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.7597635984420776,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.7325806617736816,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.7282999753952026,
            "answer": "sequences",
            "hit": false
          },
          {
            "score": 0.7114895582199097,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.7100907564163208,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.7050009369850159,
            "answer": "trio",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9797223806381226
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.9015933871269226,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.8248594403266907,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7686736583709717,
            "answer": "soc",
            "hit": false
          },
          {
            "score": 0.7544293403625488,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.7512576580047607,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.750293493270874,
            "answer": "nations",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.901593416929245
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.7757234573364258,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.7563076019287109,
            "answer": "diseases",
            "hit": false
          },
          {
            "score": 0.7540700435638428,
            "answer": "creatures",
            "hit": false
          },
          {
            "score": 0.7514049410820007,
            "answer": "mammals",
            "hit": false
          },
          {
            "score": 0.7502579092979431,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.7485250234603882,
            "answer": "ecosystems",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9812881946563721
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.7903046011924744,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7898290753364563,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7743524312973022,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.7722412943840027,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.7713941335678101,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.7703787088394165,
            "answer": "storyline",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7903046607971191
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.9148414731025696,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.819738507270813,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.7947227954864502,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.7582744359970093,
            "answer": "techniques",
            "hit": false
          },
          {
            "score": 0.7505637407302856,
            "answer": "methodology",
            "hit": false
          },
          {
            "score": 0.7501534819602966,
            "answer": "technique",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9148414731025696
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.8069462776184082,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.7630473375320435,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7581930160522461,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7569626569747925,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7508000135421753,
            "answer": "succeeded",
            "hit": false
          },
          {
            "score": 0.7440167665481567,
            "answer": "victories",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8069462776184082
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.8703292608261108,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8226080536842346,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7936340570449829,
            "answer": "innovations",
            "hit": false
          },
          {
            "score": 0.7928696870803833,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7653722763061523,
            "answer": "innovation",
            "hit": false
          },
          {
            "score": 0.7548671364784241,
            "answer": "algorithms",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8703292608261108
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.9104443192481995,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.8177828788757324,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.7766738533973694,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7618812322616577,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.74360591173172,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7426937818527222,
            "answer": "explanations",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9104443192481995
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.8205127716064453,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7601701617240906,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.7598747611045837,
            "answer": "harvard",
            "hit": false
          },
          {
            "score": 0.7568598985671997,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.756168007850647,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.7544690370559692,
            "answer": "academics",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8205127716064453
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.7552498579025269,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7527703642845154,
            "answer": "deadline",
            "hit": false
          },
          {
            "score": 0.7439419627189636,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.735445499420166,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.7313233017921448,
            "answer": "variability",
            "hit": false
          },
          {
            "score": 0.7304199934005737,
            "answer": "productions",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7552498281002045
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.8695852160453796,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.8416957855224609,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.8396328687667847,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.8248628377914429,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8201662302017212,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.8033274412155151,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8695852756500244
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.8300621509552002,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.7946653962135315,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7616404891014099,
            "answer": "ladies",
            "hit": false
          },
          {
            "score": 0.7599746584892273,
            "answer": "feminist",
            "hit": false
          },
          {
            "score": 0.7582722902297974,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.751705527305603,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.830062210559845
      }
    ],
    "result": {
      "cnt_questions_correct": 40,
      "cnt_questions_total": 44,
      "accuracy": 0.9090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c0109a63-a4f6-4125-91d2-145f7559e1dc",
      "timestamp": "2025-05-17T20:32:06.194526"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8966441750526428,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.8279399871826172,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7807202935218811,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7657982110977173,
            "answer": "easier",
            "hit": false
          },
          {
            "score": 0.7630665302276611,
            "answer": "simpler",
            "hit": false
          },
          {
            "score": 0.760714590549469,
            "answer": "poorer",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8966442048549652
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.8100106120109558,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.743072509765625,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.7405589818954468,
            "answer": "brighter",
            "hit": false
          },
          {
            "score": 0.7322708368301392,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.732214093208313,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7317237854003906,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8100106120109558
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.9080089330673218,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.8371841907501221,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.8018954992294312,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7708060145378113,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.7673321962356567,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.753797173500061,
            "answer": "greater",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9080089330673218
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.8269585371017456,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.7898789644241333,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7556098103523254,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7516970634460449,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7502310872077942,
            "answer": "softer",
            "hit": false
          },
          {
            "score": 0.7472803592681885,
            "answer": "poorer",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8269585371017456
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d650f6e7-7701-4850-bc15-0c175ba96ada",
      "timestamp": "2025-05-17T20:32:06.374167"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7754572629928589,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7421337366104126,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7387970685958862,
            "answer": "easiest",
            "hit": false
          },
          {
            "score": 0.7230830192565918,
            "answer": "fastest",
            "hit": false
          },
          {
            "score": 0.7180827856063843,
            "answer": "hardest",
            "hit": false
          },
          {
            "score": 0.7130837440490723,
            "answer": "newest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7754572629928589
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.8047611713409424,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7738462090492249,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.7617685794830322,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7191041111946106,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.7185035347938538,
            "answer": "fierce",
            "hit": false
          },
          {
            "score": 0.7129182815551758,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8047612309455872
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 2,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "71a6ea2b-ca54-46d9-bffc-be7c648ae937",
      "timestamp": "2025-05-17T20:32:06.387819"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.9351840019226074,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.8514012098312378,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8451417088508606,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8030953407287598,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7953596115112305,
            "answer": "rejects",
            "hit": false
          },
          {
            "score": 0.7926883101463318,
            "answer": "acknowledges",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9351840317249298
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7663267850875854,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7496156692504883,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7488816976547241,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.7469221353530884,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7461267709732056,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7460471987724304,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 86,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7027683407068253
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.924094557762146,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8444582223892212,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.8233882784843445,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.791608452796936,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7880005836486816,
            "answer": "acknowledges",
            "hit": false
          },
          {
            "score": 0.7849531173706055,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9240945279598236
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8379305005073547,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8155094981193542,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8010345101356506,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7951294183731079,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7933695316314697,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7891079187393188,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8379305005073547
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9542304277420044,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8897474408149719,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8548672199249268,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.833202600479126,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8148602247238159,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7997390627861023,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9542304277420044
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.9431979656219482,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8458628058433533,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7740175724029541,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7724064588546753,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.7712673544883728,
            "answer": "extends",
            "hit": false
          },
          {
            "score": 0.769463062286377,
            "answer": "allows",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9431979954242706
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8340830206871033,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.7811054587364197,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7772804498672485,
            "answer": "refuses",
            "hit": false
          },
          {
            "score": 0.7735763192176819,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.770266592502594,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7688968777656555,
            "answer": "asked",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8340829908847809
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8644101023674011,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.8264315128326416,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8262819051742554,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8111956119537354,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.795951247215271,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7742771506309509,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8644101321697235
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.9190107583999634,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8166680932044983,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.8106368780136108,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.782448947429657,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.774398922920227,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7719516754150391,
            "answer": "loses",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9190107583999634
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8472859859466553,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7811912298202515,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.777219295501709,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7694416046142578,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7693763375282288,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7653158903121948,
            "answer": "honestly",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8472859859466553
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8138347864151001,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.778266191482544,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7761706113815308,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7649937868118286,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.7633643746376038,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.762082576751709,
            "answer": "examines",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8138347566127777
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9477381706237793,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8946864008903503,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8496675491333008,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8430465459823608,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8163280487060547,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8119867444038391,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9477381706237793
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8417618274688721,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8299561142921448,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8158241510391235,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8068982362747192,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7965285778045654,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7942919135093689,
            "answer": "possesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8158242106437683
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9492310285568237,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8251886367797852,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8047910332679749,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8032059073448181,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7955681681632996,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7896286249160767,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9492311179637909
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.953106164932251,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.854645848274231,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8371387720108032,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8229649066925049,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8198888301849365,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.8137328624725342,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9531062245368958
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9417538046836853,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8430700898170471,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8218830227851868,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8151041269302368,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8128470182418823,
            "answer": "defines",
            "hit": false
          },
          {
            "score": 0.8112813830375671,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9417538046836853
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8489665985107422,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7884820699691772,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7850120067596436,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7681055665016174,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7580753564834595,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7544136643409729,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489666283130646
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8474304676055908,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.7940255403518677,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7852522134780884,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7835577726364136,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7802540063858032,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7781392931938171,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8474304378032684
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.8263596296310425,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.7882182598114014,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7827235460281372,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7758603692054749,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7685961127281189,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7685335278511047,
            "answer": "avoids",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8263596296310425
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.8590517640113831,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.8083128333091736,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.8015903234481812,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7987377047538757,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7963634729385376,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7940827012062073,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8590517938137054
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.8097493648529053,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.78434818983078,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7839857935905457,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7742148637771606,
            "answer": "survives",
            "hit": false
          },
          {
            "score": 0.7723770141601562,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7672701478004456,
            "answer": "resides",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8097493648529053
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.9278583526611328,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8580646514892578,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8397283554077148,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8322732448577881,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8303030729293823,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.8096592426300049,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9278583526611328
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7749580144882202,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7747710943222046,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7645100951194763,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7621400952339172,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7608826160430908,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7597423791885376,
            "answer": "maintains",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7749580144882202
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9241739511489868,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8826610445976257,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8424130082130432,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8343327641487122,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8236191868782043,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7973535060882568,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9241739511489868
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8729175329208374,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7966616153717041,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7690663933753967,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7647784948348999,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7623344659805298,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7594850659370422,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8729175925254822
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.9447813630104065,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.85807204246521,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8082376718521118,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7966858744621277,
            "answer": "recognizes",
            "hit": false
          },
          {
            "score": 0.7879533767700195,
            "answer": "distinguishes",
            "hit": false
          },
          {
            "score": 0.7877841591835022,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9447813332080841
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8869783282279968,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8197065591812134,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8124692440032959,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8104346990585327,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7996891736984253,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7972635626792908,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8869783282279968
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7912043929100037,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7854218482971191,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7847426533699036,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7803429365158081,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7760704755783081,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7703111171722412,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7697014808654785
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9519345760345459,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8325632810592651,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8172760009765625,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.8171048164367676,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8095715045928955,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.8049704432487488,
            "answer": "encompasses",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9519345164299011
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.847000241279602,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8118995428085327,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.8063708543777466,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7985746264457703,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7862762808799744,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7832330465316772,
            "answer": "understands",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7570793628692627
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.9222106337547302,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8625860810279846,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.849320113658905,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8151347637176514,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.8073647618293762,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7907934188842773,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9222106635570526
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9566723704338074,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.887050986289978,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8522993326187134,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8436884880065918,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8251143097877502,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.8199606537818909,
            "answer": "happen",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9566723704338074
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.955176055431366,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8053242564201355,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.802540123462677,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.799227774143219,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7957921624183655,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7924650311470032,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9551762044429779
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.8218802213668823,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.7780999541282654,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.7769207954406738,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7744550704956055,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7742123603820801,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.772769570350647,
            "answer": "prevention",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8218802809715271
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9490681886672974,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8635811805725098,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8468570113182068,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8344224691390991,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8233022093772888,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7992913126945496,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9490681886672974
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.867476761341095,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.8105450868606567,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7899011373519897,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7890732288360596,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7797247171401978,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7588958144187927,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.867476761341095
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9642682671546936,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8688023686408997,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8545923829078674,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.846839964389801,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8323622941970825,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8316048383712769,
            "answer": "provided",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9642683267593384
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9400287866592407,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.86310213804245,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.835094153881073,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8119387030601501,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7963507175445557,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7861045002937317,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9400287866592407
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9468421339988708,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8648759722709656,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8365221619606018,
            "answer": "lowers",
            "hit": false
          },
          {
            "score": 0.8342904448509216,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.832202672958374,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.8316482305526733,
            "answer": "improves",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9468421041965485
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.9206481575965881,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8455901741981506,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8199277520179749,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8148070573806763,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.798496663570404,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.7898318767547607,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9206481575965881
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8977440595626831,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8953019976615906,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.833073079586029,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8253337144851685,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.8218486309051514,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.8058324456214905,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8977441191673279
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.8237888216972351,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7718294262886047,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7666482925415039,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7644631862640381,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7640742063522339,
            "answer": "reminds",
            "hit": false
          },
          {
            "score": 0.7632961273193359,
            "answer": "knowing",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8237888813018799
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8308144211769104,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.8035414814949036,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.792624831199646,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.787288248538971,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7709075212478638,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7649024724960327,
            "answer": "constitutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8308144807815552
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8320913314819336,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.7887725830078125,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.7788482904434204,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.776865541934967,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7762168645858765,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7753735780715942,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.832091361284256
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.9492289423942566,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8886943459510803,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8660939335823059,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8159967660903931,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8135449290275574,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.7884100675582886,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9492289423942566
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.9391465783119202,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.790813148021698,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7864776849746704,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7800865173339844,
            "answer": "puts",
            "hit": false
          },
          {
            "score": 0.7733297348022461,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7699325084686279,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9391466379165649
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8211590647697449,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7940967082977295,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7933998107910156,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7895216941833496,
            "answer": "recommends",
            "hit": false
          },
          {
            "score": 0.7840931415557861,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.7747253179550171,
            "answer": "indicates",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8211590647697449
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8448261022567749,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7977677583694458,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7860596776008606,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7774070501327515,
            "answer": "expresses",
            "hit": false
          },
          {
            "score": 0.7764220237731934,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7751239538192749,
            "answer": "reveals",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8448261320590973
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.9114630818367004,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.847833514213562,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8235475420951843,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.8178989887237549,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8095327019691467,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.8034697771072388,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.911463052034378
      }
    ],
    "result": {
      "cnt_questions_correct": 45,
      "cnt_questions_total": 49,
      "accuracy": 0.9183673469387755
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3821784c-62c5-4cca-94eb-982628d2ca0f",
      "timestamp": "2025-05-17T20:32:06.395185"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.8505134582519531,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.7792305946350098,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7686330080032349,
            "answer": "overcoming",
            "hit": false
          },
          {
            "score": 0.7664994597434998,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7640602588653564,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.7611095309257507,
            "answer": "delivering",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8505134582519531
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7991199493408203,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.7381571531295776,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.7327078580856323,
            "answer": "removing",
            "hit": false
          },
          {
            "score": 0.7312994003295898,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7291553020477295,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.7257748246192932,
            "answer": "addressing",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7991199493408203
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.8151997923851013,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.7937784194946289,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.7774776220321655,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.7749484777450562,
            "answer": "granting",
            "hit": false
          },
          {
            "score": 0.771776556968689,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7678521871566772,
            "answer": "enabling",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8151997923851013
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8864192962646484,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.883182168006897,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.8682330250740051,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8214811086654663,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7875353097915649,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7768941521644592,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8831821084022522
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.9224086999893188,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.8774269223213196,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7799339294433594,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7717772126197815,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7442859411239624,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.7354731559753418,
            "answer": "putting",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9224087595939636
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.8040586709976196,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7797008752822876,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7708618640899658,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7624027729034424,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.7619909644126892,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7612302899360657,
            "answer": "reminding",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8040586709976196
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8341348767280579,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.8234823942184448,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.7869637608528137,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7742944359779358,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.7440940141677856,
            "answer": "exhibiting",
            "hit": false
          },
          {
            "score": 0.7430915236473083,
            "answer": "tickets",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8234824538230896
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.8728907108306885,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.8291919231414795,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.7900151014328003,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7818632125854492,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.780954122543335,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7798869013786316,
            "answer": "eliminating",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8728907406330109
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8885282278060913,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8445689678192139,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.748053789138794,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7414201498031616,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.7411670088768005,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7364528179168701,
            "answer": "turning",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8885281980037689
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8211415410041809,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7787511348724365,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7647749781608582,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7644116878509521,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7588748335838318,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7577950358390808,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8211415410041809
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.8148273825645447,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.7713016867637634,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7692375183105469,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7688423991203308,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.758316159248352,
            "answer": "adopting",
            "hit": false
          },
          {
            "score": 0.7581572532653809,
            "answer": "noting",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8148273825645447
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8830187320709229,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8427370190620422,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7879942059516907,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7577025294303894,
            "answer": "possessing",
            "hit": false
          },
          {
            "score": 0.7492347955703735,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7490944266319275,
            "answer": "consist",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8830187320709229
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.8906842470169067,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.8817474246025085,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.801146388053894,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7727407813072205,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7658142447471619,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7649006843566895,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8906842768192291
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.9375083446502686,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.8741065263748169,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8007944822311401,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7932043671607971,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.7842645049095154,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7840748429298401,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9375083148479462
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8347115516662598,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.7948513031005859,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7719066739082336,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7618732452392578,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.7586582899093628,
            "answer": "designing",
            "hit": false
          },
          {
            "score": 0.7579615116119385,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8347115516662598
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8803602457046509,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8653402328491211,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8592437505722046,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.850443959236145,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8096351623535156,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7990661263465881,
            "answer": "urging",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653401732444763
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.8375020027160645,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.7627922296524048,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7618626356124878,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7611784934997559,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7607582211494446,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7575803995132446,
            "answer": "enjoys",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8375020027160645
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.8632425665855408,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.7887914180755615,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7854426503181458,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7703925967216492,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7700629234313965,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.768720805644989,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8632425665855408
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.9405026435852051,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8766769766807556,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8441236615180969,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7944576740264893,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7926926612854004,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7818207144737244,
            "answer": "asserting",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9405027031898499
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.7699080109596252,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.746466338634491,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7457836866378784,
            "answer": "confronting",
            "hit": false
          },
          {
            "score": 0.7446131110191345,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7425217032432556,
            "answer": "embracing",
            "hit": false
          },
          {
            "score": 0.7338080406188965,
            "answer": "occupying",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7699079811573029
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.855755090713501,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.834526777267456,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8021112680435181,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.7731327414512634,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7594081163406372,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7495859265327454,
            "answer": "hoping",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8557550609111786
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.7960821390151978,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.7456530332565308,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7444875836372375,
            "answer": "pursuing",
            "hit": false
          },
          {
            "score": 0.7439436912536621,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7388862371444702,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.7344921827316284,
            "answer": "seeing",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7960821092128754
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8833739161491394,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.8535834550857544,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8528708219528198,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8169589042663574,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8096974492073059,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7711918354034424,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.883373886346817
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.9255573153495789,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8808084726333618,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7864220142364502,
            "answer": "recognizing",
            "hit": false
          },
          {
            "score": 0.7796752452850342,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7778326869010925,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7753620147705078,
            "answer": "locating",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9255573451519012
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.8697767853736877,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.8170270919799805,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8141945600509644,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8047371506690979,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7990115284919739,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7821788787841797,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8697767853736877
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.7598393559455872,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7477210760116577,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7420132756233215,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.7415167689323425,
            "answer": "mentioning",
            "hit": false
          },
          {
            "score": 0.7400257587432861,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.73945152759552,
            "answer": "noting",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7420132607221603
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.8871731162071228,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8717402815818787,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.8065904378890991,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.776764988899231,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7726307511329651,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.766217052936554,
            "answer": "involvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8717403411865234
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.8435231447219849,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8052194118499756,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.8012645244598389,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7955589294433594,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7648991942405701,
            "answer": "figuring",
            "hit": false
          },
          {
            "score": 0.7607097029685974,
            "answer": "studying",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8052194714546204
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.8244856595993042,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.7896147966384888,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7758827209472656,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7634890675544739,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7455953359603882,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.7448280453681946,
            "answer": "weakening",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8244856894016266
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.920717716217041,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8578432202339172,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8490921258926392,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8037018775939941,
            "answer": "keeping",
            "hit": false
          },
          {
            "score": 0.7913164496421814,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7780719995498657,
            "answer": "sustaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.920717716217041
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8867136240005493,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.861208438873291,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8531216979026794,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7824975848197937,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7585377097129822,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7554045915603638,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8867136240005493
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8909509181976318,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8463805913925171,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.8015936613082886,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7802150845527649,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7726045846939087,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7702727317810059,
            "answer": "conducting",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8463805615901947
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.7829433679580688,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7749419212341309,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7748066782951355,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7740429043769836,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7516507506370544,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.7488139271736145,
            "answer": "performed",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7516508102416992
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.8282618522644043,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.7786096334457397,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.76407790184021,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.7635095119476318,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7552499771118164,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7552183866500854,
            "answer": "prevented",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8282618522644043
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9385817646980286,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8848767280578613,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8333070874214172,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7955109477043152,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.794653594493866,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7914888262748718,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9385817646980286
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.8698045015335083,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.792816162109375,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7817959189414978,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7792351245880127,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7683521509170532,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7676687240600586,
            "answer": "preserving",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8698045015335083
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.9406455755233765,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.8865206837654114,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8320726156234741,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8144352436065674,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8004640936851501,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7975316643714905,
            "answer": "ensuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9406455755233765
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.905194878578186,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.8724428415298462,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8566001057624817,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7730720043182373,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7685678601264954,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7607592344284058,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9051949083805084
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.9394441246986389,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8726180791854858,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8400112390518188,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8383511304855347,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8322099447250366,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8285121917724609,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9394441545009613
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8710753917694092,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.8525815606117249,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8424433469772339,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8058302998542786,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7826428413391113,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7817245721817017,
            "answer": "denote",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8710753917694092
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.876945972442627,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8479799628257751,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.803647518157959,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8034632205963135,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.8019047975540161,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.7883709073066711,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8034632205963135
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.8237525224685669,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.7862646579742432,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7655675411224365,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7644314765930176,
            "answer": "forgetting",
            "hit": false
          },
          {
            "score": 0.7625137567520142,
            "answer": "having",
            "hit": false
          },
          {
            "score": 0.7575407028198242,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8237525224685669
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.8308359980583191,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7869154214859009,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7863088250160217,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.756075918674469,
            "answer": "presenting",
            "hit": false
          },
          {
            "score": 0.7537758350372314,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7517154216766357,
            "answer": "representatives",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8308360278606415
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.8155444264411926,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.7748429179191589,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7713268995285034,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.7606954574584961,
            "answer": "restricting",
            "hit": false
          },
          {
            "score": 0.7578308582305908,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7576219439506531,
            "answer": "declaring",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.815544456243515
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8851524591445923,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.866780161857605,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8345416188240051,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.8170182108879089,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7982432842254639,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7867716550827026,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8345416486263275
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.7320905923843384,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.7194859385490417,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.7185598611831665,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7162200212478638,
            "answer": "placing",
            "hit": false
          },
          {
            "score": 0.7161883115768433,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.7152575850486755,
            "answer": "presenting",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7320905923843384
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8803690671920776,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8548779487609863,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8171088695526123,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.7719669938087463,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7719394564628601,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7713570594787598,
            "answer": "expenditure",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8171088695526123
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8127201199531555,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.773966908454895,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7640950679779053,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7635999917984009,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7489732503890991,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.746101975440979,
            "answer": "teachers",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8127201497554779
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.7846248745918274,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.772487461566925,
            "answer": "reminding",
            "hit": false
          },
          {
            "score": 0.771639883518219,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.7705361843109131,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7690874338150024,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7611541152000427,
            "answer": "seeing",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7531076073646545
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8509504795074463,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8440309762954712,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8208675980567932,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8063794374465942,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.7751898765563965,
            "answer": "grasping",
            "hit": false
          },
          {
            "score": 0.7673535346984863,
            "answer": "know",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.806379497051239
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 50,
      "accuracy": 0.74
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "205298e7-96e7-47f1-b981-0e017aacf66b",
      "timestamp": "2025-05-17T20:32:06.587276"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8940902352333069,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8793500065803528,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.85693359375,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8147099018096924,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7712758779525757,
            "answer": "rejected",
            "hit": false
          },
          {
            "score": 0.7682998776435852,
            "answer": "acknowledged",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8940902352333069
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.8250058889389038,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.7915949821472168,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7869004011154175,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7654522061347961,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7504972815513611,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7494341135025024,
            "answer": "improve",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8250059485435486
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7604827880859375,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7297044992446899,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7193658351898193,
            "answer": "put",
            "hit": false
          },
          {
            "score": 0.7157557010650635,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.7118556499481201,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6967188119888306,
            "answer": "addressed",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7297044694423676
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8876449465751648,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8752279281616211,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.830729603767395,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8084233999252319,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7931227684020996,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7836501598358154,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8876449763774872
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.7751308679580688,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7629675269126892,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7577311396598816,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.75645512342453,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.7532413601875305,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7504775524139404,
            "answer": "allowing",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7629675269126892
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8163393139839172,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8067784309387207,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7674092054367065,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7546669840812683,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7416558265686035,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.7386957406997681,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7416558265686035
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9091567993164062,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.9019654393196106,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8326536417007446,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.8300250768661499,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8068568706512451,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7932205200195312,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.909156858921051
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.889689564704895,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8569298982620239,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7767106294631958,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7678391337394714,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7436318397521973,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7321692705154419,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7436318099498749
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7926411628723145,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.7700784206390381,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7680341601371765,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7659047842025757,
            "answer": "begged",
            "hit": false
          },
          {
            "score": 0.7469829320907593,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7448636293411255,
            "answer": "prayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7926411330699921
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8227779865264893,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.8130714893341064,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7879352569580078,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7827337980270386,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.7438839077949524,
            "answer": "participants",
            "hit": false
          },
          {
            "score": 0.7399741411209106,
            "answer": "tickets",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8130714595317841
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8477205634117126,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8268322348594666,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7666722536087036,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.7627666592597961,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7458747625350952,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7412415742874146,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7458747029304504
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.7966893911361694,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7885153293609619,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7657584547996521,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7507365942001343,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7431638836860657,
            "answer": "remember",
            "hit": false
          },
          {
            "score": 0.7392841577529907,
            "answer": "quite",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.796689361333847
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7788141965866089,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7511165142059326,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7484381794929504,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7478482723236084,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7446914911270142,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7432985901832581,
            "answer": "significant",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422703504562378
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8958585858345032,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8445640206336975,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8078210949897766,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8074018359184265,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7750967741012573,
            "answer": "kept",
            "hit": false
          },
          {
            "score": 0.7715291976928711,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7433823943138123
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8865010142326355,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8678562641143799,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8012318015098572,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7879089713096619,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7765825390815735,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7741785049438477,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7879089415073395
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8961770534515381,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.892509937286377,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8198565244674683,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.813958466053009,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7958844900131226,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7930295467376709,
            "answer": "chose",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8961770534515381
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8916813135147095,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8535816073417664,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7901567220687866,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7785352468490601,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7773276567459106,
            "answer": "characterized",
            "hit": false
          },
          {
            "score": 0.7736621499061584,
            "answer": "explain",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7785351872444153
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.7984130382537842,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7980015873908997,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7877351641654968,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7831372022628784,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7561659812927246,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7537257671356201,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7831372022628784
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.7632949948310852,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.7605569958686829,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7497027516365051,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.7410603761672974,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.7376267910003662,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.7321397066116333,
            "answer": "explored",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7632949948310852
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.801863431930542,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.7905651926994324,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7705659866333008,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7522043585777283,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7509324550628662,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7445923686027527,
            "answer": "endured",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.801863431930542
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8233996629714966,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.7947192788124084,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7861775159835815,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7508499622344971,
            "answer": "emphasized",
            "hit": false
          },
          {
            "score": 0.7483378648757935,
            "answer": "insisted",
            "hit": false
          },
          {
            "score": 0.7451452016830444,
            "answer": "hopefully",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8233996629714966
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8867924213409424,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8835225105285645,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8813870549201965,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7674660086631775,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.7635408639907837,
            "answer": "asserted",
            "hit": false
          },
          {
            "score": 0.751544713973999,
            "answer": "commenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8835225105285645
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8460409045219421,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8300342559814453,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8230056762695312,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7657147645950317,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7540813684463501,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7445266246795654,
            "answer": "hoped",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8300342559814453
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7833832502365112,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7552332878112793,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7518078088760376,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7344377040863037,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.732953667640686,
            "answer": "contacted",
            "hit": false
          },
          {
            "score": 0.7300741672515869,
            "answer": "earlier",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7552332878112793
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8456417322158813,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7858322858810425,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7838367819786072,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7592732906341553,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7447410821914673,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.740318238735199,
            "answer": "sounded",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7858322858810425
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8955197334289551,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.87527996301651,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8081083297729492,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.7862329483032227,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7791754007339478,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7502092719078064,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8081083297729492
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8256344199180603,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8217082023620605,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8101946115493774,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7846881747245789,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7782108783721924,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7752838134765625,
            "answer": "increase",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8217082023620605
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7612795233726501,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7378870248794556,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7344715595245361,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7276761531829834,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7272274494171143,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7241195440292358,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7612795531749725
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8942990303039551,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8911268711090088,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7693521976470947,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.7663034200668335,
            "answer": "brought",
            "hit": false
          },
          {
            "score": 0.7648522853851318,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7493576407432556,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7693522572517395
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8984577655792236,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.851686418056488,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8296641111373901,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.789506733417511,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7811530828475952,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.772852897644043,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8296641111373901
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8732243776321411,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7825413942337036,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.7745790481567383,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7708033919334412,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.7622594833374023,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.7597065567970276,
            "answer": "discovered",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7745791077613831
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.7926908135414124,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7720427513122559,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7718150615692139,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.765763521194458,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7488908171653748,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.7460242509841919,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7718150615692139
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.896882176399231,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8718499541282654,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8365249037742615,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.751244306564331,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7454202175140381,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7428513765335083,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.896882176399231
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.887703537940979,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8091543316841125,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8078205585479736,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.8036506772041321,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7904965877532959,
            "answer": "kissed",
            "hit": false
          },
          {
            "score": 0.778830349445343,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8036506772041321
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7921462059020996,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7777564525604248,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7736676931381226,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.767130434513092,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7651664018630981,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7245354652404785,
            "answer": "conducted",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7921461760997772
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9009096622467041,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8836208581924438,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8688424825668335,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8053829073905945,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.8020725250244141,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7907885909080505,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8836209177970886
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8209600448608398,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7918667197227478,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7916613817214966,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7911052703857422,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7863802909851074,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7627731561660767,
            "answer": "authored",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7916614413261414
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9119454622268677,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8822094202041626,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8569331765174866,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.748943030834198,
            "answer": "earn",
            "hit": false
          },
          {
            "score": 0.747002899646759,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7466099262237549,
            "answer": "participated",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9119454622268677
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8834002017974854,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8783926963806152,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8757883310317993,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8439840078353882,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.831699013710022,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8220027685165405,
            "answer": "reductions",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8757883012294769
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8774268627166748,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8668502569198608,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8249830007553101,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7908391952514648,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7722523808479309,
            "answer": "references",
            "hit": false
          },
          {
            "score": 0.7720469236373901,
            "answer": "denote",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8774268627166748
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8842840194702148,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8165881633758545,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7705216407775879,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7518422603607178,
            "answer": "correlated",
            "hit": false
          },
          {
            "score": 0.7494094967842102,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7492617964744568,
            "answer": "attributed",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7705216407775879
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.9155483841896057,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8604695200920105,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8224793672561646,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.8039692044258118,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7831575870513916,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7764135599136353,
            "answer": "kept",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9155483841896057
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.7802654504776001,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.7668483257293701,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7551178336143494,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7537993788719177,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7399184703826904,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7340890765190125,
            "answer": "substituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7802654206752777
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7673001289367676,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7626064419746399,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7625895738601685,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7548536062240601,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.7429929375648499,
            "answer": "mandated",
            "hit": false
          },
          {
            "score": 0.7380381226539612,
            "answer": "requirement",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7548536658287048
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.9039804935455322,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8983767032623291,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8217824101448059,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8135395646095276,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7995331883430481,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7916581630706787,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9039805829524994
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8777098059654236,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7662880420684814,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7554115653038025,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7526322603225708,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7487396597862244,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.7438690662384033,
            "answer": "brought",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7487396597862244
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8996249437332153,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8868167400360107,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8001452088356018,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7680286169052124,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7652366757392883,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7626266479492188,
            "answer": "invested",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8996249437332153
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.787316620349884,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.781227707862854,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7737436294555664,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.7580968141555786,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7578589916229248,
            "answer": "begged",
            "hit": false
          },
          {
            "score": 0.7471675872802734,
            "answer": "you",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.787316620349884
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8865199089050293,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8651835918426514,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.8156700730323792,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7850098609924316,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7812924385070801,
            "answer": "knew",
            "hit": false
          },
          {
            "score": 0.7803566455841064,
            "answer": "grasped",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8865198493003845
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.846943199634552,
            "answer": "united",
            "hit": true
          },
          {
            "score": 0.7920917868614197,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.756852388381958,
            "answer": "fused",
            "hit": false
          },
          {
            "score": 0.7432931661605835,
            "answer": "denounced",
            "hit": false
          },
          {
            "score": 0.7407947182655334,
            "answer": "divided",
            "hit": false
          },
          {
            "score": 0.7395589351654053,
            "answer": "joined",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8469432294368744
      }
    ],
    "result": {
      "cnt_questions_correct": 22,
      "cnt_questions_total": 50,
      "accuracy": 0.44
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b8ab5938-96ae-4408-b00d-4b613d790d2c",
      "timestamp": "2025-05-17T20:32:06.781852"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8218954801559448,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8205647468566895,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.8022584915161133,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8009207844734192,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7975804209709167,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7941558361053467,
            "answer": "maintains",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7846365571022034
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9294507503509521,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8561927080154419,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8281157612800598,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8240175843238831,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8209841847419739,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.8096356391906738,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9294507205486298
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8803542256355286,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8577106595039368,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8388159275054932,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8002091646194458,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7838509678840637,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.7837744355201721,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8803542256355286
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8965588212013245,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8753014802932739,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7773974537849426,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7769097089767456,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7757147550582886,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7755587100982666,
            "answer": "reduces",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8965588808059692
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.9125264883041382,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.798142671585083,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7890881896018982,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7877439856529236,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.7836073637008667,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.779717743396759,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.912526547908783
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8884481191635132,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8457682728767395,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.7999181151390076,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7764081358909607,
            "answer": "grows",
            "hit": false
          },
          {
            "score": 0.7740079760551453,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7668443918228149,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.888448178768158
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8865014314651489,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8238831758499146,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8054668307304382,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.800921618938446,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.792743444442749,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7906678915023804,
            "answer": "convinced",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8865013718605042
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8333957195281982,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7805394530296326,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.777784526348114,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.7764331698417664,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7688034176826477,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7651140093803406,
            "answer": "intends",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8333957195281982
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.916624128818512,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8654961585998535,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.85750412940979,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8437776565551758,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8402222394943237,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8333020210266113,
            "answer": "consist",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9166241884231567
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8484724760055542,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.810648500919342,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.7966984510421753,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7907472848892212,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.790170431137085,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7833492755889893,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8106485307216644
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8898508548736572,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8479464054107666,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8007211685180664,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7912330031394958,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7721190452575684,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.770725667476654,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8898508250713348
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9303051233291626,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8818312883377075,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8219581842422485,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8109819889068604,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8103717565536499,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.8086828589439392,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9303051829338074
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.824140727519989,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8162065744400024,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.8133549094200134,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.8043250441551208,
            "answer": "regardless",
            "hit": false
          },
          {
            "score": 0.8019791841506958,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8008210062980652,
            "answer": "although",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.813354879617691
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9204199314117432,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8699544072151184,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.819624662399292,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8186368942260742,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.817119836807251,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.8095923662185669,
            "answer": "refers",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9204199910163879
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8913607597351074,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8317434191703796,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7958027124404907,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7778083682060242,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7650730609893799,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7523562908172607,
            "answer": "development",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8913608193397522
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.9104993343353271,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8319421410560608,
            "answer": "finds",
            "hit": false
          },
          {
            "score": 0.8294090032577515,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8225957155227661,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.8121768832206726,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.8108769059181213,
            "answer": "explores",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9104993641376495
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.9174195528030396,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8399209976196289,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8256807327270508,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8185105323791504,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8129021525382996,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7960652709007263,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9174195826053619
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7731590270996094,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7706068754196167,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7650960683822632,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7626057863235474,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7539041042327881,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7494587898254395,
            "answer": "expands",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7731590569019318
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8884897232055664,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8552286624908447,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.8246182799339294,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8221306800842285,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8178898692131042,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.8112965822219849,
            "answer": "tells",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8884897232055664
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8318858742713928,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.8131659626960754,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.8092613220214844,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.8053203225135803,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7995713949203491,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7976150512695312,
            "answer": "since",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7995713949203491
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8852041363716125,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8586176633834839,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8445385694503784,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8362051844596863,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8255370855331421,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.793397843837738,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8852041363716125
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.7696146965026855,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7614691853523254,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7614320516586304,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7546240091323853,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7489629983901978,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7465223073959351,
            "answer": "responds",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7614692151546478
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9174450635910034,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8234887719154358,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8201625943183899,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8090486526489258,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8022990226745605,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7951626181602478,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9174451231956482
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8032444715499878,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.8026728630065918,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7982808351516724,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7829766273498535,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7807386517524719,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7769873738288879,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8032444715499878
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8890045881271362,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8352154493331909,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7971932888031006,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7852118611335754,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7839829921722412,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7803621888160706,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8890045881271362
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7965061664581299,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7759582996368408,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7729771137237549,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.765943706035614,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.7624871730804443,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7594753503799438,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7524801194667816
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.90342777967453,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8062851428985596,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.8061095476150513,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7860537767410278,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7819200754165649,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7770372629165649,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9034277200698853
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8676727414131165,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.8425300121307373,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7860339879989624,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7836151123046875,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.774660587310791,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7696183323860168,
            "answer": "owns",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8676727414131165
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9065190553665161,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8587822914123535,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8443577885627747,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.829035758972168,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.827385425567627,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7981468439102173,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9065189957618713
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8475083708763123,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8173632025718689,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7601838707923889,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7481378316879272,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7447028160095215,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7441478967666626,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8475083708763123
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8298258781433105,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.7930863499641418,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7651214003562927,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7635905146598816,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7629636526107788,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7605701684951782,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8298259377479553
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9309127926826477,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8920397758483887,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8292621374130249,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8133007287979126,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8089199066162109,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7924181222915649,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9309127926826477
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9351220726966858,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8885452747344971,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8402640223503113,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8276915550231934,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8220705986022949,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8214392066001892,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9351221323013306
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8983632326126099,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8580107092857361,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8177109956741333,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.776260256767273,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7627055644989014,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7519969940185547,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8983632028102875
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9343085885047913,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8869127631187439,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8417854309082031,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.8339062929153442,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8324963450431824,
            "answer": "lowers",
            "hit": false
          },
          {
            "score": 0.8319494724273682,
            "answer": "improves",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9343085289001465
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8874374628067017,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8328795433044434,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8217059373855591,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.8032864332199097,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7904391288757324,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.790398895740509,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8874374628067017
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8705043792724609,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8364039063453674,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8221628069877625,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7952358722686768,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7927294969558716,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7921789288520813,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8705043792724609
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8092987537384033,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7908957004547119,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7844192981719971,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7749435901641846,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7560983300209045,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7551120519638062,
            "answer": "continues",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7908957004547119
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.9047693014144897,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.8230287432670593,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7906434535980225,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.7854638695716858,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7826076745986938,
            "answer": "reflects",
            "hit": false
          },
          {
            "score": 0.781609833240509,
            "answer": "serves",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9047693312168121
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.9034650325775146,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.8112975358963013,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.8112386465072632,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8045763373374939,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8004420399665833,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7943398952484131,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9034650921821594
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8617852926254272,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8368129730224609,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8177101612091064,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.815805196762085,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.8078321218490601,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.8068345785140991,
            "answer": "seem",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8617852926254272
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8714174628257751,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7717733383178711,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7629380226135254,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7607221603393555,
            "answer": "leans",
            "hit": false
          },
          {
            "score": 0.7551143169403076,
            "answer": "stood",
            "hit": false
          },
          {
            "score": 0.7506863474845886,
            "answer": "puts",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8714174628257751
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8413305282592773,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.7952237129211426,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.7814911603927612,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.770470380783081,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7582265138626099,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7537702918052673,
            "answer": "seeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8413305580615997
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.9134792685508728,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8559848070144653,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8395140767097473,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8366571664810181,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8354012966156006,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.814828097820282,
            "answer": "proposes",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9134792983531952
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8608009219169617,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8092954754829407,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7854776978492737,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.78257155418396,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7809210419654846,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7726216316223145,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8608009219169617
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.7989058494567871,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7638204097747803,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7596762180328369,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7573628425598145,
            "answer": "refuses",
            "hit": false
          },
          {
            "score": 0.7569417357444763,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7547059655189514,
            "answer": "emphasizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7989058196544647
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8062598705291748,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7839136123657227,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7818804979324341,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7816758751869202,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.771994948387146,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7719612717628479,
            "answer": "considers",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8062598407268524
      }
    ],
    "result": {
      "cnt_questions_correct": 40,
      "cnt_questions_total": 47,
      "accuracy": 0.851063829787234
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c411a5cc-a69a-40db-a1bf-d81e6f27f587",
      "timestamp": "2025-05-17T20:32:06.973045"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8242442607879639,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.795221209526062,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7840757369995117,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.7827774286270142,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7810425758361816,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.7803061604499817,
            "answer": "moreover",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242442011833191
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8869227170944214,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8518195748329163,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.839838981628418,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.801456868648529,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.7973083257675171,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7741311192512512,
            "answer": "persuaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8869226574897766
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8604408502578735,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8262307643890381,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.8034988641738892,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7913416624069214,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.791235625743866,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7889722585678101,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7496337890625
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8564671277999878,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8332546949386597,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8179599046707153,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8009145259857178,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7797669768333435,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.7781021595001221,
            "answer": "announced",
            "hit": true
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7781021595001221
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8705012798309326,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8380413055419922,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8179701566696167,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7643666863441467,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7618453502655029,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7552012205123901,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8705012798309326
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8787627220153809,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.839716374874115,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7862693071365356,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7749899625778198,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7613693475723267,
            "answer": "applicant",
            "hit": false
          },
          {
            "score": 0.7597233057022095,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7749899625778198
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8530725240707397,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8001046776771545,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7827187180519104,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7759755253791809,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7721542119979858,
            "answer": "begged",
            "hit": false
          },
          {
            "score": 0.7695408463478088,
            "answer": "begging",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7368853092193604
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8717876672744751,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7967337369918823,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.787938117980957,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.784611165523529,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.778710126876831,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7749872207641602,
            "answer": "attendance",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8717876076698303
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8521790504455566,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8154931664466858,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7563625574111938,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7488875389099121,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.7482919692993164,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7375612258911133,
            "answer": "surpassed",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7482919692993164
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7864140868186951,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7726708650588989,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7697424292564392,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7494664192199707,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7431244850158691,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7302157282829285,
            "answer": "examined",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7864140868186951
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8415044546127319,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8296316266059875,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7969398498535156,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7915675640106201,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7639028429985046,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7577900886535645,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8296316862106323
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8467079401016235,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8269032835960388,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.820086658000946,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7896049618721008,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7712271213531494,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.7677803039550781,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7469787895679474
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8866047263145447,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8617857694625854,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7921103239059448,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7882723808288574,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.7838841676712036,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7834543585777283,
            "answer": "constructing",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7921103239059448
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8427444696426392,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8389261364936829,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8387727737426758,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8349916338920593,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7811458110809326,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7756452560424805,
            "answer": "decision",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8427445590496063
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.866752028465271,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8633372187614441,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8076145052909851,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8032196164131165,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.786636233329773,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7764522433280945,
            "answer": "depicting",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7684683799743652
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.872976541519165,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8282670974731445,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7893393039703369,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7550739049911499,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7469565272331238,
            "answer": "emerging",
            "hit": false
          },
          {
            "score": 0.7331382632255554,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8729766011238098
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8966470956802368,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8724380731582642,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.84835284948349,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7729752063751221,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7600489258766174,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.7559752464294434,
            "answer": "asserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.84835284948349
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7682137489318848,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.744086742401123,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.742475152015686,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.732927680015564,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7299717664718628,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7179491519927979,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7424751818180084
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8184119462966919,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8131535053253174,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8000547885894775,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.77825927734375,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7731231451034546,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7527559995651245,
            "answer": "waited",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7782593071460724
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8249710202217102,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.8213896155357361,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8009858727455139,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7900290489196777,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7608461976051331,
            "answer": "refused",
            "hit": false
          },
          {
            "score": 0.7582112550735474,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8213896155357361
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8408016562461853,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.8139443397521973,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.8134951591491699,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.8127257823944092,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.8046307563781738,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.800728976726532,
            "answer": "given",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.761905312538147
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7722181081771851,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7549808025360107,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7522620558738708,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7453299760818481,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7348816394805908,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7347444891929626,
            "answer": "hears",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7549808323383331
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8583961129188538,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8347145915031433,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8194661736488342,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8143195509910583,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7959693670272827,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7951356172561646,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8143195509910583
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7830875515937805,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7599111795425415,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7586508989334106,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7560168504714966,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7545316219329834,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.7522486448287964,
            "answer": "numerous",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7599112093448639
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9074036478996277,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8818995952606201,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.7707724571228027,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.7670371532440186,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7604386210441589,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7602189183235168,
            "answer": "debuted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7707724571228027
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8231372833251953,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8204318284988403,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.771328330039978,
            "answer": "undertaken",
            "hit": false
          },
          {
            "score": 0.7684563398361206,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7646415829658508,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7614712715148926,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.768456369638443
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8862020373344421,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7681094408035278,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.7672376036643982,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7564526796340942,
            "answer": "resided",
            "hit": false
          },
          {
            "score": 0.7490636706352234,
            "answer": "searching",
            "hit": false
          },
          {
            "score": 0.7489257454872131,
            "answer": "encountered",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.767237663269043
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8448570370674133,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8419139981269836,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7978219389915466,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.77536541223526,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7753328680992126,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7603253126144409,
            "answer": "loser",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8448570370674133
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8466441631317139,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8281661868095398,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8165552616119385,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7566644549369812,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7560086250305176,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.7521657347679138,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8281662464141846
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.9021534323692322,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.8189063668251038,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8151747584342957,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.8095412254333496,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7910383939743042,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.7891378402709961,
            "answer": "kissed",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8095412254333496
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8080919981002808,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7830022573471069,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7745159268379211,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7495951056480408,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7130714654922485,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.7105114459991455,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7083512544631958
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7879171371459961,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7755774259567261,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7673625946044922,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7589728832244873,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7536684274673462,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7488734126091003,
            "answer": "funded",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7755773961544037
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8864704966545105,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8813450336456299,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8558875918388367,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.834164023399353,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8202752470970154,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8070767521858215,
            "answer": "advocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8558875918388367
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8872630596160889,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8645257353782654,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8631687760353088,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8263925909996033,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7992188334465027,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7939367294311523,
            "answer": "ensuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8631687760353088
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.7973343729972839,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.7804539799690247,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7799156904220581,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7786210179328918,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7632964849472046,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7372408509254456,
            "answer": "press",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7632964849472046
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8552979230880737,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8549497127532959,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8304900527000427,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7530363202095032,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.7417939305305481,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7317431569099426,
            "answer": "recipients",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8552979826927185
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8927627801895142,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8708549737930298,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8653025031089783,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8502364754676819,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8326194882392883,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.8275379538536072,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653025031089783
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8512812852859497,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8171336054801941,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8144267797470093,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8066873550415039,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7928386330604553,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7798364758491516,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8066874146461487
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8079566359519958,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7892144918441772,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7669070363044739,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7423447370529175,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7368760108947754,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7242950201034546,
            "answer": "retained",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7892144918441772
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8929576277732849,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8686877489089966,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8040950298309326,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7963441014289856,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7934807538986206,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.7819087505340576,
            "answer": "replace",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8929576277732849
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8556821942329407,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8459665179252625,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7912316918373108,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7806916236877441,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.753677487373352,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7503875494003296,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556822240352631
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8358533382415771,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7993242144584656,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7866317629814148,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7772328853607178,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.773898720741272,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.7683861255645752,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7384112477302551
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.7760636806488037,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7653348445892334,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7289461493492126,
            "answer": "somehow",
            "hit": false
          },
          {
            "score": 0.7283111214637756,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.724635899066925,
            "answer": "communicated",
            "hit": false
          },
          {
            "score": 0.7230212688446045,
            "answer": "begged",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7283111214637756
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.797691822052002,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.790440022945404,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7769688963890076,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7731038331985474,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7720904350280762,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7382428646087646,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7731038630008698
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8408998250961304,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8307461738586426,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.791483998298645,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.790550947189331,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.7757794260978699,
            "answer": "agony",
            "hit": false
          },
          {
            "score": 0.7756479978561401,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.840899795293808
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8325983285903931,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.8027098178863525,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7934926748275757,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7831165790557861,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7805140018463135,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7688438892364502,
            "answer": "faculty",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8325983881950378
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7416069507598877,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7338472604751587,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7296800017356873,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7229710817337036,
            "answer": "conveyed",
            "hit": false
          },
          {
            "score": 0.7222609519958496,
            "answer": "yelled",
            "hit": false
          },
          {
            "score": 0.7216758728027344,
            "answer": "driven",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7416069507598877
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.7858114242553711,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7717999219894409,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.76840740442276,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7604187726974487,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7465589046478271,
            "answer": "grasped",
            "hit": false
          },
          {
            "score": 0.7430174946784973,
            "answer": "knew",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.76840740442276
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 48,
      "accuracy": 0.2916666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b3994b17-557a-44fb-9ef9-7096c9ce09a3",
      "timestamp": "2025-05-17T20:32:07.151960"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7798886895179749,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7447432279586792,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7297200560569763,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.7251964807510376,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.7079657316207886,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7009744048118591,
            "answer": "fixed",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798887491226196
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8995736837387085,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8778650164604187,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8311095237731934,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8184250593185425,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7790348529815674,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.7700197696685791,
            "answer": "acknowledged",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8995736837387085
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8562383055686951,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8510993123054504,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8207464218139648,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8074279427528381,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.805902898311615,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8002204895019531,
            "answer": "gave",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7668536305427551
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8505632877349854,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8064641952514648,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8051776885986328,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8050912618637085,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.8009833097457886,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.7945313453674316,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8009833693504333
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9192988872528076,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8965710401535034,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8327736258506775,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8293145298957825,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8108328580856323,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7979212403297424,
            "answer": "seem",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.91929891705513
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8834080696105957,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8207182884216309,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7897167801856995,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7436872720718384,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7374755144119263,
            "answer": "imposed",
            "hit": false
          },
          {
            "score": 0.7358890175819397,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7436872869729996
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8520153164863586,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8283265233039856,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.8190269470214844,
            "answer": "wondered",
            "hit": false
          },
          {
            "score": 0.8150134682655334,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.8090159893035889,
            "answer": "questioned",
            "hit": false
          },
          {
            "score": 0.7984271049499512,
            "answer": "asked",
            "hit": true
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7984270751476288
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8766306638717651,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8230156898498535,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7743792533874512,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7690808773040771,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7616742253303528,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.7612637877464294,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7690808475017548
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8834120035171509,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8246666193008423,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8227105736732483,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.8078466653823853,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7941323518753052,
            "answer": "insisted",
            "hit": false
          },
          {
            "score": 0.7921380400657654,
            "answer": "believe",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8834120333194733
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8809719681739807,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8157039880752563,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.8074240684509277,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.7905185222625732,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7790822982788086,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7734667062759399,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8809719681739807
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9389970302581787,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.906257152557373,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.871268093585968,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8484660983085632,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8314969539642334,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7883887887001038,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9389970302581787
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.7827154397964478,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7748121023178101,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7687455415725708,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.7405716180801392,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7374840974807739,
            "answer": "used",
            "hit": false
          },
          {
            "score": 0.7360384464263916,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7827154695987701
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.89127516746521,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8333380818367004,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8084350824356079,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.778252899646759,
            "answer": "persisted",
            "hit": false
          },
          {
            "score": 0.7780937552452087,
            "answer": "kept",
            "hit": false
          },
          {
            "score": 0.776280403137207,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7751960158348083
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8959389925003052,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8539646863937378,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8223970532417297,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7944381237030029,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7852108478546143,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7849802374839783,
            "answer": "created",
            "hit": true
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7849802374839783
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.9157442450523376,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8959535956382751,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8348991870880127,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8303511142730713,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.8070335984230042,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8026626706123352,
            "answer": "chose",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9157442450523376
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8842363357543945,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8472892045974731,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8107441663742065,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7970696091651917,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7923895120620728,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7900789380073547,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8107441663742065
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8732272386550903,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8397129774093628,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7999287247657776,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7777777910232544,
            "answer": "progressed",
            "hit": false
          },
          {
            "score": 0.7715792655944824,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7707794904708862,
            "answer": "development",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8732272386550903
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8909568786621094,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8637996912002563,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8583260774612427,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7754442691802979,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7751271724700928,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.7741883397102356,
            "answer": "upheld",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8583260476589203
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8569061756134033,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8385941386222839,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.821334958076477,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7955431938171387,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.7953122854232788,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7839702367782593,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8385941088199615
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8399204015731812,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8355868458747864,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8142654895782471,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7915261387825012,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7897437810897827,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.7809657454490662,
            "answer": "refused",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8399204313755035
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8085039854049683,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7530564069747925,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7262639999389648,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.7252263426780701,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.7135290503501892,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7067128419876099,
            "answer": "came",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8085039556026459
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.9153996706008911,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8753195405006409,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8390993475914001,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8173141479492188,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8130818605422974,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7891321182250977,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9153996706008911
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8283674716949463,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7871662974357605,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7431436777114868,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7300199866294861,
            "answer": "whispered",
            "hit": false
          },
          {
            "score": 0.7288088798522949,
            "answer": "witnessed",
            "hit": false
          },
          {
            "score": 0.7234352231025696,
            "answer": "hearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7871663272380829
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7607831358909607,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7536442279815674,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7392476797103882,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.7357937097549438,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7345259189605713,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.733362078666687,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7536442875862122
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.9003111124038696,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.839004635810852,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.823070764541626,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.7994672060012817,
            "answer": "vowed",
            "hit": false
          },
          {
            "score": 0.7994369864463806,
            "answer": "planned",
            "hit": false
          },
          {
            "score": 0.7991226315498352,
            "answer": "hoped",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8230707943439484
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8942140936851501,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8696796894073486,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7824543714523315,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.775108814239502,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7702115178108215,
            "answer": "debuted",
            "hit": false
          },
          {
            "score": 0.7694675326347351,
            "answer": "introduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7824543416500092
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8992888927459717,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8466386198997498,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.819757342338562,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.8108862638473511,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.799329936504364,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.791438102722168,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8197573721408844
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.871661901473999,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.8536195158958435,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8328019976615906,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7958996295928955,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7945504784584045,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.784752368927002,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8716619610786438
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.9094439744949341,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8688220381736755,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8093116283416748,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7610912919044495,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7514305710792542,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7513507008552551,
            "answer": "maintains",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9094439744949341
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9137282371520996,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.9066603183746338,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8634158372879028,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.829737663269043,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8264005780220032,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7855862975120544,
            "answer": "happening",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9137282371520996
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.9059374928474426,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.800498902797699,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7857941389083862,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.7831282615661621,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.7773096561431885,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7699999213218689,
            "answer": "operational",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7857941389083862
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9087592363357544,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7911291718482971,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7890175580978394,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7812895774841309,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7701727151870728,
            "answer": "undertook",
            "hit": false
          },
          {
            "score": 0.7678793668746948,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9087592959403992
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8906327486038208,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8772063851356506,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8764574527740479,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8297121524810791,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8223769664764404,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8151176571846008,
            "answer": "advocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8764574825763702
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9053837060928345,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8819026350975037,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8534569144248962,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.822798490524292,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8176708221435547,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.8137845993041992,
            "answer": "allows",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8819026350975037
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.9033344388008118,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8896812796592712,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8463397026062012,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.779407262802124,
            "answer": "underwent",
            "hit": false
          },
          {
            "score": 0.7713086009025574,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7680193781852722,
            "answer": "gets",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9033344984054565
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8618847131729126,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8616871237754822,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8240441679954529,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7823354601860046,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7815407514572144,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7665632963180542,
            "answer": "denotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8618847727775574
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8739336729049683,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8177969455718994,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7955618500709534,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7687095403671265,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7615408897399902,
            "answer": "correlated",
            "hit": false
          },
          {
            "score": 0.7552235722541809,
            "answer": "attributed",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7955618500709534
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8630921840667725,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8446184396743774,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7486927509307861,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7454320192337036,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7378851175308228,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7351764440536499,
            "answer": "remnants",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8630922436714172
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8836783170700073,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8546547889709473,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7969774007797241,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.7794923782348633,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7762632369995117,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7599458694458008,
            "answer": "replace",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8836783170700073
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8904736042022705,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8394680619239807,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7812607288360596,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7642734050750732,
            "answer": "constitutes",
            "hit": false
          },
          {
            "score": 0.7626500725746155,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7559444904327393,
            "answer": "reflects",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8904736340045929
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8339332938194275,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7927701473236084,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7866136431694031,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.783964991569519,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7774993181228638,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.7725316882133484,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7647397816181183
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.9266988039016724,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8954126834869385,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8388093709945679,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8134765625,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7936434745788574,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7873093485832214,
            "answer": "appear",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.92669877409935
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.891291618347168,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7844631671905518,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7618292570114136,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7598671317100525,
            "answer": "communicated",
            "hit": false
          },
          {
            "score": 0.7586339712142944,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.7580041289329529,
            "answer": "transmitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7571426630020142
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8949447870254517,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8903593420982361,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8024560809135437,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7814967632293701,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.767777144908905,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7658103108406067,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8903594017028809
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8931267261505127,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8511694073677063,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8305498361587524,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8117579221725464,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8115858435630798,
            "answer": "indicated",
            "hit": false
          },
          {
            "score": 0.8039090633392334,
            "answer": "indicate",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8931267857551575
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.9005269408226013,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7863337993621826,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7848668098449707,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7820864915847778,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7768306732177734,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7704687714576721,
            "answer": "gave",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9005270004272461
      }
    ],
    "result": {
      "cnt_questions_correct": 24,
      "cnt_questions_total": 46,
      "accuracy": 0.5217391304347826
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c74a8247-4be8-4349-a827-a2841be7a553",
      "timestamp": "2025-05-17T20:32:07.334853"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.8098769187927246,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.7248957753181458,
            "answer": "relentless",
            "hit": false
          },
          {
            "score": 0.7247612476348877,
            "answer": "brutal",
            "hit": false
          },
          {
            "score": 0.7099881172180176,
            "answer": "fierce",
            "hit": false
          },
          {
            "score": 0.7012444734573364,
            "answer": "violent",
            "hit": false
          },
          {
            "score": 0.7012087106704712,
            "answer": "reckless",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 2216,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6342425346374512
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.8150410652160645,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.7126621007919312,
            "answer": "unemployed",
            "hit": false
          },
          {
            "score": 0.6965075731277466,
            "answer": "esther",
            "hit": false
          },
          {
            "score": 0.683411717414856,
            "answer": "rebecca",
            "hit": false
          },
          {
            "score": 0.6809983253479004,
            "answer": "elderly",
            "hit": false
          },
          {
            "score": 0.6804386973381042,
            "answer": "eleanor",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 241,
        "landing_b": false,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6414499133825302
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "05d093d2-23d5-411a-a41c-e1648a4f8261",
      "timestamp": "2025-05-17T20:32:07.509349"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.7325004935264587,
            "answer": "incapable",
            "hit": false
          },
          {
            "score": 0.7259393930435181,
            "answer": "unwilling",
            "hit": false
          },
          {
            "score": 0.7237354516983032,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.7116943597793579,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.7057804465293884,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7008962631225586,
            "answer": "ineffective",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7237354665994644
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.867397665977478,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.7729561924934387,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.7629048824310303,
            "answer": "adequate",
            "hit": false
          },
          {
            "score": 0.7617078423500061,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.7613485455513,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7606041431427002,
            "answer": "unpleasant",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.867397665977478
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8795718550682068,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8083599805831909,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.791402280330658,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.7831342220306396,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.7728878259658813,
            "answer": "damaged",
            "hit": false
          },
          {
            "score": 0.7643991112709045,
            "answer": "affecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8083599805831909
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8095581531524658,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.746294379234314,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.7450758814811707,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.7360340356826782,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.7339249849319458,
            "answer": "insufficient",
            "hit": false
          },
          {
            "score": 0.7298908233642578,
            "answer": "unpublished",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8095581531524658
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.848793625831604,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.7823716402053833,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.778570294380188,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.7673969268798828,
            "answer": "unwilling",
            "hit": false
          },
          {
            "score": 0.7559875845909119,
            "answer": "acquainted",
            "hit": false
          },
          {
            "score": 0.7550654411315918,
            "answer": "unhappy",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.848793625831604
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7623814344406128,
            "answer": "whenever",
            "hit": false
          },
          {
            "score": 0.762140154838562,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7614529132843018,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.757898211479187,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.754004180431366,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.7533189654350281,
            "answer": "often",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7434189021587372
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.7563954591751099,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.7446289658546448,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7369750738143921,
            "answer": "unchanged",
            "hit": true
          },
          {
            "score": 0.7345072031021118,
            "answer": "uncertain",
            "hit": false
          },
          {
            "score": 0.7344605922698975,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.726606547832489,
            "answer": "shifted",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7369750738143921
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.864652156829834,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.7997061014175415,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.7942005395889282,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7804051041603088,
            "answer": "confident",
            "hit": false
          },
          {
            "score": 0.777584969997406,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7688467502593994,
            "answer": "cozy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8646522164344788
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.8443368673324585,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7631586790084839,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7589849233627319,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.7427255511283875,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.742145299911499,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7369047403335571,
            "answer": "ignorant",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7589848935604095
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8303026556968689,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.8180903196334839,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.7897964715957642,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7533815503120422,
            "answer": "unemployment",
            "hit": false
          },
          {
            "score": 0.7488089799880981,
            "answer": "incarcerated",
            "hit": false
          },
          {
            "score": 0.7470961213111877,
            "answer": "elderly",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8303026556968689
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.7838002443313599,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7770406007766724,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7708296179771423,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7595659494400024,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7552093267440796,
            "answer": "unexpected",
            "hit": true
          },
          {
            "score": 0.7535098195075989,
            "answer": "expecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7552092969417572
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.833106517791748,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.7440256476402283,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.7394657135009766,
            "answer": "incomplete",
            "hit": false
          },
          {
            "score": 0.7328310608863831,
            "answer": "unpublished",
            "hit": false
          },
          {
            "score": 0.7264313101768494,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.7262853384017944,
            "answer": "disappointing",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8331065475940704
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8313284516334534,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.7658998966217041,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.7633077502250671,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.7627637982368469,
            "answer": "privileged",
            "hit": false
          },
          {
            "score": 0.7577358484268188,
            "answer": "foolish",
            "hit": false
          },
          {
            "score": 0.7529280185699463,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8313284814357758
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7928780317306519,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.7582482099533081,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7535829544067383,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.7458706498146057,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7441807985305786,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7393065094947815,
            "answer": "lucky",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7928780019283295
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.805724024772644,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.7925698757171631,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7628257870674133,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7614201903343201,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7573826313018799,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7563703656196594,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.805724024772644
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7485291957855225,
            "answer": "notable",
            "hit": false
          },
          {
            "score": 0.744931161403656,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7400617599487305,
            "answer": "unidentified",
            "hit": false
          },
          {
            "score": 0.730493426322937,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7297296524047852,
            "answer": "unknown",
            "hit": true
          },
          {
            "score": 0.7272816896438599,
            "answer": "often",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7297296822071075
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8648335933685303,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7687656879425049,
            "answer": "unconstitutional",
            "hit": false
          },
          {
            "score": 0.768336296081543,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7603288292884827,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7595726251602173,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.7573859095573425,
            "answer": "improper",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8648335933685303
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.8199585676193237,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7685908079147339,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7431287169456482,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.7389349341392517,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.7377423048019409,
            "answer": "compensated",
            "hit": false
          },
          {
            "score": 0.7359890937805176,
            "answer": "payments",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8199586272239685
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.8643375635147095,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.7883269786834717,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7850421667098999,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7719210982322693,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7685155868530273,
            "answer": "amusing",
            "hit": false
          },
          {
            "score": 0.7646393179893494,
            "answer": "uncomfortable",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8643375337123871
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.8181000351905823,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7670247554779053,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.7627768516540527,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7612004280090332,
            "answer": "influential",
            "hit": false
          },
          {
            "score": 0.7564249634742737,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.7518050670623779,
            "answer": "beloved",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8181000351905823
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8334733247756958,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7838034629821777,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.7670707702636719,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.764818549156189,
            "answer": "unpleasant",
            "hit": false
          },
          {
            "score": 0.7589974403381348,
            "answer": "disappointing",
            "hit": false
          },
          {
            "score": 0.7538983821868896,
            "answer": "unreliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8334732949733734
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.7581275105476379,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.748157262802124,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.7412064075469971,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7375817894935608,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.722114622592926,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.7181555032730103,
            "answer": "manuscript",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7481572329998016
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8497742414474487,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7770081758499146,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.7706813812255859,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7698540687561035,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.7671303749084473,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7651708126068115,
            "answer": "inadequate",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.849774181842804
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.8156440258026123,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.7850935459136963,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7489530444145203,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7390176057815552,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7347740530967712,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7305830717086792,
            "answer": "linked",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8156440258026123
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8753694891929626,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.7983061671257019,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.7895001173019409,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.7825936079025269,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.7663142681121826,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.763462245464325,
            "answer": "inaccurate",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8753694891929626
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.7954367995262146,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7804962396621704,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7762830257415771,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.7672885656356812,
            "answer": "indicated",
            "hit": false
          },
          {
            "score": 0.7500897645950317,
            "answer": "defined",
            "hit": false
          },
          {
            "score": 0.7485296726226807,
            "answer": "stated",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7762830555438995
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8422181606292725,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.8030444979667664,
            "answer": "failed",
            "hit": false
          },
          {
            "score": 0.7802680730819702,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.7625388503074646,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7614154815673828,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7603616714477539,
            "answer": "failure",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8422181010246277
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.7544844150543213,
            "answer": "useful",
            "hit": false
          },
          {
            "score": 0.7507559657096863,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.7463675737380981,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.7323470115661621,
            "answer": "bought",
            "hit": false
          },
          {
            "score": 0.7278866171836853,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.7261934280395508,
            "answer": "contains",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7463676184415817
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7965202331542969,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.76900315284729,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7476952075958252,
            "answer": "ordinary",
            "hit": false
          },
          {
            "score": 0.7389702200889587,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.7384715676307678,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.733587920665741,
            "answer": "unusual",
            "hit": true
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7335879504680634
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.7148609161376953,
            "answer": "unidentified",
            "hit": false
          },
          {
            "score": 0.7142536640167236,
            "answer": "unwanted",
            "hit": true
          },
          {
            "score": 0.7060229778289795,
            "answer": "hated",
            "hit": false
          },
          {
            "score": 0.7058221697807312,
            "answer": "bought",
            "hit": false
          },
          {
            "score": 0.7056726217269897,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7038105726242065,
            "answer": "wanna",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7142536044120789
      }
    ],
    "result": {
      "cnt_questions_correct": 18,
      "cnt_questions_total": 30,
      "accuracy": 0.6
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3f3b1d8f-0123-4d36-8ce6-e88f668839b7",
      "timestamp": "2025-05-17T20:32:07.518700"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.8536866903305054,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.8303831815719604,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.8250163793563843,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.8229485750198364,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.8216322064399719,
            "answer": "however",
            "hit": false
          },
          {
            "score": 0.8205354809761047,
            "answer": "additionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 244,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.719255268573761
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.8002548813819885,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.7488173246383667,
            "answer": "specifically",
            "hit": false
          },
          {
            "score": 0.7422389984130859,
            "answer": "really",
            "hit": false
          },
          {
            "score": 0.7401998043060303,
            "answer": "literally",
            "hit": false
          },
          {
            "score": 0.739632248878479,
            "answer": "essentially",
            "hit": false
          },
          {
            "score": 0.7388448715209961,
            "answer": "honestly",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8002548813819885
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.7785113453865051,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7572034597396851,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.7364732027053833,
            "answer": "supplementary",
            "hit": false
          },
          {
            "score": 0.7346503734588623,
            "answer": "exceptionally",
            "hit": false
          },
          {
            "score": 0.7331521511077881,
            "answer": "extra",
            "hit": false
          },
          {
            "score": 0.7254921197891235,
            "answer": "significantly",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7572034597396851
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8198151588439941,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8014826774597168,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7699123620986938,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7687453031539917,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.7622052431106567,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7616055607795715,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7430746853351593
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.9017889499664307,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.872868537902832,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8680012226104736,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.857523500919342,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.848488450050354,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.8214489221572876,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.868001252412796
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7831461429595947,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.7470685839653015,
            "answer": "critics",
            "hit": false
          },
          {
            "score": 0.7409200668334961,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.7362962365150452,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.7362553477287292,
            "answer": "important",
            "hit": false
          },
          {
            "score": 0.7352422475814819,
            "answer": "nearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7831461429595947
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.8244442343711853,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.7563729286193848,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7557293176651001,
            "answer": "socio",
            "hit": false
          },
          {
            "score": 0.7450065016746521,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7441307306289673,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.7404512763023376,
            "answer": "archaeological",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8244442641735077
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8643843531608582,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8369354009628296,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8105202913284302,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.7752072215080261,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7751728296279907,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.772910475730896,
            "answer": "deciding",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 123,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7148246169090271
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.8114537000656128,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7747025489807129,
            "answer": "differentiated",
            "hit": false
          },
          {
            "score": 0.7680200338363647,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.7626423239707947,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.7616119980812073,
            "answer": "differentiate",
            "hit": false
          },
          {
            "score": 0.7585010528564453,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8114537000656128
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8361308574676514,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7650980949401855,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.7429993748664856,
            "answer": "digit",
            "hit": false
          },
          {
            "score": 0.7342039942741394,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7328494787216187,
            "answer": "culturally",
            "hit": false
          },
          {
            "score": 0.730092465877533,
            "answer": "visually",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.836130827665329
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7966424822807312,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7766237258911133,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.7742313742637634,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7738219499588013,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.768194317817688,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7453916072845459,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7766237258911133
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.842011034488678,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.8064587712287903,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.7945823669433594,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.7739010453224182,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.7702906131744385,
            "answer": "ecology",
            "hit": false
          },
          {
            "score": 0.7698130011558533,
            "answer": "epa",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.842011034488678
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.8291792273521423,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.8130786418914795,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.8109527230262756,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.8042210936546326,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7920475006103516,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7896354794502258,
            "answer": "comprehensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8291792571544647
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.7962321639060974,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.792229175567627,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7875121831893921,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7870010137557983,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7835958003997803,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7670604586601257,
            "answer": "popular",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7962321937084198
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.8208287954330444,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.7887139916419983,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7688905000686646,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.7681297063827515,
            "answer": "financed",
            "hit": false
          },
          {
            "score": 0.7658621072769165,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7648805975914001,
            "answer": "bankers",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8208287954330444
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8528903126716614,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.7755705118179321,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7595800161361694,
            "answer": "globe",
            "hit": false
          },
          {
            "score": 0.7505955100059509,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.7395708560943604,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.7393919229507446,
            "answer": "geo",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8528903126716614
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.820034384727478,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.7906183004379272,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.7839948534965515,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7725041508674622,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7587510347366333,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.7386915683746338,
            "answer": "cultural",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7906182408332825
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8082451820373535,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.7954599857330322,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.782418966293335,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.7648321986198425,
            "answer": "incredibly",
            "hit": false
          },
          {
            "score": 0.7622009515762329,
            "answer": "immensely",
            "hit": false
          },
          {
            "score": 0.7599390745162964,
            "answer": "extremely",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8082452714443207
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.7947449684143066,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7765418291091919,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7443832159042358,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.742491602897644,
            "answer": "urgent",
            "hit": false
          },
          {
            "score": 0.7346969842910767,
            "answer": "swiftly",
            "hit": false
          },
          {
            "score": 0.7346829175949097,
            "answer": "quickly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7947449386119843
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.7788021564483643,
            "answer": "unfortunately",
            "hit": false
          },
          {
            "score": 0.7714741826057434,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.7691750526428223,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7677250504493713,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.7674071788787842,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.7667192220687866,
            "answer": "note",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7590965926647186
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.8196691870689392,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8097994327545166,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.7839788198471069,
            "answer": "steadily",
            "hit": false
          },
          {
            "score": 0.7765821218490601,
            "answer": "progressively",
            "hit": false
          },
          {
            "score": 0.775456964969635,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7744500637054443,
            "answer": "accelerating",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.809799462556839
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7710881233215332,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.7495647668838501,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7470982670783997,
            "answer": "irs",
            "hit": false
          },
          {
            "score": 0.7146486043930054,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.7054290771484375,
            "answer": "initially",
            "hit": false
          },
          {
            "score": 0.7048022747039795,
            "answer": "integrated",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7710881233215332
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.7870239019393921,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7344788312911987,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.7329375743865967,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.728703498840332,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.7208666801452637,
            "answer": "institute",
            "hit": false
          },
          {
            "score": 0.7100334167480469,
            "answer": "overseas",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7870239615440369
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.8173530101776123,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7867700457572937,
            "answer": "law",
            "hit": false
          },
          {
            "score": 0.782782793045044,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7808544039726257,
            "answer": "litigation",
            "hit": false
          },
          {
            "score": 0.777917206287384,
            "answer": "prosecutors",
            "hit": false
          },
          {
            "score": 0.7732356190681458,
            "answer": "attorneys",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8173529505729675
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.7747188806533813,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7296528220176697,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.7276970744132996,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.721216082572937,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7179497480392456,
            "answer": "psychotic",
            "hit": false
          },
          {
            "score": 0.7178585529327393,
            "answer": "culturally",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7747189104557037
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.8359763026237488,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8191040754318237,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.7989206314086914,
            "answer": "neat",
            "hit": false
          },
          {
            "score": 0.7898238897323608,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.7820035219192505,
            "answer": "cute",
            "hit": false
          },
          {
            "score": 0.7811381816864014,
            "answer": "beautifully",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8191041350364685
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.8029896020889282,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.7900528907775879,
            "answer": "plainly",
            "hit": false
          },
          {
            "score": 0.7852402925491333,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7830613851547241,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.7802630662918091,
            "answer": "glaring",
            "hit": false
          },
          {
            "score": 0.7682647109031677,
            "answer": "obviously",
            "hit": true
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7682647109031677
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8834066987037659,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.7421553730964661,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.7372826337814331,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7315192818641663,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.7204136848449707,
            "answer": "emotional",
            "hit": false
          },
          {
            "score": 0.7170675992965698,
            "answer": "digitally",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8834066987037659
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.8384751081466675,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.826162576675415,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.8018450140953064,
            "answer": "democratic",
            "hit": false
          },
          {
            "score": 0.7912827730178833,
            "answer": "republican",
            "hit": false
          },
          {
            "score": 0.7758442759513855,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.7756767272949219,
            "answer": "ideological",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8384750783443451
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7731027603149414,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7614134550094604,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.755831241607666,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7506612539291382,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7482064962387085,
            "answer": "practically",
            "hit": true
          },
          {
            "score": 0.7480272054672241,
            "answer": "theoretically",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7482064962387085
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8447356224060059,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.8023322820663452,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7456592321395874,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7403764128684998,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.7396547794342041,
            "answer": "predecessor",
            "hit": false
          },
          {
            "score": 0.7381044626235962,
            "answer": "predecessors",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8447356820106506
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7699913382530212,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.7642753720283508,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7520325779914856,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.7470172047615051,
            "answer": "sometimes",
            "hit": false
          },
          {
            "score": 0.7389890551567078,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.7308372259140015,
            "answer": "typically",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7699913382530212
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.8018370866775513,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7774538993835449,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7618681192398071,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7591032385826111,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.7590016722679138,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.753135085105896,
            "answer": "genuine",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7408325970172882
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8263301849365234,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.8106414079666138,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7816916108131409,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.7795402407646179,
            "answer": "gender",
            "hit": false
          },
          {
            "score": 0.7755866050720215,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7748539447784424,
            "answer": "homosexuality",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8263302147388458
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.7992597818374634,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.7944684624671936,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7807570099830627,
            "answer": "substantially",
            "hit": false
          },
          {
            "score": 0.7734568119049072,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7708024978637695,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7664058208465576,
            "answer": "meaningful",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7992598116397858
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7867452502250671,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7777901291847229,
            "answer": "reminiscent",
            "hit": false
          },
          {
            "score": 0.7711930274963379,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.7678621411323547,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7649750709533691,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.7619291543960571,
            "answer": "essentially",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7649750709533691
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.8523905277252197,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.8014718294143677,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.796855092048645,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.7899811267852783,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.7839891910552979,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7722975015640259,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7968550622463226
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8684227466583252,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.8344541788101196,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.8001163005828857,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.7914849519729614,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.7821745872497559,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.7727733850479126,
            "answer": "afterward",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.86842280626297
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.818602442741394,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.7940648794174194,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7857348322868347,
            "answer": "failed",
            "hit": false
          },
          {
            "score": 0.7694112658500671,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7651269435882568,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7606246471405029,
            "answer": "successes",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8186023831367493
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.8562216758728027,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.8405942320823669,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7665667533874512,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7633911371231079,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.7569231986999512,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.7366436719894409,
            "answer": "commonly",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8562216758728027
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.7754490971565247,
            "answer": "usual",
            "hit": false
          },
          {
            "score": 0.7719463109970093,
            "answer": "commonly",
            "hit": false
          },
          {
            "score": 0.7679179906845093,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.7665750980377197,
            "answer": "traditional",
            "hit": false
          },
          {
            "score": 0.7639768123626709,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.7572643756866455,
            "answer": "traditionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7639768123626709
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.8252872228622437,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.7561473250389099,
            "answer": "exceptionally",
            "hit": false
          },
          {
            "score": 0.7512384057044983,
            "answer": "remarkably",
            "hit": false
          },
          {
            "score": 0.7470238208770752,
            "answer": "inherently",
            "hit": false
          },
          {
            "score": 0.7467708587646484,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.7373262643814087,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8252872228622437
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.74051433801651,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.7339868545532227,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.7310018539428711,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7186334133148193,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.7158228158950806,
            "answer": "simulations",
            "hit": false
          },
          {
            "score": 0.7148795127868652,
            "answer": "globally",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7186333537101746
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.8184814453125,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.7391186952590942,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.7375799417495728,
            "answer": "visibly",
            "hit": false
          },
          {
            "score": 0.7373754978179932,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.736643373966217,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.7339872121810913,
            "answer": "consciously",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8184815049171448
      }
    ],
    "result": {
      "cnt_questions_correct": 27,
      "cnt_questions_total": 44,
      "accuracy": 0.6136363636363636
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1ee849a7-a2ec-43a2-81d6-0c694b9222a1",
      "timestamp": "2025-05-17T20:32:07.634108"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.8068537712097168,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7565650343894958,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.75532066822052,
            "answer": "acquainted",
            "hit": false
          },
          {
            "score": 0.7546147108078003,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.7503051161766052,
            "answer": "noticing",
            "hit": false
          },
          {
            "score": 0.743423581123352,
            "answer": "awareness",
            "hit": true
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.743423581123352
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.8584580421447754,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7884252667427063,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7646132707595825,
            "answer": "spirituality",
            "hit": false
          },
          {
            "score": 0.7608219385147095,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.747279942035675,
            "answer": "cognition",
            "hit": false
          },
          {
            "score": 0.7468664050102234,
            "answer": "consciously",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8584580421447754
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.8037617206573486,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7818022966384888,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.7682626247406006,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7361152172088623,
            "answer": "intensity",
            "hit": false
          },
          {
            "score": 0.7355173826217651,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7267060279846191,
            "answer": "eligible",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8037617206573486
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.7720097303390503,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.7518784999847412,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.7451640367507935,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7435401678085327,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.7407622337341309,
            "answer": "gratitude",
            "hit": false
          },
          {
            "score": 0.7389213442802429,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7720097601413727
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.780115008354187,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.7649994492530823,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.7584385871887207,
            "answer": "insane",
            "hit": false
          },
          {
            "score": 0.7468421459197998,
            "answer": "insanity",
            "hit": false
          },
          {
            "score": 0.7299321889877319,
            "answer": "pissed",
            "hit": false
          },
          {
            "score": 0.7225821614265442,
            "answer": "furious",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7801150381565094
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.8057287931442261,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7554623484611511,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7447813153266907,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.7401740550994873,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.7380820512771606,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.734382152557373,
            "answer": "agony",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8057288527488708
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.8055787682533264,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7988077402114868,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7543396949768066,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7531023621559143,
            "answer": "profound",
            "hit": false
          },
          {
            "score": 0.7418254017829895,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7374443411827087,
            "answer": "considerable",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8055787980556488
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.796295166015625,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.7630820274353027,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7615299224853516,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7537035942077637,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7522769570350647,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7359393239021301,
            "answer": "strengths",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.796295166015625
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 8,
      "accuracy": 0.875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2be55e91-eff2-4adf-90ad-3a26ac97a3f1",
      "timestamp": "2025-05-17T20:32:07.799525"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8567627668380737,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8562750816345215,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8478806614875793,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7959496974945068,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7834839820861816,
            "answer": "acceptable",
            "hit": true
          },
          {
            "score": 0.7528790235519409,
            "answer": "reject",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7834840416908264
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.8297994136810303,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.8187992572784424,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.8122183680534363,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7988396883010864,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.7837549448013306,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7318999171257019,
            "answer": "variable",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.829799473285675
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.7901445627212524,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.7786859273910522,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7578326463699341,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7424116134643555,
            "answer": "adequate",
            "hit": false
          },
          {
            "score": 0.7384712100028992,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7352705001831055,
            "answer": "expensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7786859273910522
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7754490375518799,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.765977144241333,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7513720393180847,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7494568228721619,
            "answer": "considerable",
            "hit": true
          },
          {
            "score": 0.7474309206008911,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7454578876495361,
            "answer": "significant",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7494568079710007
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.7942544221878052,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.7806904315948486,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7652338743209839,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7560222148895264,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7541927099227905,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7526609897613525,
            "answer": "seriously",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.79425448179245
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.870501697063446,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8646702170372009,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8040271401405334,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.7738658785820007,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7653304934501648,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7638044357299805,
            "answer": "locate",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8040271997451782
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8009437918663025,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.7937864065170288,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.7605794072151184,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7586816549301147,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.757296085357666,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.7477548122406006,
            "answer": "sustainable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7937864363193512
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8765321969985962,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.8709348440170288,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8562431335449219,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8018525242805481,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.7959722280502319,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.7689182162284851,
            "answer": "utilize",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686644792556763
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8205576539039612,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.7911733388900757,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.7774062752723694,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.760849118232727,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.7109566926956177,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7055989503860474,
            "answer": "affordable",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8205576241016388
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8404601216316223,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.7941030263900757,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7519077658653259,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.7466068267822266,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7370945811271667,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.7333654165267944,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7043577134609222
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8780668377876282,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8359746932983398,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.824978232383728,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7984731197357178,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7890180349349976,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7786621451377869,
            "answer": "differs",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 70,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7034294009208679
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 11,
      "accuracy": 0.2727272727272727
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "00bf1ec0-e8ea-4f4b-9eef-ad7209c57b8f",
      "timestamp": "2025-05-17T20:32:07.825651"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.7696433663368225,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.765067458152771,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7556241154670715,
            "answer": "believer",
            "hit": true
          },
          {
            "score": 0.7496746182441711,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7462983131408691,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7373057007789612,
            "answer": "remember",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7556240856647491
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8616801500320435,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.7991924285888672,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7815152406692505,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.7599515914916992,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.735103964805603,
            "answer": "conductor",
            "hit": false
          },
          {
            "score": 0.7332643270492554,
            "answer": "compositions",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7815153002738953
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8740817308425903,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.8572219610214233,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.7970346808433533,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.7736788392066956,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.7536299228668213,
            "answer": "eaten",
            "hit": false
          },
          {
            "score": 0.7505654096603394,
            "answer": "drank",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7331034243106842
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7602322101593018,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.753685474395752,
            "answer": "contender",
            "hit": true
          },
          {
            "score": 0.7485275268554688,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.7415953874588013,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.740594744682312,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.7323600053787231,
            "answer": "argued",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.753685474395752
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8576273322105408,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.8534873723983765,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.7964346408843994,
            "answer": "defense",
            "hit": false
          },
          {
            "score": 0.790284276008606,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.782931923866272,
            "answer": "defence",
            "hit": false
          },
          {
            "score": 0.7637543678283691,
            "answer": "defenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7450845837593079
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.7850852012634277,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7775147557258606,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7604290843009949,
            "answer": "developer",
            "hit": true
          },
          {
            "score": 0.7559819221496582,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7466869354248047,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7465783953666687,
            "answer": "programmer",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7604291141033173
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8703612685203552,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8478438258171082,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8393405079841614,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7869713306427002,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7832130789756775,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7813588976860046,
            "answer": "assess",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 60,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7225846946239471
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.882117748260498,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8674998879432678,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8517132997512817,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.769719660282135,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.7694342136383057,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7664148211479187,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7156075239181519
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7748222351074219,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.741430401802063,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.7411049008369446,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7333234548568726,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.7285277247428894,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7194235920906067,
            "answer": "shortly",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7414303719997406
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8583972454071045,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.8195761442184448,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.8194934129714966,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.8032851219177246,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.7676637172698975,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.729015588760376,
            "answer": "textual",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7676637172698975
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.8094745874404907,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.8014760613441467,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7862629890441895,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7733905911445618,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7365823984146118,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7361119985580444,
            "answer": "preacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8094745576381683
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.7792338728904724,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7621253728866577,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7562786340713501,
            "answer": "loser",
            "hit": true
          },
          {
            "score": 0.7532482147216797,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7289160490036011,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7233006358146667,
            "answer": "lost",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7562786340713501
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8488306999206543,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8462784290313721,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8375996351242065,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7598531246185303,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.7477085590362549,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7449048757553101,
            "answer": "administrator",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.759853184223175
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.8740898966789246,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8595844507217407,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8223941922187805,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8133803009986877,
            "answer": "observer",
            "hit": true
          },
          {
            "score": 0.7758352160453796,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.772330641746521,
            "answer": "observers",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8133803606033325
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8690844774246216,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.856353223323822,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.8407140970230103,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8182294368743896,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7828315496444702,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.7764322757720947,
            "answer": "organization",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8563532531261444
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.8167538046836853,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.7955699563026428,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7580387592315674,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7575187683105469,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.746563732624054,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7387914657592773,
            "answer": "dancer",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8167538046836853
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8704601526260376,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.8242218494415283,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7959408164024353,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.7691092491149902,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.7557677030563354,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.7511052489280701,
            "answer": "theology",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242218792438507
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8752756118774414,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.874529242515564,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8319714069366455,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7951236963272095,
            "answer": "promoter",
            "hit": true
          },
          {
            "score": 0.7919391393661499,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7821642756462097,
            "answer": "promoters",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7951236367225647
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.8760338425636292,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8630754947662354,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8303689956665039,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.7914586067199707,
            "answer": "offer",
            "hit": false
          },
          {
            "score": 0.7739284634590149,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7679322957992554,
            "answer": "offers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 58,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.71236951649189
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8364951610565186,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.8347346782684326,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8051220178604126,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.793298065662384,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7665306329727173,
            "answer": "journalist",
            "hit": false
          },
          {
            "score": 0.7628849744796753,
            "answer": "pub",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8364951610565186
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8689418435096741,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8527728319168091,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8497312068939209,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7835214734077454,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7483956217765808,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.7415592074394226,
            "answer": "recipients",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7410319745540619
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.7276698350906372,
            "answer": "terminology",
            "hit": false
          },
          {
            "score": 0.7270568013191223,
            "answer": "speech",
            "hit": false
          },
          {
            "score": 0.7099899053573608,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7072696089744568,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.7047321796417236,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7020208239555359,
            "answer": "rhetoric",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7003765255212784
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.7873255014419556,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.7715467214584351,
            "answer": "teacher",
            "hit": true
          },
          {
            "score": 0.7568000555038452,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7550031542778015,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7499765157699585,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7483906149864197,
            "answer": "taught",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7715467512607574
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8349561095237732,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.8270447254180908,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7739479541778564,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.7530835866928101,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.7393426895141602,
            "answer": "columnist",
            "hit": false
          },
          {
            "score": 0.735370397567749,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7530835568904877
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 24,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1bb336a0-b49c-49bc-8dfc-6df2a40048f3",
      "timestamp": "2025-05-17T20:32:07.860649"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8800297975540161,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8688710927963257,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.8431440591812134,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.8407028913497925,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.7906103730201721,
            "answer": "alleging",
            "hit": false
          },
          {
            "score": 0.7801048159599304,
            "answer": "allegations",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8688710927963257
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8331195116043091,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.8136413097381592,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.7460262179374695,
            "answer": "appreciation",
            "hit": false
          },
          {
            "score": 0.7307263612747192,
            "answer": "praise",
            "hit": false
          },
          {
            "score": 0.7296038866043091,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.7281467914581299,
            "answer": "enthusiasts",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8331195414066315
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8367226123809814,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.7934011220932007,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7800086736679077,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.7637910842895508,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.7619680166244507,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.7403541207313538,
            "answer": "calculating",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8367226421833038
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.8812110424041748,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8568612933158875,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8027843236923218,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7950671911239624,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7640063762664795,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7587878108024597,
            "answer": "ongoing",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7950671911239624
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8761223554611206,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8696047067642212,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.8690676093101501,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.862706184387207,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.7749619483947754,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.7579654455184937,
            "answer": "assertion",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8696047067642212
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8726069331169128,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8655933141708374,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8181660175323486,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.8095065355300903,
            "answer": "determination",
            "hit": true
          },
          {
            "score": 0.8089200854301453,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7849439382553101,
            "answer": "deciding",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8095065355300903
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8784290552139282,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8590516448020935,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8384644985198975,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8087300658226013,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.7995890378952026,
            "answer": "examination",
            "hit": true
          },
          {
            "score": 0.7841648459434509,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7995890080928802
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8869186639785767,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8656189441680908,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8468546867370605,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7929495573043823,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.7645431756973267,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.764488160610199,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7929494976997375
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.783621072769165,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.7752404808998108,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.7601363658905029,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.7470132112503052,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.7452354431152344,
            "answer": "everybody",
            "hit": false
          },
          {
            "score": 0.7445071339607239,
            "answer": "often",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 74,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.710230827331543
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8472230434417725,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.8083816766738892,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.8061176538467407,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.7694699764251709,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.7613986730575562,
            "answer": "admiration",
            "hit": false
          },
          {
            "score": 0.7504963278770447,
            "answer": "motivation",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8083816766738892
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.8855008482933044,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.857779860496521,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8413537740707397,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8229323029518127,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.8080424070358276,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.7817376255989075,
            "answer": "observer",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8229323029518127
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8814694881439209,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8591911792755127,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8394219279289246,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.8055646419525146,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.7607685327529907,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.7556276917457581,
            "answer": "inhabit",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8055647015571594
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8883792161941528,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8443540930747986,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8104822635650635,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7944298386573792,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7927420735359192,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.7843191623687744,
            "answer": "organization",
            "hit": true
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7843191623687744
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8711742162704468,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.8575787544250488,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8520883321762085,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.836837887763977,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.8034325838088989,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7727482914924622,
            "answer": "prep",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8711742460727692
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.7932990789413452,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.748425304889679,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.7467573285102844,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.7299695014953613,
            "answer": "recovery",
            "hit": false
          },
          {
            "score": 0.7299556732177734,
            "answer": "preservation",
            "hit": false
          },
          {
            "score": 0.7157655954360962,
            "answer": "rebuilding",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7467573285102844
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8789889216423035,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.872722864151001,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.7770390510559082,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.7719205617904663,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.7689153552055359,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.7475067377090454,
            "answer": "unstable",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8727228939533234
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "13d9c94e-0665-4ba0-a45b-1161406497fe",
      "timestamp": "2025-05-17T20:32:07.942179"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.843815267086029,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.8351463079452515,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.799239456653595,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.7964320182800293,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7882847189903259,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7668560743331909,
            "answer": "achievement",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8351463079452515
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.7908402681350708,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7772709131240845,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7727136611938477,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7726548910140991,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.7523593306541443,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7494654655456543,
            "answer": "accomplishments",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7727136611938477
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.8601855635643005,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.8338404893875122,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8108319044113159,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.7876995205879211,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.7765591740608215,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7353402972221375,
            "answer": "adapt",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8601855635643005
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8617773056030273,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8406893014907837,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.8289993405342102,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8214092254638672,
            "answer": "agreement",
            "hit": true
          },
          {
            "score": 0.780224621295929,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7793764472007751,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8214092552661896
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.8795080184936523,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.8586747646331787,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.7443220615386963,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.7255492806434631,
            "answer": "orientation",
            "hit": false
          },
          {
            "score": 0.7150137424468994,
            "answer": "convergence",
            "hit": false
          },
          {
            "score": 0.7142170071601868,
            "answer": "affiliation",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.87950798869133
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8179669380187988,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.7725279331207275,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7668371200561523,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.7586455345153809,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.7474859356880188,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.7432292699813843,
            "answer": "alterations",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.76683709025383
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8426851034164429,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.8351500034332275,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.7556027173995972,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7502740025520325,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7321702241897583,
            "answer": "notification",
            "hit": false
          },
          {
            "score": 0.7253254652023315,
            "answer": "announced",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8426850438117981
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8273144960403442,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.8184804916381836,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7959665656089783,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.7464306354522705,
            "answer": "nominee",
            "hit": false
          },
          {
            "score": 0.7433382272720337,
            "answer": "adviser",
            "hit": false
          },
          {
            "score": 0.7417362928390503,
            "answer": "nomination",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8184804618358612
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8827442526817322,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8522765040397644,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.8282718062400818,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.8110992312431335,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7726813554763794,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.7359731793403625,
            "answer": "organised",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8282717764377594
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8783284425735474,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.8636245727539062,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8496743440628052,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.8495286703109741,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8055492639541626,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.7839359045028687,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8783284425735474
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8636215925216675,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.840071439743042,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.835338294506073,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7971653342247009,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.7598260641098022,
            "answer": "allocation",
            "hit": false
          },
          {
            "score": 0.7453582286834717,
            "answer": "allocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8353383243083954
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.8517422080039978,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.837140679359436,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.8190242052078247,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.8044910430908203,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7507002353668213,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.7097322940826416,
            "answer": "contribution",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8044911026954651
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.8201481103897095,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.7954954504966736,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7716878056526184,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7501038908958435,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7487079501152039,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7428953051567078,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8201481699943542
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8608971238136292,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8312240839004517,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7653145790100098,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7563672661781311,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7513960599899292,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7456411123275757,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8312240839004517
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.868842601776123,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8610873818397522,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8416125774383545,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8227665424346924,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.8224672079086304,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.7897542715072632,
            "answer": "promote",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8224672079086304
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8620429635047913,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8406863212585449,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7847940921783447,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.740488588809967,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.7343594431877136,
            "answer": "implementation",
            "hit": false
          },
          {
            "score": 0.7323082685470581,
            "answer": "infringement",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7847940623760223
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.8849814534187317,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8780155777931213,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8550743460655212,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.8426211476325989,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.7672039866447449,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.7577099800109863,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8426210880279541
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8742855787277222,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8645681142807007,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.8023654222488403,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7897146344184875,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7863677144050598,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7791442275047302,
            "answer": "maximize",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8645680844783783
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.7887263298034668,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7841418981552124,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.760902464389801,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7531930208206177,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7483977675437927,
            "answer": "hope",
            "hit": false
          },
          {
            "score": 0.7471469044685364,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.78414186835289
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8044000864028931,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7938823103904724,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.7504762411117554,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7367777228355408,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7356072664260864,
            "answer": "amusement",
            "hit": false
          },
          {
            "score": 0.7338820099830627,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7302114963531494
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8937939405441284,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8718588352203369,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8455449342727661,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.771209716796875,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.7513572573661804,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7467221021652222,
            "answer": "impose",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7712097465991974
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8509361743927002,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.8508172035217285,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.8503227829933167,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.7971243262290955,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.7713081240653992,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.7517150640487671,
            "answer": "accomplish",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8503227829933167
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8140774965286255,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.8117644190788269,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8046501874923706,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8027812242507935,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7945380806922913,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.786392092704773,
            "answer": "increase",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8140774965286255
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.8123412728309631,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7851630449295044,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.7551466822624207,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7383895516395569,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.7359378337860107,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7352484464645386,
            "answer": "investigation",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7851630449295044
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8810924291610718,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8326221108436584,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.794661819934845,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7880592942237854,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.7539993524551392,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.75312340259552,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7880593240261078
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8508359789848328,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8469637632369995,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8341953158378601,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.770671010017395,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.7318437099456787,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7268803119659424,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.770671010017395
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8688351511955261,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.865670919418335,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7840880155563354,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.7587847709655762,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.7535464763641357,
            "answer": "condemnation",
            "hit": false
          },
          {
            "score": 0.7527124881744385,
            "answer": "penalty",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8656709790229797
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.8609176874160767,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.8556147217750549,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.794466495513916,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.790950357913971,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7772293090820312,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.7671542167663574,
            "answer": "undermine",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556147217750549
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.7714669108390808,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.7677032947540283,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7493084669113159,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7463714480400085,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.7369178533554077,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7332377433776855,
            "answer": "remove",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7714669704437256
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.762749195098877,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.7587186694145203,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7466737627983093,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7380638122558594,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7352423071861267,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.728535532951355,
            "answer": "necessity",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7627492249011993
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 30,
      "accuracy": 0.26666666666666666
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "45dcb0ed-f552-47a4-baed-5303bdf8a49f",
      "timestamp": "2025-05-17T20:32:07.996126"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.9077096581459045,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.8118910789489746,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.8095420598983765,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.796985924243927,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7919116020202637,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7875538468360901,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9077096581459045
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8602427840232849,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.8595890998840332,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8112119436264038,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.8108654022216797,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.8073733448982239,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8053861856460571,
            "answer": "kuwait",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8602427542209625
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.9255849123001099,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8444939255714417,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.8331913948059082,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8190792202949524,
            "answer": "myanmar",
            "hit": false
          },
          {
            "score": 0.8144643306732178,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.805355966091156,
            "answer": "bangladesh",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9255848526954651
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.9197586178779602,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.838707447052002,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.816447377204895,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.8151296377182007,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.8121134638786316,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.8099396228790283,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9197586476802826
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.8724642395973206,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.8180152773857117,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.8098034858703613,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8091237545013428,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.8060213923454285,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.8025234937667847,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8724642693996429
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7354031801223755,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.7225406169891357,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7182561755180359,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7166181802749634,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7106174826622009,
            "answer": "bernard",
            "hit": false
          },
          {
            "score": 0.7063795328140259,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7354031950235367
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8746630549430847,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.8235207796096802,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.8144683837890625,
            "answer": "europe",
            "hit": false
          },
          {
            "score": 0.8117329478263855,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8045657277107239,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7970558404922485,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8746631145477295
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.9251443147659302,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.8744059801101685,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8300623893737793,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8174195885658264,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.8129035830497742,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8114945292472839,
            "answer": "poland",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9251442551612854
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.9000194072723389,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8437610864639282,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8087136745452881,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.792894184589386,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.781944751739502,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7789385318756104,
            "answer": "syria",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9000194668769836
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8968669176101685,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8514516949653625,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.8276025056838989,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.826362133026123,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.809013307094574,
            "answer": "iceland",
            "hit": false
          },
          {
            "score": 0.7995607852935791,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8968669176101685
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.857757031917572,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8189336061477661,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8033891916275024,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7923369407653809,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.7860882878303528,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7812788486480713,
            "answer": "saudi",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.857757031917572
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8957045674324036,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.8180547952651978,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7870769500732422,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7863771915435791,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7854779362678528,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.7821261286735535,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8957045674324036
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8854585886001587,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.8421297073364258,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.81168133020401,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7981812357902527,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7918181419372559,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7897550463676453,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8854585886001587
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7938548922538757,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.747489869594574,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.74626225233078,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.7424148321151733,
            "answer": "ghana",
            "hit": false
          },
          {
            "score": 0.7330727577209473,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7326182723045349,
            "answer": "king",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7938548922538757
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8874068260192871,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.816616415977478,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.8098264336585999,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7955747842788696,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7932218313217163,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7917001843452454,
            "answer": "brazil",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8874068260192871
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8773176074028015,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.8307899236679077,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.8166855573654175,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.813439130783081,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.8127174973487854,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.8068698644638062,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8773176074028015
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8690958023071289,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.8646577596664429,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.7981879115104675,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7954752445220947,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.79298335313797,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.7868850231170654,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8646577596664429
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.9038629531860352,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.8617537617683411,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.8343279957771301,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8100897073745728,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.8073524236679077,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.8068143725395203,
            "answer": "ukraine",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9038629531860352
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8915930390357971,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8371209502220154,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8139145374298096,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8027110695838928,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7977162003517151,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7887681722640991,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8915930688381195
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.855302095413208,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.8413118124008179,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.8321647644042969,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.8271405696868896,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.8229126930236816,
            "answer": "quebec",
            "hit": false
          },
          {
            "score": 0.8206161856651306,
            "answer": "alberta",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8553021252155304
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.8523324728012085,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.8233864903450012,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.8207527995109558,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8094350099563599,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7903831005096436,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7872451543807983,
            "answer": "england",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8523325026035309
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.861685574054718,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7994872331619263,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7969592809677124,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7955520153045654,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7799580693244934,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7791100740432739,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.861685574054718
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.8285449147224426,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7915948033332825,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7856229543685913,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.7695983648300171,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.7685511708259583,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7593694925308228,
            "answer": "cuba",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8285449147224426
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8993955254554749,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8429667949676514,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8339113593101501,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8294669389724731,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8241388201713562,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.796205997467041,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8993954956531525
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.902813196182251,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.8800491690635681,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8080176115036011,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8031554222106934,
            "answer": "pakistan",
            "hit": false
          },
          {
            "score": 0.8025356531143188,
            "answer": "saudi",
            "hit": false
          },
          {
            "score": 0.7994366884231567,
            "answer": "russia",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9028131365776062
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.9127269387245178,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.8367785215377808,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7983595132827759,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7953084707260132,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.7885355949401855,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7859188318252563,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.912726879119873
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8828998804092407,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.8185789585113525,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8155154585838318,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8126282691955566,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7974002361297607,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7949329614639282,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8828999400138855
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8935632705688477,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.8227494955062866,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.8049476146697998,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8002016544342041,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7920148968696594,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7888218760490417,
            "answer": "poles",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8935632705688477
      }
    ],
    "result": {
      "cnt_questions_correct": 27,
      "cnt_questions_total": 28,
      "accuracy": 0.9642857142857143
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "21242fc4-2118-46ce-ae9f-7f0b5b306e88",
      "timestamp": "2025-05-17T20:32:08.103681"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8824726939201355,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8521354794502258,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.832643985748291,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.8006146550178528,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.8002107739448547,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7900141477584839,
            "answer": "argent",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8521355390548706
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.8954060077667236,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.8333427906036377,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7974705696105957,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.7945727705955505,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.7832744121551514,
            "answer": "queensland",
            "hit": false
          },
          {
            "score": 0.7799438834190369,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 106,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6890497505664825
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.864101231098175,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8093734383583069,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8014357089996338,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7922631502151489,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7915350794792175,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.784468412399292,
            "answer": "vienna",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7915350794792175
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8931252956390381,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8599140048027039,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.8553133606910706,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7852309942245483,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.781894326210022,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7722204923629761,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8599140048027039
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8604627251625061,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.8123560547828674,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.8035274744033813,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7890702486038208,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7875453233718872,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.780358076095581,
            "answer": "ontario",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7117558717727661
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8602542877197266,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7785303592681885,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7782374620437622,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7772155404090881,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.771625280380249,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7701436281204224,
            "answer": "brazilian",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8602543473243713
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.845452070236206,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8037044405937195,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7891733646392822,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7676775455474854,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7669109106063843,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7576943635940552,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8454521298408508
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8710418939590454,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.8392982482910156,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7861524820327759,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7725275754928589,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7710559368133545,
            "answer": "castro",
            "hit": false
          },
          {
            "score": 0.767101526260376,
            "answer": "cub",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.839298278093338
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8067841529846191,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7972270846366882,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7961260676383972,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7670310735702515,
            "answer": "turkish",
            "hit": true
          },
          {
            "score": 0.7623093724250793,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7620853781700134,
            "answer": "byzantine",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7972270846366882
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.9114089012145996,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.836395263671875,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8194408416748047,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.794879138469696,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7884516716003418,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7736608982086182,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.836395263671875
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8272029161453247,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7955020666122437,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7913733124732971,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7825161814689636,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7657139301300049,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.757831335067749,
            "answer": "indonesian",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8272029757499695
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8782685995101929,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8334859609603882,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.817030131816864,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.8102099895477295,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8044427633285522,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7913385033607483,
            "answer": "islamic",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8170301914215088
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.860274076461792,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8261887431144714,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7936546802520752,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7893762588500977,
            "answer": "kurdish",
            "hit": true
          },
          {
            "score": 0.7862176299095154,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7833477258682251,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8261888027191162
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8710315227508545,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.8650872707366943,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.8275904655456543,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.8227075338363647,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.818961501121521,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.8021402359008789,
            "answer": "palestinian",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8650873303413391
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7852602005004883,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7294623851776123,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7220880389213562,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7170217037200928,
            "answer": "arab",
            "hit": false
          },
          {
            "score": 0.7148948907852173,
            "answer": "christian",
            "hit": false
          },
          {
            "score": 0.7072157263755798,
            "answer": "isaiah",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7852601408958435
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8288228511810303,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7977224588394165,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.7924231290817261,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.776421844959259,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.774300754070282,
            "answer": "lebanese",
            "hit": false
          },
          {
            "score": 0.7688127160072327,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8288227915763855
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8465785980224609,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.8369379639625549,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8203769326210022,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.8073815703392029,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.7726269364356995,
            "answer": "arab",
            "hit": false
          },
          {
            "score": 0.7719985246658325,
            "answer": "israeli",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8369379639625549
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8446696400642395,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8085033893585205,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7676936388015747,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.762902557849884,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7606070637702942,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7575926780700684,
            "answer": "sanskrit",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8446696102619171
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8686758279800415,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.8075706958770752,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7874494791030884,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7871065139770508,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7748315334320068,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7713161706924438,
            "answer": "french",
            "hit": true
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7748315334320068
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8619334101676941,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8372225761413574,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8185954093933105,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7910668849945068,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7878522276878357,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.7850944995880127,
            "answer": "russian",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8372225761413574
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.8010299801826477,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.7986698746681213,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7952756881713867,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7944161295890808,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7811663150787354,
            "answer": "tai",
            "hit": false
          },
          {
            "score": 0.774147629737854,
            "answer": "vietnamese",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8010300099849701
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.763163149356842,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7186038494110107,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.717153787612915,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7113608717918396,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.710712730884552,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6945933103561401,
            "answer": "dutch",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 48,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6600075960159302
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8511324524879456,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.79051274061203,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7815488576889038,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7759138345718384,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7708492279052734,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7694942951202393,
            "answer": "argentine",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8511325120925903
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 23,
      "accuracy": 0.34782608695652173
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0be9e9e7-b0ec-4198-a8e6-bcda9e30c58f",
      "timestamp": "2025-05-17T20:32:08.204172"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8195912837982178,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7616704106330872,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7559918165206909,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.7354797124862671,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7238709330558777,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.723508358001709,
            "answer": "bathrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7559918761253357
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8488498330116272,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7775177359580994,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7543815970420837,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7530372142791748,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7433598041534424,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.742617130279541,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8488498330116272
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8539251089096069,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8064160346984863,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.8061113357543945,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7717322707176208,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.7625634670257568,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7544383406639099,
            "answer": "bright",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8064160346984863
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7704955339431763,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7375825643539429,
            "answer": "chassis",
            "hit": false
          },
          {
            "score": 0.726463794708252,
            "answer": "vessel",
            "hit": false
          },
          {
            "score": 0.7128095030784607,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.7095467448234558,
            "answer": "yacht",
            "hit": false
          },
          {
            "score": 0.7080600261688232,
            "answer": "axle",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7704955339431763
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8972815275192261,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7961684465408325,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7884515523910522,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.777675986289978,
            "answer": "newcastle",
            "hit": false
          },
          {
            "score": 0.7761169075965881,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7751208543777466,
            "answer": "sheffield",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8972815871238708
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.8433451652526855,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8119796514511108,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7680235505104065,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.7637766599655151,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7602125406265259,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.7462866306304932,
            "answer": "hampshire",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7680235803127289
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8686829805374146,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8075640797615051,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7895704507827759,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7814902663230896,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.774695098400116,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7674662470817566,
            "answer": "manchester",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8686829805374146
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7580451965332031,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7088003754615784,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.7018581032752991,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6995679140090942,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6943932175636292,
            "answer": "stephens",
            "hit": false
          },
          {
            "score": 0.6886151432991028,
            "answer": "delaware",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7088003754615784
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8361977934837341,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8032014966011047,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7991707921028137,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.7742839455604553,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7724244594573975,
            "answer": "zealand",
            "hit": false
          },
          {
            "score": 0.770234227180481,
            "answer": "orleans",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8361977934837341
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d1b1407e-0419-48e3-90f3-b0d234efc884",
      "timestamp": "2025-05-17T20:32:08.283403"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8131173849105835,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.8036892414093018,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7986466884613037,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.798309326171875,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7917423844337463,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7723351716995239,
            "answer": "russian",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131173849105835
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7775934934616089,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7599492073059082,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7495020627975464,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7428554892539978,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.7428061962127686,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7404589653015137,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7428555190563202
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7795549035072327,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7646130323410034,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7417706847190857,
            "answer": "evolutionary",
            "hit": false
          },
          {
            "score": 0.7412168383598328,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7384485602378845,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7363559007644653,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.67843297123909
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.76670241355896,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7460479736328125,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7446273565292358,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7327485680580139,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.729699432849884,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7228167653083801,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7446273565292358
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.8236794471740723,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7685615420341492,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7625443935394287,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.762062668800354,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7617306709289551,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7569018006324768,
            "answer": "american",
            "hit": true
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7497070133686066
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8652681112289429,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.8516172170639038,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.8290008902549744,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8119511008262634,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.800237774848938,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7767301201820374,
            "answer": "russian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.851617157459259
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8143628835678101,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7750201225280762,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7506096363067627,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7505924105644226,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7459688186645508,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7306979894638062,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.775020182132721
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7721918821334839,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.770606517791748,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7600107192993164,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7566895484924316,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7503637671470642,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7388128042221069,
            "answer": "scottish",
            "hit": true
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7388128042221069
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7912057042121887,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7595236301422119,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.743985116481781,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7426316738128662,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7410444021224976,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.7392550706863403,
            "answer": "european",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7912057340145111
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7693086266517639,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7486739754676819,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7311329245567322,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7296110987663269,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.726362407207489,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7261955142021179,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7693086862564087
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.8302233815193176,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.8169681429862976,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7976282835006714,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.7877950668334961,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7792539596557617,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7775859832763672,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7976283133029938
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7779104709625244,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7519080638885498,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7502073049545288,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7387508153915405,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7306597232818604,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7302114963531494,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7519080936908722
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7616848349571228,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7516681551933289,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7486969232559204,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7387784719467163,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7380146384239197,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7342402338981628,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7042312324047089
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8302934169769287,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.8175565004348755,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7775894403457642,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7729824185371399,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7693136930465698,
            "answer": "soviet",
            "hit": false
          },
          {
            "score": 0.7662250399589539,
            "answer": "jewish",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8175564706325531
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7570138573646545,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7304787039756775,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7205616235733032,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7172828912734985,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7089669704437256,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7035038471221924,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6775605976581573
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7731054425239563,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7387793064117432,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7350423336029053,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7287984490394592,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7218605875968933,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.7192120552062988,
            "answer": "scottish",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6836568415164948
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8090294003486633,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.807296633720398,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7916685938835144,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7772220373153687,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7757553458213806,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.771751344203949,
            "answer": "greece",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8072966933250427
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7725419998168945,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7541927695274353,
            "answer": "soviet",
            "hit": false
          },
          {
            "score": 0.7522180080413818,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7492833137512207,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7428396344184875,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.7407485246658325,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7522180378437042
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7893688082695007,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7452487945556641,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7366575598716736,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7335559129714966,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7333258390426636,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7301241159439087,
            "answer": "ukrainian",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7893687784671783
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 19,
      "accuracy": 0.3157894736842105
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "53036eaa-1eaa-438b-a4a9-d0ec0fb435e3",
      "timestamp": "2025-05-17T20:32:08.312887"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8666465878486633,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8222087621688843,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8066544532775879,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8048452138900757,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7846130132675171,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.781699538230896,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8666466176509857
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7878875732421875,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7626816034317017,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7555215358734131,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.7342495918273926,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7341082096099854,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.725836455821991,
            "answer": "augustus",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7555215060710907
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.771247148513794,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7463541030883789,
            "answer": "ohio",
            "hit": false
          },
          {
            "score": 0.739704966545105,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.7377939224243164,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.733208179473877,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.7291616201400757,
            "answer": "founder",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 2385,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6405194401741028
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7950430512428284,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7759960889816284,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.754163384437561,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.752716064453125,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.752272367477417,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7497714757919312,
            "answer": "rapper",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7759960889816284
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7723579406738281,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7697066068649292,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7538934350013733,
            "answer": "inventor",
            "hit": true
          },
          {
            "score": 0.7419180274009705,
            "answer": "entrepreneur",
            "hit": false
          },
          {
            "score": 0.7366097569465637,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7331703901290894,
            "answer": "scientist",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7538934350013733
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.8454456925392151,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.8269244432449341,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7929254174232483,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.7734641432762146,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7696150541305542,
            "answer": "inventor",
            "hit": false
          },
          {
            "score": 0.7564120292663574,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8454456925392151
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.851262629032135,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.8329726457595825,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8012048006057739,
            "answer": "dictator",
            "hit": true
          },
          {
            "score": 0.7933754324913025,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7708598971366882,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7700191736221313,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8012048304080963
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.8219525814056396,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7719568014144897,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7715373039245605,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7533308267593384,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7514388561248779,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.7482891082763672,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8219525516033173
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8132685422897339,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7750760316848755,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.768412172794342,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7543764114379883,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.7506327033042908,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7504701018333435,
            "answer": "scholar",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8132685422897339
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7828716039657593,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7515877485275269,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7467119693756104,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7452309727668762,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7330097556114197,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.7315780520439148,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7189603000879288
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7918868064880371,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7606221437454224,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7433573603630066,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7429203987121582,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.7292717099189758,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7290788888931274,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7918868064880371
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.8556928634643555,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.8058486580848694,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7806026339530945,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7796367406845093,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.7761609554290771,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.77144455909729,
            "answer": "communist",
            "hit": true
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8058486580848694
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7695480585098267,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7478371858596802,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7135694026947021,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.713567852973938,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.710206151008606,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.708473801612854,
            "answer": "inventor",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7478372156620026
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.78932124376297,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7735894322395325,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.7632016539573669,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.7564239501953125,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.756207287311554,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.7486469745635986,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7735894322395325
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.807461142539978,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7760717868804932,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.7668673992156982,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7584388852119446,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.757168173789978,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7484697699546814,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7760717868804932
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8692869544029236,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8249160051345825,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8170955181121826,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7892165184020996,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7804257869720459,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7768236398696899,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.869286984205246
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7913171648979187,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7611996531486511,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7583755254745483,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7579149007797241,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7466718554496765,
            "answer": "prophet",
            "hit": false
          },
          {
            "score": 0.7385919094085693,
            "answer": "roosevelt",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7317526787519455
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7755506634712219,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7567659616470337,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.7468316555023193,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7413285374641418,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7327051162719727,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7302618026733398,
            "answer": "scholar",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7567659616470337
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 18,
      "accuracy": 0.3888888888888889
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "a89b0b98-fdb8-414a-b874-07f24fe72344",
      "timestamp": "2025-05-17T20:32:08.377518"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8302835822105408,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7592605948448181,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7348992228507996,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7096297740936279,
            "answer": "infant",
            "hit": true
          },
          {
            "score": 0.7044398784637451,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7033348083496094,
            "answer": "cuban",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6673228442668915
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7254611253738403,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7108639478683472,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7086889147758484,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7028186321258545,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7012414932250977,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7010275721549988,
            "answer": "endure",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7254610955715179
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7571274042129517,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7520257234573364,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7345572710037231,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7230658531188965,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.714017391204834,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.7131569981575012,
            "answer": "herds",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7520257234573364
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7720307111740112,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7589274048805237,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7471293210983276,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7416397333145142,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7233630418777466,
            "answer": "circus",
            "hit": false
          },
          {
            "score": 0.7212622165679932,
            "answer": "kid",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7471293061971664
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.8463175296783447,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7878240346908569,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7434902787208557,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7320137023925781,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7297006845474243,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7214385271072388,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 232,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6638245731592178
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7335433959960938,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7325667142868042,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7190445065498352,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.6992213129997253,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6974859833717346,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.6896606683731079,
            "answer": "legion",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7335433661937714
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.836392879486084,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7453101277351379,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7415438890457153,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7253507375717163,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.7247684001922607,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.7133275270462036,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6814276874065399
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7529887557029724,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7020256519317627,
            "answer": "detainees",
            "hit": false
          },
          {
            "score": 0.7005535364151001,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.6990117430686951,
            "answer": "dod",
            "hit": false
          },
          {
            "score": 0.6985068321228027,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.6968576908111572,
            "answer": "pentagon",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 217,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6620489656925201
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.765180766582489,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7552825212478638,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7377822399139404,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7298657894134521,
            "answer": "fins",
            "hit": false
          },
          {
            "score": 0.7272540330886841,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.727115273475647,
            "answer": "swimming",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7127612233161926
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7685419321060181,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7430387139320374,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7040654420852661,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6973702907562256,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6917448043823242,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.6915124654769897,
            "answer": "tornado",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7430387288331985
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7864781618118286,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7550463676452637,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7081000804901123,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7025302052497864,
            "answer": "sperm",
            "hit": false
          },
          {
            "score": 0.6995201110839844,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6994161605834961,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7081000506877899
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 11,
      "accuracy": 0.18181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7c42fc7b-124a-4045-b32b-874feb238c2d",
      "timestamp": "2025-05-17T20:32:08.438798"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7513602375984192,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.7313287854194641,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.7281298041343689,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.7177027463912964,
            "answer": "bloom",
            "hit": false
          },
          {
            "score": 0.7103667855262756,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6943971514701843,
            "answer": "bird",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7513602375984192
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7442635893821716,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.730150580406189,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.72649085521698,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7213825583457947,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7213695049285889,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.7031985521316528,
            "answer": "buzz",
            "hit": true
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7031985521316528
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.769996702671051,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.6820999383926392,
            "answer": "raid",
            "hit": false
          },
          {
            "score": 0.680915117263794,
            "answer": "dod",
            "hit": false
          },
          {
            "score": 0.680067777633667,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.679821789264679,
            "answer": "seo",
            "hit": false
          },
          {
            "score": 0.6785672903060913,
            "answer": "nsa",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 11106,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5915389955043793
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7987655401229858,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7670725584030151,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7218151688575745,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6875066161155701,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6837952733039856,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.6766877174377441,
            "answer": "sharks",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 14098,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5579362511634827
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 4,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f9c4bd52-7b6f-496d-be0f-ecdd6b822b82",
      "timestamp": "2025-05-17T20:32:08.474713"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8362406492233276,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.738497793674469,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7022260427474976,
            "answer": "pagan",
            "hit": false
          },
          {
            "score": 0.7018691301345825,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7002843618392944,
            "answer": "extinct",
            "hit": false
          },
          {
            "score": 0.7001920938491821,
            "answer": "monkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6667780578136444
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7636358141899109,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.7612088322639465,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6893335580825806,
            "answer": "batting",
            "hit": false
          },
          {
            "score": 0.6851261258125305,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.6797841191291809,
            "answer": "glove",
            "hit": false
          },
          {
            "score": 0.678458571434021,
            "answer": "baths",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 693,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6226320117712021
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7286965847015381,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6967335343360901,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.695852518081665,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.6952166557312012,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6816984415054321,
            "answer": "carry",
            "hit": false
          },
          {
            "score": 0.6799573302268982,
            "answer": "suffer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6615144312381744
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.8471716642379761,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8067656755447388,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7769750356674194,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7700762748718262,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7606785297393799,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.7462894320487976,
            "answer": "agricultural",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 1892,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6422460824251175
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7566364407539368,
            "answer": "tennis",
            "hit": false
          },
          {
            "score": 0.7502501010894775,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.7496916055679321,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7463332414627075,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7407658100128174,
            "answer": "soccer",
            "hit": false
          },
          {
            "score": 0.7387819290161133,
            "answer": "rugby",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7496916055679321
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7566565275192261,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6942788362503052,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6882283091545105,
            "answer": "boyd",
            "hit": false
          },
          {
            "score": 0.6868088245391846,
            "answer": "brook",
            "hit": false
          },
          {
            "score": 0.683115541934967,
            "answer": "grove",
            "hit": false
          },
          {
            "score": 0.6828055381774902,
            "answer": "swan",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7566565275192261
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7805066704750061,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7210050821304321,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.6984937787055969,
            "answer": "goose",
            "hit": false
          },
          {
            "score": 0.6941213607788086,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6889907717704773,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6758543848991394,
            "answer": "eugene",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6618905067443848
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7479578256607056,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7323766946792603,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.729810357093811,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7216222882270813,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7059860825538635,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7023220658302307,
            "answer": "flights",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7479578256607056
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7499920725822449,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7443150281906128,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.7122975587844849,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.709203839302063,
            "answer": "netflix",
            "hit": false
          },
          {
            "score": 0.6914421916007996,
            "answer": "reuters",
            "hit": false
          },
          {
            "score": 0.6910863518714905,
            "answer": "abc",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6893817037343979
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.796286940574646,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7830832600593567,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7110252380371094,
            "answer": "larvae",
            "hit": false
          },
          {
            "score": 0.7094294428825378,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7042117714881897,
            "answer": "seeds",
            "hit": false
          },
          {
            "score": 0.703447699546814,
            "answer": "gardening",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7830833196640015
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7393146753311157,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7034947276115417,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6749120950698853,
            "answer": "traitor",
            "hit": false
          },
          {
            "score": 0.6745785474777222,
            "answer": "spies",
            "hit": false
          },
          {
            "score": 0.67359459400177,
            "answer": "rift",
            "hit": false
          },
          {
            "score": 0.6729059815406799,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6362418979406357
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8435813188552856,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7567640542984009,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7122425436973572,
            "answer": "monastery",
            "hit": false
          },
          {
            "score": 0.7048448324203491,
            "answer": "monks",
            "hit": false
          },
          {
            "score": 0.703740119934082,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.7034810781478882,
            "answer": "mon",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 54,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6709967851638794
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7421939969062805,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.726000189781189,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7057754993438721,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6964661478996277,
            "answer": "switch",
            "hit": false
          },
          {
            "score": 0.6963088512420654,
            "answer": "menu",
            "hit": false
          },
          {
            "score": 0.6907463073730469,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7421940267086029
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7338635921478271,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7076268792152405,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6881097555160522,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.6748456358909607,
            "answer": "ratio",
            "hit": false
          },
          {
            "score": 0.6731096506118774,
            "answer": "benedict",
            "hit": false
          },
          {
            "score": 0.6686071157455444,
            "answer": "barn",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7338636219501495
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7591501474380493,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7425247430801392,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.6899836659431458,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6852934956550598,
            "answer": "evan",
            "hit": false
          },
          {
            "score": 0.6852402091026306,
            "answer": "roman",
            "hit": false
          },
          {
            "score": 0.6827155947685242,
            "answer": "marion",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7591501474380493
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7696073055267334,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7630069255828857,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6879934072494507,
            "answer": "tornado",
            "hit": false
          },
          {
            "score": 0.6862936019897461,
            "answer": "auburn",
            "hit": false
          },
          {
            "score": 0.6808205246925354,
            "answer": "dong",
            "hit": false
          },
          {
            "score": 0.6805585622787476,
            "answer": "panthers",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 156,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6496697962284088
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.7758928537368774,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7574435472488403,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6982914805412292,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.6870743632316589,
            "answer": "glen",
            "hit": false
          },
          {
            "score": 0.6866209506988525,
            "answer": "fish",
            "hit": false
          },
          {
            "score": 0.6863678693771362,
            "answer": "pond",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 130,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6599473357200623
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8470765948295593,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7788653373718262,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7077745199203491,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7028074860572815,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7009339332580566,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6983839273452759,
            "answer": "wilderness",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6861225664615631
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 18,
      "accuracy": 0.3888888888888889
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ab599464-c897-4582-9b60-68ab0f1190d2",
      "timestamp": "2025-05-17T20:32:08.497943"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7841747403144836,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.731651246547699,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7301680445671082,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7071422338485718,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6939865350723267,
            "answer": "anton",
            "hit": false
          },
          {
            "score": 0.6790481805801392,
            "answer": "anti",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7841747403144836
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7831581830978394,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7289097905158997,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7169967889785767,
            "answer": "orange",
            "hit": true
          },
          {
            "score": 0.7035500407218933,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.7007163166999817,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6991298794746399,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.682685911655426
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7973562479019165,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7695292234420776,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7154430747032166,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7100831866264343,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7068048119544983,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.697446346282959,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6974463313817978
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7650797367095947,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7614905834197998,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7455976009368896,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7407974600791931,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7382388114929199,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.7329978346824646,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7407974451780319
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7478184700012207,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.747504711151123,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7405081987380981,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7309219241142273,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7297018766403198,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7269802093505859,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7096972465515137
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7607747912406921,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.760361909866333,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7518619298934937,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7482221126556396,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7143091559410095,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7113806009292603,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7518619298934937
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7862322330474854,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7702992558479309,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7596035003662109,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7427667379379272,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7409922480583191,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.73958420753479,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7596035003662109
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7641128301620483,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7525990605354309,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7338767647743225,
            "answer": "grey",
            "hit": true
          },
          {
            "score": 0.710289716720581,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.70611971616745,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.703088641166687,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7641128301620483
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7686300277709961,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7574124336242676,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7376224994659424,
            "answer": "fossil",
            "hit": false
          },
          {
            "score": 0.7274742722511292,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7202304601669312,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7200753688812256,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686300277709961
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7734981775283813,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7599923610687256,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.746994137763977,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7410833835601807,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7306538820266724,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7205560207366943,
            "answer": "chocolate",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7734981775283813
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.780847430229187,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.759757936000824,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7589468955993652,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7494001388549805,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7445968985557556,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7261760830879211,
            "answer": "creamy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7589468955993652
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7843422889709473,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7583770751953125,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7309802770614624,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7204539179801941,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7057530879974365,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7022695541381836,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7843422293663025
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8661922216415405,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7462460994720459,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7415559887886047,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7311424016952515,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7281628847122192,
            "answer": "closet",
            "hit": false
          },
          {
            "score": 0.7272040843963623,
            "answer": "supermarket",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7462461739778519
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.7724413871765137,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7317551970481873,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.723531186580658,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7166706323623657,
            "answer": "grey",
            "hit": true
          },
          {
            "score": 0.7159990072250366,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7057465314865112,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.723531186580658
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.763384222984314,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7594790458679199,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7502515912055969,
            "answer": "berries",
            "hit": false
          },
          {
            "score": 0.7479149699211121,
            "answer": "wine",
            "hit": false
          },
          {
            "score": 0.7369273900985718,
            "answer": "blacks",
            "hit": false
          },
          {
            "score": 0.7361151576042175,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7285217940807343
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7709689140319824,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7633250951766968,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7272389531135559,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7264548540115356,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7240960001945496,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7126280069351196,
            "answer": "lawn",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7272389382123947
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7605012655258179,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7549630403518677,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7440100312232971,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.7275269031524658,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7242523431777954,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.7207325100898743,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7030177712440491
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7626886367797852,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7602554559707642,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.758392333984375,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7389375567436218,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7224109172821045,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7130641937255859,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.758392333984375
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.7613882422447205,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7244576215744019,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7052720189094543,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7037762403488159,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7006909847259521,
            "answer": "newspapers",
            "hit": false
          },
          {
            "score": 0.6968773007392883,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7244576215744019
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7651042938232422,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7501236200332642,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7459272146224976,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7362717986106873,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7253274321556091,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.724285900592804,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7651042938232422
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7572737336158752,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7565113306045532,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.752489447593689,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.745037317276001,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7346088886260986,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7280070781707764,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6911148875951767
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7860087156295776,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7479560375213623,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.7440708875656128,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.729020893573761,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7166817784309387,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6940062046051025,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7860087156295776
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7860745787620544,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7744950652122498,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7702088356018066,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7519821524620056,
            "answer": "pink",
            "hit": true
          },
          {
            "score": 0.7487069368362427,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7454770803451538,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7454770654439926
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7881815433502197,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7564581632614136,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7444554567337036,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7308071255683899,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7276461124420166,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7177899479866028,
            "answer": "yang",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7564581036567688
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7691537737846375,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.762787938117981,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7529392838478088,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7452961206436157,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7398818731307983,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7347607016563416,
            "answer": "utah",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7691538333892822
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7680673599243164,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7543745040893555,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7388379573822021,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7301579713821411,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.7270256876945496,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7220984697341919,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7301580309867859
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7749607563018799,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7504889965057373,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.7442694902420044,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7266165018081665,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7035271525382996,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6948571801185608,
            "answer": "shadow",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7504889965057373
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7759066820144653,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.765474796295166,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7446648478507996,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7265129685401917,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7175172567367554,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.7145158648490906,
            "answer": "gray",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7654748260974884
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.8043652772903442,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7685505151748657,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7418839931488037,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7179533839225769,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7077940702438354,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.706748902797699,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7418839633464813
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7786746025085449,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7586818933486938,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7511842250823975,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7404288649559021,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7147602438926697,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7113186120986938,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7586819231510162
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7642639875411987,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7386332154273987,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.720291256904602,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7188181281089783,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7110793590545654,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7006620168685913,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.711079329252243
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7633270025253296,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7479783296585083,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7210493087768555,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7190597057342529,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7134019732475281,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7096969485282898,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7479782998561859
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7698356509208679,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7643554210662842,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7349112629890442,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7234984040260315,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7082703113555908,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7064031362533569,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7643554508686066
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.8404956459999084,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7692636251449585,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.765701949596405,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7450379133224487,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7423465251922607,
            "answer": "vegetable",
            "hit": false
          },
          {
            "score": 0.7397500276565552,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7450378835201263
      }
    ],
    "result": {
      "cnt_questions_correct": 12,
      "cnt_questions_total": 34,
      "accuracy": 0.35294117647058826
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "90f47856-2ffe-4de2-8653-6b10f63aaf38",
      "timestamp": "2025-05-17T20:32:08.560319"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.9262996912002563,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.87775719165802,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.8101860284805298,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7948418855667114,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7925357818603516,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.7886072397232056,
            "answer": "filmmaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.926299661397934
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.8146708607673645,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.8084951639175415,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.7773634791374207,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7759454250335693,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.7602812051773071,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7553731799125671,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8146708905696869
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.7936102151870728,
            "answer": "sisters",
            "hit": false
          },
          {
            "score": 0.7878404259681702,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7814278602600098,
            "answer": "sister",
            "hit": true
          },
          {
            "score": 0.7799837589263916,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7672674655914307,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7519949674606323,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7814278602600098
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.756035566329956,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.7099675536155701,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6949316263198853,
            "answer": "peggy",
            "hit": false
          },
          {
            "score": 0.6938672661781311,
            "answer": "becca",
            "hit": false
          },
          {
            "score": 0.6901282072067261,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6901075839996338,
            "answer": "annie",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 1073,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6396017372608185
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.7495207786560059,
            "answer": "bullying",
            "hit": false
          },
          {
            "score": 0.7156327962875366,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7130480408668518,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.7054352760314941,
            "answer": "bully",
            "hit": false
          },
          {
            "score": 0.7018663883209229,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.6994249820709229,
            "answer": "bitch",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6811571419239044
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.8934165239334106,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.8525809049606323,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8233659863471985,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8110888004302979,
            "answer": "mum",
            "hit": true
          },
          {
            "score": 0.8038668036460876,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.7887364625930786,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8934164941310883
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7933749556541443,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.7335258722305298,
            "answer": "durham",
            "hit": false
          },
          {
            "score": 0.7290886044502258,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.7255449295043945,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.7255337238311768,
            "answer": "virginia",
            "hit": false
          },
          {
            "score": 0.7246986031532288,
            "answer": "diana",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7933749556541443
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.8665907979011536,
            "answer": "dad",
            "hit": false
          },
          {
            "score": 0.8408949375152588,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.830856442451477,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8307251334190369,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.830108106136322,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8257736563682556,
            "answer": "mom",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7730260491371155
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7816506624221802,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7791391015052795,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7669826149940491,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.7560523748397827,
            "answer": "prayed",
            "hit": false
          },
          {
            "score": 0.7523332834243774,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.7515385746955872,
            "answer": "jesus",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7669826745986938
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.9042749404907227,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.865140438079834,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.8047066926956177,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7999507784843445,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7888249158859253,
            "answer": "grandchildren",
            "hit": false
          },
          {
            "score": 0.7840036153793335,
            "answer": "mothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9042749106884003
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.7426416873931885,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7323161363601685,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7276421785354614,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7242578268051147,
            "answer": "wedding",
            "hit": false
          },
          {
            "score": 0.7164313793182373,
            "answer": "dresses",
            "hit": false
          },
          {
            "score": 0.7160957455635071,
            "answer": "marrying",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7426417171955109
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8541491031646729,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8395130038261414,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.823503851890564,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.8182555437088013,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7965836524963379,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7790781259536743,
            "answer": "lover",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8395130038261414
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7964097261428833,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.7643839716911316,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.7606735229492188,
            "answer": "kingdom",
            "hit": false
          },
          {
            "score": 0.7568819522857666,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.7480852603912354,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.7385263442993164,
            "answer": "monarch",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7964097261428833
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.7923401594161987,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.7359837889671326,
            "answer": "women",
            "hit": false
          },
          {
            "score": 0.7298036217689514,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7291710376739502,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.728905200958252,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.7232397198677063,
            "answer": "manning",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7923401892185211
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9070010185241699,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8429151773452759,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8344459533691406,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8243330121040344,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.8099483251571655,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7837797999382019,
            "answer": "grandmother",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9070010781288147
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8603894710540771,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7992470860481262,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.7762156128883362,
            "answer": "royal",
            "hit": false
          },
          {
            "score": 0.7749242782592773,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.7634966373443604,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.7586009502410889,
            "answer": "emperor",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.799247145652771
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.7020570039749146,
            "answer": "her",
            "hit": false
          },
          {
            "score": 0.7009158134460449,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6975761651992798,
            "answer": "set",
            "hit": false
          },
          {
            "score": 0.6960007548332214,
            "answer": "mrs",
            "hit": false
          },
          {
            "score": 0.6959890723228455,
            "answer": "person",
            "hit": false
          },
          {
            "score": 0.6952388286590576,
            "answer": "san",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.68507519364357
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8288810849189758,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8112661242485046,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7923458218574524,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7829865217208862,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7704805135726929,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7630343437194824,
            "answer": "mom",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 1565,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6553923785686493
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 18,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4ce91768-b797-4e82-941f-4472f45f132f",
      "timestamp": "2025-05-17T20:32:08.684955"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7429748177528381,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.7391327619552612,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.7311152219772339,
            "answer": "attitude",
            "hit": false
          },
          {
            "score": 0.727246105670929,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.7270655632019043,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.7209335565567017,
            "answer": "gases",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6635011434555054
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7928113341331482,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.7106093168258667,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.7068628072738647,
            "answer": "leather",
            "hit": true
          },
          {
            "score": 0.703971266746521,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.7015163898468018,
            "answer": "belt",
            "hit": false
          },
          {
            "score": 0.6999722719192505,
            "answer": "backpack",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7068628370761871
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7242546081542969,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.7135201096534729,
            "answer": "burns",
            "hit": false
          },
          {
            "score": 0.7104518413543701,
            "answer": "facial",
            "hit": false
          },
          {
            "score": 0.7085093259811401,
            "answer": "scars",
            "hit": false
          },
          {
            "score": 0.7041054964065552,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7040309906005859,
            "answer": "hairs",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7242546379566193
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.7549468278884888,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.6990200281143188,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.6957852244377136,
            "answer": "limbs",
            "hit": false
          },
          {
            "score": 0.6865967512130737,
            "answer": "tissues",
            "hit": false
          },
          {
            "score": 0.6862131953239441,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6820259690284729,
            "answer": "bodily",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.642999142408371
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7979335784912109,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7745102047920227,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7538548707962036,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7348548173904419,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.733028769493103,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.7304056882858276,
            "answer": "boot",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7222121208906174
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.9045090675354004,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7629708051681519,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7591090202331543,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7582166194915771,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7578966617584229,
            "answer": "cans",
            "hit": false
          },
          {
            "score": 0.7549188733100891,
            "answer": "alcohol",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7066555619239807
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8861984014511108,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7526251077651978,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7223532199859619,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.708397388458252,
            "answer": "cricket",
            "hit": false
          },
          {
            "score": 0.7071309089660645,
            "answer": "pitchers",
            "hit": false
          },
          {
            "score": 0.7069277763366699,
            "answer": "pot",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6608844846487045
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.760312557220459,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7577226161956787,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7523618936538696,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.749740719795227,
            "answer": "cock",
            "hit": false
          },
          {
            "score": 0.7467013001441956,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7392181158065796,
            "answer": "champagne",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7132207751274109
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.72091144323349,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.7195041179656982,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.718887209892273,
            "answer": "laptop",
            "hit": false
          },
          {
            "score": 0.7184689044952393,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.7139941453933716,
            "answer": "couch",
            "hit": false
          },
          {
            "score": 0.7117877006530762,
            "answer": "cabinets",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 174,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6712488830089569
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7853868007659912,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7454304695129395,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.7190444469451904,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.7180169820785522,
            "answer": "copper",
            "hit": false
          },
          {
            "score": 0.7168415188789368,
            "answer": "crystal",
            "hit": false
          },
          {
            "score": 0.7145583629608154,
            "answer": "aluminum",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 2924,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6273112148046494
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.7476949691772461,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.7068937420845032,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.7037460803985596,
            "answer": "gay",
            "hit": false
          },
          {
            "score": 0.7019610404968262,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7007356882095337,
            "answer": "hat",
            "hit": false
          },
          {
            "score": 0.699465274810791,
            "answer": "police",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 4698,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6410123854875565
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8599135875701904,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6955139636993408,
            "answer": "farm",
            "hit": false
          },
          {
            "score": 0.6933947801589966,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.687602698802948,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.6861734986305237,
            "answer": "yard",
            "hit": false
          },
          {
            "score": 0.6832185387611389,
            "answer": "buildings",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6389230340719223
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7005231380462646,
            "answer": "jazz",
            "hit": false
          },
          {
            "score": 0.6961612701416016,
            "answer": "jelly",
            "hit": false
          },
          {
            "score": 0.6861346960067749,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.685023844242096,
            "answer": "jihad",
            "hit": false
          },
          {
            "score": 0.6847832798957825,
            "answer": "jem",
            "hit": false
          },
          {
            "score": 0.6836177110671997,
            "answer": "ham",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 486,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6245959550142288
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7858659625053406,
            "answer": "grass",
            "hit": true
          },
          {
            "score": 0.766086995601654,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7614851593971252,
            "answer": "gardens",
            "hit": false
          },
          {
            "score": 0.7579631805419922,
            "answer": "porch",
            "hit": false
          },
          {
            "score": 0.7543048858642578,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7521114349365234,
            "answer": "gardening",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7858659327030182
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7904068827629089,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.7174603939056396,
            "answer": "camera",
            "hit": false
          },
          {
            "score": 0.7101320028305054,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7093325853347778,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.7089436650276184,
            "answer": "glasses",
            "hit": false
          },
          {
            "score": 0.70551598072052,
            "answer": "bulbs",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7043016254901886
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.7648571133613586,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7364505529403687,
            "answer": "mir",
            "hit": false
          },
          {
            "score": 0.7263848781585693,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.7191131114959717,
            "answer": "shadow",
            "hit": false
          },
          {
            "score": 0.709854006767273,
            "answer": "telegraph",
            "hit": false
          },
          {
            "score": 0.7089625597000122,
            "answer": "herald",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6732057332992554
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7591312527656555,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.7504544258117676,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.7422623634338379,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7401304841041565,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7376866340637207,
            "answer": "wealth",
            "hit": false
          },
          {
            "score": 0.7359386682510376,
            "answer": "dollars",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6319911181926727
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7589877843856812,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7356038093566895,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7321224808692932,
            "answer": "atlantic",
            "hit": false
          },
          {
            "score": 0.7317293286323547,
            "answer": "water",
            "hit": true
          },
          {
            "score": 0.7266280651092529,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.7238075137138367,
            "answer": "aquatic",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7317293584346771
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.7868351936340332,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.7748960256576538,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7736219167709351,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.7673897743225098,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.7596985101699829,
            "answer": "chefs",
            "hit": false
          },
          {
            "score": 0.7588835954666138,
            "answer": "cakes",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7319630682468414
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.744813859462738,
            "answer": "jenny",
            "hit": false
          },
          {
            "score": 0.7179811000823975,
            "answer": "shirley",
            "hit": false
          },
          {
            "score": 0.714069128036499,
            "answer": "erin",
            "hit": false
          },
          {
            "score": 0.7139555811882019,
            "answer": "rebecca",
            "hit": false
          },
          {
            "score": 0.7089508771896362,
            "answer": "molly",
            "hit": false
          },
          {
            "score": 0.7083405256271362,
            "answer": "stephanie",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6771618276834488
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7591628432273865,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7299139499664307,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.726791501045227,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.6955817937850952,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6952663064002991,
            "answer": "walls",
            "hit": false
          },
          {
            "score": 0.6922304630279541,
            "answer": "pillar",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 367,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6510334610939026
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.8378695249557495,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7725479602813721,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7608538269996643,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7605705857276917,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.7565394639968872,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.7553740739822388,
            "answer": "rubber",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.740462139248848
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8098554611206055,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.773221492767334,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7465127110481262,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7443441152572632,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.740929126739502,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.7351787090301514,
            "answer": "aquatic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7210859060287476
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7614485025405884,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.7231305241584778,
            "answer": "scoop",
            "hit": false
          },
          {
            "score": 0.7219253778457642,
            "answer": "plaster",
            "hit": false
          },
          {
            "score": 0.7190723419189453,
            "answer": "knife",
            "hit": false
          },
          {
            "score": 0.7168525457382202,
            "answer": "chewing",
            "hit": false
          },
          {
            "score": 0.7141247987747192,
            "answer": "vegetables",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 203,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6822999566793442
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8752321004867554,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6966238617897034,
            "answer": "graph",
            "hit": false
          },
          {
            "score": 0.6961299777030945,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.6960358023643494,
            "answer": "sheet",
            "hit": false
          },
          {
            "score": 0.6902362108230591,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6886929869651794,
            "answer": "charts",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 135,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6489978581666946
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7190523743629456,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.6963021755218506,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6886559128761292,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.6870217323303223,
            "answer": "wool",
            "hit": false
          },
          {
            "score": 0.6864780783653259,
            "answer": "metallic",
            "hit": false
          },
          {
            "score": 0.6846036314964294,
            "answer": "glared",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 1173,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6442431807518005
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.8786255121231079,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.8029546737670898,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7886184453964233,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.7867774367332458,
            "answer": "grapes",
            "hit": true
          },
          {
            "score": 0.7846836447715759,
            "answer": "alcohol",
            "hit": false
          },
          {
            "score": 0.7783949375152588,
            "answer": "champagne",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7867774367332458
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.8535485863685608,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.7788856029510498,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.7437554001808167,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.7221037745475769,
            "answer": "cables",
            "hit": false
          },
          {
            "score": 0.7124972343444824,
            "answer": "copper",
            "hit": false
          },
          {
            "score": 0.7066022753715515,
            "answer": "nylon",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6766272187232971
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 28,
      "accuracy": 0.07142857142857142
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "886f906b-b355-4056-b7ea-d5f6b70329cd",
      "timestamp": "2025-05-17T20:32:08.746950"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7819831371307373,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.7373257875442505,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.7371242642402649,
            "answer": "wild",
            "hit": false
          },
          {
            "score": 0.72544264793396,
            "answer": "hawks",
            "hit": false
          },
          {
            "score": 0.7249727845191956,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.7249593734741211,
            "answer": "bee",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7249727547168732
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8668934106826782,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7914003729820251,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.756324827671051,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.7481175661087036,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7350509166717529,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7336428761482239,
            "answer": "herds",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7158070206642151
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.8221602439880371,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.797641396522522,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7600122690200806,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7590386271476746,
            "answer": "sedan",
            "hit": false
          },
          {
            "score": 0.7577158808708191,
            "answer": "suv",
            "hit": false
          },
          {
            "score": 0.7567971348762512,
            "answer": "cars",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 154,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6480427235364914
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8784652948379517,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8384886384010315,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.798274040222168,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.783262312412262,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7768415808677673,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7706762552261353,
            "answer": "herd",
            "hit": true
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7706762552261353
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.8565226793289185,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.828981876373291,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.8124175071716309,
            "answer": "religious",
            "hit": false
          },
          {
            "score": 0.8026807308197021,
            "answer": "evangelical",
            "hit": false
          },
          {
            "score": 0.7819192409515381,
            "answer": "baptist",
            "hit": false
          },
          {
            "score": 0.7813632488250732,
            "answer": "theological",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7048474848270416
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.772956371307373,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7527187466621399,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.746955394744873,
            "answer": "graduating",
            "hit": false
          },
          {
            "score": 0.7442469000816345,
            "answer": "graduation",
            "hit": false
          },
          {
            "score": 0.7441718578338623,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.740026593208313,
            "answer": "undergraduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7262344658374786
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.8632872104644775,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7894949913024902,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7777615189552307,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7757659554481506,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7687122821807861,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7657413482666016,
            "answer": "province",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7076993882656097
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7807193398475647,
            "answer": "cowboys",
            "hit": false
          },
          {
            "score": 0.7541276812553406,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7436269521713257,
            "answer": "dallas",
            "hit": false
          },
          {
            "score": 0.7408065795898438,
            "answer": "stew",
            "hit": false
          },
          {
            "score": 0.7318435311317444,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7264181971549988,
            "answer": "chicken",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7086564004421234
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7073547840118408,
            "answer": "claw",
            "hit": false
          },
          {
            "score": 0.6971625089645386,
            "answer": "hawks",
            "hit": false
          },
          {
            "score": 0.6960472464561462,
            "answer": "swan",
            "hit": false
          },
          {
            "score": 0.6946088075637817,
            "answer": "cobb",
            "hit": false
          },
          {
            "score": 0.6931557059288025,
            "answer": "cousins",
            "hit": false
          },
          {
            "score": 0.6927288174629211,
            "answer": "bow",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 8302,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6153244748711586
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.824419379234314,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7507670521736145,
            "answer": "circus",
            "hit": false
          },
          {
            "score": 0.728515088558197,
            "answer": "zoo",
            "hit": false
          },
          {
            "score": 0.7234078645706177,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.720564603805542,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7173627614974976,
            "answer": "eagles",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7075395286083221
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.9023455381393433,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.8132642507553101,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.8035078644752502,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7875844836235046,
            "answer": "workers",
            "hit": false
          },
          {
            "score": 0.7840075492858887,
            "answer": "workforce",
            "hit": false
          },
          {
            "score": 0.7768822312355042,
            "answer": "workplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.715744286775589
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.7461950778961182,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7377355098724365,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.7370879650115967,
            "answer": "trout",
            "hit": false
          },
          {
            "score": 0.7258952856063843,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7222610116004944,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.7204418182373047,
            "answer": "seafood",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 1998,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6335611939430237
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8536440134048462,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.7941698431968689,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.781650960445404,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.7666037082672119,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.7641861438751221,
            "answer": "universe",
            "hit": true
          },
          {
            "score": 0.7533175945281982,
            "answer": "planets",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7641861438751221
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.7803373336791992,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7345422506332397,
            "answer": "let",
            "hit": false
          },
          {
            "score": 0.7230764627456665,
            "answer": "paragraph",
            "hit": false
          },
          {
            "score": 0.7145742177963257,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7129113674163818,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.7100759744644165,
            "answer": "email",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6858910620212555
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.774752140045166,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.719077467918396,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7123308181762695,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7113519906997681,
            "answer": "legion",
            "hit": false
          },
          {
            "score": 0.7025495767593384,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.6991236209869385,
            "answer": "zoo",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6810345649719238
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8922678232192993,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7911308407783508,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.7841044664382935,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7820616364479065,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7565613985061646,
            "answer": "viewers",
            "hit": false
          },
          {
            "score": 0.746414065361023,
            "answer": "audience",
            "hit": true
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7464141249656677
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.8099218010902405,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7525992393493652,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7237141728401184,
            "answer": "groups",
            "hit": false
          },
          {
            "score": 0.7142778635025024,
            "answer": "congregation",
            "hit": false
          },
          {
            "score": 0.7129290699958801,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7128901481628418,
            "answer": "founder",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 49,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6848442107439041
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8955317139625549,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8568287491798401,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.8380877375602722,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.832149863243103,
            "answer": "rapper",
            "hit": false
          },
          {
            "score": 0.8268251419067383,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.8120487928390503,
            "answer": "comedian",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7495325654745102
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7544001936912537,
            "answer": "personal",
            "hit": false
          },
          {
            "score": 0.7359399795532227,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7354720830917358,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.7317793965339661,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7310677766799927,
            "answer": "individual",
            "hit": false
          },
          {
            "score": 0.7306607961654663,
            "answer": "public",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 5821,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6413552165031433
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.7593715190887451,
            "answer": "courtesy",
            "hit": false
          },
          {
            "score": 0.7509867548942566,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.7409107685089111,
            "answer": "image",
            "hit": false
          },
          {
            "score": 0.7393918037414551,
            "answer": "photography",
            "hit": false
          },
          {
            "score": 0.7391336560249329,
            "answer": "photographed",
            "hit": false
          },
          {
            "score": 0.7351689338684082,
            "answer": "photographs",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 231,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6760018467903137
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.7812641859054565,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7499552965164185,
            "answer": "rookie",
            "hit": false
          },
          {
            "score": 0.7458333969116211,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7319862842559814,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.7278509736061096,
            "answer": "team",
            "hit": true
          },
          {
            "score": 0.726452112197876,
            "answer": "coach",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7278509736061096
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8251813650131226,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.8092950582504272,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7783766388893127,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7748826146125793,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.7542542219161987,
            "answer": "patrol",
            "hit": false
          },
          {
            "score": 0.7517409324645996,
            "answer": "magistrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8251813650131226
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7802855968475342,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7684943675994873,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7674117684364319,
            "answer": "democratic",
            "hit": false
          },
          {
            "score": 0.7671024799346924,
            "answer": "chair",
            "hit": false
          },
          {
            "score": 0.764890730381012,
            "answer": "clinton",
            "hit": false
          },
          {
            "score": 0.7592470645904541,
            "answer": "republican",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 218,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7050095051527023
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8534557819366455,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8149730563163757,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.8079350590705872,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.8071756958961487,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.7965706586837769,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.775854229927063,
            "answer": "politician",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8079350590705872
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7499973773956299,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7411890029907227,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.735856831073761,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7332113981246948,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7264441847801208,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.726114809513092,
            "answer": "cattle",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7264442145824432
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8989542722702026,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.8023080229759216,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7861523628234863,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.7785766124725342,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.7687526941299438,
            "answer": "colonel",
            "hit": false
          },
          {
            "score": 0.7638944387435913,
            "answer": "military",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7861523032188416
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.8272520303726196,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.7998377680778503,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7924520969390869,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7919625043869019,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7899564504623413,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7733275890350342,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6867146790027618
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7541042566299438,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7286660075187683,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.7278873324394226,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7235006093978882,
            "answer": "legislature",
            "hit": false
          },
          {
            "score": 0.7206411361694336,
            "answer": "system",
            "hit": false
          },
          {
            "score": 0.7185932397842407,
            "answer": "general",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 373,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6510519683361053
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8547856211662292,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7780802845954895,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.7752723693847656,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7745139598846436,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7743241786956787,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7705181837081909,
            "answer": "school",
            "hit": true
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6723109185695648
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.7779226303100586,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7012941241264343,
            "answer": "nature",
            "hit": false
          },
          {
            "score": 0.6991657018661499,
            "answer": "canopy",
            "hit": false
          },
          {
            "score": 0.6960848569869995,
            "answer": "forest",
            "hit": true
          },
          {
            "score": 0.6955785751342773,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.6950752139091492,
            "answer": "forests",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6960848271846771
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.8854551911354065,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7506909966468811,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.7364715933799744,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.7318556904792786,
            "answer": "wild",
            "hit": false
          },
          {
            "score": 0.7305331230163574,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7297307252883911,
            "answer": "canine",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 1594,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6492812037467957
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7219411730766296,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7058323621749878,
            "answer": "message",
            "hit": false
          },
          {
            "score": 0.7036689519882202,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.7027358412742615,
            "answer": "sentence",
            "hit": true
          },
          {
            "score": 0.6984791159629822,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.698208749294281,
            "answer": "terminology",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.619136281311512
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3ef6e160-d653-41a0-99fb-65b06ca7b7c0",
      "timestamp": "2025-05-17T20:32:08.852272"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.7083607912063599,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6936445236206055,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.6871417760848999,
            "answer": "important",
            "hit": false
          },
          {
            "score": 0.6798117160797119,
            "answer": "council",
            "hit": false
          },
          {
            "score": 0.6779507994651794,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.6776249408721924,
            "answer": "path",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6171634942293167
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.731646716594696,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.7273018956184387,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.7208855152130127,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6971855759620667,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6941602230072021,
            "answer": "bits",
            "hit": false
          },
          {
            "score": 0.6909059882164001,
            "answer": "encoded",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6665394306182861
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.6820399761199951,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6756865978240967,
            "answer": "battling",
            "hit": false
          },
          {
            "score": 0.672168493270874,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6686813831329346,
            "answer": "gathered",
            "hit": false
          },
          {
            "score": 0.6654263734817505,
            "answer": "clashes",
            "hit": false
          },
          {
            "score": 0.6623927354812622,
            "answer": "confront",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 1595,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6123107522726059
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.7756789922714233,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7199633121490479,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.7134808301925659,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7055926322937012,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.7043559551239014,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.7007092833518982,
            "answer": "penny",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 1050,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6344622820615768
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "aeafed75-af2f-4643-adbc-d0b6657e2b16",
      "timestamp": "2025-05-17T20:32:08.975142"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.8373717069625854,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8226810097694397,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.8073171377182007,
            "answer": "intrigued",
            "hit": false
          },
          {
            "score": 0.8000988960266113,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.7959868907928467,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.7860226631164551,
            "answer": "anxious",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7768892049789429
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8506306409835815,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.688284158706665,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.6870989799499512,
            "answer": "horse",
            "hit": false
          },
          {
            "score": 0.6810084581375122,
            "answer": "masters",
            "hit": false
          },
          {
            "score": 0.6809356212615967,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6792169809341431,
            "answer": "farm",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6610819548368454
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7682089805603027,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7623234987258911,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7590847611427307,
            "answer": "reservoir",
            "hit": false
          },
          {
            "score": 0.7555425763130188,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.7438780665397644,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.7418094873428345,
            "answer": "canoe",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.714989572763443
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.7474414110183716,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.7464076280593872,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.732438862323761,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7203062176704407,
            "answer": "nausea",
            "hit": false
          },
          {
            "score": 0.7185977697372437,
            "answer": "surgery",
            "hit": false
          },
          {
            "score": 0.7123007774353027,
            "answer": "discomfort",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7024140655994415
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.7034165263175964,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.7028343677520752,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.6948080062866211,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.6943774819374084,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.694144070148468,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.6931902766227722,
            "answer": "prince",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.694144070148468
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.8055616021156311,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7736989259719849,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7350751757621765,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7337325215339661,
            "answer": "mediterranean",
            "hit": false
          },
          {
            "score": 0.7277188897132874,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.7226966023445129,
            "answer": "navy",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7277189195156097
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8878681659698486,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.7833621501922607,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7720537185668945,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7616511583328247,
            "answer": "eaten",
            "hit": false
          },
          {
            "score": 0.7614062428474426,
            "answer": "chewing",
            "hit": false
          },
          {
            "score": 0.7607672214508057,
            "answer": "breakfast",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6623235046863556
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.8240780830383301,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8050525188446045,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.7965813279151917,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.7826118469238281,
            "answer": "frustrated",
            "hit": false
          },
          {
            "score": 0.7750684022903442,
            "answer": "annoyed",
            "hit": false
          },
          {
            "score": 0.7670904994010925,
            "answer": "fatigue",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7965813279151917
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 8,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "132eff1b-b952-4123-b1b0-1d04705763fb",
      "timestamp": "2025-05-17T20:32:08.989085"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.7930116057395935,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.7922917604446411,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.7858362197875977,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7811388969421387,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.7730128765106201,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.7498505115509033,
            "answer": "roadway",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7730128765106201
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7631890773773193,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.7628039121627808,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.7576550245285034,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.7544461488723755,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7521481513977051,
            "answer": "cotton",
            "hit": false
          },
          {
            "score": 0.7513660788536072,
            "answer": "towel",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6566492021083832
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8236997127532959,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7583512663841248,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7511268854141235,
            "answer": "euros",
            "hit": false
          },
          {
            "score": 0.7457070350646973,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7450101375579834,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.7422631978988647,
            "answer": "gallons",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 591,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6746270805597305
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.8854451179504395,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.8426373600959778,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8348506093025208,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8233867883682251,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.8055480122566223,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7920050621032715,
            "answer": "mom",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8854451179504395
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7777343988418579,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.7653288841247559,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7555280923843384,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7544388175010681,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.7379592061042786,
            "answer": "helpful",
            "hit": false
          },
          {
            "score": 0.7376147508621216,
            "answer": "improve",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6873594969511032
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.7876123189926147,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7715545892715454,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.7697058916091919,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.7695122957229614,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7561726570129395,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7552769780158997,
            "answer": "intellect",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7697059214115143
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8690038919448853,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7721459269523621,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7402094006538391,
            "answer": "necklace",
            "hit": false
          },
          {
            "score": 0.725142240524292,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7243221998214722,
            "answer": "treasure",
            "hit": false
          },
          {
            "score": 0.7240210771560669,
            "answer": "treasures",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7051656544208527
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.8166711330413818,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.7486375570297241,
            "answer": "cemetery",
            "hit": false
          },
          {
            "score": 0.7416595816612244,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7320195436477661,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.7270566821098328,
            "answer": "sculpture",
            "hit": false
          },
          {
            "score": 0.7254672050476074,
            "answer": "erected",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7416595816612244
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7535622119903564,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.7493396997451782,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.7119981050491333,
            "answer": "additional",
            "hit": false
          },
          {
            "score": 0.7075175046920776,
            "answer": "upcoming",
            "hit": false
          },
          {
            "score": 0.6997225284576416,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.6954617500305176,
            "answer": "former",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 402,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6201230138540268
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.8828147649765015,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.76314777135849,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7502200603485107,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.7409543991088867,
            "answer": "packet",
            "hit": true
          },
          {
            "score": 0.7245715856552124,
            "answer": "parcel",
            "hit": true
          },
          {
            "score": 0.7169117331504822,
            "answer": "shipment",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7245716154575348
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8065930604934692,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.7443252801895142,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.7408860921859741,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.7372976541519165,
            "answer": "transport",
            "hit": false
          },
          {
            "score": 0.7350178956985474,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7332188487052917,
            "answer": "maritime",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8065930604934692
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.8152318000793457,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.7630758881568909,
            "answer": "reasonable",
            "hit": true
          },
          {
            "score": 0.7378162741661072,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.736487865447998,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7327724695205688,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7307708263397217,
            "answer": "reasoning",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7237542122602463
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.811988353729248,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7922801971435547,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7735867500305176,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7706642150878906,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7611778974533081,
            "answer": "significant",
            "hit": false
          },
          {
            "score": 0.7609129548072815,
            "answer": "rational",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7589419186115265
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7428895831108093,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.7300470471382141,
            "answer": "jack",
            "hit": false
          },
          {
            "score": 0.7268345355987549,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7230261564254761,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.7215399742126465,
            "answer": "rocket",
            "hit": false
          },
          {
            "score": 0.7193173170089722,
            "answer": "way",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 2518,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6486110836267471
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.8698762059211731,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.7801275849342346,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.7637246251106262,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7633017301559448,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.762104868888855,
            "answer": "fireplace",
            "hit": false
          },
          {
            "score": 0.7545593976974487,
            "answer": "balcony",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8698762655258179
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.8432762622833252,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7708534002304077,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7533266544342041,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.738411545753479,
            "answer": "type",
            "hit": false
          },
          {
            "score": 0.7366896867752075,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.7193845510482788,
            "answer": "aesthetics",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7165147364139557
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2284e075-1572-41fa-ab00-b01479f8adaa",
      "timestamp": "2025-05-17T20:32:09.015722"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8310792446136475,
            "answer": "before",
            "hit": true
          },
          {
            "score": 0.7586332559585571,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7546232342720032,
            "answer": "every",
            "hit": false
          },
          {
            "score": 0.7544848322868347,
            "answer": "afterwards",
            "hit": false
          },
          {
            "score": 0.7473480701446533,
            "answer": "afterward",
            "hit": false
          },
          {
            "score": 0.746607780456543,
            "answer": "shortly",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8310792446136475
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.7408730387687683,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.7304697036743164,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7260561585426331,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.7228358387947083,
            "answer": "beyond",
            "hit": false
          },
          {
            "score": 0.7216628789901733,
            "answer": "along",
            "hit": false
          },
          {
            "score": 0.7207852602005005,
            "answer": "amid",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7408730387687683
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8685205578804016,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8262911438941956,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.8060388565063477,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.7927583456039429,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.7614337801933289,
            "answer": "abdomen",
            "hit": false
          },
          {
            "score": 0.7601593732833862,
            "answer": "abdominal",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.868520587682724
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.8417971134185791,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.7793847322463989,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.763202965259552,
            "answer": "every",
            "hit": false
          },
          {
            "score": 0.7605868577957153,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7463744878768921,
            "answer": "immediately",
            "hit": false
          },
          {
            "score": 0.7369990944862366,
            "answer": "some",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8417971134185791
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7945295572280884,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.7842491269111633,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7834234237670898,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.7801041603088379,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7752435803413391,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.7659095525741577,
            "answer": "along",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 88,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.657349556684494
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7351173162460327,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.7295157313346863,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.7129184007644653,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7122963070869446,
            "answer": "grateful",
            "hit": false
          },
          {
            "score": 0.7100003957748413,
            "answer": "deadline",
            "hit": false
          },
          {
            "score": 0.7099441289901733,
            "answer": "lifeless",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.694364070892334
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8612791895866394,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7570582628250122,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7514533996582031,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.724617600440979,
            "answer": "explore",
            "hit": false
          },
          {
            "score": 0.7206213474273682,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.7171577215194702,
            "answer": "climb",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 4333,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.62952721118927
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.7746500968933105,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7612345814704895,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.7470257878303528,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.7460958361625671,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.7364286184310913,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.726588249206543,
            "answer": "summer",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6688238382339478
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8199626207351685,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.7892120480537415,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.7586740851402283,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.7585006952285767,
            "answer": "there",
            "hit": false
          },
          {
            "score": 0.7583292126655579,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7566667795181274,
            "answer": "two",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7238539159297943
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.8229361772537231,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.792671799659729,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.7737313508987427,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.7324929237365723,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.730561375617981,
            "answer": "parameters",
            "hit": false
          },
          {
            "score": 0.7230640649795532,
            "answer": "settings",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.792671799659729
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7798779010772705,
            "answer": "behind",
            "hit": false
          },
          {
            "score": 0.7611097097396851,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7473185062408447,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.7259356379508972,
            "answer": "beyond",
            "hit": false
          },
          {
            "score": 0.7256234884262085,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7254765629768372,
            "answer": "beneath",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7256234884262085
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.7562439441680908,
            "answer": "irs",
            "hit": false
          },
          {
            "score": 0.7352354526519775,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.7352297306060791,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7190707921981812,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7153253555297852,
            "answer": "integrated",
            "hit": false
          },
          {
            "score": 0.7041490077972412,
            "answer": "inner",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7352297008037567
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7263351082801819,
            "answer": "fatal",
            "hit": false
          },
          {
            "score": 0.7141396999359131,
            "answer": "playstation",
            "hit": false
          },
          {
            "score": 0.7069963812828064,
            "answer": "venom",
            "hit": false
          },
          {
            "score": 0.7042725086212158,
            "answer": "heavenly",
            "hit": false
          },
          {
            "score": 0.7013277411460876,
            "answer": "marvel",
            "hit": false
          },
          {
            "score": 0.7013193368911743,
            "answer": "miserable",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6983086168766022
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.840100884437561,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.8223499059677124,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8149521350860596,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7981367111206055,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7825976014137268,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.7507309913635254,
            "answer": "invaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7465692162513733
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.865532636642456,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.6952076554298401,
            "answer": "down",
            "hit": false
          },
          {
            "score": 0.6817410588264465,
            "answer": "that",
            "hit": false
          },
          {
            "score": 0.6796708106994629,
            "answer": "from",
            "hit": false
          },
          {
            "score": 0.6771712303161621,
            "answer": "multiple",
            "hit": false
          },
          {
            "score": 0.6768785119056702,
            "answer": "better",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6528043746948242
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.8143512010574341,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.7387479543685913,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7372218370437622,
            "answer": "traditionally",
            "hit": false
          },
          {
            "score": 0.735780656337738,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.7270747423171997,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.7141386270523071,
            "answer": "commonly",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7387479543685913
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8263547420501709,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.7760273814201355,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7550740242004395,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7242898941040039,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7186951637268066,
            "answer": "dispose",
            "hit": false
          },
          {
            "score": 0.7157185673713684,
            "answer": "profit",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 433,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6448979377746582
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.7388880848884583,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7301898002624512,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.724606990814209,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7183900475502014,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7105182409286499,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7084711790084839,
            "answer": "decline",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 57,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6069777458906174
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.7808974385261536,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.7792597413063049,
            "answer": "southern",
            "hit": false
          },
          {
            "score": 0.7593331336975098,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7563329935073853,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7541594505310059,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.7498407363891602,
            "answer": "northeast",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7808974087238312
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.8381146192550659,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.7919653058052063,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7882604598999023,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.7820758819580078,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7591298222541809,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7589068412780762,
            "answer": "south",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7882604598999023
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.925311803817749,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.7425112724304199,
            "answer": "tow",
            "hit": false
          },
          {
            "score": 0.7190834283828735,
            "answer": "upward",
            "hit": false
          },
          {
            "score": 0.7158398032188416,
            "answer": "leans",
            "hit": false
          },
          {
            "score": 0.715148389339447,
            "answer": "downward",
            "hit": false
          },
          {
            "score": 0.7110799551010132,
            "answer": "nearer",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.70228411257267
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7388370633125305,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.7028036713600159,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.6996382474899292,
            "answer": "love",
            "hit": false
          },
          {
            "score": 0.6963869333267212,
            "answer": "before",
            "hit": false
          },
          {
            "score": 0.6953228712081909,
            "answer": "non",
            "hit": false
          },
          {
            "score": 0.6949012875556946,
            "answer": "feasible",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7388370782136917
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.9255242943763733,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.855789303779602,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.8103213310241699,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.7518026828765869,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.7465487718582153,
            "answer": "inland",
            "hit": false
          },
          {
            "score": 0.7369316220283508,
            "answer": "northwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9255242347717285
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 23,
      "accuracy": 0.34782608695652173
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "01e15bca-af67-4447-8408-2e75729b5eb2",
      "timestamp": "2025-05-17T20:32:09.070731"
    }
  }
]