[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.8180176019668579,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.7515760660171509,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.7416940927505493,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.7331203818321228,
            "answer": "beatles",
            "hit": false
          },
          {
            "score": 0.7327041625976562,
            "answer": "podcast",
            "hit": false
          },
          {
            "score": 0.7290633916854858,
            "answer": "song",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8180176019668579,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.8957517743110657,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.784428060054779,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7811803221702576,
            "answer": "applicant",
            "hit": false
          },
          {
            "score": 0.7642196416854858,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7453510761260986,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.7385203838348389,
            "answer": "apps",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8957517445087433,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7522072792053223,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.7366753816604614,
            "answer": "distance",
            "hit": false
          },
          {
            "score": 0.7211359739303589,
            "answer": "width",
            "hit": false
          },
          {
            "score": 0.7121849656105042,
            "answer": "ground",
            "hit": false
          },
          {
            "score": 0.7117931842803955,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.7117927670478821,
            "answer": "position",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7522072792053223,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.837336003780365,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.8140761256217957,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7697674036026001,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.76847904920578,
            "answer": "sedan",
            "hit": false
          },
          {
            "score": 0.7683590650558472,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.7633962631225586,
            "answer": "suv",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7683590352535248,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.7756617665290833,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.756145715713501,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7541660070419312,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.750422477722168,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7476446628570557,
            "answer": "graduation",
            "hit": false
          },
          {
            "score": 0.7436228394508362,
            "answer": "ncaa",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7756617367267609,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8235316276550293,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7684717774391174,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7660735249519348,
            "answer": "commission",
            "hit": false
          },
          {
            "score": 0.7651860117912292,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7577188611030579,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7537136077880859,
            "answer": "police",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8235316276550293,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8420824408531189,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.7673739790916443,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7445952892303467,
            "answer": "service",
            "hit": false
          },
          {
            "score": 0.7445041537284851,
            "answer": "supplier",
            "hit": false
          },
          {
            "score": 0.7441011071205139,
            "answer": "review",
            "hit": false
          },
          {
            "score": 0.7417124509811401,
            "answer": "consumers",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8420824706554413,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7574687600135803,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7470788359642029,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7423980236053467,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.7394188642501831,
            "answer": "monday",
            "hit": false
          },
          {
            "score": 0.7345187664031982,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.734351396560669,
            "answer": "saturday",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7423980236053467,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.8430585861206055,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7890650629997253,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.7870146632194519,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.7835779190063477,
            "answer": "murder",
            "hit": false
          },
          {
            "score": 0.7797688245773315,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.7487510442733765,
            "answer": "funeral",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8430585563182831,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8159221410751343,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.8095617890357971,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.779672384262085,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7700083255767822,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.7679688930511475,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.7663133144378662,
            "answer": "assistant",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8095618486404419,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.8089437484741211,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7886580228805542,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7699794173240662,
            "answer": "production",
            "hit": false
          },
          {
            "score": 0.7644914984703064,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7624040246009827,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7544974088668823,
            "answer": "developments",
            "hit": true
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7544974088668823,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7847773432731628,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7749539613723755,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.754462718963623,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7521690130233765,
            "answer": "gap",
            "hit": false
          },
          {
            "score": 0.7413440346717834,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.7356095314025879,
            "answer": "differ",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7847773134708405,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.801272988319397,
            "answer": "founder",
            "hit": false
          },
          {
            "score": 0.7949076890945435,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7856014966964722,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7774742245674133,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7750494480133057,
            "answer": "directs",
            "hit": false
          },
          {
            "score": 0.769027590751648,
            "answer": "directing",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7856014966964722,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.7784677743911743,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.715191125869751,
            "answer": "incident",
            "hit": false
          },
          {
            "score": 0.713710367679596,
            "answer": "episode",
            "hit": false
          },
          {
            "score": 0.7122288346290588,
            "answer": "festival",
            "hit": false
          },
          {
            "score": 0.710572361946106,
            "answer": "ticket",
            "hit": false
          },
          {
            "score": 0.7081882953643799,
            "answer": "exciting",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7784678339958191,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8111827969551086,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.7437057495117188,
            "answer": "analogy",
            "hit": false
          },
          {
            "score": 0.7374020218849182,
            "answer": "illustration",
            "hit": false
          },
          {
            "score": 0.7365880012512207,
            "answer": "comparison",
            "hit": false
          },
          {
            "score": 0.7328038215637207,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.7282773852348328,
            "answer": "thus",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8111827373504639,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7837104201316833,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.7399089336395264,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.7231289744377136,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.7060714960098267,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.6958554983139038,
            "answer": "factor",
            "hit": false
          },
          {
            "score": 0.6950613260269165,
            "answer": "claim",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7837104201316833,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.7915340065956116,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.7589613795280457,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.7400507926940918,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7329879999160767,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.7325924634933472,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7246446013450623,
            "answer": "colleague",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7915340662002563,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7950475215911865,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7875803709030151,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.7647862434387207,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7631452083587646,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.7617762088775635,
            "answer": "prayed",
            "hit": false
          },
          {
            "score": 0.7571421265602112,
            "answer": "theology",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7875803709030151,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8403398990631104,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.8208594918251038,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.7883802056312561,
            "answer": "federal",
            "hit": false
          },
          {
            "score": 0.7547403573989868,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.7520713210105896,
            "answer": "treasury",
            "hit": false
          },
          {
            "score": 0.744986891746521,
            "answer": "authorities",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8403399586677551,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.7488927841186523,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.7472187876701355,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.7335964441299438,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.7176527380943298,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7113175392150879,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.7086467742919922,
            "answer": "year",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7488928288221359,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.7855105996131897,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.758808970451355,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7368859052658081,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7311710119247437,
            "answer": "thinking",
            "hit": false
          },
          {
            "score": 0.7284383773803711,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7284290790557861,
            "answer": "concepts",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7855106592178345,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.7978817820549011,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.769950270652771,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7401670217514038,
            "answer": "translation",
            "hit": false
          },
          {
            "score": 0.7270615100860596,
            "answer": "translations",
            "hit": false
          },
          {
            "score": 0.7259880304336548,
            "answer": "translator",
            "hit": false
          },
          {
            "score": 0.7224166989326477,
            "answer": "vocabulary",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7978817820549011,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.8007478713989258,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.7864505052566528,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7862032651901245,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7707005739212036,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.7688367366790771,
            "answer": "court",
            "hit": false
          },
          {
            "score": 0.761233925819397,
            "answer": "attorneys",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7862032353878021,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.8058068752288818,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7482587099075317,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7335193753242493,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7284931540489197,
            "answer": "founder",
            "hit": false
          },
          {
            "score": 0.7234022617340088,
            "answer": "director",
            "hit": false
          },
          {
            "score": 0.7193606495857239,
            "answer": "supporter",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8058069348335266,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8066608905792236,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.7983700633049011,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.7546131610870361,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.749245285987854,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.7470788359642029,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.7348437309265137,
            "answer": "february",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8066609501838684,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.7745084166526794,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.7526468634605408,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.749635636806488,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7481305003166199,
            "answer": "morrow",
            "hit": false
          },
          {
            "score": 0.7306341528892517,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.7290205359458923,
            "answer": "evenings",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7745084166526794,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7891981601715088,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7679688930511475,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7368979454040527,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.734920859336853,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7310830354690552,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7289279699325562,
            "answer": "council",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7891981899738312,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8749607801437378,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7361353039741516,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.7300935983657837,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7214015126228333,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.7205281257629395,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.701092541217804,
            "answer": "phases",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8749608397483826,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.7793467044830322,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7610518932342529,
            "answer": "rookie",
            "hit": false
          },
          {
            "score": 0.7465474605560303,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7397147417068481,
            "answer": "coach",
            "hit": false
          },
          {
            "score": 0.7295169234275818,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.7267248630523682,
            "answer": "footballer",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7793467044830322,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8020864129066467,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.7577390670776367,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.7477437257766724,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.7454795241355896,
            "answer": "census",
            "hit": false
          },
          {
            "score": 0.7428232431411743,
            "answer": "unemployment",
            "hit": false
          },
          {
            "score": 0.7398054003715515,
            "answer": "residents",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8020863831043243,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.8337064385414124,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7600405216217041,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.7596900463104248,
            "answer": "trouble",
            "hit": false
          },
          {
            "score": 0.7586101293563843,
            "answer": "solution",
            "hit": false
          },
          {
            "score": 0.7552814483642578,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.7365304231643677,
            "answer": "argument",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8337064385414124,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.7916488647460938,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.736994743347168,
            "answer": "consumer",
            "hit": false
          },
          {
            "score": 0.7263556718826294,
            "answer": "merchandise",
            "hit": false
          },
          {
            "score": 0.7246212959289551,
            "answer": "marketing",
            "hit": false
          },
          {
            "score": 0.7203693389892578,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.7197748422622681,
            "answer": "goods",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7916488647460938,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.7792960405349731,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.7273616790771484,
            "answer": "nutrient",
            "hit": false
          },
          {
            "score": 0.726152241230011,
            "answer": "asset",
            "hit": false
          },
          {
            "score": 0.7241805791854858,
            "answer": "tool",
            "hit": false
          },
          {
            "score": 0.7241392135620117,
            "answer": "cultural",
            "hit": false
          },
          {
            "score": 0.7141904830932617,
            "answer": "repository",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7792960107326508,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7947321534156799,
            "answer": "rivera",
            "hit": false
          },
          {
            "score": 0.774750828742981,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.7436743378639221,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7349243760108948,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7284026145935059,
            "answer": "sullivan",
            "hit": false
          },
          {
            "score": 0.7267577648162842,
            "answer": "fishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7747507989406586,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.7870204448699951,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7817274332046509,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7681331038475037,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.7622514963150024,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.7367222905158997,
            "answer": "pavement",
            "hit": false
          },
          {
            "score": 0.7324515581130981,
            "answer": "boulevard",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7870204448699951,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.7799878120422363,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7079178094863892,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.7023924589157104,
            "answer": "relationship",
            "hit": false
          },
          {
            "score": 0.7003491520881653,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6998792290687561,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.6997828483581543,
            "answer": "responsibilities",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7799878120422363,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8229075074195862,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.8061608672142029,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.7979291677474976,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.7931488752365112,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.7804967164993286,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.7484550476074219,
            "answer": "chemistry",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8229075074195862,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.8061650991439819,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7674716711044312,
            "answer": "luckily",
            "hit": false
          },
          {
            "score": 0.7672204971313477,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.765896737575531,
            "answer": "fortunately",
            "hit": false
          },
          {
            "score": 0.7586101293563843,
            "answer": "problem",
            "hit": false
          },
          {
            "score": 0.7583729028701782,
            "answer": "solved",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8061651289463043,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8098615407943726,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7746731638908386,
            "answer": "sang",
            "hit": false
          },
          {
            "score": 0.7606063485145569,
            "answer": "sings",
            "hit": false
          },
          {
            "score": 0.7605925798416138,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7403280138969421,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.7349147796630859,
            "answer": "poem",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8098615109920502,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.8509999513626099,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.792620062828064,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.7637676000595093,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.758115828037262,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.7571460008621216,
            "answer": "pavement",
            "hit": false
          },
          {
            "score": 0.7496403455734253,
            "answer": "alley",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8509999513626099,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8511859178543091,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7880153059959412,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7793139219284058,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7724186778068542,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7723849415779114,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.7706869840621948,
            "answer": "classroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8511858880519867,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.8158690929412842,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.7332471013069153,
            "answer": "data",
            "hit": false
          },
          {
            "score": 0.7309337854385376,
            "answer": "systemic",
            "hit": false
          },
          {
            "score": 0.7282071709632874,
            "answer": "general",
            "hit": false
          },
          {
            "score": 0.7277812957763672,
            "answer": "them",
            "hit": false
          },
          {
            "score": 0.7267156839370728,
            "answer": "state",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8158690333366394,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.8156432509422302,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.7245185971260071,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.717119574546814,
            "answer": "phenomenon",
            "hit": false
          },
          {
            "score": 0.7124396562576294,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.7112711071968079,
            "answer": "damn",
            "hit": false
          },
          {
            "score": 0.707985520362854,
            "answer": "aspect",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8156432509422302,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8579930663108826,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.8190671801567078,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7618355751037598,
            "answer": "hometown",
            "hit": false
          },
          {
            "score": 0.7602090835571289,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7582581043243408,
            "answer": "suburb",
            "hit": false
          },
          {
            "score": 0.7560039758682251,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8579930663108826,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7729101181030273,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.7406265735626221,
            "answer": "consumer",
            "hit": false
          },
          {
            "score": 0.7346348166465759,
            "answer": "programmer",
            "hit": false
          },
          {
            "score": 0.7238699197769165,
            "answer": "patient",
            "hit": false
          },
          {
            "score": 0.721951961517334,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7138852477073669,
            "answer": "visitor",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7729101181030273,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.8702704906463623,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.7118085622787476,
            "answer": "activation",
            "hit": false
          },
          {
            "score": 0.7033854722976685,
            "answer": "variation",
            "hit": false
          },
          {
            "score": 0.7023686170578003,
            "answer": "revision",
            "hit": false
          },
          {
            "score": 0.7021375298500061,
            "answer": "verse",
            "hit": false
          },
          {
            "score": 0.7019191980361938,
            "answer": "edition",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8702704906463623,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.8841385841369629,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8313686847686768,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.819067120552063,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7849344611167908,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.7761189341545105,
            "answer": "tribe",
            "hit": false
          },
          {
            "score": 0.7666870355606079,
            "answer": "monastery",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8841386139392853,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.7910596132278442,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.7712088823318481,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7603200078010559,
            "answer": "email",
            "hit": false
          },
          {
            "score": 0.7589131593704224,
            "answer": "address",
            "hit": false
          },
          {
            "score": 0.755640983581543,
            "answer": "www",
            "hit": false
          },
          {
            "score": 0.7423006296157837,
            "answer": "facebook",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.791059672832489,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7592660188674927,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7546131610870361,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7444436550140381,
            "answer": "monday",
            "hit": false
          },
          {
            "score": 0.7441596984863281,
            "answer": "weekly",
            "hit": false
          },
          {
            "score": 0.7440915107727051,
            "answer": "wednesday",
            "hit": false
          },
          {
            "score": 0.7436506748199463,
            "answer": "saturday",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7361798584461212,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7983700633049011,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7626274228096008,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7582483887672424,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7511465549468994,
            "answer": "yearly",
            "hit": false
          },
          {
            "score": 0.7424644231796265,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7353028059005737,
            "answer": "annual",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7424644827842712,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 5
      }
    ],
    "result": {
      "cnt_questions_correct": 40,
      "cnt_questions_total": 50,
      "accuracy": 0.8
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "434c2100-d2d3-425d-b381-c21ec7387887",
      "timestamp": "2025-05-17T20:30:15.937697"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.7082223892211914,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7033999562263489,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.6978108882904053,
            "answer": "compatibility",
            "hit": false
          },
          {
            "score": 0.6951752305030823,
            "answer": "functionality",
            "hit": false
          },
          {
            "score": 0.6948264837265015,
            "answer": "accessibility",
            "hit": false
          },
          {
            "score": 0.6897976398468018,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6745086014270782,
        "b in neighbourhood of b_prime": 1423,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8009045720100403,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.7197839617729187,
            "answer": "participation",
            "hit": false
          },
          {
            "score": 0.7161228656768799,
            "answer": "structure",
            "hit": false
          },
          {
            "score": 0.7122040390968323,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.7121982574462891,
            "answer": "participants",
            "hit": false
          },
          {
            "score": 0.7095734477043152,
            "answer": "behaviors",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8009046316146851,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.799930214881897,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7418041825294495,
            "answer": "authority",
            "hit": false
          },
          {
            "score": 0.7271101474761963,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7270280718803406,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.7225537896156311,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.7192713022232056,
            "answer": "agent",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7999301850795746,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.8986849784851074,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.8152719736099243,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.8138272166252136,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.8074007034301758,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.8061485886573792,
            "answer": "assessment",
            "hit": false
          },
          {
            "score": 0.7859952449798584,
            "answer": "analytical",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8986850082874298,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.7879644632339478,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7792741060256958,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7785893082618713,
            "answer": "soldier",
            "hit": false
          },
          {
            "score": 0.7734888792037964,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.7592482566833496,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7573258280754089,
            "answer": "naval",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.773488849401474,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7871968746185303,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.7418041825294495,
            "answer": "agency",
            "hit": false
          },
          {
            "score": 0.724753737449646,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.720149040222168,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.7135695219039917,
            "answer": "advisory",
            "hit": false
          },
          {
            "score": 0.7134811878204346,
            "answer": "appeals",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7871969044208527,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7409688234329224,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.7386363744735718,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.7329305410385132,
            "answer": "grounds",
            "hit": false
          },
          {
            "score": 0.7324552536010742,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.7260340452194214,
            "answer": "assumption",
            "hit": false
          },
          {
            "score": 0.7211540937423706,
            "answer": "bases",
            "hit": true
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7211540937423706,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.8081223964691162,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7585333585739136,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.749882161617279,
            "answer": "corporate",
            "hit": false
          },
          {
            "score": 0.7436478734016418,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.7429330945014954,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7428601980209351,
            "answer": "industries",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.808122456073761,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.773985743522644,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7519420385360718,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.7372639775276184,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.7354027628898621,
            "answer": "rating",
            "hit": false
          },
          {
            "score": 0.7205531597137451,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.7190231680870056,
            "answer": "genres",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.773985743522644,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.7978010773658752,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.7882488965988159,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7560898065567017,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.7411872148513794,
            "answer": "dozen",
            "hit": false
          },
          {
            "score": 0.740057647228241,
            "answer": "nineteenth",
            "hit": false
          },
          {
            "score": 0.7378034591674805,
            "answer": "twentieth",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7978011071681976,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.8199709057807922,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.7673416137695312,
            "answer": "childhood",
            "hit": false
          },
          {
            "score": 0.7600760459899902,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7571171522140503,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.74937903881073,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7364299297332764,
            "answer": "pediatric",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8199709057807922,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.760665237903595,
            "answer": "state",
            "hit": false
          },
          {
            "score": 0.7359553575515747,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.732486367225647,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7216376662254333,
            "answer": "municipal",
            "hit": false
          },
          {
            "score": 0.7215120792388916,
            "answer": "council",
            "hit": false
          },
          {
            "score": 0.7182542681694031,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7324863970279694,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.7777690291404724,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7319396734237671,
            "answer": "communal",
            "hit": false
          },
          {
            "score": 0.7303383350372314,
            "answer": "neighborhood",
            "hit": false
          },
          {
            "score": 0.730302631855011,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7277739644050598,
            "answer": "ecosystem",
            "hit": false
          },
          {
            "score": 0.7273868322372437,
            "answer": "network",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7777690589427948,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.8236075639724731,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.7649272084236145,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.7549193501472473,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7426646947860718,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.7320237755775452,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.7280162572860718,
            "answer": "society",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8236075639724731,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.874400794506073,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7958857417106628,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.786202073097229,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7828850746154785,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7697906494140625,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7638373970985413,
            "answer": "village",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8744008243083954,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7721426486968994,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7608145475387573,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7292923927307129,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.723770260810852,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7119578123092651,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.694431722164154,
            "answer": "officers",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7721427083015442,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.839482307434082,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.7747795581817627,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.7653201818466187,
            "answer": "gdp",
            "hit": false
          },
          {
            "score": 0.7562825679779053,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.74606853723526,
            "answer": "recession",
            "hit": false
          },
          {
            "score": 0.7455222606658936,
            "answer": "economically",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.839482307434082,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.7743862867355347,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7699292302131653,
            "answer": "environmental",
            "hit": false
          },
          {
            "score": 0.7678140997886658,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.7553799748420715,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.7507018446922302,
            "answer": "fuel",
            "hit": false
          },
          {
            "score": 0.7500990629196167,
            "answer": "environment",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7743863463401794,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.7857084274291992,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.7324196100234985,
            "answer": "registration",
            "hit": false
          },
          {
            "score": 0.7281076312065125,
            "answer": "opening",
            "hit": false
          },
          {
            "score": 0.7274194955825806,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7259472608566284,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.7232493162155151,
            "answer": "entrance",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7857084274291992,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.837599515914917,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.7404249906539917,
            "answer": "located",
            "hit": false
          },
          {
            "score": 0.7350286841392517,
            "answer": "infrastructure",
            "hit": false
          },
          {
            "score": 0.732548713684082,
            "answer": "site",
            "hit": false
          },
          {
            "score": 0.7310752868652344,
            "answer": "laboratory",
            "hit": false
          },
          {
            "score": 0.7299202680587769,
            "answer": "institution",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8375995755195618,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.7954573035240173,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7765106558799744,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.7466129064559937,
            "answer": "parent",
            "hit": false
          },
          {
            "score": 0.7437375783920288,
            "answer": "parental",
            "hit": false
          },
          {
            "score": 0.7379027009010315,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.7362410426139832,
            "answer": "parenting",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7954573035240173,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8512851595878601,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7493702173233032,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.747590184211731,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7345490455627441,
            "answer": "heritage",
            "hit": false
          },
          {
            "score": 0.7271832823753357,
            "answer": "geography",
            "hit": false
          },
          {
            "score": 0.723488986492157,
            "answer": "mythology",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8512850999832153,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.819372832775116,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.7430654764175415,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7425065040588379,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.7378884553909302,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.7315888404846191,
            "answer": "business",
            "hit": false
          },
          {
            "score": 0.7309409976005554,
            "answer": "investment",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8193728923797607,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.7925496101379395,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7491241097450256,
            "answer": "documents",
            "hit": false
          },
          {
            "score": 0.7302616834640503,
            "answer": "database",
            "hit": false
          },
          {
            "score": 0.7238063216209412,
            "answer": "museum",
            "hit": false
          },
          {
            "score": 0.7220743894577026,
            "answer": "literature",
            "hit": false
          },
          {
            "score": 0.720727264881134,
            "answer": "reader",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7925496101379395,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7378934621810913,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.7207621932029724,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7103961110115051,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.7038283348083496,
            "answer": "career",
            "hit": false
          },
          {
            "score": 0.7019907236099243,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.6985160112380981,
            "answer": "lifespan",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7378935217857361,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8341622352600098,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7857648134231567,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7708936929702759,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.767993688583374,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7556005716323853,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7317167520523071,
            "answer": "impairment",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8341622352600098,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.760331392288208,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.7516583800315857,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7470813989639282,
            "answer": "storage",
            "hit": false
          },
          {
            "score": 0.7374737858772278,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.733501672744751,
            "answer": "address",
            "hit": false
          },
          {
            "score": 0.7270158529281616,
            "answer": "socket",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.760331392288208,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8814225196838379,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.755541205406189,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.7289566993713379,
            "answer": "invitation",
            "hit": false
          },
          {
            "score": 0.728814423084259,
            "answer": "option",
            "hit": false
          },
          {
            "score": 0.7253665924072266,
            "answer": "incentive",
            "hit": false
          },
          {
            "score": 0.7252762317657471,
            "answer": "chances",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8814224600791931,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8127561807632446,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7601007223129272,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.7356772422790527,
            "answer": "ideology",
            "hit": false
          },
          {
            "score": 0.7265018820762634,
            "answer": "regulations",
            "hit": false
          },
          {
            "score": 0.7264369130134583,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.7254315614700317,
            "answer": "advocacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8127561807632446,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.7363557815551758,
            "answer": "estate",
            "hit": false
          },
          {
            "score": 0.730191707611084,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7121334075927734,
            "answer": "premises",
            "hit": false
          },
          {
            "score": 0.7101131677627563,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.7069933414459229,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.7063316106796265,
            "answer": "owned",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.730191707611084,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.7881938815116882,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7662820219993591,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.7476382255554199,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7404880523681641,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7367890477180481,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.7302075624465942,
            "answer": "failure",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.788193941116333,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7961521148681641,
            "answer": "police",
            "hit": false
          },
          {
            "score": 0.766329824924469,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.7462027668952942,
            "answer": "encryption",
            "hit": false
          },
          {
            "score": 0.7456758618354797,
            "answer": "investigators",
            "hit": false
          },
          {
            "score": 0.7443830370903015,
            "answer": "privacy",
            "hit": false
          },
          {
            "score": 0.7433125972747803,
            "answer": "storage",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 253,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7003176361322403,
        "b in neighbourhood of b_prime": 154,
        "b_prime in neighbourhood of b": 254
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.758564293384552,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.7072727084159851,
            "answer": "trio",
            "hit": false
          },
          {
            "score": 0.7048914432525635,
            "answer": "saga",
            "hit": false
          },
          {
            "score": 0.7030760645866394,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.6995409727096558,
            "answer": "installment",
            "hit": false
          },
          {
            "score": 0.6957663297653198,
            "answer": "storyline",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 1.0,
        "b in neighbourhood of b_prime": 0,
        "b_prime in neighbourhood of b": 0
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8687365055084229,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.8257747292518616,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7740881443023682,
            "answer": "soc",
            "hit": false
          },
          {
            "score": 0.7505311369895935,
            "answer": "humanity",
            "hit": false
          },
          {
            "score": 0.7451107501983643,
            "answer": "social",
            "hit": false
          },
          {
            "score": 0.7433995604515076,
            "answer": "socio",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8687364757061005,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.7532106041908264,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.7530397176742554,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.7508381009101868,
            "answer": "habitat",
            "hit": false
          },
          {
            "score": 0.7498173713684082,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.7450830936431885,
            "answer": "diseases",
            "hit": false
          },
          {
            "score": 0.7374043464660645,
            "answer": "wildlife",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 1.0,
        "b in neighbourhood of b_prime": 0,
        "b_prime in neighbourhood of b": 0
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.7805941104888916,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.7735719680786133,
            "answer": "storyline",
            "hit": false
          },
          {
            "score": 0.7695847749710083,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.7655332088470459,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7610310316085815,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7537850141525269,
            "answer": "narratives",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7655331790447235,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.8808665871620178,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.8285953402519226,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.7953646779060364,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.7645982503890991,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.7601007223129272,
            "answer": "policy",
            "hit": false
          },
          {
            "score": 0.7572394609451294,
            "answer": "approach",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8808666467666626,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7865343689918518,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.765210747718811,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7568734884262085,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7521109580993652,
            "answer": "succeeded",
            "hit": false
          },
          {
            "score": 0.7516310214996338,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7447097301483154,
            "answer": "succeeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7865343391895294,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.8408884406089783,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8237624168395996,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7701189517974854,
            "answer": "innovation",
            "hit": false
          },
          {
            "score": 0.7618913054466248,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7609269618988037,
            "answer": "innovations",
            "hit": false
          },
          {
            "score": 0.7568113207817078,
            "answer": "culture",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8408884406089783,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8856449127197266,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.8246803283691406,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.7810367345809937,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7463211417198181,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7410407066345215,
            "answer": "ideology",
            "hit": false
          },
          {
            "score": 0.7376366257667542,
            "answer": "conjecture",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.885644942522049,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.7960599064826965,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7618246078491211,
            "answer": "harvard",
            "hit": false
          },
          {
            "score": 0.7578509449958801,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.7572141885757446,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.7558505535125732,
            "answer": "institute",
            "hit": false
          },
          {
            "score": 0.7498999238014221,
            "answer": "yale",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7960598766803741,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.7620371580123901,
            "answer": "deadline",
            "hit": false
          },
          {
            "score": 0.7344924807548523,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.7298873662948608,
            "answer": "variability",
            "hit": false
          },
          {
            "score": 0.7290729284286499,
            "answer": "vanity",
            "hit": false
          },
          {
            "score": 0.7178541421890259,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7151592969894409,
            "answer": "entertainment",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7178541123867035,
        "b in neighbourhood of b_prime": 147,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.8524259924888611,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.8522720336914062,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.8430386185646057,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.83442622423172,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.8294909000396729,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.8047326803207397,
            "answer": "widow",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8524259924888611,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.8240262866020203,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.7978500127792358,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7592400908470154,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.7585488557815552,
            "answer": "feminist",
            "hit": false
          },
          {
            "score": 0.7557224035263062,
            "answer": "ladies",
            "hit": false
          },
          {
            "score": 0.7509803175926208,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8240262866020203,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 34,
      "cnt_questions_total": 44,
      "accuracy": 0.7727272727272727
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "211f87e3-7c50-4cd1-bb8e-22e8c1994897",
      "timestamp": "2025-05-17T20:30:16.359934"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.870103120803833,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.8650236129760742,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.8079442381858826,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7891804575920105,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.7539590001106262,
            "answer": "costly",
            "hit": false
          },
          {
            "score": 0.7475372552871704,
            "answer": "economical",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.865023672580719,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.7712708711624146,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.7688949704170227,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.7580097913742065,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7530111074447632,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7511211633682251,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7496935725212097,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7712708711624146,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.855614423751831,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.8062990307807922,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7988947629928589,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.7788648009300232,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7718819379806519,
            "answer": "fierce",
            "hit": false
          },
          {
            "score": 0.7713518738746643,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8556144535541534,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.7930901050567627,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.7796412706375122,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.7629063129425049,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7604615092277527,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.753749668598175,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7399461269378662,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7930900454521179,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 4,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "6db53e89-161a-4f8b-ab27-8af11683e8d4",
      "timestamp": "2025-05-17T20:30:16.746824"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7351785898208618,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7247733473777771,
            "answer": "spicy",
            "hit": false
          },
          {
            "score": 0.7176413536071777,
            "answer": "sexy",
            "hit": false
          },
          {
            "score": 0.7118290066719055,
            "answer": "long",
            "hit": false
          },
          {
            "score": 0.7118112444877625,
            "answer": "sticky",
            "hit": false
          },
          {
            "score": 0.7115651369094849,
            "answer": "heated",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7351785749197006,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.855614423751831,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.8062990307807922,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7988947629928589,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.7788648009300232,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7718819379806519,
            "answer": "fierce",
            "hit": false
          },
          {
            "score": 0.7713518738746643,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8062990605831146,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 2,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "9d071b03-57dd-448b-9528-c4fc26f98d6f",
      "timestamp": "2025-05-17T20:30:16.781471"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.8812359571456909,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.8616819381713867,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8471617698669434,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8135681748390198,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7893924713134766,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7829528450965881,
            "answer": "acknowledge",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8812359571456909,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7776837348937988,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7397527098655701,
            "answer": "put",
            "hit": false
          },
          {
            "score": 0.7293214797973633,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.7263641953468323,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7239279747009277,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7186739444732666,
            "answer": "added",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6863646954298019,
        "b in neighbourhood of b_prime": 249,
        "b_prime in neighbourhood of b": 32
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8747408986091614,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8463164567947388,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.8376426100730896,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8146569728851318,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7868318557739258,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7832311987876892,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8747408986091614,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.784852147102356,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7761775255203247,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7692797780036926,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.7617345452308655,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7526968121528625,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7522655129432678,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7692797780036926,
        "b in neighbourhood of b_prime": 79,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8894322514533997,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.873900294303894,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8625097870826721,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8230941295623779,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.784520149230957,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7743936777114868,
            "answer": "resemble",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8894322514533997,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8803086280822754,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8566805720329285,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7642196416854858,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7583029866218567,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.749640941619873,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.747160792350769,
            "answer": "operate",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8803086578845978,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7798082232475281,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.7793563604354858,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7711085081100464,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7684743404388428,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7569563388824463,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7531207799911499,
            "answer": "inquired",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7798081636428833,
        "b in neighbourhood of b_prime": 38,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8444678783416748,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8425672054290771,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.813289999961853,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.8108333349227905,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.7560185194015503,
            "answer": "minimize",
            "hit": false
          },
          {
            "score": 0.7522709369659424,
            "answer": "eliminate",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8108333349227905,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8541465997695923,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8298917412757874,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7641721963882446,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7563961148262024,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7508519291877747,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.745560348033905,
            "answer": "receive",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8541466593742371,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.789851188659668,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7771400809288025,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7725263833999634,
            "answer": "remember",
            "hit": false
          },
          {
            "score": 0.7683278918266296,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655190825462341,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7509874105453491,
            "answer": "somehow",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7898512184619904,
        "b in neighbourhood of b_prime": 30,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7873882055282593,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.76761794090271,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7594759464263916,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.7553911805152893,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7509146332740784,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501175403594971,
            "answer": "consideration",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7553911805152893,
        "b in neighbourhood of b_prime": 128,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9067867994308472,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8884591460227966,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8441291451454163,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8169124722480774,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.8113941550254822,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8036609292030334,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9067868590354919,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8441824913024902,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8413856625556946,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8056542873382568,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.7747023105621338,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7684354782104492,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.766893744468689,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8056543171405792,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8821447491645813,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8460824489593506,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.838066816329956,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7716391682624817,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.768410325050354,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7644777894020081,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8821447789669037,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.8799015879631042,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8630783557891846,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8388220071792603,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8185253143310547,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7881203293800354,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8799015879631042,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8837364912033081,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8542653322219849,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8172335028648376,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7950354814529419,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7949798107147217,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.791204571723938,
            "answer": "refer",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8837364912033081,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8089436888694763,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8078879117965698,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.801114559173584,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7689806222915649,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7655152082443237,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7522775530815125,
            "answer": "developed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.801114559173584,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.7897679805755615,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.784852147102356,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.7739753723144531,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7638545036315918,
            "answer": "install",
            "hit": false
          },
          {
            "score": 0.758230984210968,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.7570898532867432,
            "answer": "ensure",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7897679805755615,
        "b in neighbourhood of b_prime": 44,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.802365779876709,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7805742025375366,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7773585319519043,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.7650200724601746,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7647693157196045,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7599952220916748,
            "answer": "seriously",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7773585617542267,
        "b in neighbourhood of b_prime": 36,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.8099626302719116,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7980968952178955,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.7933966517448425,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.777827799320221,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7702526450157166,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7612544298171997,
            "answer": "hopefully",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7980969250202179,
        "b in neighbourhood of b_prime": 29,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7613648176193237,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7567750811576843,
            "answer": "existing",
            "hit": false
          },
          {
            "score": 0.7449507117271423,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7442035675048828,
            "answer": "thrive",
            "hit": false
          },
          {
            "score": 0.7427289485931396,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.738715410232544,
            "answer": "operate",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7613648772239685,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8699201941490173,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8503100872039795,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8445826768875122,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8419860601425171,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.8180440664291382,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.8172335624694824,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8699201941490173,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7919028401374817,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7816227078437805,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7622911930084229,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.7542133927345276,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7430704832077026,
            "answer": "more",
            "hit": false
          },
          {
            "score": 0.742680549621582,
            "answer": "tell",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7314073741436005,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8663575649261475,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8624013066291809,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8607302308082581,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8444942831993103,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7768881320953369,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.776100754737854,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8663576245307922,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8441766500473022,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7647356986999512,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.761001706123352,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7587735652923584,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7527254819869995,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7504032850265503,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8441766500473022,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.8861654996871948,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8696572184562683,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7913399934768677,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898828983306885,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7777283191680908,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7776364088058472,
            "answer": "recognize",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8861655592918396,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8296696543693542,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8195098638534546,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8163614273071289,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8059799671173096,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8043168783187866,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7961733341217041,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8296696841716766,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7509152889251709,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7464979887008667,
            "answer": "define",
            "hit": false
          },
          {
            "score": 0.7457940578460693,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7453495264053345,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7432122230529785,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7404922842979431,
            "answer": "including",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7509152889251709,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8940271735191345,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8378751873970032,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7988952994346619,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7883210182189941,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867550849914551,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7864935398101807,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8940272033214569,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8437526226043701,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7977203726768494,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7819182872772217,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.7800626158714294,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7641099691390991,
            "answer": "educate",
            "hit": false
          },
          {
            "score": 0.7570240497589111,
            "answer": "discovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7295653522014618,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 29
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.8606416583061218,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8603666424751282,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8585183024406433,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8006333708763123,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7786165475845337,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7712342739105225,
            "answer": "preserve",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8603665828704834,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8982287645339966,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.871414303779602,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8624013662338257,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8536919355392456,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.822080671787262,
            "answer": "arise",
            "hit": false
          },
          {
            "score": 0.7933403849601746,
            "answer": "originate",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8982287645339966,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8997897505760193,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8135003447532654,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.793157160282135,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7721701860427856,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7719244956970215,
            "answer": "behave",
            "hit": false
          },
          {
            "score": 0.7670764327049255,
            "answer": "manipulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8997897505760193,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.7884567379951477,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7842454314231873,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.7717387676239014,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7632977962493896,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.7529065012931824,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7433030605316162,
            "answer": "protect",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7632977962493896,
        "b in neighbourhood of b_prime": 84,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8944276571273804,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8781282305717468,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.834546685218811,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.833732545375824,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8177136182785034,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8074908256530762,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8944276571273804,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.8304131031036377,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.8186190724372864,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.7995808124542236,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7705774903297424,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.7688825726509094,
            "answer": "protector",
            "hit": false
          },
          {
            "score": 0.7656154036521912,
            "answer": "protection",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8186190724372864,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8921647071838379,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8623682260513306,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8273400068283081,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8154902458190918,
            "answer": "offer",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8005397319793701,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8921646773815155,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8786810636520386,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8574068546295166,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8465615510940552,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7840771675109863,
            "answer": "earn",
            "hit": false
          },
          {
            "score": 0.7792286276817322,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741419076919556,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8786810636520386,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8797911405563354,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8762948513031006,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8542435765266418,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8334842920303345,
            "answer": "eliminate",
            "hit": false
          },
          {
            "score": 0.8329498767852783,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.831622838973999,
            "answer": "reduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8797910809516907,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8613799214363098,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8357599973678589,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8239927291870117,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8097106218338013,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.7912045121192932,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7714014053344727,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8613799214363098,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8815066814422607,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8517317771911621,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8460824489593506,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7923887968063354,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.790602445602417,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7786165475845337,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8517317175865173,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.7873385548591614,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7808151245117188,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7725263833999634,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.7713238596916199,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7692499160766602,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7616791129112244,
            "answer": "also",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7808151543140411,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8036062717437744,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7986710667610168,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7981086373329163,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7726412415504456,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7676958441734314,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.7669655084609985,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7726412415504456,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7725623846054077,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7708101272583008,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.7526369094848633,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7498552203178406,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7459633946418762,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.7457940578460693,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708101570606232,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8934711217880249,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8755402565002441,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8625097274780273,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8044610619544983,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7907747626304626,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7668272852897644,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8934711217880249,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.8780576586723328,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.7699900269508362,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7653619050979614,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7600958347320557,
            "answer": "communicate",
            "hit": false
          },
          {
            "score": 0.7508852481842041,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7501956820487976,
            "answer": "create",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8780576586723328,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8040996193885803,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.8005603551864624,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7961198091506958,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.7748672962188721,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7708449363708496,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7532178163528442,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708448767662048,
        "b in neighbourhood of b_prime": 66,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.786358118057251,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7859585881233215,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7857807874679565,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.768474280834198,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7657139301300049,
            "answer": "you",
            "hit": false
          },
          {
            "score": 0.7564617991447449,
            "answer": "imagine",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7859585881233215,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8598813414573669,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.846223771572113,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8212219476699829,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8040351867675781,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7957169413566589,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.7945903539657593,
            "answer": "understanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8598813414573669,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 30,
      "cnt_questions_total": 49,
      "accuracy": 0.6122448979591837
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "0c0beb09-6e30-4ff3-9baf-0eebffda596b",
      "timestamp": "2025-05-17T20:30:16.799723"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.7977561950683594,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.7961733341217041,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7923891544342041,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7866895794868469,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7702526450157166,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7625035047531128,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7977561950683594,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7776837348937988,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.7397527098655701,
            "answer": "put",
            "hit": false
          },
          {
            "score": 0.7293214797973633,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.7263641953468323,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7239279747009277,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7186739444732666,
            "answer": "added",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7776837348937988,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.784852147102356,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7761775255203247,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7692797780036926,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7617345452308655,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.7526968121528625,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7522655129432678,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7617345154285431,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8894322514533997,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.873900294303894,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8625097870826721,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8230941295623779,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.784520149230957,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7743936777114868,
            "answer": "resemble",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8230941295623779,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.8803086280822754,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8566805720329285,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.7642196416854858,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7583029866218567,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.749640941619873,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.747160792350769,
            "answer": "operate",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8566806316375732,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.7798082232475281,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7793563604354858,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7711085081100464,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7684743404388428,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7569563388824463,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7531207799911499,
            "answer": "inquired",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7569563984870911,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8418477773666382,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.8012180924415588,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7920687794685364,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.7915189862251282,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.7616352438926697,
            "answer": "tickets",
            "hit": false
          },
          {
            "score": 0.7507513761520386,
            "answer": "participants",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7915190160274506,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.8444678783416748,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8425672054290771,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.813289999961853,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.8108333349227905,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7560185194015503,
            "answer": "minimize",
            "hit": false
          },
          {
            "score": 0.7522709369659424,
            "answer": "eliminate",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8425672054290771,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8541465997695923,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8298917412757874,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.7641721963882446,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7563961148262024,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7508519291877747,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.745560348033905,
            "answer": "receive",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8298917412757874,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.789851188659668,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7771400809288025,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7725263833999634,
            "answer": "remember",
            "hit": false
          },
          {
            "score": 0.7683278918266296,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655190825462341,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7509874105453491,
            "answer": "somehow",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7771400809288025,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.7873882055282593,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.76761794090271,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7594759464263916,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.7553911805152893,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7509146332740784,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501175403594971,
            "answer": "consideration",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7873881757259369,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8441824913024902,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8413856625556946,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8056542873382568,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7747023105621338,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.7684354782104492,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.766893744468689,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.841385692358017,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.8821447491645813,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8460824489593506,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.838066816329956,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.7716391682624817,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.768410325050354,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7644777894020081,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.838066816329956,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.8799015879631042,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8630783557891846,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.8388220071792603,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8185253143310547,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7881203293800354,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8630782961845398,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8089436888694763,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8078879117965698,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.801114559173584,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7689806222915649,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7655152082443237,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7522775530815125,
            "answer": "developed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8078879117965698,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8907163143157959,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8900813460350037,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8492974638938904,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.834546685218811,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8242209553718567,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.812472939491272,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8242209255695343,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.802365779876709,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.7805742025375366,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7773585319519043,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7650200724601746,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7647693157196045,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7599952220916748,
            "answer": "seriously",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.802365779876709,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.8099626302719116,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.7980968952178955,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7933966517448425,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.777827799320221,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7702526450157166,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7612544298171997,
            "answer": "hopefully",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8099626302719116,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.8837044835090637,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8817809224128723,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8385322093963623,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7884154319763184,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7879511117935181,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7849710583686829,
            "answer": "create",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8817809224128723,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.7613648176193237,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7567750811576843,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.7449507117271423,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7442035675048828,
            "answer": "thrive",
            "hit": false
          },
          {
            "score": 0.7427289485931396,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.738715410232544,
            "answer": "operate",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7567750513553619,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.8536182641983032,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8281023502349854,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.8001547455787659,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.7709763646125793,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.7691769003868103,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7594791650772095,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8281023800373077,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.7919028401374817,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.7816227078437805,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7622911930084229,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.7542133927345276,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7430704832077026,
            "answer": "more",
            "hit": false
          },
          {
            "score": 0.742680549621582,
            "answer": "tell",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7919028401374817,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8663575649261475,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8624013066291809,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8607302308082581,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8444942831993103,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.7768881320953369,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.776100754737854,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8444942533969879,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.8861654996871948,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8696572184562683,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.7913399934768677,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898828983306885,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7777283191680908,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7776364088058472,
            "answer": "recognize",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8696572184562683,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.8296696543693542,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8195098638534546,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8163614273071289,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.8059799671173096,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8043168783187866,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7961733341217041,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8163614869117737,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.7509152889251709,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7464979887008667,
            "answer": "define",
            "hit": false
          },
          {
            "score": 0.7457940578460693,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7453495264053345,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7432122230529785,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7404922842979431,
            "answer": "including",
            "hit": true
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7404922693967819,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.8940271735191345,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8378751873970032,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7988952994346619,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7883210182189941,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867550849914551,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7864935398101807,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8378751873970032,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.8437526226043701,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7977203726768494,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7819182872772217,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.7800626158714294,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7641099691390991,
            "answer": "educate",
            "hit": false
          },
          {
            "score": 0.7570240497589111,
            "answer": "discovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7819183468818665,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.7982137203216553,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7736964821815491,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.767993688583374,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.758047342300415,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7531151175498962,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7472254037857056,
            "answer": "have",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7736964821815491,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.8606416583061218,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8603666424751282,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8585183024406433,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8006333708763123,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7786165475845337,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7712342739105225,
            "answer": "preserve",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8606416583061218,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8690981864929199,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.853716254234314,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8358297944068909,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.7727906703948975,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606361508369446,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549205422401428,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8358297944068909,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8997897505760193,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8135003447532654,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.793157160282135,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7721701860427856,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7719244956970215,
            "answer": "behave",
            "hit": false
          },
          {
            "score": 0.7670764327049255,
            "answer": "manipulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.813500314950943,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.7900588512420654,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.789702832698822,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7777844667434692,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7761020660400391,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7598533630371094,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7326408624649048,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7317947447299957,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.7884567379951477,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.7842454314231873,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.7717387676239014,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7632977962493896,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7529065012931824,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7433030605316162,
            "answer": "protect",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7884567379951477,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.8944276571273804,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8781282305717468,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.834546685218811,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.833732545375824,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8177136182785034,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8074908256530762,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8781282305717468,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.8304131031036377,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.8186190724372864,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7995808124542236,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7705774903297424,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.7688825726509094,
            "answer": "protector",
            "hit": false
          },
          {
            "score": 0.7656154036521912,
            "answer": "protection",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8304131031036377,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.8921647071838379,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8623682260513306,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.8273400068283081,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8154902458190918,
            "answer": "offer",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8005397319793701,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8623681664466858,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.8786810636520386,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8574068546295166,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8465615510940552,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.7840771675109863,
            "answer": "earn",
            "hit": false
          },
          {
            "score": 0.7792286276817322,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741419076919556,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8465615212917328,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.8797911405563354,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8762948513031006,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8542435765266418,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8334842920303345,
            "answer": "eliminate",
            "hit": false
          },
          {
            "score": 0.8329498767852783,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.831622838973999,
            "answer": "reduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8762948513031006,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8613799214363098,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8357599973678589,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.8239927291870117,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.8097106218338013,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.7912045121192932,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7714014053344727,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8239926695823669,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8815066814422607,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8517317771911621,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8460824489593506,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7923887968063354,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.790602445602417,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7786165475845337,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.77287757396698,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.7873385548591614,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.7808151245117188,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7725263833999634,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.7713238596916199,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7692499160766602,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7616791129112244,
            "answer": "also",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7873386144638062,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.8036062717437744,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7986710667610168,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7981086373329163,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7726412415504456,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7676958441734314,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.7669655084609985,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7981086373329163,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.7725623846054077,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.7708101272583008,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7526369094848633,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7498552203178406,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7459633946418762,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.7457940578460693,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7725623846054077,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8934711217880249,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8755402565002441,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8625097274780273,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8044610619544983,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7907747626304626,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7668272852897644,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7907747626304626,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.7399394512176514,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.7172284126281738,
            "answer": "put",
            "hit": false
          },
          {
            "score": 0.7160396575927734,
            "answer": "located",
            "hit": false
          },
          {
            "score": 0.7124612331390381,
            "answer": "situations",
            "hit": false
          },
          {
            "score": 0.7120369672775269,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.7117981314659119,
            "answer": "come",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7047902941703796,
        "b in neighbourhood of b_prime": 52,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8888044357299805,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8601112365722656,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8071852922439575,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.7720335721969604,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7682469487190247,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7456814050674438,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8071852326393127,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8099057674407959,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.7920910120010376,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7776774168014526,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7769609689712524,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7528445720672607,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7411012649536133,
            "answer": "curriculum",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8099058270454407,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.786358118057251,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7859585881233215,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7857807874679565,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.768474280834198,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7657139301300049,
            "answer": "you",
            "hit": false
          },
          {
            "score": 0.7564617991447449,
            "answer": "imagine",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7392987310886383,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 30
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8598813414573669,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.846223771572113,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8212219476699829,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8040351867675781,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7957169413566589,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.7945903539657593,
            "answer": "understanding",
            "hit": true
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7945903539657593,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      }
    ],
    "result": {
      "cnt_questions_correct": 12,
      "cnt_questions_total": 50,
      "accuracy": 0.24
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "a281577f-02f5-4a9a-9e45-0818635e30d0",
      "timestamp": "2025-05-17T20:30:17.214262"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8812359571456909,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8616819381713867,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8471617698669434,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8135681748390198,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7893924713134766,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7829528450965881,
            "answer": "acknowledge",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8471617698669434,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.7977561950683594,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7961733341217041,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7923891544342041,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7866895794868469,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.7702526450157166,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7625035047531128,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7866895794868469,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7776837348937988,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7397527098655701,
            "answer": "put",
            "hit": false
          },
          {
            "score": 0.7293214797973633,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.7263641953468323,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7239279747009277,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7186739444732666,
            "answer": "added",
            "hit": true
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7186739295721054,
        "b in neighbourhood of b_prime": 38,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8747408986091614,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8463164567947388,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8376426100730896,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8146569728851318,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7868318557739258,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7832311987876892,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8463165163993835,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.784852147102356,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7761775255203247,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7692797780036926,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7617345452308655,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7526968121528625,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7522655129432678,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7501262426376343,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8383635878562927,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8196548223495483,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7855234742164612,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7711190581321716,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7337155342102051,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.7316839098930359,
            "answer": "releases",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7337155491113663,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8894322514533997,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.873900294303894,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8625097870826721,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8230941295623779,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.784520149230957,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7743936777114868,
            "answer": "resemble",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8739003539085388,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8803086280822754,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8566805720329285,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7642196416854858,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7583029866218567,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.749640941619873,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.747160792350769,
            "answer": "operate",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7239291369915009,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 29
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7798082232475281,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7793563604354858,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.7711085081100464,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7684743404388428,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7569563388824463,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7531207799911499,
            "answer": "inquired",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7793563604354858,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8418477773666382,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.8012180924415588,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7920687794685364,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7915189862251282,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.7616352438926697,
            "answer": "tickets",
            "hit": false
          },
          {
            "score": 0.7507513761520386,
            "answer": "participants",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.792068749666214,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8541465997695923,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8298917412757874,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7641721963882446,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7563961148262024,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7508519291877747,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.745560348033905,
            "answer": "receive",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7381236851215363,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.789851188659668,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7771400809288025,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7725263833999634,
            "answer": "remember",
            "hit": false
          },
          {
            "score": 0.7683278918266296,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655190825462341,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7509874105453491,
            "answer": "somehow",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7655190825462341,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7873882055282593,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.76761794090271,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7594759464263916,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.7553911805152893,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7509146332740784,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501175403594971,
            "answer": "consideration",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 107,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7082042694091797,
        "b in neighbourhood of b_prime": 166,
        "b_prime in neighbourhood of b": 108
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8821447491645813,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8460824489593506,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.838066816329956,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7716391682624817,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.768410325050354,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7644777894020081,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 51,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7168580591678619,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 52
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8799015879631042,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8630783557891846,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8388220071792603,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.8185253143310547,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7881203293800354,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7570494413375854,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.891858696937561,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8601758480072021,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.85053950548172,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8217674493789673,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.802772045135498,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7841740250587463,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8505395352840424,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8837364912033081,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8542653322219849,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8172335028648376,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7950354814529419,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7949798107147217,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.791204571723938,
            "answer": "refer",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7563391923904419,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8089436888694763,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8078879117965698,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.801114559173584,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7689806222915649,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7655152082443237,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7522775530815125,
            "answer": "developed",
            "hit": true
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7522775530815125,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.7757450938224792,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7641962170600891,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.7571261525154114,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.749338686466217,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.7448461055755615,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.7383489608764648,
            "answer": "explore",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7315298765897751,
        "b in neighbourhood of b_prime": 73,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.802365779876709,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7805742025375366,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.7773585319519043,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7650200724601746,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7647693157196045,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7599952220916748,
            "answer": "seriously",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7805741429328918,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8099626302719116,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7980968952178955,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7933966517448425,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.777827799320221,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7702526450157166,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7612544298171997,
            "answer": "hopefully",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7933966517448425,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8837044835090637,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8817809224128723,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8385322093963623,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7884154319763184,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7879511117935181,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7849710583686829,
            "answer": "create",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8385322093963623,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8536182641983032,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8281023502349854,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.8001547455787659,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7709763646125793,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.7691769003868103,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7594791650772095,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8001547455787659,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7919028401374817,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7816227078437805,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7622911930084229,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.7542133927345276,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7430704832077026,
            "answer": "more",
            "hit": false
          },
          {
            "score": 0.742680549621582,
            "answer": "tell",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7350091487169266,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8441766500473022,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7647356986999512,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.761001706123352,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7587735652923584,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7527254819869995,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7504032850265503,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.764735758304596,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8861654996871948,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8696572184562683,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7913399934768677,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898828983306885,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7777283191680908,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.7776364088058472,
            "answer": "recognize",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7777283489704132,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8296696543693542,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8195098638534546,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8163614273071289,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8059799671173096,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8043168783187866,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7961733341217041,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8059799671173096,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7509152889251709,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7464979887008667,
            "answer": "define",
            "hit": false
          },
          {
            "score": 0.7457940578460693,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7453495264053345,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7432122230529785,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7404922842979431,
            "answer": "including",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7252131700515747,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8941633105278015,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8934997320175171,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7703481912612915,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.7702428102493286,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.7682056427001953,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7656987905502319,
            "answer": "impose",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7460368722677231,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8940271735191345,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8378751873970032,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7988952994346619,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7883210182189941,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867550849914551,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7864935398101807,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7988952994346619,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8807564377784729,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7946009039878845,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.7898828983306885,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7721215486526489,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.771304190158844,
            "answer": "detect",
            "hit": false
          },
          {
            "score": 0.7709107995033264,
            "answer": "location",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.768436849117279,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.7982137203216553,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7736964821815491,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.767993688583374,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.758047342300415,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7531151175498962,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7472254037857056,
            "answer": "have",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7354460060596466,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8690981864929199,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.853716254234314,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8358297944068909,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7727906703948975,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606361508369446,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549205422401428,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.853716254234314,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8953396081924438,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8141117095947266,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.8123193383216858,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7933924198150635,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7779340744018555,
            "answer": "wedding",
            "hit": false
          },
          {
            "score": 0.7755292057991028,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7933924496173859,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7900588512420654,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.789702832698822,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7777844667434692,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7761020660400391,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7598533630371094,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7326408624649048,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7598533928394318,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8921647071838379,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8623682260513306,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8273400068283081,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.8154902458190918,
            "answer": "offer",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8005397319793701,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8273399770259857,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8227951526641846,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7960236072540283,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.794284462928772,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7909399271011353,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7761962413787842,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7728314995765686,
            "answer": "pub",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7761962413787842,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8786810636520386,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8574068546295166,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8465615510940552,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7840771675109863,
            "answer": "earn",
            "hit": false
          },
          {
            "score": 0.7792286276817322,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741419076919556,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.857406884431839,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8797911405563354,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8762948513031006,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8542435765266418,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8334842920303345,
            "answer": "eliminate",
            "hit": false
          },
          {
            "score": 0.8329498767852783,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.831622838973999,
            "answer": "reduced",
            "hit": true
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8316227793693542,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8613799214363098,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8357599973678589,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8239927291870117,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8097106218338013,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.7912045121192932,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7714014053344727,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8357599675655365,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8807259202003479,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8156640529632568,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7680745124816895,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7673816084861755,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7643442749977112,
            "answer": "arise",
            "hit": false
          },
          {
            "score": 0.7635799646377563,
            "answer": "derive",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7535555362701416,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8815066814422607,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8517317771911621,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8460824489593506,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7923887968063354,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.790602445602417,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7786165475845337,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8815066814422607,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.7788103222846985,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.770729660987854,
            "answer": "remove",
            "hit": false
          },
          {
            "score": 0.7621681690216064,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7580517530441284,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.7576747536659241,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7505239248275757,
            "answer": "replacements",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7580517530441284,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7725623846054077,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7708101272583008,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7526369094848633,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7498552203178406,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7459633946418762,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.7457940578460693,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7459634095430374,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8934711217880249,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8755402565002441,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8625097274780273,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8044610619544983,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7907747626304626,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7668272852897644,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8755402863025665,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8780576586723328,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7699900269508362,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7653619050979614,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7600958347320557,
            "answer": "communicate",
            "hit": false
          },
          {
            "score": 0.7508852481842041,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7501956820487976,
            "answer": "create",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7348900884389877,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8888044357299805,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8601112365722656,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8071852922439575,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7720335721969604,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7682469487190247,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7456814050674438,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8601112365722656,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.786358118057251,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7859585881233215,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7857807874679565,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.768474280834198,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7657139301300049,
            "answer": "you",
            "hit": false
          },
          {
            "score": 0.7564617991447449,
            "answer": "imagine",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.753994345664978,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8598813414573669,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.846223771572113,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8212219476699829,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.8040351867675781,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7957169413566589,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.7945903539657593,
            "answer": "understanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.846223771572113,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.8280278444290161,
            "answer": "united",
            "hit": true
          },
          {
            "score": 0.7717961072921753,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.7680507302284241,
            "answer": "converge",
            "hit": false
          },
          {
            "score": 0.7668056488037109,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.7665383815765381,
            "answer": "collaborate",
            "hit": false
          },
          {
            "score": 0.7587188482284546,
            "answer": "gather",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8280279040336609,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 50,
      "accuracy": 0.04
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "30387929-4d72-4ae9-b408-5128b28fe7ae",
      "timestamp": "2025-05-17T20:30:17.642840"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8133938312530518,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.8016446232795715,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7949200868606567,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.7938991785049438,
            "answer": "moving",
            "hit": false
          },
          {
            "score": 0.7896724343299866,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.7871471643447876,
            "answer": "given",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7691885828971863,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8805664777755737,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.8465210199356079,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8376972079277039,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8372223973274231,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8342397212982178,
            "answer": "granting",
            "hit": false
          },
          {
            "score": 0.8214994072914124,
            "answer": "permitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8376972079277039,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8240135908126831,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8230940699577332,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7954910397529602,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.7906213998794556,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7858084440231323,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7659599184989929,
            "answer": "exhibiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7954910397529602,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8566805720329285,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8140236139297485,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7953147888183594,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7861372828483582,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7844281196594238,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7835468053817749,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8140236437320709,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8509686589241028,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.8368517756462097,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8056074380874634,
            "answer": "urging",
            "hit": false
          },
          {
            "score": 0.7964531183242798,
            "answer": "begging",
            "hit": false
          },
          {
            "score": 0.7963433861732483,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7963338494300842,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8368517756462097,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8298916816711426,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8090358376502991,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7996625304222107,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.7836948037147522,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.7776493430137634,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.7723944187164307,
            "answer": "turning",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7996625304222107,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8212488889694214,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.817931056022644,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.8176790475845337,
            "answer": "trusting",
            "hit": false
          },
          {
            "score": 0.7990617156028748,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7979859709739685,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7892347574234009,
            "answer": "convinced",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8212489485740662,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7873882055282593,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7815349102020264,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7779384851455688,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7733876705169678,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.7727734446525574,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7710909843444824,
            "answer": "comparing",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7643294930458069,
        "b in neighbourhood of b_prime": 99,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8877526521682739,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8729190826416016,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.865155041217804,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8607455492019653,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8441291451454163,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8203017115592957,
            "answer": "containing",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8729191422462463,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8413856625556946,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8203017115592957,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7931042313575745,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7916604280471802,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.787883460521698,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.7858437299728394,
            "answer": "contains",
            "hit": true
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7858437895774841,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.838066816329956,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8253852725028992,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.8134353756904602,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.7976763248443604,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7807901501655579,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.766329824924469,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8134354054927826,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.8630783557891846,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8341835737228394,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8327044248580933,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8263276815414429,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.8261052370071411,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8230756521224976,
            "answer": "putting",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8327044248580933,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8382564783096313,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.8368527889251709,
            "answer": "regardless",
            "hit": false
          },
          {
            "score": 0.8346218466758728,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.8254799246788025,
            "answer": "unless",
            "hit": false
          },
          {
            "score": 0.8115540742874146,
            "answer": "essentially",
            "hit": false
          },
          {
            "score": 0.8115352392196655,
            "answer": "while",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.780189037322998,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 34
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8571445941925049,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8542653322219849,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.839969277381897,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.824997067451477,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8200936317443848,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.8197277188301086,
            "answer": "stating",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.839969277381897,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8299304246902466,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8193051218986511,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8078879117965698,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7782160639762878,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.7711150646209717,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7706130743026733,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8193051815032959,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8497618436813354,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8265965580940247,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.822152316570282,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.821272075176239,
            "answer": "realizing",
            "hit": false
          },
          {
            "score": 0.8180214166641235,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.8167853355407715,
            "answer": "discovered",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8497618436813354,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8465210199356079,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8396028876304626,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8309797048568726,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8105636835098267,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8086439371109009,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7908442616462708,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8396028280258179,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7888236045837402,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7567750215530396,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7491428852081299,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.730236291885376,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.7285605072975159,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7243019938468933,
            "answer": "overlapping",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7156389802694321,
        "b in neighbourhood of b_prime": 153,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8571445941925049,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8503100872039795,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.8216403126716614,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.8170735239982605,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8149421215057373,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.8141953349113464,
            "answer": "arguing",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8170735538005829,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8562406897544861,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.8380470275878906,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.8320865631103516,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.8247377872467041,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.8191478848457336,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.818657398223877,
            "answer": "however",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 62,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7562487125396729,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 63
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8795456290245056,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8444942831993103,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8293108940124512,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8155957460403442,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.7821605801582336,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.769505500793457,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8155957460403442,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.7956224679946899,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7795621156692505,
            "answer": "seeing",
            "hit": false
          },
          {
            "score": 0.761001706123352,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7566115260124207,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7462376356124878,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.745267391204834,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7419374585151672,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8430705070495605,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8413522243499756,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8320392370223999,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8228068351745605,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8163614273071289,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8124974370002747,
            "answer": "expanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.841352254152298,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7907256484031677,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7851302623748779,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7798647880554199,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.7637315988540649,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7636657357215881,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7626829147338867,
            "answer": "besides",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7851302623748779,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8378751873970032,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8286482691764832,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8139203786849976,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7970836162567139,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.7924797534942627,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7902533411979675,
            "answer": "consisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8286482989788055,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7819183468818665,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7815786600112915,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.7595869898796082,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.7589494585990906,
            "answer": "education",
            "hit": false
          },
          {
            "score": 0.7586285471916199,
            "answer": "training",
            "hit": false
          },
          {
            "score": 0.7502326965332031,
            "answer": "studying",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7321628332138062,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8325533270835876,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.7988099455833435,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7985799908638,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7942339181900024,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7736965417861938,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7708937525749207,
            "answer": "loss",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8325533270835876,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8358297944068909,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.802585780620575,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7965542078018188,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7821112871170044,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7708877325057983,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.7679303288459778,
            "answer": "controlling",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8025857210159302,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8795456290245056,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8536919355392456,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.83498615026474,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8222823143005371,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7999239563941956,
            "answer": "arising",
            "hit": false
          },
          {
            "score": 0.7936992645263672,
            "answer": "occurrence",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.83498615026474,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8135003447532654,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7860444784164429,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.782485842704773,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.762488067150116,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7239336967468262,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.7224425673484802,
            "answer": "operations",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.782485842704773,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.808701753616333,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7730848789215088,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7721884250640869,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.7653696537017822,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7590246796607971,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7454869747161865,
            "answer": "paying",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7721884250640869,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8781282305717468,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8544701337814331,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8413750529289246,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8217034935951233,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8120155930519104,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8058106303215027,
            "answer": "encouraging",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8544701337814331,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8623681664466858,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8584290146827698,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8422341346740723,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.8372223973274231,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.836929440498352,
            "answer": "delivering",
            "hit": false
          },
          {
            "score": 0.8362119197845459,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8327577710151672,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8465615510940552,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8196138739585876,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8022311925888062,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7698599696159363,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7648655772209167,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7625958919525146,
            "answer": "undergoing",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8196138739585876,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8762947916984558,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8581923246383667,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.8560550808906555,
            "answer": "lowering",
            "hit": false
          },
          {
            "score": 0.8543435335159302,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8497283458709717,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8442757725715637,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8497283756732941,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8742408752441406,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.824997067451477,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8239927291870117,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8140114545822144,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.811818540096283,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8062190413475037,
            "answer": "mentioning",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8140114545822144,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8730308413505554,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8297630548477173,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.8158742189407349,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8156640529632568,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8139203190803528,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7997742295265198,
            "answer": "related",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8158742785453796,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8293253779411316,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7835416197776794,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.77287757396698,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7656395435333252,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7412061095237732,
            "answer": "lingering",
            "hit": false
          },
          {
            "score": 0.7377855181694031,
            "answer": "remains",
            "hit": true
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7377855777740479,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8312587738037109,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.8184896111488342,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7981086373329163,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.792159914970398,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.7864760160446167,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7843104004859924,
            "answer": "indicating",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8312587141990662,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8470680713653564,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8199443221092224,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.8197484612464905,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8118282556533813,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7961112856864929,
            "answer": "restricting",
            "hit": false
          },
          {
            "score": 0.7924797534942627,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8199443817138672,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8384591937065125,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.8067822456359863,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8000922203063965,
            "answer": "startling",
            "hit": false
          },
          {
            "score": 0.7907747626304626,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7906213998794556,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7854087948799133,
            "answer": "seems",
            "hit": true
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7854087948799133,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8027817010879517,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7860742807388306,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7776009440422058,
            "answer": "staring",
            "hit": false
          },
          {
            "score": 0.7684109210968018,
            "answer": "hanging",
            "hit": false
          },
          {
            "score": 0.7484599947929382,
            "answer": "laying",
            "hit": false
          },
          {
            "score": 0.7460677623748779,
            "answer": "standing",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8027817606925964,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8071852922439575,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8019521832466125,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.7955578565597534,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7915631532669067,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7604914903640747,
            "answer": "budgets",
            "hit": false
          },
          {
            "score": 0.7492564916610718,
            "answer": "investing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8019521832466125,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8956277370452881,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8888320922851562,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.8414430022239685,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.827837347984314,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8218170404434204,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.8176966309547424,
            "answer": "noting",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8414430022239685,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8119627833366394,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8099058270454407,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8084125518798828,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8018732666969299,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7981266975402832,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7824604511260986,
            "answer": "classrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8119627833366394,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.756358802318573,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.7435359954833984,
            "answer": "bringing",
            "hit": false
          },
          {
            "score": 0.7426097989082336,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7402044534683228,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7392987608909607,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7382509708404541,
            "answer": "reading",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7352503091096878,
        "b in neighbourhood of b_prime": 152,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8131852746009827,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7945903539657593,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7606042623519897,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7598381042480469,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7586098909378052,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7533447742462158,
            "answer": "seeing",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7606042325496674,
        "b in neighbourhood of b_prime": 46,
        "b_prime in neighbourhood of b": 3
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 47,
      "accuracy": 0.1276595744680851
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "196f3e29-d6ca-4872-a136-4940bbb4baf0",
      "timestamp": "2025-05-17T20:30:18.065791"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8133938312530518,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.8016446232795715,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7949200868606567,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.7938991785049438,
            "answer": "moving",
            "hit": false
          },
          {
            "score": 0.7896724343299866,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.7871471643447876,
            "answer": "given",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8016446232795715,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8376426100730896,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8330423831939697,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8252032399177551,
            "answer": "acknowledging",
            "hit": false
          },
          {
            "score": 0.8244208097457886,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8096808195114136,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.80254727602005,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8330423533916473,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8805664777755737,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.8465210199356079,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8376972079277039,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8372223973274231,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8342397212982178,
            "answer": "granting",
            "hit": false
          },
          {
            "score": 0.8214994072914124,
            "answer": "permitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7197802364826202,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 180
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8456185460090637,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8339987993240356,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8334439396858215,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8203732967376709,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8080887794494629,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7959422469139099,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7559236586093903,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 46
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8240135908126831,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8230940699577332,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7954910397529602,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7906213998794556,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7858084440231323,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7659599184989929,
            "answer": "exhibiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8240135610103607,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8566805720329285,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8140236139297485,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7953147888183594,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7861372828483582,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7844281196594238,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7835468053817749,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7576155662536621,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 38
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8509686589241028,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.8368517756462097,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8056074380874634,
            "answer": "urging",
            "hit": false
          },
          {
            "score": 0.7964531183242798,
            "answer": "begging",
            "hit": false
          },
          {
            "score": 0.7963433861732483,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7963338494300842,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 116,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7230110466480255,
        "b in neighbourhood of b_prime": 182,
        "b_prime in neighbourhood of b": 117
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8334203958511353,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8164001107215881,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.8053422570228577,
            "answer": "visiting",
            "hit": false
          },
          {
            "score": 0.791519045829773,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.7893301248550415,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7803295254707336,
            "answer": "attendees",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8334203362464905,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8298916816711426,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8090358376502991,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7996625304222107,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7836948037147522,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.7776493430137634,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.7723944187164307,
            "answer": "turning",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 97,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7194336801767349,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 98
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7873882055282593,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7815349102020264,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7779384851455688,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7733876705169678,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.7727734446525574,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7710909843444824,
            "answer": "comparing",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7513296008110046,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8413856625556946,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8203017115592957,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7931042313575745,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7916604280471802,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.787883460521698,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.7858437299728394,
            "answer": "contains",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7931042313575745,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.838066816329956,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8253852725028992,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.8134353756904602,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7976763248443604,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7807901501655579,
            "answer": "continual",
            "hit": false
          },
          {
            "score": 0.766329824924469,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.733778640627861,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 26
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8630783557891846,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8341835737228394,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8327044248580933,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8263276815414429,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.8261052370071411,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8230756521224976,
            "answer": "putting",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 92,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7500420808792114,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 93
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8810919523239136,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8217673897743225,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.82124263048172,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8206201791763306,
            "answer": "choosing",
            "hit": false
          },
          {
            "score": 0.8081682920455933,
            "answer": "figuring",
            "hit": false
          },
          {
            "score": 0.7987930774688721,
            "answer": "selecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7888121604919434,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8571445941925049,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8542653322219849,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.839969277381897,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.824997067451477,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8200936317443848,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.8197277188301086,
            "answer": "stating",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 86,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.742821529507637,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 87
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8299304246902466,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8193051218986511,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8078879117965698,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7782160639762878,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.7711150646209717,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7706130743026733,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8299304842948914,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8817809224128723,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8505600094795227,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8170395493507385,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8168480396270752,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.809104323387146,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8090150356292725,
            "answer": "introducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7999345660209656,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7888236045837402,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7567750215530396,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.7491428852081299,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.730236291885376,
            "answer": "evolving",
            "hit": false
          },
          {
            "score": 0.7285605072975159,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.7243019938468933,
            "answer": "overlapping",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7285604774951935,
        "b in neighbourhood of b_prime": 60,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8436245322227478,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.8281023502349854,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.814634382724762,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8144391775131226,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7868679165840149,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7662090063095093,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7612251043319702,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.818784236907959,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.8065690994262695,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.8018268346786499,
            "answer": "refusing",
            "hit": false
          },
          {
            "score": 0.8004772663116455,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7985261082649231,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7717282176017761,
            "answer": "struggling",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8004772663116455,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8562406897544861,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.8380470275878906,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.8320865631103516,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.8247377872467041,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.8191478848457336,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.818657398223877,
            "answer": "however",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 99,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7438229322433472,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 100
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7956224679946899,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7795621156692505,
            "answer": "seeing",
            "hit": false
          },
          {
            "score": 0.761001706123352,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7566115260124207,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7462376356124878,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.745267391204834,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7415968477725983,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8430705070495605,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8413522243499756,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8320392370223999,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8228068351745605,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8163614273071289,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8124974370002747,
            "answer": "expanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7925735116004944,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7907256484031677,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7851302623748779,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7798647880554199,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.7637315988540649,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7636657357215881,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7626829147338867,
            "answer": "besides",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7294562608003616,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 70
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8934997320175171,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8608831167221069,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8090150356292725,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8080887794494629,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8019782304763794,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.794347882270813,
            "answer": "presenting",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 121,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7346912026405334,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 122
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8378751873970032,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8286482691764832,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8139203786849976,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7970836162567139,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.7924797534942627,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7902533411979675,
            "answer": "consisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.761563241481781,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8807564377784729,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7936803102493286,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.791789710521698,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7916192412376404,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7896648645401001,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.7883455157279968,
            "answer": "searching",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7529968023300171,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 42
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8325533270835876,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7988099455833435,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7985799908638,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7942339181900024,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7736965417861938,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7708937525749207,
            "answer": "loss",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7988099455833435,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8358297944068909,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.802585780620575,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7965542078018188,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7821112871170044,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7708877325057983,
            "answer": "administering",
            "hit": false
          },
          {
            "score": 0.7679303288459778,
            "answer": "controlling",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7821112871170044,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8953396081924438,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.821144163608551,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.819665789604187,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7913082242012024,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7781423330307007,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7769721746444702,
            "answer": "kissing",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7913082242012024,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8135003447532654,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7860444784164429,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.782485842704773,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.762488067150116,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7239336967468262,
            "answer": "operators",
            "hit": false
          },
          {
            "score": 0.7224425673484802,
            "answer": "operations",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7055741399526596,
        "b in neighbourhood of b_prime": 47,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.808701753616333,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7730848789215088,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7721884250640869,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7653696537017822,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7590246796607971,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7454869747161865,
            "answer": "paying",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.740417093038559,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8741138577461243,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8723641633987427,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8369503021240234,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8333657383918762,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.827837347984314,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8225036263465881,
            "answer": "proposals",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8163755536079407,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8623681664466858,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8584290146827698,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8422341346740723,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.8372223973274231,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.836929440498352,
            "answer": "delivering",
            "hit": false
          },
          {
            "score": 0.8362119197845459,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7938646674156189,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8119507431983948,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.8032182455062866,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7976306676864624,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7960236072540283,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7602397203445435,
            "answer": "broadcasting",
            "hit": false
          },
          {
            "score": 0.7602182626724243,
            "answer": "publication",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7504221796989441,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8465615510940552,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8196138739585876,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8022311925888062,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7698599696159363,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7648655772209167,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7625958919525146,
            "answer": "undergoing",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8022312521934509,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8762947916984558,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8581923246383667,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.8560550808906555,
            "answer": "lowering",
            "hit": false
          },
          {
            "score": 0.8543435335159302,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8497283458709717,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8442757725715637,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8188662528991699,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8730308413505554,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8297630548477173,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.8158742189407349,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8156640529632568,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8139203190803528,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7997742295265198,
            "answer": "related",
            "hit": true
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7997742295265198,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8293253779411316,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7835416197776794,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.77287757396698,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7656395435333252,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7412061095237732,
            "answer": "lingering",
            "hit": false
          },
          {
            "score": 0.7377855181694031,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7656396329402924,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8484786748886108,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8466207385063171,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.832084059715271,
            "answer": "removing",
            "hit": false
          },
          {
            "score": 0.8060039281845093,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.8010238409042358,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7930981516838074,
            "answer": "installing",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8466206789016724,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8312587738037109,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.8184896111488342,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7981086373329163,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.792159914970398,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.7864760160446167,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7843104004859924,
            "answer": "indicating",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8184896111488342,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8470680713653564,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.8199443221092224,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8197484612464905,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8118282556533813,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7961112856864929,
            "answer": "restricting",
            "hit": false
          },
          {
            "score": 0.7924797534942627,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 146,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7225217670202255,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 147
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.7778627872467041,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7699900269508362,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7507086992263794,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7496709823608398,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7473976016044617,
            "answer": "seeing",
            "hit": false
          },
          {
            "score": 0.7437587976455688,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7268335819244385,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8071852922439575,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8019521832466125,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7955578565597534,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7915631532669067,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7604914903640747,
            "answer": "budgets",
            "hit": false
          },
          {
            "score": 0.7492564916610718,
            "answer": "investing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7455409318208694,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8419610261917114,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8072408437728882,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8043478727340698,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.8001788258552551,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7929862141609192,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.789663553237915,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8072409331798553,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8119627833366394,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8099058270454407,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8084125518798828,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.8018732666969299,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7981266975402832,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7824604511260986,
            "answer": "classrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8084125518798828,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.756358802318573,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.7435359954833984,
            "answer": "bringing",
            "hit": false
          },
          {
            "score": 0.7426097989082336,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7402044534683228,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7392987608909607,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7382509708404541,
            "answer": "reading",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7146915644407272,
        "b in neighbourhood of b_prime": 153,
        "b_prime in neighbourhood of b": 35
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8131852746009827,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7945903539657593,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7606042623519897,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7598381042480469,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7586098909378052,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7533447742462158,
            "answer": "seeing",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7427008152008057,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 14
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 48,
      "accuracy": 0.0625
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "d4724522-d14c-4060-80ac-3053868482cb",
      "timestamp": "2025-05-17T20:30:18.466569"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7747567892074585,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.772689938545227,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.769188642501831,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7415338754653931,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7368216514587402,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7301548719406128,
            "answer": "expands",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7747567594051361,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8747408986091614,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8528190851211548,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8244208097457886,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8164291381835938,
            "answer": "acknowledges",
            "hit": false
          },
          {
            "score": 0.810379147529602,
            "answer": "confirms",
            "hit": false
          },
          {
            "score": 0.8068259358406067,
            "answer": "admits",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8528190851211548,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9065104126930237,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8793087005615234,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8756290674209595,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8486602306365967,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8466890454292297,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8433730602264404,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 211,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7325299829244614,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 212
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8456185460090637,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.829345166683197,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8170047998428345,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8097971081733704,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8072450160980225,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8062041401863098,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7857032418251038,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8929884433746338,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8923685550689697,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8894321918487549,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.813023567199707,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8073585629463196,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8044610619544983,
            "answer": "seem",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8923685550689697,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8803086280822754,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8140236139297485,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7986372113227844,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7951476573944092,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7897676229476929,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.787199854850769,
            "answer": "extends",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 167,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7223160862922668,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 168
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8368517756462097,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8171185851097107,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.8165292739868164,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.815101683139801,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8114275336265564,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.8079968690872192,
            "answer": "decides",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.769403338432312,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 64
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8541465997695923,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8496675491333008,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.824262261390686,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8129410147666931,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.8042036890983582,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.804093062877655,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 76,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7552210986614227,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 77
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8925979137420654,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.845437228679657,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8419104218482971,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.8388930559158325,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8356305360794067,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8349192142486572,
            "answer": "understands",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8454372584819794,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8564624786376953,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8356305360794067,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8346357345581055,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8245717287063599,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8223872184753418,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8158765435218811,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8346357345581055,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9212068319320679,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.9067868590354919,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8850575685501099,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8729192018508911,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8432273864746094,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8256129026412964,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9212068021297455,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8056542277336121,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7866798043251038,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7858437299728394,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.7687846422195435,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7637315988540649,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.752822995185852,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7687846422195435,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8821448087692261,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8134353756904602,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.8127979636192322,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8098021745681763,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.8014545440673828,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7884516716003418,
            "answer": "progresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7521759867668152,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 53
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8799015879631042,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8740875720977783,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8541377782821655,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.8450169563293457,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.841788113117218,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8352633118629456,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 187,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7439314723014832,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 188
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.89276522397995,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.891858696937561,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8714783191680908,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8645631074905396,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8223872184753418,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8220089077949524,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8714783489704132,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8837364912033081,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8481801152229309,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8459345102310181,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.8414368629455566,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.839969277381897,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8348996639251709,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7809714078903198,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 40
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8254926800727844,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.823097825050354,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.8193051815032959,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8178882598876953,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.811610221862793,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8055905103683472,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8254926800727844,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.883704423904419,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8505600094795227,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8324109315872192,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8267450332641602,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8246394395828247,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8230708837509155,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8090417087078094,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8536182641983032,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.8512351512908936,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.8388930559158325,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8350206017494202,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8158069252967834,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.814634382724762,
            "answer": "expecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7940635979175568,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.825319766998291,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.8210455179214478,
            "answer": "refuses",
            "hit": false
          },
          {
            "score": 0.8187841773033142,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8156259655952454,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.8129664659500122,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8116172552108765,
            "answer": "failures",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8156259655952454,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7952242493629456,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7562487125396729,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7481116056442261,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7402294874191284,
            "answer": "emerges",
            "hit": false
          },
          {
            "score": 0.7385327816009521,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7385186553001404,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7952242791652679,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.9005054235458374,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8799358010292053,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8663575649261475,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8155957460403442,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7985091209411621,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7961061000823975,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9005055129528046,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8441766500473022,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7756782174110413,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7752286195755005,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7566943168640137,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7484822273254395,
            "answer": "whispers",
            "hit": false
          },
          {
            "score": 0.7419373989105225,
            "answer": "hearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7756782174110413,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7866798043251038,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7851302623748779,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7793174982070923,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.776103138923645,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7584944367408752,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7548462152481079,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7297139465808868,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 37
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.9017736911773682,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.8512351512908936,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8382847905158997,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.8373184204101562,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8350863456726074,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.8308373093605042,
            "answer": "wants",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7886791527271271,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8941633105278015,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8608830571174622,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8170014023780823,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.815927267074585,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8158113956451416,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8097971081733704,
            "answer": "announces",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 100,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7576389312744141,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 101
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8940271139144897,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8555600643157959,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.8432273268699646,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.8286482691764832,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8217018842697144,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.820902943611145,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7817528247833252,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 31
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8325533270835876,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8325077891349792,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.829925000667572,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.8254698514938354,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.824262261390686,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8218103647232056,
            "answer": "lost",
            "hit": true
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8218104541301727,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8690981864929199,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8644626140594482,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8201595544815063,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.802585780620575,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7965290546417236,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7931190729141235,
            "answer": "operates",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8644626140594482,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.8982287645339966,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8875593543052673,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8799358010292053,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8427302837371826,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.83498615026474,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8199828863143921,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8875593543052673,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8997897505760193,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8275564312934875,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8249984979629517,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.818693995475769,
            "answer": "regulates",
            "hit": false
          },
          {
            "score": 0.8147779703140259,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.8140261173248291,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 110,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7596904933452606,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 111
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8693251609802246,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8109900951385498,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8057971000671387,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7980237007141113,
            "answer": "participates",
            "hit": false
          },
          {
            "score": 0.7971218824386597,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.793611466884613,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8693251609802246,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8939136266708374,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8723641037940979,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8373184204101562,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.8299245238304138,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8254379034042358,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.824966311454773,
            "answer": "seeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8299245238304138,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8921647071838379,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8895291090011597,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8756291270256042,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8579071760177612,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8478533029556274,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.8455919027328491,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8152181506156921,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8786810636520386,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8487167954444885,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8457984924316406,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.8196138739585876,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8173999786376953,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.8134335279464722,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8487167954444885,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8613799214363098,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8481801152229309,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8267989754676819,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.819049060344696,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.8190352320671082,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8140114545822144,
            "answer": "referring",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8267989754676819,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8807259202003479,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8158742189407349,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.8139026165008545,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8099035620689392,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7968924641609192,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7951476573944092,
            "answer": "applies",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7697620391845703,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8531312942504883,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8517317771911621,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8127979040145874,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.78614741563797,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7792513370513916,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.7646709084510803,
            "answer": "hasn",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8531313538551331,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8585187792778015,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8484786748886108,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8171373009681702,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7956863641738892,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.791762113571167,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7913522720336914,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8585187792778015,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8501491546630859,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8312587738037109,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.821909487247467,
            "answer": "reflects",
            "hit": false
          },
          {
            "score": 0.8200610876083374,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.8187308311462402,
            "answer": "constitutes",
            "hit": false
          },
          {
            "score": 0.8088287711143494,
            "answer": "illustrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8501491844654083,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8555600643157959,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8382769823074341,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8353570699691772,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8217385411262512,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.8199443817138672,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8190515637397766,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 92,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.749630331993103,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 93
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.9024052023887634,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8934711217880249,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8929884433746338,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8234530687332153,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.816767692565918,
            "answer": "doesn",
            "hit": false
          },
          {
            "score": 0.8164418935775757,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9024052321910858,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8780576586723328,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8173999786376953,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8144125938415527,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8083146810531616,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8012223839759827,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7973704934120178,
            "answer": "brings",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 175,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7336814701557159,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 176
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8888044357299805,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8542740345001221,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8019522428512573,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7891007661819458,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.789046049118042,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.788180410861969,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8542740345001221,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8872098922729492,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8738620281219482,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8452358245849609,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8414430022239685,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.834172248840332,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.8326635956764221,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8452358245849609,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.862478494644165,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8460108637809753,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.8301728963851929,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.8260927796363831,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8210557699203491,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.8165292739868164,
            "answer": "asks",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.862478494644165,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 11,
      "cnt_questions_total": 46,
      "accuracy": 0.2391304347826087
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "9df8c8ed-89b1-4325-9c07-f10105f03c7c",
      "timestamp": "2025-05-17T20:30:18.871534"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7670539021492004,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.7289313077926636,
            "answer": "education",
            "hit": false
          },
          {
            "score": 0.7205706238746643,
            "answer": "welcome",
            "hit": false
          },
          {
            "score": 0.720007061958313,
            "answer": "housing",
            "hit": false
          },
          {
            "score": 0.7186687588691711,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7181470394134521,
            "answer": "residence",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 3075,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6451378613710403,
        "b in neighbourhood of b_prime": 5607,
        "b_prime in neighbourhood of b": 3076
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7562350630760193,
            "answer": "rebecca",
            "hit": false
          },
          {
            "score": 0.7506512999534607,
            "answer": "esther",
            "hit": false
          },
          {
            "score": 0.7446844577789307,
            "answer": "judith",
            "hit": false
          },
          {
            "score": 0.7420084476470947,
            "answer": "theresa",
            "hit": false
          },
          {
            "score": 0.7352898716926575,
            "answer": "rachel",
            "hit": false
          },
          {
            "score": 0.7319016456604004,
            "answer": "shirley",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 357,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6713458597660065,
        "b in neighbourhood of b_prime": 5256,
        "b_prime in neighbourhood of b": 358
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "09b0cd09-3fc9-4c83-93c7-3f8c7ec3eff5",
      "timestamp": "2025-05-17T20:30:19.261802"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.7097909450531006,
            "answer": "capable",
            "hit": false
          },
          {
            "score": 0.7091525793075562,
            "answer": "incapable",
            "hit": false
          },
          {
            "score": 0.7059804201126099,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.7042508125305176,
            "answer": "guitar",
            "hit": false
          },
          {
            "score": 0.7021381258964539,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.6997940540313721,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7059803754091263,
        "b in neighbourhood of b_prime": 132,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8395746350288391,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.7997024059295654,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.7849938869476318,
            "answer": "adequate",
            "hit": false
          },
          {
            "score": 0.7831606864929199,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7769665718078613,
            "answer": "respectable",
            "hit": false
          },
          {
            "score": 0.7744772434234619,
            "answer": "tolerated",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8395746946334839,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.9052900671958923,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8073043823242188,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.807284951210022,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.8014777898788452,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7750557065010071,
            "answer": "harmed",
            "hit": false
          },
          {
            "score": 0.7735620141029358,
            "answer": "affecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.80147784948349,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.7765344381332397,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.758004903793335,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.7357280254364014,
            "answer": "effective",
            "hit": false
          },
          {
            "score": 0.7345936298370361,
            "answer": "released",
            "hit": false
          },
          {
            "score": 0.7302262783050537,
            "answer": "updated",
            "hit": false
          },
          {
            "score": 0.7266428470611572,
            "answer": "issued",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7765344381332397,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.8245025873184204,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.7808544635772705,
            "answer": "acquainted",
            "hit": false
          },
          {
            "score": 0.77568119764328,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.7610125541687012,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7594283819198608,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7567586302757263,
            "answer": "confident",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8245026469230652,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7816495895385742,
            "answer": "whenever",
            "hit": false
          },
          {
            "score": 0.779043436050415,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7716765999794006,
            "answer": "these",
            "hit": false
          },
          {
            "score": 0.7716317176818848,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.7710214257240295,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.7695144414901733,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 439,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7026179730892181,
        "b in neighbourhood of b_prime": 152,
        "b_prime in neighbourhood of b": 440
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.7509620189666748,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.7406112551689148,
            "answer": "transformed",
            "hit": false
          },
          {
            "score": 0.738068163394928,
            "answer": "shifted",
            "hit": false
          },
          {
            "score": 0.7365032434463501,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.7326520681381226,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.7320595383644104,
            "answer": "switched",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7077362537384033,
        "b in neighbourhood of b_prime": 37,
        "b_prime in neighbourhood of b": 53
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8312747478485107,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.8093091249465942,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7950555086135864,
            "answer": "confident",
            "hit": false
          },
          {
            "score": 0.778382420539856,
            "answer": "cozy",
            "hit": false
          },
          {
            "score": 0.7693631052970886,
            "answer": "luxurious",
            "hit": false
          },
          {
            "score": 0.7657908201217651,
            "answer": "accustomed",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8312748074531555,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.8604264855384827,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7867431044578552,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7599000334739685,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.741879403591156,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.7394168376922607,
            "answer": "cognition",
            "hit": false
          },
          {
            "score": 0.7367047071456909,
            "answer": "spirituality",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7297050654888153,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8355219960212708,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.808245062828064,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.7985754609107971,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7667701244354248,
            "answer": "skilled",
            "hit": false
          },
          {
            "score": 0.755280613899231,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7540764212608337,
            "answer": "employing",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8082450330257416,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.8050681352615356,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.8001547455787659,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7940636277198792,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7819880843162537,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7685283422470093,
            "answer": "projected",
            "hit": false
          },
          {
            "score": 0.7612251043319702,
            "answer": "expecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7169756889343262,
        "b in neighbourhood of b_prime": 82,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.7912589907646179,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.7544347643852234,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.7487521767616272,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.747300922870636,
            "answer": "completed",
            "hit": false
          },
          {
            "score": 0.7349848747253418,
            "answer": "finish",
            "hit": false
          },
          {
            "score": 0.7343531250953674,
            "answer": "polished",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7912589907646179,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8137789368629456,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.794152021408081,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.7847563028335571,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.7835302948951721,
            "answer": "privileged",
            "hit": false
          },
          {
            "score": 0.7518404722213745,
            "answer": "prosperous",
            "hit": false
          },
          {
            "score": 0.7471828460693359,
            "answer": "foolish",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8137789964675903,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7712708711624146,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7688949704170227,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.7580097913742065,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7530111074447632,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.7511211633682251,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7496935725212097,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7530111074447632,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.8214136362075806,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7837901711463928,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7777283191680908,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7628355026245117,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7577080726623535,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.7562466263771057,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7577081024646759,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7584505677223206,
            "answer": "notable",
            "hit": false
          },
          {
            "score": 0.7522381544113159,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7435412406921387,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.738646388053894,
            "answer": "along",
            "hit": false
          },
          {
            "score": 0.7369176745414734,
            "answer": "features",
            "hit": false
          },
          {
            "score": 0.7333933115005493,
            "answer": "following",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 94,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7025704979896545,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 95
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8503977656364441,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7763420343399048,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.7721064686775208,
            "answer": "legally",
            "hit": false
          },
          {
            "score": 0.7566026449203491,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7537071704864502,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.7474617958068848,
            "answer": "peaceful",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8503978252410889,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.7849727869033813,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7814691066741943,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7588460445404053,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.7563217878341675,
            "answer": "compensated",
            "hit": false
          },
          {
            "score": 0.7521578669548035,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.75068598985672,
            "answer": "financed",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.781469076871872,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.8268167972564697,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.7950912117958069,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7949225306510925,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.7680639624595642,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7674160003662109,
            "answer": "soothing",
            "hit": false
          },
          {
            "score": 0.765917181968689,
            "answer": "amusing",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8268167972564697,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.783327579498291,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.7804546356201172,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7774653434753418,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7668752670288086,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.752414345741272,
            "answer": "beloved",
            "hit": false
          },
          {
            "score": 0.7509875297546387,
            "answer": "prevalent",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7804546654224396,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8082910776138306,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7686644792556763,
            "answer": "predict",
            "hit": false
          },
          {
            "score": 0.7567962408065796,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.7503305673599243,
            "answer": "consistent",
            "hit": false
          },
          {
            "score": 0.7488511800765991,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.7474251389503479,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8082910776138306,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.7761961817741394,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7504221796989441,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7491811513900757,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7350747585296631,
            "answer": "authored",
            "hit": false
          },
          {
            "score": 0.7304392457008362,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.7273171544075012,
            "answer": "released",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7124606370925903,
        "b in neighbourhood of b_prime": 45,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8191365003585815,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7950650453567505,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7785040736198425,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7776215672492981,
            "answer": "rational",
            "hit": false
          },
          {
            "score": 0.7761174440383911,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7702973484992981,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8191365599632263,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.7997742295265198,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7795233130455017,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.7697620391845703,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7561427354812622,
            "answer": "linked",
            "hit": false
          },
          {
            "score": 0.7546373605728149,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7535555362701416,
            "answer": "relate",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7795233130455017,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8463107347488403,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.8134177327156067,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.8104931116104126,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.8028723001480103,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.7826648354530334,
            "answer": "trusted",
            "hit": false
          },
          {
            "score": 0.7758015394210815,
            "answer": "durable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8463107645511627,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.812063455581665,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.8006470203399658,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7792271375656128,
            "answer": "indicated",
            "hit": false
          },
          {
            "score": 0.7759623527526855,
            "answer": "defined",
            "hit": false
          },
          {
            "score": 0.7687854766845703,
            "answer": "stated",
            "hit": false
          },
          {
            "score": 0.7662063837051392,
            "answer": "prescribed",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7305339276790619,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8076921701431274,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.8075762987136841,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.800918459892273,
            "answer": "failed",
            "hit": false
          },
          {
            "score": 0.7792505621910095,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7680691480636597,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.767116367816925,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8075762987136841,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.7785387635231018,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.7652770280838013,
            "answer": "useful",
            "hit": false
          },
          {
            "score": 0.7401615977287292,
            "answer": "bought",
            "hit": false
          },
          {
            "score": 0.7383928298950195,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.7355668544769287,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.7344202995300293,
            "answer": "contains",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 74,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6976036131381989,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 75
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.8126479387283325,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7974239587783813,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7567895650863647,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.75098717212677,
            "answer": "traditional",
            "hit": false
          },
          {
            "score": 0.7462269067764282,
            "answer": "ordinary",
            "hit": false
          },
          {
            "score": 0.7419742345809937,
            "answer": "usually",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7089298069477081,
        "b in neighbourhood of b_prime": 141,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.72533118724823,
            "answer": "wished",
            "hit": false
          },
          {
            "score": 0.7227842211723328,
            "answer": "bought",
            "hit": false
          },
          {
            "score": 0.7203316688537598,
            "answer": "wanna",
            "hit": false
          },
          {
            "score": 0.7160823345184326,
            "answer": "liked",
            "hit": false
          },
          {
            "score": 0.713807225227356,
            "answer": "definitely",
            "hit": false
          },
          {
            "score": 0.7123377919197083,
            "answer": "wants",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 282,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6706028431653976,
        "b in neighbourhood of b_prime": 674,
        "b_prime in neighbourhood of b": 283
      }
    ],
    "result": {
      "cnt_questions_correct": 11,
      "cnt_questions_total": 30,
      "accuracy": 0.36666666666666664
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "b7067b14-6fde-4a42-acc4-7dd21c5d6fe0",
      "timestamp": "2025-05-17T20:30:19.288361"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.8462988138198853,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.8342611789703369,
            "answer": "however",
            "hit": false
          },
          {
            "score": 0.8335165977478027,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.8325945138931274,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.830474317073822,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.8247377872467041,
            "answer": "following",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 727,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7028996646404266,
        "b in neighbourhood of b_prime": 43,
        "b_prime in neighbourhood of b": 728
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.7851852774620056,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.7434080839157104,
            "answer": "original",
            "hit": false
          },
          {
            "score": 0.7316687107086182,
            "answer": "really",
            "hit": false
          },
          {
            "score": 0.7272080183029175,
            "answer": "specifically",
            "hit": false
          },
          {
            "score": 0.7258427143096924,
            "answer": "effective",
            "hit": false
          },
          {
            "score": 0.7257622480392456,
            "answer": "genuine",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7851852774620056,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.7760829329490662,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7477264404296875,
            "answer": "supplementary",
            "hit": false
          },
          {
            "score": 0.7468820810317993,
            "answer": "extra",
            "hit": false
          },
          {
            "score": 0.7451692819595337,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.73778235912323,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7348207831382751,
            "answer": "addition",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7451692372560501,
        "b in neighbourhood of b_prime": 86,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8408776521682739,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.827987551689148,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7789691090583801,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7789197564125061,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7634950280189514,
            "answer": "alleged",
            "hit": false
          },
          {
            "score": 0.7500138282775879,
            "answer": "unclear",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7277268767356873,
        "b in neighbourhood of b_prime": 369,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.9124805331230164,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8907606601715088,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8715381622314453,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.8688174486160278,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.838422417640686,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.8364343643188477,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8384224474430084,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7533063888549805,
            "answer": "important",
            "hit": false
          },
          {
            "score": 0.7501600980758667,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.7500609159469604,
            "answer": "critics",
            "hit": false
          },
          {
            "score": 0.7451774477958679,
            "answer": "damage",
            "hit": false
          },
          {
            "score": 0.7420514822006226,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7362711429595947,
            "answer": "certain",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7501601278781891,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.7970375418663025,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.7697429656982422,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7589067220687866,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.7583160996437073,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7535783052444458,
            "answer": "socio",
            "hit": false
          },
          {
            "score": 0.7533585429191589,
            "answer": "archaeological",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7970375418663025,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8714783191680908,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.85053950548172,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8187978267669678,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.7888121604919434,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7873486280441284,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7815225124359131,
            "answer": "concluded",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 569,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6852924525737762,
        "b in neighbourhood of b_prime": 1735,
        "b_prime in neighbourhood of b": 570
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7891318202018738,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7796145677566528,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.7709475159645081,
            "answer": "differentiated",
            "hit": false
          },
          {
            "score": 0.7700491547584534,
            "answer": "similar",
            "hit": false
          },
          {
            "score": 0.7614709138870239,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.7610738277435303,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7891318798065186,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8073572516441345,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7538925409317017,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7501548528671265,
            "answer": "electronic",
            "hit": false
          },
          {
            "score": 0.7457351088523865,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.7454224824905396,
            "answer": "digit",
            "hit": false
          },
          {
            "score": 0.7432326078414917,
            "answer": "computational",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8073572516441345,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7956430912017822,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7841298580169678,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.7790944576263428,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.754784107208252,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.7441943287849426,
            "answer": "eligible",
            "hit": false
          },
          {
            "score": 0.741523027420044,
            "answer": "adequate",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7319291234016418,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.823029100894928,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.8170126676559448,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.8137087821960449,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.7824463844299316,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.7772420644760132,
            "answer": "ecology",
            "hit": false
          },
          {
            "score": 0.7741354703903198,
            "answer": "epa",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.823029100894928,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.8207736015319824,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.8181288838386536,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.81471848487854,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.8090869784355164,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.8043274879455566,
            "answer": "comprehensive",
            "hit": false
          },
          {
            "score": 0.7976796627044678,
            "answer": "immense",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7884378135204315,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.8008877038955688,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7971535921096802,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7904067039489746,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7892906665802002,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.783327579498291,
            "answer": "popular",
            "hit": false
          },
          {
            "score": 0.7737544178962708,
            "answer": "legendary",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7591348588466644,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7885767817497253,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7882660627365112,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7874833345413208,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.7752972841262817,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.7748078107833862,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7746797800064087,
            "answer": "political",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7874833941459656,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8203617334365845,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.775618314743042,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7567777633666992,
            "answer": "globe",
            "hit": false
          },
          {
            "score": 0.7552980184555054,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.7468752264976501,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.7457907795906067,
            "answer": "international",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8203617334365845,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.8402177691459656,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.7882064580917358,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7800413966178894,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7692938446998596,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.7589067220687866,
            "answer": "cultural",
            "hit": false
          },
          {
            "score": 0.7553351521492004,
            "answer": "historically",
            "hit": true
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7553351521492004,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8044834136962891,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7972854971885681,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.7716994881629944,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.765873908996582,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.7658481597900391,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.7652803659439087,
            "answer": "tremendous",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7716995179653168,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.7757792472839355,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7587035894393921,
            "answer": "urgent",
            "hit": false
          },
          {
            "score": 0.7516508102416992,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.750555694103241,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7393285632133484,
            "answer": "initial",
            "hit": false
          },
          {
            "score": 0.7389176487922668,
            "answer": "instantly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7757792472839355,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.7750812768936157,
            "answer": "note",
            "hit": false
          },
          {
            "score": 0.7746846675872803,
            "answer": "interesting",
            "hit": false
          },
          {
            "score": 0.7730430364608765,
            "answer": "unfortunately",
            "hit": false
          },
          {
            "score": 0.769450306892395,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7633975744247437,
            "answer": "useful",
            "hit": false
          },
          {
            "score": 0.7632678151130676,
            "answer": "crucial",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7491455227136612,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 33
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.832648515701294,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.794476330280304,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.7884048223495483,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7872064113616943,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7827305197715759,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7806888818740845,
            "answer": "reducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.794476330280304,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7572909593582153,
            "answer": "irs",
            "hit": false
          },
          {
            "score": 0.7398197054862976,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.7325636148452759,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.7251710295677185,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7201233506202698,
            "answer": "integrated",
            "hit": false
          },
          {
            "score": 0.704168975353241,
            "answer": "investigation",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7398197054862976,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.75594562292099,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7457907795906067,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.7271288633346558,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7253955006599426,
            "answer": "institute",
            "hit": false
          },
          {
            "score": 0.7228741645812988,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7216740846633911,
            "answer": "european",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.75594562292099,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.8007478713989258,
            "answer": "law",
            "hit": false
          },
          {
            "score": 0.7964767217636108,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7905133962631226,
            "answer": "litigation",
            "hit": false
          },
          {
            "score": 0.788970410823822,
            "answer": "political",
            "hit": false
          },
          {
            "score": 0.7880004644393921,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7834712862968445,
            "answer": "judicial",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7880004644393921,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.7475475668907166,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7432863712310791,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7392349243164062,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.7234516143798828,
            "answer": "psychotic",
            "hit": false
          },
          {
            "score": 0.7176523804664612,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.715679943561554,
            "answer": "schizophrenia",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7475475519895554,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.8492533564567566,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8121665716171265,
            "answer": "neat",
            "hit": false
          },
          {
            "score": 0.8073068261146545,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.794787585735321,
            "answer": "cute",
            "hit": false
          },
          {
            "score": 0.7941687107086182,
            "answer": "beautiful",
            "hit": false
          },
          {
            "score": 0.7913609743118286,
            "answer": "nasty",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7896370589733124,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.827987551689148,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.8054416179656982,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.781493067741394,
            "answer": "glaring",
            "hit": false
          },
          {
            "score": 0.7737396955490112,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7677423357963562,
            "answer": "easy",
            "hit": false
          },
          {
            "score": 0.7594298720359802,
            "answer": "straightforward",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7489338964223862,
        "b in neighbourhood of b_prime": 124,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8445913791656494,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.755947470664978,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7429332733154297,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.7370074391365051,
            "answer": "emotional",
            "hit": false
          },
          {
            "score": 0.7363896369934082,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.7330085039138794,
            "answer": "mechanical",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8445914089679718,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.8355284333229065,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.813392162322998,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.8126935958862305,
            "answer": "democratic",
            "hit": false
          },
          {
            "score": 0.8028638362884521,
            "answer": "republican",
            "hit": false
          },
          {
            "score": 0.7919284701347351,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7889704704284668,
            "answer": "legal",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8133921921253204,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7729470729827881,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7700469493865967,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.7694884538650513,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7666107416152954,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7529219388961792,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.7461287975311279,
            "answer": "tangible",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7141639292240143,
        "b in neighbourhood of b_prime": 104,
        "b_prime in neighbourhood of b": 46
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8223733305931091,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.8125362396240234,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7549648880958557,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.7428470849990845,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.737031877040863,
            "answer": "predecessor",
            "hit": false
          },
          {
            "score": 0.7366370558738708,
            "answer": "predecessors",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8223733603954315,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7766910791397095,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7478389143943787,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.7446893453598022,
            "answer": "sometimes",
            "hit": false
          },
          {
            "score": 0.7393369078636169,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.7292428016662598,
            "answer": "very",
            "hit": false
          },
          {
            "score": 0.7239607572555542,
            "answer": "seldom",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7478389590978622,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.8229536414146423,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7916977405548096,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7790451049804688,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7659858465194702,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7573561668395996,
            "answer": "profound",
            "hit": false
          },
          {
            "score": 0.7539856433868408,
            "answer": "major",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7206887304782867,
        "b in neighbourhood of b_prime": 248,
        "b_prime in neighbourhood of b": 31
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8171874284744263,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.806898832321167,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.7847896218299866,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7847163677215576,
            "answer": "gender",
            "hit": false
          },
          {
            "score": 0.784565806388855,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.781341552734375,
            "answer": "sex",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.806898832321167,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.8138231039047241,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7857973575592041,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7730208039283752,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7729215621948242,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7723382711410522,
            "answer": "meaningful",
            "hit": false
          },
          {
            "score": 0.768660306930542,
            "answer": "reasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7577729821205139,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.791843056678772,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7801984548568726,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.7783622741699219,
            "answer": "reminiscent",
            "hit": false
          },
          {
            "score": 0.7700491547584534,
            "answer": "different",
            "hit": false
          },
          {
            "score": 0.7683148384094238,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7655549049377441,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7511591911315918,
        "b in neighbourhood of b_prime": 63,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.855614423751831,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.8062990307807922,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7988947629928589,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.7788648009300232,
            "answer": "robust",
            "hit": false
          },
          {
            "score": 0.7718819379806519,
            "answer": "fierce",
            "hit": false
          },
          {
            "score": 0.7713518738746643,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7598307728767395,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8573927879333496,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.8450167179107666,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7978571653366089,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.7963600158691406,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.7883358597755432,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.7682294249534607,
            "answer": "succeeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8450167775154114,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8076921701431274,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.8075762987136841,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.800918459892273,
            "answer": "failed",
            "hit": false
          },
          {
            "score": 0.7792505621910095,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7680691480636597,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.767116367816925,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8076921701431274,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.8546515107154846,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.8256118893623352,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.7868363261222839,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7778876423835754,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.75098717212677,
            "answer": "usual",
            "hit": false
          },
          {
            "score": 0.7442334294319153,
            "answer": "mainstream",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8256118893623352,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.7974239587783813,
            "answer": "usual",
            "hit": false
          },
          {
            "score": 0.7868363261222839,
            "answer": "traditional",
            "hit": false
          },
          {
            "score": 0.7679617404937744,
            "answer": "characteristic",
            "hit": false
          },
          {
            "score": 0.7616229057312012,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7515503168106079,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.7488648891448975,
            "answer": "typically",
            "hit": true
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7488648891448975,
        "b in neighbourhood of b_prime": 68,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.7960126399993896,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.7557631731033325,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.7435108423233032,
            "answer": "peculiar",
            "hit": false
          },
          {
            "score": 0.7388193607330322,
            "answer": "different",
            "hit": false
          },
          {
            "score": 0.7336915135383606,
            "answer": "innovative",
            "hit": false
          },
          {
            "score": 0.7321990132331848,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7960126399993896,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.7442651987075806,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.7406291961669922,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7254859805107117,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7223029136657715,
            "answer": "simulations",
            "hit": false
          },
          {
            "score": 0.7190394997596741,
            "answer": "physical",
            "hit": false
          },
          {
            "score": 0.718550443649292,
            "answer": "digital",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6894384920597076,
        "b in neighbourhood of b_prime": 314,
        "b_prime in neighbourhood of b": 47
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.7885484099388123,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.7574599981307983,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.7444055676460266,
            "answer": "graphics",
            "hit": false
          },
          {
            "score": 0.738005518913269,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7371503114700317,
            "answer": "graphic",
            "hit": false
          },
          {
            "score": 0.734755277633667,
            "answer": "animation",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7885484099388123,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 44,
      "accuracy": 0.3181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "1cdd4c6e-aa36-483f-ad2a-ae820a24bc90",
      "timestamp": "2025-05-17T20:30:19.542516"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.8245025873184204,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7808544635772705,
            "answer": "acquainted",
            "hit": false
          },
          {
            "score": 0.77568119764328,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.7610125541687012,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7594283819198608,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7567586302757263,
            "answer": "confident",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7304719239473343,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 33
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.8604264855384827,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7867431044578552,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7599000334739685,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.741879403591156,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.7394168376922607,
            "answer": "cognition",
            "hit": false
          },
          {
            "score": 0.7367047071456909,
            "answer": "spirituality",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8604264855384827,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7956430912017822,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7841298580169678,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7790944576263428,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.754784107208252,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.7441943287849426,
            "answer": "eligible",
            "hit": false
          },
          {
            "score": 0.741523027420044,
            "answer": "adequate",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7841298282146454,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.7712708711624146,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7688949704170227,
            "answer": "merry",
            "hit": false
          },
          {
            "score": 0.7580097913742065,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.7530111074447632,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7511211633682251,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7496935725212097,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7580098211765289,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7929527759552002,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.7838464379310608,
            "answer": "insane",
            "hit": false
          },
          {
            "score": 0.7532415986061096,
            "answer": "pissed",
            "hit": false
          },
          {
            "score": 0.7520315647125244,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.7472661733627319,
            "answer": "furious",
            "hit": false
          },
          {
            "score": 0.7327290177345276,
            "answer": "paranoid",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7520315647125244,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7875174880027771,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7451943159103394,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.7421852350234985,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.7364072799682617,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7336915135383606,
            "answer": "shame",
            "hit": false
          },
          {
            "score": 0.7310097813606262,
            "answer": "pathetic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7875174880027771,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.8229536414146423,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7916977405548096,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7790451049804688,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7659858465194702,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7573561668395996,
            "answer": "profound",
            "hit": false
          },
          {
            "score": 0.7539856433868408,
            "answer": "major",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7916977405548096,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.7930901050567627,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7796412706375122,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.7629063129425049,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7604615092277527,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.753749668598175,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7399461269378662,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7796412706375122,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 8,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "93aa86dd-928d-4785-874b-2b6dc11f9301",
      "timestamp": "2025-05-17T20:30:19.916258"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8812359571456909,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8616819381713867,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8471617698669434,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8135681748390198,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7893924713134766,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7829528450965881,
            "answer": "acknowledge",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7451696693897247,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.8381293416023254,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.8325181007385254,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8317505121231079,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8124634623527527,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.795519232749939,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7581203579902649,
            "answer": "adapt",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8124634921550751,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.8001708984375,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.74411940574646,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7348300814628601,
            "answer": "sustain",
            "hit": false
          },
          {
            "score": 0.7337706089019775,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7317423224449158,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7316213846206665,
            "answer": "tolerate",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7441193908452988,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7873882055282593,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.76761794090271,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7594759464263916,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.7553911805152893,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7509146332740784,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501175403594971,
            "answer": "consideration",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7425214052200317,
        "b in neighbourhood of b_prime": 57,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.802365779876709,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7805742025375366,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7773585319519043,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7650200724601746,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.7647693157196045,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7599952220916748,
            "answer": "seriously",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7650200724601746,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8861654996871948,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8696572184562683,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7913399934768677,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898828983306885,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7777283191680908,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7776364088058472,
            "answer": "recognize",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7704991698265076,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8243813514709473,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.7825640439987183,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.7686870694160461,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7686644792556763,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.7619775533676147,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.7437673211097717,
            "answer": "guess",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7686644792556763,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8925274610519409,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8872596621513367,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.8710021376609802,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8145929574966431,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.8023030161857605,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.7995752096176147,
            "answer": "utilize",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 51,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7253270149230957,
        "b in neighbourhood of b_prime": 57,
        "b_prime in neighbourhood of b": 52
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8229604959487915,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.8148243427276611,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.7826876044273376,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.7302911281585693,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.7229526042938232,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7222426533699036,
            "answer": "regeneration",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8229604959487915,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8568927049636841,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.7894560098648071,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7711230516433716,
            "answer": "maintain",
            "hit": false
          },
          {
            "score": 0.7555716037750244,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7398037314414978,
            "answer": "withstand",
            "hit": false
          },
          {
            "score": 0.7348300814628601,
            "answer": "afford",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 116,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6872930377721786,
        "b in neighbourhood of b_prime": 903,
        "b_prime in neighbourhood of b": 117
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8999713063240051,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8648770451545715,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.8239564895629883,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8084554076194763,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.8078441619873047,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7951550483703613,
            "answer": "varying",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 165,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7001777440309525,
        "b in neighbourhood of b_prime": 77,
        "b_prime in neighbourhood of b": 166
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 11,
      "accuracy": 0.09090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "ead342af-0ad9-4ba3-94b8-4c60ad159039",
      "timestamp": "2025-05-17T20:30:19.986223"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.789851188659668,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7771400809288025,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7725263833999634,
            "answer": "remember",
            "hit": false
          },
          {
            "score": 0.7683278918266296,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655190825462341,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7509874105453491,
            "answer": "somehow",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7324869334697723,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8786735534667969,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.8120553493499756,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7811483144760132,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7678360939025879,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.7550617456436157,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.7492936253547668,
            "answer": "constitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7465783655643463,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8809993267059326,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.8698251247406006,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.8067681789398193,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.7893384099006653,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.7731224298477173,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7705976963043213,
            "answer": "eaten",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 103,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7121397256851196,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 104
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.8033343553543091,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.7678634524345398,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.7653692960739136,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.7646871209144592,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.7598716020584106,
            "answer": "compete",
            "hit": false
          },
          {
            "score": 0.7589131593704224,
            "answer": "argued",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7316745519638062,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 24
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8650187253952026,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8554074764251709,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.7912014722824097,
            "answer": "defense",
            "hit": false
          },
          {
            "score": 0.7763418555259705,
            "answer": "oppose",
            "hit": false
          },
          {
            "score": 0.774274468421936,
            "answer": "defenses",
            "hit": false
          },
          {
            "score": 0.7730915546417236,
            "answer": "defenders",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 108,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.712995320558548,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 109
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.8089436888694763,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.8078879117965698,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.801114559173584,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7689806222915649,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7655152082443237,
            "answer": "developer",
            "hit": true
          },
          {
            "score": 0.7522775530815125,
            "answer": "developed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7655152380466461,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.876515805721283,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8689924478530884,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.86396723985672,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8415411114692688,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.838348925113678,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8255592584609985,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 334,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7022350281476974,
        "b in neighbourhood of b_prime": 27,
        "b_prime in neighbourhood of b": 335
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8854643106460571,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8792335987091064,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8693757057189941,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8239714503288269,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.8197020292282104,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7934336066246033,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 425,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.693078875541687,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 426
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7919028401374817,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7816227078437805,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.7622911930084229,
            "answer": "check",
            "hit": false
          },
          {
            "score": 0.7542133927345276,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7430704832077026,
            "answer": "more",
            "hit": false
          },
          {
            "score": 0.742680549621582,
            "answer": "tell",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7185900807380676,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 45
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8747392892837524,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.8420223593711853,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.8272646069526672,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.825629472732544,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.7602589130401611,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.750038206577301,
            "answer": "understand",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7410031855106354,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.7985239624977112,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7972870469093323,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7956781387329102,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7870676517486572,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.7542133927345276,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7495563626289368,
            "answer": "wait",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7870676517486572,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.7982137203216553,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7736964821815491,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.767993688583374,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.758047342300415,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7531151175498962,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7472254037857056,
            "answer": "have",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7257810682058334,
        "b in neighbourhood of b_prime": 17,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8690981864929199,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.853716254234314,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8358297944068909,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7727906703948975,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606361508369446,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549205422401428,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7138374298810959,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 60
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.8811901211738586,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8771398663520813,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.841106116771698,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7922847270965576,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7851663827896118,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.7838945388793945,
            "answer": "observation",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7749579846858978,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8760029077529907,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8424127697944641,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8142950534820557,
            "answer": "arrange",
            "hit": false
          },
          {
            "score": 0.8077592849731445,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.7951906323432922,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7826447486877441,
            "answer": "organizational",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8077593147754669,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.7900588512420654,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.789702832698822,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7777844667434692,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.7761020660400391,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7598533630371094,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7326408624649048,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7777844667434692,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.883453905582428,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.8023789525032043,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.7929009199142456,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7664799094200134,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.7638993263244629,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7581470608711243,
            "answer": "theology",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7929009199142456,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8944276571273804,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8781282305717468,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.834546685218811,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.833732545375824,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8177136182785034,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8074908256530762,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 68,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7405976951122284,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 69
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.8921647071838379,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8623682260513306,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8273400068283081,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.8154902458190918,
            "answer": "offer",
            "hit": false
          },
          {
            "score": 0.8132532238960266,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8005397319793701,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 569,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6812721490859985,
        "b in neighbourhood of b_prime": 895,
        "b_prime in neighbourhood of b": 570
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8227951526641846,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7960236072540283,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.794284462928772,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7909399271011353,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.7761962413787842,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.7728314995765686,
            "answer": "pub",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7909399271011353,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8786810636520386,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8574068546295166,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.8465615510940552,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7840771675109863,
            "answer": "earn",
            "hit": false
          },
          {
            "score": 0.7792286276817322,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741419076919556,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 207,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6965554505586624,
        "b in neighbourhood of b_prime": 32,
        "b_prime in neighbourhood of b": 208
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.7389698028564453,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7352645397186279,
            "answer": "terminology",
            "hit": false
          },
          {
            "score": 0.7344374060630798,
            "answer": "speech",
            "hit": false
          },
          {
            "score": 0.7294402718544006,
            "answer": "communicate",
            "hit": false
          },
          {
            "score": 0.7225757837295532,
            "answer": "peak",
            "hit": false
          },
          {
            "score": 0.7172324657440186,
            "answer": "discourse",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 1319,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.658616304397583,
        "b in neighbourhood of b_prime": 469,
        "b_prime in neighbourhood of b": 1320
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8099057674407959,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.7920910120010376,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7776774168014526,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7769609689712524,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7528445720672607,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7411012649536133,
            "answer": "curriculum",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7399468868970871,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8553212881088257,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.8477043509483337,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7855045795440674,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.7537355422973633,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7474796772003174,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7443215250968933,
            "answer": "writings",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7196433842182159,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 14
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "4059935e-e3ac-4b54-a76a-dd1723ea3e31",
      "timestamp": "2025-05-17T20:30:20.081236"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8784928321838379,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8400365114212036,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.8369956016540527,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.8270106315612793,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.7956174612045288,
            "answer": "alleging",
            "hit": false
          },
          {
            "score": 0.7925012111663818,
            "answer": "argue",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8369956016540527,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8413833379745483,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.8253170251846313,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.750001847743988,
            "answer": "appreciate",
            "hit": false
          },
          {
            "score": 0.7434136867523193,
            "answer": "devote",
            "hit": false
          },
          {
            "score": 0.7423833012580872,
            "answer": "enthusiasts",
            "hit": false
          },
          {
            "score": 0.7422032356262207,
            "answer": "praise",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8253170847892761,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8217121958732605,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.8051832914352417,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8043127059936523,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7979649901390076,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.7730880975723267,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.7526702880859375,
            "answer": "calculating",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8217122554779053,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.8821447491645813,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8460824489593506,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.838066816329956,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7716391682624817,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.768410325050354,
            "answer": "persist",
            "hit": false
          },
          {
            "score": 0.7644777894020081,
            "answer": "continuation",
            "hit": true
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7644778192043304,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8843807578086853,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.875140368938446,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.870732307434082,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.834311842918396,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.7802308797836304,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.7684003114700317,
            "answer": "specify",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8343118727207184,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8787233829498291,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8601758480072021,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8572856783866882,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.813644528388977,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.8123118877410889,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8096566200256348,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7607985734939575,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.876515805721283,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8689924478530884,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.86396723985672,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8415411114692688,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.838348925113678,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8255592584609985,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7642337083816528,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8854643106460571,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8792335987091064,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8693757057189941,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8239714503288269,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.8197020292282104,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7934336066246033,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7685581743717194,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.8269497752189636,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.7835217714309692,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.7805238366127014,
            "answer": "would",
            "hit": false
          },
          {
            "score": 0.7786827683448792,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.7707399725914001,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.767959475517273,
            "answer": "nearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 255,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7065180838108063,
        "b in neighbourhood of b_prime": 68,
        "b_prime in neighbourhood of b": 256
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8513110280036926,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.8088189363479614,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.7924565076828003,
            "answer": "provoke",
            "hit": false
          },
          {
            "score": 0.7914880514144897,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7911897301673889,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7687807679176331,
            "answer": "convince",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7914880812168121,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.8811901211738586,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8771398663520813,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.841106116771698,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7922847270965576,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7851663827896118,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.7838945388793945,
            "answer": "observation",
            "hit": true
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7838945388793945,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8963383436203003,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8586013317108154,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.844307541847229,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.790918231010437,
            "answer": "inhabit",
            "hit": false
          },
          {
            "score": 0.7825363278388977,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.7638499140739441,
            "answer": "occupations",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7825363278388977,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8760029077529907,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8424127697944641,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8142950534820557,
            "answer": "arrange",
            "hit": false
          },
          {
            "score": 0.8077592849731445,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7951906323432922,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7826447486877441,
            "answer": "organizational",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7623173892498016,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8695789575576782,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.8560336232185364,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8280866146087646,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.8253259062767029,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.7832155823707581,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7765306234359741,
            "answer": "prep",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8253259062767029,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.8099651336669922,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.7643481492996216,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.7423219084739685,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.7316914200782776,
            "answer": "protect",
            "hit": false
          },
          {
            "score": 0.7313107252120972,
            "answer": "repairing",
            "hit": false
          },
          {
            "score": 0.7311278581619263,
            "answer": "revive",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7423219531774521,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8842180967330933,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.8531013131141663,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.7780047059059143,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.7650733590126038,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7644925713539124,
            "answer": "alleviate",
            "hit": false
          },
          {
            "score": 0.7641832232475281,
            "answer": "stability",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8531013131141663,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 16,
      "accuracy": 0.0625
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "6af6bcad-70fd-45cd-a929-b1720dfe08fa",
      "timestamp": "2025-05-17T20:30:20.290444"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8457323312759399,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7993797063827515,
            "answer": "fulfill",
            "hit": false
          },
          {
            "score": 0.797417402267456,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.7972654104232788,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7923891544342041,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7912809252738953,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.797417402267456,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.7977561950683594,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7961733341217041,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7923891544342041,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7866895794868469,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7702526450157166,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7625035047531128,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7366446256637573,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.8381293416023254,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.8325181007385254,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8317505121231079,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8124634623527527,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.795519232749939,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7581203579902649,
            "answer": "adapt",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8381293416023254,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8747408986091614,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8463164567947388,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.8376426100730896,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8146569728851318,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7868318557739258,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7832311987876892,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.782015323638916,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.8795993328094482,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.856399655342102,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.7440764307975769,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.736268162727356,
            "answer": "intersect",
            "hit": false
          },
          {
            "score": 0.7359451651573181,
            "answer": "coincide",
            "hit": false
          },
          {
            "score": 0.7242767810821533,
            "answer": "conform",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8563996851444244,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8212092518806458,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.7913305759429932,
            "answer": "modify",
            "hit": false
          },
          {
            "score": 0.7706155180931091,
            "answer": "clarify",
            "hit": false
          },
          {
            "score": 0.7690081596374512,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7573710680007935,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7545443773269653,
            "answer": "amendment",
            "hit": true
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7545443773269653,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8383635878562927,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8196548223495483,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.7855234742164612,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7711190581321716,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7337155342102051,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.7316839098930359,
            "answer": "releases",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8196548521518707,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8336489200592041,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.79222571849823,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.7893868088722229,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7579070329666138,
            "answer": "designate",
            "hit": false
          },
          {
            "score": 0.7530350685119629,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7507055401802063,
            "answer": "assigns",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7893868088722229,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8891289234161377,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8551252484321594,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.8142950534820557,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.7934900522232056,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7914072275161743,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.7694354057312012,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7914072275161743,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8609716892242432,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8532692790031433,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8495540022850037,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.8351750373840332,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.834985613822937,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.8052909970283508,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8349857032299042,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.887913167476654,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.8426977396011353,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.8010732531547546,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7904415130615234,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.7556427121162415,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.7543545365333557,
            "answer": "designate",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8010733127593994,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.8659106492996216,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.8603789210319519,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.8349875211715698,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.7662383913993835,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7419564127922058,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.731924295425415,
            "answer": "engage",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7662383913993835,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.8089436888694763,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.8078879117965698,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.801114559173584,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7689806222915649,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7655152082443237,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7522775530815125,
            "answer": "developed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8089437484741211,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8802740573883057,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8146569728851318,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8102709054946899,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7898792028427124,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7702646851539612,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7618396282196045,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8102708756923676,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8907163143157959,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8900813460350037,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8492974638938904,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.834546685218811,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8242209553718567,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.812472939491272,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7885053157806396,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8760976195335388,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8415918350219727,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7777717709541321,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7708544731140137,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.7617479562759399,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7611159682273865,
            "answer": "uphold",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708544731140137,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.9038457870483398,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8818831443786621,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8631463050842285,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.7998557090759277,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.7967199087142944,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7751706838607788,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7998557388782501,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8734084367752075,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8462091684341431,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8281517028808594,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.8198781609535217,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.8195098638534546,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8164164423942566,
            "answer": "maximize",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8281517028808594,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.802365779876709,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7805742025375366,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7773585319519043,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7650200724601746,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7647693157196045,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.7599952220916748,
            "answer": "seriously",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7647693157196045,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8317208886146545,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.8103907108306885,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.7554556131362915,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7458691596984863,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7394974231719971,
            "answer": "celebrities",
            "hit": false
          },
          {
            "score": 0.7388454675674438,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.724579319357872,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8837044835090637,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8817809224128723,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8385322093963623,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7884154319763184,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7879511117935181,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7849710583686829,
            "answer": "create",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 82,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7325432896614075,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 83
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8582571148872375,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.8562915921211243,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.8441337943077087,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.8285118937492371,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.7993797063827515,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7751894593238831,
            "answer": "comply",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8285118937492371,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8296696543693542,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8195098638534546,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.8163614273071289,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8059799671173096,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8043168783187866,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7961733341217041,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7770254611968994,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.8239250779151917,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7750328779220581,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.7646598219871521,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7556890845298767,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7406778931617737,
            "answer": "investors",
            "hit": false
          },
          {
            "score": 0.7386382818222046,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7750329375267029,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8940271735191345,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8378751873970032,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7988952994346619,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7883210182189941,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867550849914551,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7864935398101807,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7559201717376709,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8690981864929199,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.853716254234314,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8358297944068909,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7727906703948975,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606361508369446,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549205422401428,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7510140538215637,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8856204152107239,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.8382808566093445,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7806763052940369,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7703158855438232,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7683603763580322,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.7672052979469299,
            "answer": "discourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8382808566093445,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.863868772983551,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.8408116698265076,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8287289142608643,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.8111598491668701,
            "answer": "undermine",
            "hit": false
          },
          {
            "score": 0.8002064228057861,
            "answer": "enhance",
            "hit": false
          },
          {
            "score": 0.7900663018226624,
            "answer": "emphasize",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8287289142608643,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.7788103222846985,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.770729660987854,
            "answer": "remove",
            "hit": false
          },
          {
            "score": 0.7621681690216064,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7580517530441284,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.7576747536659241,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.7505239248275757,
            "answer": "replacements",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7576747536659241,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.7725623846054077,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7708101272583008,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7526369094848633,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7498552203178406,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7459633946418762,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.7457940578460693,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7374425530433655,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 10
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 30,
      "accuracy": 0.06666666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "6af76fc3-8446-44d5-b8a8-1032178f88df",
      "timestamp": "2025-05-17T20:30:20.425035"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8584608435630798,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7984424829483032,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7937690019607544,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7763763666152954,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.7741377949714661,
            "answer": "rome",
            "hit": false
          },
          {
            "score": 0.7731666564941406,
            "answer": "baghdad",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8584608435630798,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.849578320980072,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8370392322540283,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.8351040482521057,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8191671371459961,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8068902492523193,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7879788875579834,
            "answer": "cairo",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8370393216609955,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.885789155960083,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.842150092124939,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.8061552047729492,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.805385410785675,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8018350005149841,
            "answer": "manila",
            "hit": false
          },
          {
            "score": 0.8011801242828369,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.885789155960083,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.8686030507087708,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.842155933380127,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.8235291838645935,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.8232085704803467,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.8166512250900269,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.8129627704620361,
            "answer": "tokyo",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8686030507087708,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.8095227479934692,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7988259196281433,
            "answer": "hamburg",
            "hit": false
          },
          {
            "score": 0.7948046326637268,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.7877218127250671,
            "answer": "frankfurt",
            "hit": false
          },
          {
            "score": 0.7873785495758057,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.786754846572876,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8095227777957916,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7242113351821899,
            "answer": "bernard",
            "hit": false
          },
          {
            "score": 0.7054066061973572,
            "answer": "bert",
            "hit": false
          },
          {
            "score": 0.7012877464294434,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.701209545135498,
            "answer": "mont",
            "hit": false
          },
          {
            "score": 0.6968568563461304,
            "answer": "wil",
            "hit": false
          },
          {
            "score": 0.6967096924781799,
            "answer": "switzerland",
            "hit": true
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6967096924781799,
        "b in neighbourhood of b_prime": 198,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8248515129089355,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.80964595079422,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.780300498008728,
            "answer": "berlin",
            "hit": false
          },
          {
            "score": 0.774908185005188,
            "answer": "amsterdam",
            "hit": false
          },
          {
            "score": 0.7729206085205078,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.7683224081993103,
            "answer": "budapest",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8248515129089355,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.8741941452026367,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.8646154999732971,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8207146525382996,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.801874041557312,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.7990772128105164,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.785260021686554,
            "answer": "helsinki",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8741941452026367,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.8488572239875793,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8253157138824463,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7913211584091187,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.7879789471626282,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7830139398574829,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7756031155586243,
            "answer": "damascus",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8488572239875793,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8445372581481934,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8358477354049683,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.8128436207771301,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8057299852371216,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7829864025115967,
            "answer": "kyoto",
            "hit": false
          },
          {
            "score": 0.7806398272514343,
            "answer": "paris",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8445373177528381,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.8256477117538452,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8191671371459961,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.81219482421875,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.808806836605072,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7802814245223999,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.7756031155586243,
            "answer": "cairo",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8256478309631348,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8373740911483765,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.8125240802764893,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.8052331209182739,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.8029779195785522,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7895952463150024,
            "answer": "edinburgh",
            "hit": false
          },
          {
            "score": 0.7853293418884277,
            "answer": "auckland",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8373740911483765,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8339910507202148,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.8241719007492065,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.8128577470779419,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7977485656738281,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.785260021686554,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.7739369869232178,
            "answer": "copenhagen",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8339909911155701,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7707877159118652,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.7368748188018799,
            "answer": "johnston",
            "hit": false
          },
          {
            "score": 0.7330948114395142,
            "answer": "richmond",
            "hit": false
          },
          {
            "score": 0.7274987101554871,
            "answer": "jacksonville",
            "hit": false
          },
          {
            "score": 0.7272815108299255,
            "answer": "ottawa",
            "hit": false
          },
          {
            "score": 0.7255947589874268,
            "answer": "nottingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7707877159118652,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8374383449554443,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.8061774969100952,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.8053951263427734,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.777259886264801,
            "answer": "amsterdam",
            "hit": false
          },
          {
            "score": 0.7759066820144653,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.7746019959449768,
            "answer": "budapest",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8374383449554443,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8412874937057495,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.8302385807037354,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.8061774969100952,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.7912907600402832,
            "answer": "valencia",
            "hit": false
          },
          {
            "score": 0.787255048751831,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7753915786743164,
            "answer": "buenos",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8302385807037354,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8581762313842773,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.8368808031082153,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.8018350601196289,
            "answer": "bangkok",
            "hit": false
          },
          {
            "score": 0.7851470708847046,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.7827513217926025,
            "answer": "tokyo",
            "hit": false
          },
          {
            "score": 0.7794315814971924,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8368808031082153,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.8615214824676514,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.850142240524292,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.8212100267410278,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8170000314712524,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8166511058807373,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.8065677881240845,
            "answer": "vladimir",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8615214824676514,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8388020992279053,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8197505474090576,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8128436803817749,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.8075076341629028,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7977485656738281,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.7841347455978394,
            "answer": "amsterdam",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8388020992279053,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.8441610336303711,
            "answer": "edmonton",
            "hit": false
          },
          {
            "score": 0.8413048982620239,
            "answer": "toronto",
            "hit": false
          },
          {
            "score": 0.8394502401351929,
            "answer": "calgary",
            "hit": false
          },
          {
            "score": 0.8318185210227966,
            "answer": "montreal",
            "hit": false
          },
          {
            "score": 0.8305830955505371,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.8232996463775635,
            "answer": "vancouver",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8018955588340759,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.8078858852386475,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7917882800102234,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.7806398272514343,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.7670405507087708,
            "answer": "brussels",
            "hit": false
          },
          {
            "score": 0.763155460357666,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.7627564072608948,
            "answer": "barcelona",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7917882800102234,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.8021582961082458,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7755997180938721,
            "answer": "romans",
            "hit": false
          },
          {
            "score": 0.7741378545761108,
            "answer": "athens",
            "hit": false
          },
          {
            "score": 0.7690008878707886,
            "answer": "vatican",
            "hit": false
          },
          {
            "score": 0.7600593566894531,
            "answer": "roman",
            "hit": false
          },
          {
            "score": 0.7585129737854004,
            "answer": "venice",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8021583259105682,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.788672685623169,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7573400139808655,
            "answer": "sanchez",
            "hit": false
          },
          {
            "score": 0.7570033073425293,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.7526850700378418,
            "answer": "francisco",
            "hit": false
          },
          {
            "score": 0.7495712041854858,
            "answer": "jorge",
            "hit": false
          },
          {
            "score": 0.7494528293609619,
            "answer": "buenos",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.788672685623169,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8470112681388855,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8274473547935486,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8128576874732971,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.8075076341629028,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8057299852371216,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.7777743935585022,
            "answer": "norway",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8470112085342407,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8771956562995911,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.870674729347229,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8351040482521057,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8212100267410278,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.808806836605072,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.7909491658210754,
            "answer": "delhi",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8771956861019135,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.856612503528595,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.8268633484840393,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.8163857460021973,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.8129627704620361,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.7881174087524414,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.7833560705184937,
            "answer": "kyoto",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8566124439239502,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8293165564537048,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.8042536973953247,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.801874041557312,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.8015913963317871,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.8014616370201111,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.7867099642753601,
            "answer": "berlin",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8293164968490601,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8388850688934326,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.8055572509765625,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.8018128871917725,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.7849991321563721,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.7824826836585999,
            "answer": "berlin",
            "hit": false
          },
          {
            "score": 0.7778785824775696,
            "answer": "moscow",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8388850390911102,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 22,
      "cnt_questions_total": 28,
      "accuracy": 0.7857142857142857
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "37a97de8-5688-4ed6-ab03-adf4f378fbb6",
      "timestamp": "2025-05-17T20:30:20.679960"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8835858106613159,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8684958815574646,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.8283562064170837,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.8282061219215393,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8225198984146118,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.8126605153083801,
            "answer": "peru",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 75,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7248109579086304,
        "b in neighbourhood of b_prime": 55,
        "b_prime in neighbourhood of b": 76
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.8912683725357056,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.8649008274078369,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.8296326994895935,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.8264927864074707,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.8204243183135986,
            "answer": "queensland",
            "hit": false
          },
          {
            "score": 0.815909743309021,
            "answer": "nsw",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 6666,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6222076341509819,
        "b in neighbourhood of b_prime": 7468,
        "b_prime in neighbourhood of b": 6667
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8649756908416748,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8499855995178223,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8293165564537048,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.8213245272636414,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.8205389976501465,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.8189868330955505,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.75029057264328,
        "b in neighbourhood of b_prime": 53,
        "b_prime in neighbourhood of b": 37
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8837974667549133,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8225198984146118,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8214658498764038,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.8112620711326599,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.8045728206634521,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8044172525405884,
            "answer": "peru",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.790737509727478,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8683274984359741,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.8441053628921509,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.8108870983123779,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.8096910119056702,
            "answer": "alberta",
            "hit": false
          },
          {
            "score": 0.8019376397132874,
            "answer": "quebec",
            "hit": false
          },
          {
            "score": 0.8018955588340759,
            "answer": "ottawa",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 65,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6441320180892944,
        "b in neighbourhood of b_prime": 2158,
        "b_prime in neighbourhood of b": 66
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8283562064170837,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8237347602844238,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8112620711326599,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.8036996126174927,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7963265180587769,
            "answer": "guatemala",
            "hit": false
          },
          {
            "score": 0.7918573021888733,
            "answer": "colombia",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7307761460542679,
        "b in neighbourhood of b_prime": 44,
        "b_prime in neighbourhood of b": 54
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8208736181259155,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8062721490859985,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8045728206634521,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.8036000728607178,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.7960973381996155,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.7918573617935181,
            "answer": "chile",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 89,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.724195122718811,
        "b in neighbourhood of b_prime": 56,
        "b_prime in neighbourhood of b": 90
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8616441488265991,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.8329229354858398,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.795096755027771,
            "answer": "castro",
            "hit": false
          },
          {
            "score": 0.7895461320877075,
            "answer": "haiti",
            "hit": false
          },
          {
            "score": 0.7887691855430603,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7857905030250549,
            "answer": "jamaica",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 78,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7175692319869995,
        "b in neighbourhood of b_prime": 72,
        "b_prime in neighbourhood of b": 79
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8135187029838562,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7927640080451965,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7729739546775818,
            "answer": "malta",
            "hit": false
          },
          {
            "score": 0.772944450378418,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7721360921859741,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7703828811645508,
            "answer": "romania",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7502648830413818,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 23
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8946475982666016,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8488572239875793,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.8008700609207153,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.7924139499664307,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7877477407455444,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7841140627861023,
            "answer": "morocco",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.74360191822052,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 45
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8128275871276855,
            "answer": "mexico",
            "hit": false
          },
          {
            "score": 0.8010612726211548,
            "answer": "haiti",
            "hit": false
          },
          {
            "score": 0.7986735701560974,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.7963265180587769,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.7910351753234863,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7904478311538696,
            "answer": "ecuador",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7011487036943436,
        "b in neighbourhood of b_prime": 103,
        "b_prime in neighbourhood of b": 180
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8951465487480164,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8771956562995911,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8221477270126343,
            "answer": "saudi",
            "hit": false
          },
          {
            "score": 0.8214038014411926,
            "answer": "iraq",
            "hit": false
          },
          {
            "score": 0.8191910982131958,
            "answer": "israel",
            "hit": false
          },
          {
            "score": 0.818351149559021,
            "answer": "syria",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7757693529129028,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8793516755104065,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8370392322540283,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8364219665527344,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8214038014411926,
            "answer": "iran",
            "hit": false
          },
          {
            "score": 0.8212410807609558,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.8077459335327148,
            "answer": "kuwait",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.741721585392952,
        "b in neighbourhood of b_prime": 42,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8796477317810059,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.8565924167633057,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.8258544206619263,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.8191910982131958,
            "answer": "iran",
            "hit": false
          },
          {
            "score": 0.8174662590026855,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.8172714710235596,
            "answer": "palestinian",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8067687153816223,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.739233672618866,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7357454895973206,
            "answer": "chad",
            "hit": false
          },
          {
            "score": 0.7270670533180237,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7223241329193115,
            "answer": "daniel",
            "hit": false
          },
          {
            "score": 0.7205753326416016,
            "answer": "kuwait",
            "hit": false
          },
          {
            "score": 0.7195542454719543,
            "answer": "israel",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 48,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6947230845689774,
        "b in neighbourhood of b_prime": 206,
        "b_prime in neighbourhood of b": 49
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8113756775856018,
            "answer": "qatar",
            "hit": false
          },
          {
            "score": 0.8077459335327148,
            "answer": "iraq",
            "hit": false
          },
          {
            "score": 0.7938128709793091,
            "answer": "saudi",
            "hit": false
          },
          {
            "score": 0.7918212413787842,
            "answer": "dubai",
            "hit": false
          },
          {
            "score": 0.7868555188179016,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7858998775482178,
            "answer": "uae",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7411026954650879,
        "b in neighbourhood of b_prime": 43,
        "b_prime in neighbourhood of b": 37
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8662835955619812,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.8463540077209473,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.8240243196487427,
            "answer": "gaza",
            "hit": false
          },
          {
            "score": 0.8169279098510742,
            "answer": "jerusalem",
            "hit": false
          },
          {
            "score": 0.8078360557556152,
            "answer": "israel",
            "hit": false
          },
          {
            "score": 0.7839373350143433,
            "answer": "lebanon",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7441652715206146,
        "b in neighbourhood of b_prime": 39,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8237347602844238,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.8127400875091553,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.8126605153083801,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8062721490859985,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8044172525405884,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.8040205836296082,
            "answer": "venezuela",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 73,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7236305773258209,
        "b in neighbourhood of b_prime": 57,
        "b_prime in neighbourhood of b": 74
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8609507083892822,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.8205390572547913,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8151775598526001,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8122354745864868,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.8030447959899902,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7995321154594421,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 71,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7283461540937424,
        "b in neighbourhood of b_prime": 108,
        "b_prime in neighbourhood of b": 72
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8680398464202881,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8364220261573792,
            "answer": "iraq",
            "hit": false
          },
          {
            "score": 0.82564777135849,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8256034851074219,
            "answer": "ukraine",
            "hit": false
          },
          {
            "score": 0.818351149559021,
            "answer": "iran",
            "hit": false
          },
          {
            "score": 0.8140336275100708,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 84,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7394193708896637,
        "b in neighbourhood of b_prime": 46,
        "b_prime in neighbourhood of b": 85
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.8200569748878479,
            "answer": "tai",
            "hit": false
          },
          {
            "score": 0.8052115440368652,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.7977597713470459,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7929595708847046,
            "answer": "singapore",
            "hit": false
          },
          {
            "score": 0.7903246283531189,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.786490797996521,
            "answer": "korea",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7650977969169617,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7248210310935974,
            "answer": "americas",
            "hit": false
          },
          {
            "score": 0.7133161425590515,
            "answer": "countries",
            "hit": false
          },
          {
            "score": 0.7123464345932007,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7118198275566101,
            "answer": "america",
            "hit": false
          },
          {
            "score": 0.7104400396347046,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.7100655436515808,
            "answer": "netherlands",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 8121,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6022518649697304,
        "b in neighbourhood of b_prime": 12057,
        "b_prime in neighbourhood of b": 8122
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8329229354858398,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.8282061219215393,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8208736181259155,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8040205836296082,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8038153648376465,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.8036996126174927,
            "answer": "chile",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 107,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7205698043107986,
        "b in neighbourhood of b_prime": 64,
        "b_prime in neighbourhood of b": 108
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 23,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "1993bd40-741d-4981-a426-f062e3f79aad",
      "timestamp": "2025-05-17T20:30:20.917345"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7986791133880615,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7608221769332886,
            "answer": "bathrooms",
            "hit": false
          },
          {
            "score": 0.7549952268600464,
            "answer": "bathroom",
            "hit": false
          },
          {
            "score": 0.7500016689300537,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.7373752593994141,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.7327073216438293,
            "answer": "bristol",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7011883556842804,
        "b in neighbourhood of b_prime": 117,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7786294221878052,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7651258111000061,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.7493096590042114,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7474689483642578,
            "answer": "birmingham",
            "hit": false
          },
          {
            "score": 0.7464557886123657,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.7417247295379639,
            "answer": "brighton",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.749309629201889,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.7955000400543213,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7923498153686523,
            "answer": "bright",
            "hit": false
          },
          {
            "score": 0.7822030186653137,
            "answer": "bristol",
            "hit": false
          },
          {
            "score": 0.7706612348556519,
            "answer": "leicester",
            "hit": false
          },
          {
            "score": 0.7657057046890259,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7657009363174438,
            "answer": "nottingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7955000996589661,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7559603452682495,
            "answer": "chassis",
            "hit": false
          },
          {
            "score": 0.7453708648681641,
            "answer": "vessel",
            "hit": false
          },
          {
            "score": 0.7359429001808167,
            "answer": "ship",
            "hit": false
          },
          {
            "score": 0.7283894419670105,
            "answer": "cockpit",
            "hit": false
          },
          {
            "score": 0.7259052991867065,
            "answer": "yacht",
            "hit": false
          },
          {
            "score": 0.7245426177978516,
            "answer": "vessels",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 629,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6680412888526917,
        "b in neighbourhood of b_prime": 1421,
        "b_prime in neighbourhood of b": 630
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8202177286148071,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8191447854042053,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.8094331622123718,
            "answer": "newcastle",
            "hit": false
          },
          {
            "score": 0.8056153059005737,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.795324981212616,
            "answer": "liverpool",
            "hit": false
          },
          {
            "score": 0.7902432680130005,
            "answer": "manchester",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8202176988124847,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.7680880427360535,
            "answer": "worcester",
            "hit": false
          },
          {
            "score": 0.758283257484436,
            "answer": "bristol",
            "hit": false
          },
          {
            "score": 0.757845401763916,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.7528232336044312,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.7516822814941406,
            "answer": "cambridge",
            "hit": false
          },
          {
            "score": 0.7481946349143982,
            "answer": "brighton",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7578453719615936,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8235995769500732,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.8191447854042053,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7884922027587891,
            "answer": "manchester",
            "hit": false
          },
          {
            "score": 0.7863576412200928,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7786871194839478,
            "answer": "glasgow",
            "hit": false
          },
          {
            "score": 0.7777620553970337,
            "answer": "birmingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7863576412200928,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7062214016914368,
            "answer": "stephens",
            "hit": false
          },
          {
            "score": 0.7000291347503662,
            "answer": "wellness",
            "hit": false
          },
          {
            "score": 0.6976410150527954,
            "answer": "erin",
            "hit": false
          },
          {
            "score": 0.6972658038139343,
            "answer": "goldman",
            "hit": false
          },
          {
            "score": 0.6956167221069336,
            "answer": "bankers",
            "hit": false
          },
          {
            "score": 0.6936556100845337,
            "answer": "webster",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 1696,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6417316943407059,
        "b in neighbourhood of b_prime": 6591,
        "b_prime in neighbourhood of b": 1697
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8200706243515015,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.8002658486366272,
            "answer": "orleans",
            "hit": false
          },
          {
            "score": 0.7975095510482788,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.773326575756073,
            "answer": "zealand",
            "hit": false
          },
          {
            "score": 0.7473559379577637,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7465800046920776,
            "answer": "toronto",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7473559677600861,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 5
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 9,
      "accuracy": 0.2222222222222222
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e4ede79c-d40e-45b7-b8c9-50f4cac36911",
      "timestamp": "2025-05-17T20:30:21.132275"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.838543713092804,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.8361579179763794,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7894826531410217,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7805496454238892,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7704048156738281,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7700984477996826,
            "answer": "philosopher",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7353281676769257,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 29
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7678574323654175,
            "answer": "augustus",
            "hit": false
          },
          {
            "score": 0.7321896553039551,
            "answer": "napoleon",
            "hit": false
          },
          {
            "score": 0.7302172183990479,
            "answer": "rome",
            "hit": false
          },
          {
            "score": 0.7243124842643738,
            "answer": "julius",
            "hit": false
          },
          {
            "score": 0.7181742191314697,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.7160414457321167,
            "answer": "pasta",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7147034406661987,
        "b in neighbourhood of b_prime": 49,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7689838409423828,
            "answer": "evolutionary",
            "hit": false
          },
          {
            "score": 0.7364785075187683,
            "answer": "evolution",
            "hit": false
          },
          {
            "score": 0.735136866569519,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7281455397605896,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.7256285548210144,
            "answer": "brisbane",
            "hit": false
          },
          {
            "score": 0.7215472459793091,
            "answer": "victorian",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 2176,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6111665666103363,
        "b in neighbourhood of b_prime": 10340,
        "b_prime in neighbourhood of b": 2177
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7405685186386108,
            "answer": "einstein",
            "hit": false
          },
          {
            "score": 0.7211678624153137,
            "answer": "tesla",
            "hit": false
          },
          {
            "score": 0.7154884338378906,
            "answer": "emerson",
            "hit": false
          },
          {
            "score": 0.713900625705719,
            "answer": "ibm",
            "hit": false
          },
          {
            "score": 0.7135789394378662,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7127174139022827,
            "answer": "princeton",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 456,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6641812175512314,
        "b in neighbourhood of b_prime": 1558,
        "b_prime in neighbourhood of b": 457
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7898617386817932,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7772128582000732,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.7659305334091187,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7604969143867493,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7574640512466431,
            "answer": "gravitational",
            "hit": false
          },
          {
            "score": 0.7569167613983154,
            "answer": "hitler",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 167,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6971053630113602,
        "b in neighbourhood of b_prime": 481,
        "b_prime in neighbourhood of b": 168
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8786312937736511,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.8463708162307739,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8154280781745911,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7820915579795837,
            "answer": "holocaust",
            "hit": false
          },
          {
            "score": 0.7801514863967896,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7789682149887085,
            "answer": "nietzsche",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.762294352054596,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7703807950019836,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7598696947097778,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7501780390739441,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7489634156227112,
            "answer": "lisa",
            "hit": false
          },
          {
            "score": 0.7479439973831177,
            "answer": "springfield",
            "hit": false
          },
          {
            "score": 0.7297233939170837,
            "answer": "troy",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7088099420070648,
        "b in neighbourhood of b_prime": 76,
        "b_prime in neighbourhood of b": 37
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7560789585113525,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7515504360198975,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7486386299133301,
            "answer": "locke",
            "hit": false
          },
          {
            "score": 0.7425802946090698,
            "answer": "metaphysical",
            "hit": false
          },
          {
            "score": 0.7425044775009155,
            "answer": "kant",
            "hit": false
          },
          {
            "score": 0.740380048751831,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 809,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6606796681880951,
        "b in neighbourhood of b_prime": 991,
        "b_prime in neighbourhood of b": 810
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7539376020431519,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7530906796455383,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7486624121665955,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7425044775009155,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7342113852500916,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7257322072982788,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 264,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6727964878082275,
        "b in neighbourhood of b_prime": 1635,
        "b_prime in neighbourhood of b": 265
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7569224834442139,
            "answer": "maxwell",
            "hit": false
          },
          {
            "score": 0.7403193712234497,
            "answer": "telescopes",
            "hit": false
          },
          {
            "score": 0.7350226044654846,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7301852703094482,
            "answer": "astronomy",
            "hit": false
          },
          {
            "score": 0.7295380234718323,
            "answer": "jupiter",
            "hit": false
          },
          {
            "score": 0.7294511795043945,
            "answer": "planets",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 3173,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6501052975654602,
        "b in neighbourhood of b_prime": 6437,
        "b_prime in neighbourhood of b": 3174
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.826930582523346,
            "answer": "marx",
            "hit": false
          },
          {
            "score": 0.7989460229873657,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7930178046226501,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7851120233535767,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.7764498591423035,
            "answer": "mao",
            "hit": false
          },
          {
            "score": 0.774420976638794,
            "answer": "putin",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7851120829582214,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.772592306137085,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7485181093215942,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7464811205863953,
            "answer": "omaha",
            "hit": false
          },
          {
            "score": 0.7395790815353394,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7365370392799377,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.732720136642456,
            "answer": "springfield",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 286,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.674325481057167,
        "b in neighbourhood of b_prime": 815,
        "b_prime in neighbourhood of b": 287
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7486386299133301,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7314013242721558,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7257094383239746,
            "answer": "newton",
            "hit": false
          },
          {
            "score": 0.7200620174407959,
            "answer": "neill",
            "hit": false
          },
          {
            "score": 0.7190818786621094,
            "answer": "burke",
            "hit": false
          },
          {
            "score": 0.7173494696617126,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 1339,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6395640224218369,
        "b in neighbourhood of b_prime": 3039,
        "b_prime in neighbourhood of b": 1340
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8704503178596497,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.826930582523346,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.799231767654419,
            "answer": "mao",
            "hit": false
          },
          {
            "score": 0.7853163480758667,
            "answer": "bourgeois",
            "hit": false
          },
          {
            "score": 0.7738949060440063,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.7706617712974548,
            "answer": "communist",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7169126570224762,
        "b in neighbourhood of b_prime": 172,
        "b_prime in neighbourhood of b": 64
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7569224834442139,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.716693639755249,
            "answer": "richardson",
            "hit": false
          },
          {
            "score": 0.7166718244552612,
            "answer": "leonard",
            "hit": false
          },
          {
            "score": 0.7155102491378784,
            "answer": "jeffrey",
            "hit": false
          },
          {
            "score": 0.7105312943458557,
            "answer": "matthew",
            "hit": false
          },
          {
            "score": 0.7101626396179199,
            "answer": "newton",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 8798,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6088107973337173,
        "b in neighbourhood of b_prime": 11979,
        "b_prime in neighbourhood of b": 8799
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7522488236427307,
            "answer": "einstein",
            "hit": false
          },
          {
            "score": 0.7257094979286194,
            "answer": "locke",
            "hit": false
          },
          {
            "score": 0.7208303213119507,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.720318078994751,
            "answer": "newman",
            "hit": false
          },
          {
            "score": 0.7201463580131531,
            "answer": "panthers",
            "hit": false
          },
          {
            "score": 0.7170885801315308,
            "answer": "cambridge",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 2772,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6124110072851181,
        "b in neighbourhood of b_prime": 10019,
        "b_prime in neighbourhood of b": 2773
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8451720476150513,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.838543713092804,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.781446635723114,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7760928869247437,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.770662248134613,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7703807950019836,
            "answer": "homer",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7279906421899796,
        "b in neighbourhood of b_prime": 44,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7875628471374512,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7620884776115417,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.7616780400276184,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7596354484558105,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7518230080604553,
            "answer": "theodore",
            "hit": false
          },
          {
            "score": 0.7428755760192871,
            "answer": "churchill",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 478,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6756521463394165,
        "b in neighbourhood of b_prime": 751,
        "b_prime in neighbourhood of b": 479
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7394613027572632,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7351294159889221,
            "answer": "weber",
            "hit": false
          },
          {
            "score": 0.7320274710655212,
            "answer": "fischer",
            "hit": false
          },
          {
            "score": 0.7293894290924072,
            "answer": "schneider",
            "hit": false
          },
          {
            "score": 0.7245316505432129,
            "answer": "walsh",
            "hit": false
          },
          {
            "score": 0.7196722030639648,
            "answer": "fritz",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 73,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6889789551496506,
        "b in neighbourhood of b_prime": 551,
        "b_prime in neighbourhood of b": 74
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 19,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "ca1b6850-82cf-4b6a-8015-effb0feb4aa8",
      "timestamp": "2025-05-17T20:30:21.214696"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.838543713092804,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.8361579179763794,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7894826531410217,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7805496454238892,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7704048156738281,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7700984477996826,
            "answer": "philosopher",
            "hit": true
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7700983881950378,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7678574323654175,
            "answer": "augustus",
            "hit": false
          },
          {
            "score": 0.7321896553039551,
            "answer": "napoleon",
            "hit": false
          },
          {
            "score": 0.7302172183990479,
            "answer": "rome",
            "hit": false
          },
          {
            "score": 0.7243124842643738,
            "answer": "julius",
            "hit": false
          },
          {
            "score": 0.7181742191314697,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.7160414457321167,
            "answer": "pasta",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7181742489337921,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7746069431304932,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.7711602449417114,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.77082359790802,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.764767050743103,
            "answer": "ohio",
            "hit": false
          },
          {
            "score": 0.7567495107650757,
            "answer": "nashville",
            "hit": false
          },
          {
            "score": 0.7508901357650757,
            "answer": "pittsburgh",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 2887,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6388952434062958,
        "b in neighbourhood of b_prime": 3883,
        "b_prime in neighbourhood of b": 2888
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7405610084533691,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7367936372756958,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7365335822105408,
            "answer": "bruno",
            "hit": false
          },
          {
            "score": 0.7347064018249512,
            "answer": "giovanni",
            "hit": false
          },
          {
            "score": 0.7335669994354248,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.7330170273780823,
            "answer": "antonio",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7101417183876038,
        "b in neighbourhood of b_prime": 203,
        "b_prime in neighbourhood of b": 43
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7405685186386108,
            "answer": "einstein",
            "hit": false
          },
          {
            "score": 0.7211678624153137,
            "answer": "tesla",
            "hit": false
          },
          {
            "score": 0.7154884338378906,
            "answer": "emerson",
            "hit": false
          },
          {
            "score": 0.713900625705719,
            "answer": "ibm",
            "hit": false
          },
          {
            "score": 0.7135789394378662,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7127174139022827,
            "answer": "princeton",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6998047530651093,
        "b in neighbourhood of b_prime": 147,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7898617386817932,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7772128582000732,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.7659305334091187,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7604969143867493,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7574640512466431,
            "answer": "gravitational",
            "hit": false
          },
          {
            "score": 0.7569167613983154,
            "answer": "hitler",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.789861798286438,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.8786312937736511,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.8463708162307739,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.8154280781745911,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7820915579795837,
            "answer": "holocaust",
            "hit": false
          },
          {
            "score": 0.7801514863967896,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7789682149887085,
            "answer": "nietzsche",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7621845901012421,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7560789585113525,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7515504360198975,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7486386299133301,
            "answer": "locke",
            "hit": false
          },
          {
            "score": 0.7425802946090698,
            "answer": "metaphysical",
            "hit": false
          },
          {
            "score": 0.7425044775009155,
            "answer": "kant",
            "hit": false
          },
          {
            "score": 0.740380048751831,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7168760895729065,
        "b in neighbourhood of b_prime": 190,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7539376020431519,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7530906796455383,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7486624121665955,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7425044775009155,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7342113852500916,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7257322072982788,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7014612853527069,
        "b in neighbourhood of b_prime": 500,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.772592306137085,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7485181093215942,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7464811205863953,
            "answer": "omaha",
            "hit": false
          },
          {
            "score": 0.7395790815353394,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7365370392799377,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.732720136642456,
            "answer": "springfield",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 542,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6641470342874527,
        "b in neighbourhood of b_prime": 307,
        "b_prime in neighbourhood of b": 543
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7486386299133301,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7314013242721558,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7257094383239746,
            "answer": "newton",
            "hit": false
          },
          {
            "score": 0.7200620174407959,
            "answer": "neill",
            "hit": false
          },
          {
            "score": 0.7190818786621094,
            "answer": "burke",
            "hit": false
          },
          {
            "score": 0.7173494696617126,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 161,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6838726997375488,
        "b in neighbourhood of b_prime": 1477,
        "b_prime in neighbourhood of b": 162
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.8704503178596497,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.826930582523346,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.799231767654419,
            "answer": "mao",
            "hit": false
          },
          {
            "score": 0.7853163480758667,
            "answer": "bourgeois",
            "hit": false
          },
          {
            "score": 0.7738949060440063,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.7706617712974548,
            "answer": "communist",
            "hit": true
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7053264081478119,
        "b in neighbourhood of b_prime": 390,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7569224834442139,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.716693639755249,
            "answer": "richardson",
            "hit": false
          },
          {
            "score": 0.7166718244552612,
            "answer": "leonard",
            "hit": false
          },
          {
            "score": 0.7155102491378784,
            "answer": "jeffrey",
            "hit": false
          },
          {
            "score": 0.7105312943458557,
            "answer": "matthew",
            "hit": false
          },
          {
            "score": 0.7101626396179199,
            "answer": "newton",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 93,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6839919984340668,
        "b in neighbourhood of b_prime": 1440,
        "b_prime in neighbourhood of b": 94
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7548673152923584,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7524567246437073,
            "answer": "abraham",
            "hit": false
          },
          {
            "score": 0.7489516139030457,
            "answer": "noah",
            "hit": false
          },
          {
            "score": 0.746626615524292,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7434895038604736,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.7428338527679443,
            "answer": "isaiah",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.735776349902153,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7735029458999634,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.7499529719352722,
            "answer": "augustus",
            "hit": false
          },
          {
            "score": 0.7493387460708618,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7464092969894409,
            "answer": "nap",
            "hit": false
          },
          {
            "score": 0.7434725165367126,
            "answer": "ottoman",
            "hit": false
          },
          {
            "score": 0.740957498550415,
            "answer": "emperor",
            "hit": true
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7409575134515762,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8451720476150513,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.838543713092804,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.781446635723114,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7760928869247437,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.770662248134613,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7703807950019836,
            "answer": "homer",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.770662248134613,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7875628471374512,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7620884776115417,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.7616780400276184,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7596354484558105,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7518230080604553,
            "answer": "theodore",
            "hit": false
          },
          {
            "score": 0.7428755760192871,
            "answer": "churchill",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 234,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6836734712123871,
        "b in neighbourhood of b_prime": 106,
        "b_prime in neighbourhood of b": 235
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7394613027572632,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7351294159889221,
            "answer": "weber",
            "hit": false
          },
          {
            "score": 0.7320274710655212,
            "answer": "fischer",
            "hit": false
          },
          {
            "score": 0.7293894290924072,
            "answer": "schneider",
            "hit": false
          },
          {
            "score": 0.7245316505432129,
            "answer": "walsh",
            "hit": false
          },
          {
            "score": 0.7196722030639648,
            "answer": "fritz",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7148965001106262,
        "b in neighbourhood of b_prime": 90,
        "b_prime in neighbourhood of b": 9
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 18,
      "accuracy": 0.1111111111111111
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e8f8a409-b578-4243-a8aa-8309a074bab7",
      "timestamp": "2025-05-17T20:30:21.411595"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8906217217445374,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.772655725479126,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7532550692558289,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7313230633735657,
            "answer": "savage",
            "hit": false
          },
          {
            "score": 0.7212951183319092,
            "answer": "beasts",
            "hit": false
          },
          {
            "score": 0.7204264998435974,
            "answer": "evolutionary",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 167,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6518498659133911,
        "b in neighbourhood of b_prime": 837,
        "b_prime in neighbourhood of b": 168
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7330707311630249,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7248003482818604,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7188956141471863,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.7122237682342529,
            "answer": "carry",
            "hit": false
          },
          {
            "score": 0.6992202401161194,
            "answer": "wolf",
            "hit": false
          },
          {
            "score": 0.6951268911361694,
            "answer": "suffer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 2935,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6221819147467613,
        "b in neighbourhood of b_prime": 4774,
        "b_prime in neighbourhood of b": 2936
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7553842663764954,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7519110441207886,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.7502435445785522,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7499003410339355,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.7457635998725891,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7440527081489563,
            "answer": "herds",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7234300822019577,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 23
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8337458968162537,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7456834316253662,
            "answer": "circus",
            "hit": false
          },
          {
            "score": 0.7362308502197266,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7314715385437012,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.731295108795166,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.727013885974884,
            "answer": "eagle",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7176014184951782,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.8990848064422607,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7587406635284424,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7519110441207886,
            "answer": "buffalo",
            "hit": false
          },
          {
            "score": 0.7452607750892639,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7419155240058899,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7395409345626831,
            "answer": "calf",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 1867,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6577426791191101,
        "b in neighbourhood of b_prime": 2315,
        "b_prime in neighbourhood of b": 1868
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7750688791275024,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7301279306411743,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7284584045410156,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7205050587654114,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7067831754684448,
            "answer": "shepherd",
            "hit": false
          },
          {
            "score": 0.7041024565696716,
            "answer": "legion",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 3614,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6309551000595093,
        "b in neighbourhood of b_prime": 2522,
        "b_prime in neighbourhood of b": 3615
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8964778780937195,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.772655725479126,
            "answer": "ape",
            "hit": false
          },
          {
            "score": 0.7614524364471436,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.734107255935669,
            "answer": "snake",
            "hit": false
          },
          {
            "score": 0.7251788973808289,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.7246631979942322,
            "answer": "puppy",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 547,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6664454638957977,
        "b in neighbourhood of b_prime": 886,
        "b_prime in neighbourhood of b": 548
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7298601865768433,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.7233399152755737,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.7198154330253601,
            "answer": "taliban",
            "hit": false
          },
          {
            "score": 0.7190453410148621,
            "answer": "raid",
            "hit": false
          },
          {
            "score": 0.7175915241241455,
            "answer": "sailor",
            "hit": false
          },
          {
            "score": 0.7163223624229431,
            "answer": "dod",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 1048,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6628120690584183,
        "b in neighbourhood of b_prime": 982,
        "b_prime in neighbourhood of b": 1049
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8074662685394287,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7679671049118042,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7634536027908325,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7574800848960876,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7515020966529846,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7489733099937439,
            "answer": "fins",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 339,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6022941917181015,
        "b in neighbourhood of b_prime": 10981,
        "b_prime in neighbourhood of b": 340
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7983801364898682,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7284584045410156,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7218694090843201,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7114556431770325,
            "answer": "tornado",
            "hit": false
          },
          {
            "score": 0.7088078260421753,
            "answer": "thunder",
            "hit": false
          },
          {
            "score": 0.7036775946617126,
            "answer": "panthers",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 3778,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6312757581472397,
        "b in neighbourhood of b_prime": 2454,
        "b_prime in neighbourhood of b": 3779
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8272721171379089,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7515020370483398,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7362308502197266,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7223042249679565,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7189440727233887,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7161855697631836,
            "answer": "maritime",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 223,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6738626509904861,
        "b in neighbourhood of b_prime": 476,
        "b_prime in neighbourhood of b": 224
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "1024618d-d203-4d1c-abb8-e6fe7193fe7c",
      "timestamp": "2025-05-17T20:30:21.572532"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7936066389083862,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.7372390627861023,
            "answer": "bird",
            "hit": false
          },
          {
            "score": 0.7314847111701965,
            "answer": "bloom",
            "hit": false
          },
          {
            "score": 0.7237539291381836,
            "answer": "node",
            "hit": false
          },
          {
            "score": 0.7219811677932739,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7188459634780884,
            "answer": "bot",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7087468206882477,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7736501693725586,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7732160687446594,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7672884464263916,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7394816875457764,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7253394722938538,
            "answer": "flight",
            "hit": false
          },
          {
            "score": 0.7240281701087952,
            "answer": "flights",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 297,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6638338416814804,
        "b in neighbourhood of b_prime": 1037,
        "b_prime in neighbourhood of b": 298
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7298601865768433,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.7233399152755737,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.7198154330253601,
            "answer": "taliban",
            "hit": false
          },
          {
            "score": 0.7190453410148621,
            "answer": "raid",
            "hit": false
          },
          {
            "score": 0.7175915241241455,
            "answer": "sailor",
            "hit": false
          },
          {
            "score": 0.7163223624229431,
            "answer": "dod",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 10304,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6223234385251999,
        "b in neighbourhood of b_prime": 9382,
        "b_prime in neighbourhood of b": 10305
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.8272721171379089,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7515020370483398,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7362308502197266,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7223042249679565,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7189440727233887,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7161855697631836,
            "answer": "maritime",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 14077,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.583480715751648,
        "b in neighbourhood of b_prime": 13715,
        "b_prime in neighbourhood of b": 14078
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "2daa76ea-8276-48d3-b9ff-9c445e349d62",
      "timestamp": "2025-05-17T20:30:21.689755"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8906217217445374,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.772655725479126,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7532550692558289,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7313230633735657,
            "answer": "savage",
            "hit": false
          },
          {
            "score": 0.7212951183319092,
            "answer": "beasts",
            "hit": false
          },
          {
            "score": 0.7204264998435974,
            "answer": "evolutionary",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 753,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6585468947887421,
        "b in neighbourhood of b_prime": 1046,
        "b_prime in neighbourhood of b": 754
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8410131335258484,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.7342949509620667,
            "answer": "batting",
            "hit": false
          },
          {
            "score": 0.7114879488945007,
            "answer": "glove",
            "hit": false
          },
          {
            "score": 0.7039625644683838,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.7012887001037598,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.7004649639129639,
            "answer": "cricket",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 574,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6420240700244904,
        "b in neighbourhood of b_prime": 2645,
        "b_prime in neighbourhood of b": 575
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7330707311630249,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7248003482818604,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.7188956141471863,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.7122237682342529,
            "answer": "carry",
            "hit": false
          },
          {
            "score": 0.6992202401161194,
            "answer": "wolf",
            "hit": false
          },
          {
            "score": 0.6951268911361694,
            "answer": "suffer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 5028,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5888113379478455,
        "b in neighbourhood of b_prime": 12612,
        "b_prime in neighbourhood of b": 5029
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.889541745185852,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8544097542762756,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7979356646537781,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7964886426925659,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7850570678710938,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.782273530960083,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 2374,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6566484570503235,
        "b in neighbourhood of b_prime": 498,
        "b_prime in neighbourhood of b": 2375
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8005574345588684,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.7980716228485107,
            "answer": "tennis",
            "hit": false
          },
          {
            "score": 0.792422354221344,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7895636558532715,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7839696407318115,
            "answer": "soccer",
            "hit": false
          },
          {
            "score": 0.7714347243309021,
            "answer": "hockey",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 7001,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.63365638256073,
        "b in neighbourhood of b_prime": 2599,
        "b_prime in neighbourhood of b": 7002
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7131459712982178,
            "answer": "claw",
            "hit": false
          },
          {
            "score": 0.7057920694351196,
            "answer": "cobb",
            "hit": false
          },
          {
            "score": 0.7028748989105225,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7022536396980286,
            "answer": "swan",
            "hit": false
          },
          {
            "score": 0.7006703615188599,
            "answer": "cousins",
            "hit": false
          },
          {
            "score": 0.7002443075180054,
            "answer": "hawks",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 2269,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6403420865535736,
        "b in neighbourhood of b_prime": 1492,
        "b_prime in neighbourhood of b": 2270
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7678199410438538,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.7461862564086914,
            "answer": "goose",
            "hit": false
          },
          {
            "score": 0.7153204679489136,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.7108490467071533,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7091005444526672,
            "answer": "bird",
            "hit": false
          },
          {
            "score": 0.707012951374054,
            "answer": "dove",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 576,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6555886566638947,
        "b in neighbourhood of b_prime": 1896,
        "b_prime in neighbourhood of b": 577
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7736501693725586,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7732160687446594,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7672884464263916,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7394816875457764,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7253394722938538,
            "answer": "flight",
            "hit": false
          },
          {
            "score": 0.7240281701087952,
            "answer": "flights",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 4343,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6309681832790375,
        "b in neighbourhood of b_prime": 3147,
        "b_prime in neighbourhood of b": 4344
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7825239896774292,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.7436252236366272,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.7252879738807678,
            "answer": "netflix",
            "hit": false
          },
          {
            "score": 0.724234402179718,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.7228754162788391,
            "answer": "dallas",
            "hit": false
          },
          {
            "score": 0.7190179824829102,
            "answer": "monday",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 3805,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6273097097873688,
        "b in neighbourhood of b_prime": 2119,
        "b_prime in neighbourhood of b": 3806
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.8504851460456848,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7513786554336548,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.7460026741027832,
            "answer": "larvae",
            "hit": false
          },
          {
            "score": 0.7402401566505432,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.7391982078552246,
            "answer": "ants",
            "hit": false
          },
          {
            "score": 0.7368488311767578,
            "answer": "mammalian",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 961,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6724270284175873,
        "b in neighbourhood of b_prime": 37,
        "b_prime in neighbourhood of b": 962
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7056499719619751,
            "answer": "lesions",
            "hit": false
          },
          {
            "score": 0.7042190432548523,
            "answer": "traitor",
            "hit": false
          },
          {
            "score": 0.7007583379745483,
            "answer": "tumor",
            "hit": false
          },
          {
            "score": 0.6956390142440796,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.6948567032814026,
            "answer": "informant",
            "hit": false
          },
          {
            "score": 0.6924858093261719,
            "answer": "spies",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 2104,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6428220868110657,
        "b in neighbourhood of b_prime": 1166,
        "b_prime in neighbourhood of b": 2105
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8964778780937195,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.772655725479126,
            "answer": "ape",
            "hit": false
          },
          {
            "score": 0.7614524364471436,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.734107255935669,
            "answer": "snake",
            "hit": false
          },
          {
            "score": 0.7251788973808289,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.7246631979942322,
            "answer": "puppy",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6791150718927383,
        "b in neighbourhood of b_prime": 54,
        "b_prime in neighbourhood of b": 180
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.786493718624115,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7375797033309937,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7191461324691772,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7173065543174744,
            "answer": "clicking",
            "hit": false
          },
          {
            "score": 0.7148341536521912,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.7113993167877197,
            "answer": "switch",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 3597,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6209591999650002,
        "b in neighbourhood of b_prime": 5886,
        "b_prime in neighbourhood of b": 3598
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7114819288253784,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.6995798349380493,
            "answer": "ratio",
            "hit": false
          },
          {
            "score": 0.698157787322998,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6875717639923096,
            "answer": "brain",
            "hit": false
          },
          {
            "score": 0.6866310834884644,
            "answer": "tad",
            "hit": false
          },
          {
            "score": 0.6865980625152588,
            "answer": "ratios",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 1033,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6177010908722878,
        "b in neighbourhood of b_prime": 6935,
        "b_prime in neighbourhood of b": 1034
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.78608238697052,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.721949577331543,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7028748989105225,
            "answer": "crow",
            "hit": false
          },
          {
            "score": 0.6990437507629395,
            "answer": "huff",
            "hit": false
          },
          {
            "score": 0.6983081102371216,
            "answer": "marion",
            "hit": false
          },
          {
            "score": 0.69731605052948,
            "answer": "bailey",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1488,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6436933130025864,
        "b in neighbourhood of b_prime": 1087,
        "b_prime in neighbourhood of b": 1489
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7983801364898682,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7284584045410156,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7218694090843201,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7114556431770325,
            "answer": "tornado",
            "hit": false
          },
          {
            "score": 0.7088078260421753,
            "answer": "thunder",
            "hit": false
          },
          {
            "score": 0.7036775946617126,
            "answer": "panthers",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 1883,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5799213722348213,
        "b in neighbourhood of b_prime": 13634,
        "b_prime in neighbourhood of b": 1884
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8272721171379089,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7515020370483398,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7362308502197266,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7223042249679565,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7189440727233887,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7161855697631836,
            "answer": "maritime",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6914990544319153,
        "b in neighbourhood of b_prime": 61,
        "b_prime in neighbourhood of b": 42
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8918856382369995,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7515065670013428,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.7412285208702087,
            "answer": "canine",
            "hit": false
          },
          {
            "score": 0.7368810176849365,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.7340153455734253,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7306146621704102,
            "answer": "wild",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 401,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6167949587106705,
        "b in neighbourhood of b_prime": 4674,
        "b_prime in neighbourhood of b": 402
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 18,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "91075379-1e9b-49e0-bbcb-ab5ae89b281a",
      "timestamp": "2025-05-17T20:30:21.753258"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7424501180648804,
            "answer": "anton",
            "hit": false
          },
          {
            "score": 0.7257693409919739,
            "answer": "ants",
            "hit": false
          },
          {
            "score": 0.7020816802978516,
            "answer": "antique",
            "hit": false
          },
          {
            "score": 0.700215220451355,
            "answer": "antonio",
            "hit": false
          },
          {
            "score": 0.6950348615646362,
            "answer": "anti",
            "hit": false
          },
          {
            "score": 0.692678689956665,
            "answer": "antennas",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6607712805271149,
        "b in neighbourhood of b_prime": 49,
        "b_prime in neighbourhood of b": 47
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7342488169670105,
            "answer": "apples",
            "hit": false
          },
          {
            "score": 0.704338550567627,
            "answer": "iphone",
            "hit": false
          },
          {
            "score": 0.7028120756149292,
            "answer": "adobe",
            "hit": false
          },
          {
            "score": 0.6979948282241821,
            "answer": "ios",
            "hit": false
          },
          {
            "score": 0.6978744864463806,
            "answer": "orange",
            "hit": true
          },
          {
            "score": 0.6965607404708862,
            "answer": "oak",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5818206965923309,
        "b in neighbourhood of b_prime": 11394,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7103623151779175,
            "answer": "plasma",
            "hit": false
          },
          {
            "score": 0.7088465690612793,
            "answer": "bloody",
            "hit": false
          },
          {
            "score": 0.7087304592132568,
            "answer": "serum",
            "hit": false
          },
          {
            "score": 0.7084784507751465,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.7083394527435303,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7077784538269043,
            "answer": "killers",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 12281,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6076931208372116,
        "b in neighbourhood of b_prime": 2980,
        "b_prime in neighbourhood of b": 12282
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.8084855079650879,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.780501663684845,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7790002226829529,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.7775859832763672,
            "answer": "onions",
            "hit": false
          },
          {
            "score": 0.7749854922294617,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7671544551849365,
            "answer": "vegetable",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 1986,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6716286391019821,
        "b in neighbourhood of b_prime": 556,
        "b_prime in neighbourhood of b": 1987
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7603187561035156,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7553327083587646,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.7509962320327759,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7341436743736267,
            "answer": "garlic",
            "hit": false
          },
          {
            "score": 0.7325150370597839,
            "answer": "vegetable",
            "hit": false
          },
          {
            "score": 0.7307660579681396,
            "answer": "fruits",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 221,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.685531884431839,
        "b in neighbourhood of b_prime": 481,
        "b_prime in neighbourhood of b": 222
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7230541110038757,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7200804352760315,
            "answer": "grapes",
            "hit": false
          },
          {
            "score": 0.7187843322753906,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7180553674697876,
            "answer": "citrus",
            "hit": false
          },
          {
            "score": 0.7155231237411499,
            "answer": "apples",
            "hit": false
          },
          {
            "score": 0.7145299911499023,
            "answer": "lemon",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 390,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6527596712112427,
        "b in neighbourhood of b_prime": 64,
        "b_prime in neighbourhood of b": 391
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8031955361366272,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7702391743659973,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.7625032663345337,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7581712007522583,
            "answer": "coconut",
            "hit": false
          },
          {
            "score": 0.7570958137512207,
            "answer": "candy",
            "hit": false
          },
          {
            "score": 0.7518594861030579,
            "answer": "cheese",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 815,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6436457931995392,
        "b in neighbourhood of b_prime": 2665,
        "b_prime in neighbourhood of b": 816
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7642141580581665,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7224096059799194,
            "answer": "storms",
            "hit": false
          },
          {
            "score": 0.7094871401786804,
            "answer": "azure",
            "hit": false
          },
          {
            "score": 0.7058202028274536,
            "answer": "disk",
            "hit": false
          },
          {
            "score": 0.7028887271881104,
            "answer": "netflix",
            "hit": false
          },
          {
            "score": 0.7018721699714661,
            "answer": "grey",
            "hit": true
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6509839743375778,
        "b in neighbourhood of b_prime": 1435,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7807660102844238,
            "answer": "fossil",
            "hit": false
          },
          {
            "score": 0.7571412324905396,
            "answer": "miners",
            "hit": false
          },
          {
            "score": 0.7558529376983643,
            "answer": "uranium",
            "hit": false
          },
          {
            "score": 0.7509163618087769,
            "answer": "timber",
            "hit": false
          },
          {
            "score": 0.7453525066375732,
            "answer": "copper",
            "hit": false
          },
          {
            "score": 0.742839515209198,
            "answer": "charcoal",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 7419,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6249695718288422,
        "b in neighbourhood of b_prime": 944,
        "b_prime in neighbourhood of b": 7420
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7702391743659973,
            "answer": "chocolate",
            "hit": false
          },
          {
            "score": 0.7687993049621582,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7673053741455078,
            "answer": "starbucks",
            "hit": false
          },
          {
            "score": 0.7621574401855469,
            "answer": "cafe",
            "hit": false
          },
          {
            "score": 0.7454344034194946,
            "answer": "tea",
            "hit": false
          },
          {
            "score": 0.743393063545227,
            "answer": "beans",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 4627,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6272202134132385,
        "b in neighbourhood of b_prime": 779,
        "b_prime in neighbourhood of b": 4628
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7826101779937744,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.733486533164978,
            "answer": "chocolate",
            "hit": false
          },
          {
            "score": 0.7274211049079895,
            "answer": "jelly",
            "hit": false
          },
          {
            "score": 0.7265588045120239,
            "answer": "coconut",
            "hit": false
          },
          {
            "score": 0.7199857831001282,
            "answer": "milk",
            "hit": false
          },
          {
            "score": 0.7187250256538391,
            "answer": "citrus",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 2694,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6493833661079407,
        "b in neighbourhood of b_prime": 1665,
        "b_prime in neighbourhood of b": 2695
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7131459712982178,
            "answer": "claw",
            "hit": false
          },
          {
            "score": 0.7057920694351196,
            "answer": "cobb",
            "hit": false
          },
          {
            "score": 0.7028748989105225,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7022536396980286,
            "answer": "swan",
            "hit": false
          },
          {
            "score": 0.7006703615188599,
            "answer": "cousins",
            "hit": false
          },
          {
            "score": 0.7002443075180054,
            "answer": "hawks",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 533,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6557799875736237,
        "b in neighbourhood of b_prime": 77,
        "b_prime in neighbourhood of b": 534
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.9334284067153931,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7745667099952698,
            "answer": "supermarket",
            "hit": false
          },
          {
            "score": 0.7635465860366821,
            "answer": "microwave",
            "hit": false
          },
          {
            "score": 0.7542246580123901,
            "answer": "grocery",
            "hit": false
          },
          {
            "score": 0.751246452331543,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.7508368492126465,
            "answer": "closet",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 6589,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.621022142469883,
        "b in neighbourhood of b_prime": 9344,
        "b_prime in neighbourhood of b": 6590
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.7273495197296143,
            "answer": "trout",
            "hit": false
          },
          {
            "score": 0.7161680459976196,
            "answer": "fish",
            "hit": false
          },
          {
            "score": 0.7072359323501587,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7069336771965027,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7062593698501587,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.705345094203949,
            "answer": "rodents",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 301,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6623205840587616,
        "b in neighbourhood of b_prime": 1149,
        "b_prime in neighbourhood of b": 302
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.8121127486228943,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7998987436294556,
            "answer": "berries",
            "hit": false
          },
          {
            "score": 0.7972304821014404,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7949100136756897,
            "answer": "wine",
            "hit": false
          },
          {
            "score": 0.7883551716804504,
            "answer": "vine",
            "hit": false
          },
          {
            "score": 0.7682049870491028,
            "answer": "apples",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 3817,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5655166655778885,
        "b in neighbourhood of b_prime": 13896,
        "b_prime in neighbourhood of b": 3818
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7744858264923096,
            "answer": "lawn",
            "hit": false
          },
          {
            "score": 0.7727773189544678,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.755894124507904,
            "answer": "grassroots",
            "hit": false
          },
          {
            "score": 0.7554070353507996,
            "answer": "pasture",
            "hit": false
          },
          {
            "score": 0.7442703247070312,
            "answer": "weeds",
            "hit": false
          },
          {
            "score": 0.7428442239761353,
            "answer": "turf",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 155,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6762742549180984,
        "b in neighbourhood of b_prime": 362,
        "b_prime in neighbourhood of b": 156
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7781237959861755,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.7663066387176514,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.7579336762428284,
            "answer": "stems",
            "hit": false
          },
          {
            "score": 0.7462586760520935,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.7393248081207275,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7370321154594421,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 1336,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6488694846630096,
        "b in neighbourhood of b_prime": 3012,
        "b_prime in neighbourhood of b": 1337
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.8347468376159668,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.7742012739181519,
            "answer": "butter",
            "hit": false
          },
          {
            "score": 0.7694905400276184,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7477273941040039,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7473963499069214,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.7403469681739807,
            "answer": "cereal",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 5156,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6329136192798615,
        "b in neighbourhood of b_prime": 5503,
        "b_prime in neighbourhood of b": 5157
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.7563844919204712,
            "answer": "parchment",
            "hit": false
          },
          {
            "score": 0.7480746507644653,
            "answer": "newspapers",
            "hit": false
          },
          {
            "score": 0.7381666898727417,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7294551134109497,
            "answer": "papers",
            "hit": false
          },
          {
            "score": 0.7236013412475586,
            "answer": "manuscript",
            "hit": false
          },
          {
            "score": 0.7145683169364929,
            "answer": "write",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 4217,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6115492209792137,
        "b in neighbourhood of b_prime": 11865,
        "b_prime in neighbourhood of b": 4218
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7643893957138062,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.7124478220939636,
            "answer": "peanut",
            "hit": false
          },
          {
            "score": 0.7107475399971008,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7092470526695251,
            "answer": "chili",
            "hit": false
          },
          {
            "score": 0.7090804576873779,
            "answer": "clare",
            "hit": false
          },
          {
            "score": 0.7065945863723755,
            "answer": "vinegar",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 266,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6221346110105515,
        "b in neighbourhood of b_prime": 1228,
        "b_prime in neighbourhood of b": 267
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8246696591377258,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.749241828918457,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7463855743408203,
            "answer": "cheese",
            "hit": false
          },
          {
            "score": 0.7444965839385986,
            "answer": "pork",
            "hit": false
          },
          {
            "score": 0.7414482235908508,
            "answer": "pumpkin",
            "hit": false
          },
          {
            "score": 0.7411379814147949,
            "answer": "banana",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 8844,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6295537203550339,
        "b in neighbourhood of b_prime": 2463,
        "b_prime in neighbourhood of b": 8845
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.78608238697052,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.721949577331543,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7028748989105225,
            "answer": "crow",
            "hit": false
          },
          {
            "score": 0.6990437507629395,
            "answer": "huff",
            "hit": false
          },
          {
            "score": 0.6983081102371216,
            "answer": "marion",
            "hit": false
          },
          {
            "score": 0.69731605052948,
            "answer": "bailey",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 425,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6575324237346649,
        "b in neighbourhood of b_prime": 59,
        "b_prime in neighbourhood of b": 426
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7656705379486084,
            "answer": "roses",
            "hit": false
          },
          {
            "score": 0.7461546659469604,
            "answer": "pink",
            "hit": true
          },
          {
            "score": 0.7404592037200928,
            "answer": "lisa",
            "hit": false
          },
          {
            "score": 0.7396928071975708,
            "answer": "rachel",
            "hit": false
          },
          {
            "score": 0.737382173538208,
            "answer": "davis",
            "hit": false
          },
          {
            "score": 0.7333420515060425,
            "answer": "kelly",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6559016704559326,
        "b in neighbourhood of b_prime": 45,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.771030843257904,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7593852281570435,
            "answer": "yang",
            "hit": false
          },
          {
            "score": 0.7393165826797485,
            "answer": "scala",
            "hit": false
          },
          {
            "score": 0.7378989458084106,
            "answer": "blake",
            "hit": false
          },
          {
            "score": 0.7353667616844177,
            "answer": "php",
            "hit": false
          },
          {
            "score": 0.7269272208213806,
            "answer": "julia",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 167,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6725516766309738,
        "b in neighbourhood of b_prime": 17,
        "b_prime in neighbourhood of b": 168
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7822753190994263,
            "answer": "utah",
            "hit": false
          },
          {
            "score": 0.7725770473480225,
            "answer": "salts",
            "hit": false
          },
          {
            "score": 0.7538676261901855,
            "answer": "sodium",
            "hit": false
          },
          {
            "score": 0.7392193078994751,
            "answer": "chloride",
            "hit": false
          },
          {
            "score": 0.7373618483543396,
            "answer": "philadelphia",
            "hit": false
          },
          {
            "score": 0.7369484305381775,
            "answer": "kansas",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 3322,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6575427800416946,
        "b in neighbourhood of b_prime": 795,
        "b_prime in neighbourhood of b": 3323
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.8247000575065613,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7876670360565186,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7542566061019897,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7526460886001587,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7473565936088562,
            "answer": "shore",
            "hit": false
          },
          {
            "score": 0.7466211318969727,
            "answer": "mediterranean",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 218,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6517921984195709,
        "b in neighbourhood of b_prime": 229,
        "b_prime in neighbourhood of b": 219
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7332866787910461,
            "answer": "skies",
            "hit": false
          },
          {
            "score": 0.7038885951042175,
            "answer": "shadow",
            "hit": false
          },
          {
            "score": 0.6996521353721619,
            "answer": "thunder",
            "hit": false
          },
          {
            "score": 0.6948519945144653,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.6911584138870239,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.6895633339881897,
            "answer": "dream",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6792826950550079,
        "b in neighbourhood of b_prime": 41,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7612314820289612,
            "answer": "skiing",
            "hit": false
          },
          {
            "score": 0.7550815343856812,
            "answer": "precipitation",
            "hit": false
          },
          {
            "score": 0.7538591623306274,
            "answer": "frost",
            "hit": false
          },
          {
            "score": 0.7458751797676086,
            "answer": "rains",
            "hit": false
          },
          {
            "score": 0.7422010898590088,
            "answer": "ski",
            "hit": false
          },
          {
            "score": 0.7379704713821411,
            "answer": "sand",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 730,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6549628376960754,
        "b in neighbourhood of b_prime": 1010,
        "b_prime in neighbourhood of b": 731
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.8780450820922852,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7493541836738586,
            "answer": "terrain",
            "hit": false
          },
          {
            "score": 0.7483053207397461,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.7475870251655579,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.7465181946754456,
            "answer": "turf",
            "hit": false
          },
          {
            "score": 0.7412917613983154,
            "answer": "sediment",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 4993,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5933454111218452,
        "b in neighbourhood of b_prime": 8526,
        "b_prime in neighbourhood of b": 4994
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7382913827896118,
            "answer": "honey",
            "hit": false
          },
          {
            "score": 0.7302582263946533,
            "answer": "sweetness",
            "hit": false
          },
          {
            "score": 0.7299666404724121,
            "answer": "coconut",
            "hit": false
          },
          {
            "score": 0.7295008897781372,
            "answer": "soda",
            "hit": false
          },
          {
            "score": 0.7273547053337097,
            "answer": "syrup",
            "hit": false
          },
          {
            "score": 0.7273042798042297,
            "answer": "glucose",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 2379,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6440605074167252,
        "b in neighbourhood of b_prime": 2586,
        "b_prime in neighbourhood of b": 2380
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7371383905410767,
            "answer": "sunlight",
            "hit": false
          },
          {
            "score": 0.7229438424110413,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.7172907590866089,
            "answer": "sunshine",
            "hit": false
          },
          {
            "score": 0.7125904560089111,
            "answer": "sunset",
            "hit": false
          },
          {
            "score": 0.7021886110305786,
            "answer": "sunny",
            "hit": false
          },
          {
            "score": 0.7013869881629944,
            "answer": "morning",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 182,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.667124018073082,
        "b in neighbourhood of b_prime": 1966,
        "b_prime in neighbourhood of b": 183
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7034039497375488,
            "answer": "wan",
            "hit": false
          },
          {
            "score": 0.7028898000717163,
            "answer": "allan",
            "hit": false
          },
          {
            "score": 0.70278400182724,
            "answer": "thames",
            "hit": false
          },
          {
            "score": 0.7022536396980286,
            "answer": "crow",
            "hit": false
          },
          {
            "score": 0.6973717212677002,
            "answer": "natalie",
            "hit": false
          },
          {
            "score": 0.6973248720169067,
            "answer": "shepherd",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 1703,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6359538435935974,
        "b in neighbourhood of b_prime": 4563,
        "b_prime in neighbourhood of b": 1704
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7454344034194946,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.7375285625457764,
            "answer": "herbal",
            "hit": false
          },
          {
            "score": 0.7364635467529297,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.734384298324585,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.7313701510429382,
            "answer": "tobacco",
            "hit": false
          },
          {
            "score": 0.7312717437744141,
            "answer": "dinner",
            "hit": false
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 911,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6162877529859543,
        "b in neighbourhood of b_prime": 2010,
        "b_prime in neighbourhood of b": 912
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.9140876531600952,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.797842800617218,
            "answer": "vegetable",
            "hit": false
          },
          {
            "score": 0.7966213822364807,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.780501663684845,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7771079540252686,
            "answer": "garlic",
            "hit": false
          },
          {
            "score": 0.7764019966125488,
            "answer": "pasta",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 9043,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6360117197036743,
        "b in neighbourhood of b_prime": 233,
        "b_prime in neighbourhood of b": 9044
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 34,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "d1393e8b-9cce-422c-80a4-b3df1bcc9eab",
      "timestamp": "2025-05-17T20:30:21.960507"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.8972555994987488,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.896757185459137,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.8014159202575684,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.8009560108184814,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7908705472946167,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.7779818177223206,
            "answer": "musician",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.896757185459137,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.7851184606552124,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7758219838142395,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.7665246725082397,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.7650551795959473,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.7502753734588623,
            "answer": "teenage",
            "hit": false
          },
          {
            "score": 0.7477675676345825,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7650551795959473,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.8166481256484985,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7738974094390869,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7651979923248291,
            "answer": "sisters",
            "hit": false
          },
          {
            "score": 0.7621262669563293,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.7565014362335205,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7554067373275757,
            "answer": "brethren",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7455470114946365,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.7728713750839233,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.7173962593078613,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6889771819114685,
            "answer": "ticket",
            "hit": false
          },
          {
            "score": 0.6841897964477539,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.6820675134658813,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.6808903217315674,
            "answer": "buddy",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 2330,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6341746300458908,
        "b in neighbourhood of b_prime": 5820,
        "b_prime in neighbourhood of b": 2331
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.7615097165107727,
            "answer": "bullying",
            "hit": false
          },
          {
            "score": 0.7336772680282593,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.7234790325164795,
            "answer": "bully",
            "hit": false
          },
          {
            "score": 0.6966440677642822,
            "answer": "cow",
            "hit": true
          },
          {
            "score": 0.6950106024742126,
            "answer": "wolf",
            "hit": false
          },
          {
            "score": 0.6946077346801758,
            "answer": "discrimination",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6966440826654434,
        "b in neighbourhood of b_prime": 73,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.8939676880836487,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8777536153793335,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.8132921457290649,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.8084985613822937,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8041914701461792,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7980859279632568,
            "answer": "mum",
            "hit": true
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8777536153793335,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7657560110092163,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.7461432218551636,
            "answer": "durham",
            "hit": false
          },
          {
            "score": 0.7455056309700012,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.7249541282653809,
            "answer": "yale",
            "hit": false
          },
          {
            "score": 0.7194619178771973,
            "answer": "virginia",
            "hit": false
          },
          {
            "score": 0.7163400650024414,
            "answer": "baron",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7657560110092163,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.8939676880836487,
            "answer": "dad",
            "hit": false
          },
          {
            "score": 0.8505324125289917,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8422455787658691,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.833926796913147,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.8112624287605286,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7985389232635498,
            "answer": "mom",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7497197538614273,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7950475215911865,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.7875803709030151,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7647862434387207,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7631452083587646,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.7617762088775635,
            "answer": "prayed",
            "hit": false
          },
          {
            "score": 0.7571421265602112,
            "answer": "theology",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7449439167976379,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8838671445846558,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8698412775993347,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.8422455787658691,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8260378837585449,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8084985613822937,
            "answer": "dad",
            "hit": false
          },
          {
            "score": 0.8055385947227478,
            "answer": "uncle",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8838671147823334,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.7227199673652649,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7219223976135254,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7139806151390076,
            "answer": "wedding",
            "hit": false
          },
          {
            "score": 0.7112700939178467,
            "answer": "mentor",
            "hit": false
          },
          {
            "score": 0.7091072797775269,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7082183957099915,
            "answer": "marrying",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.721922367811203,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.862072229385376,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8358153700828552,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.8294909000396729,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.8138841390609741,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7902100682258606,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7797800898551941,
            "answer": "lover",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8294909596443176,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.775312602519989,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.7735084295272827,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.7663528919219971,
            "answer": "kingdom",
            "hit": false
          },
          {
            "score": 0.7475176453590393,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.7360354661941528,
            "answer": "royal",
            "hit": false
          },
          {
            "score": 0.7309850454330444,
            "answer": "knight",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7753126621246338,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.7436761856079102,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.7275983095169067,
            "answer": "people",
            "hit": false
          },
          {
            "score": 0.7166541218757629,
            "answer": "manning",
            "hit": false
          },
          {
            "score": 0.7159970998764038,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.7119538187980652,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.7113150358200073,
            "answer": "boy",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7436761856079102,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.8860206007957458,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8705562949180603,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8205149173736572,
            "answer": "uncle",
            "hit": false
          },
          {
            "score": 0.8204497694969177,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.8039815425872803,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7937080264091492,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8860206604003906,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8785057663917542,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7810510993003845,
            "answer": "royal",
            "hit": false
          },
          {
            "score": 0.7699588537216187,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.7610964775085449,
            "answer": "lord",
            "hit": false
          },
          {
            "score": 0.7596173882484436,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.756859540939331,
            "answer": "monarch",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7596173882484436,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.7022137641906738,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.7001838684082031,
            "answer": "star",
            "hit": false
          },
          {
            "score": 0.6971074938774109,
            "answer": "steven",
            "hit": false
          },
          {
            "score": 0.6965665221214294,
            "answer": "san",
            "hit": false
          },
          {
            "score": 0.695421576499939,
            "answer": "les",
            "hit": false
          },
          {
            "score": 0.6949844360351562,
            "answer": "person",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 120,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6700820624828339,
        "b in neighbourhood of b_prime": 539,
        "b_prime in neighbourhood of b": 121
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8205149173736572,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.805538535118103,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7954694032669067,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7894691228866577,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.782800555229187,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7810806035995483,
            "answer": "father",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 1300,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6543435156345367,
        "b in neighbourhood of b_prime": 502,
        "b_prime in neighbourhood of b": 1301
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "13f0b7c8-e329-4d75-be39-fc4ba5f21795",
      "timestamp": "2025-05-17T20:30:22.358708"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7545225620269775,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.7498325705528259,
            "answer": "attitude",
            "hit": false
          },
          {
            "score": 0.7453991174697876,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.7364128828048706,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.7333406209945679,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.7271804809570312,
            "answer": "spectacle",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6538118571043015,
        "b in neighbourhood of b_prime": 199,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.794264554977417,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.7142331600189209,
            "answer": "backpack",
            "hit": false
          },
          {
            "score": 0.714061975479126,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.7130440473556519,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.7089252471923828,
            "answer": "bike",
            "hit": false
          },
          {
            "score": 0.7061046361923218,
            "answer": "basket",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 103,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6712280660867691,
        "b in neighbourhood of b_prime": 636,
        "b_prime in neighbourhood of b": 104
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7142021059989929,
            "answer": "facial",
            "hit": false
          },
          {
            "score": 0.710418701171875,
            "answer": "burns",
            "hit": false
          },
          {
            "score": 0.7070984840393066,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.7056534886360168,
            "answer": "barbecue",
            "hit": false
          },
          {
            "score": 0.7056361436843872,
            "answer": "scars",
            "hit": false
          },
          {
            "score": 0.705542802810669,
            "answer": "cock",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7070984989404678,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.756023108959198,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.7113367319107056,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.6903849244117737,
            "answer": "somebody",
            "hit": false
          },
          {
            "score": 0.6887375712394714,
            "answer": "limbs",
            "hit": false
          },
          {
            "score": 0.686669111251831,
            "answer": "place",
            "hit": false
          },
          {
            "score": 0.6860435009002686,
            "answer": "abdominal",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6318655908107758,
        "b in neighbourhood of b_prime": 7044,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.8077297210693359,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7799417972564697,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7579388618469238,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7442437410354614,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.7364237904548645,
            "answer": "robes",
            "hit": false
          },
          {
            "score": 0.7357600927352905,
            "answer": "boot",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 65,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6944775283336639,
        "b in neighbourhood of b_prime": 144,
        "b_prime in neighbourhood of b": 66
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.9133611917495728,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7598277926445007,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7576481699943542,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.757048487663269,
            "answer": "cans",
            "hit": false
          },
          {
            "score": 0.7570006251335144,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7560520172119141,
            "answer": "vodka",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 166,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6725435256958008,
        "b in neighbourhood of b_prime": 64,
        "b_prime in neighbourhood of b": 167
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8966180086135864,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7593796253204346,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7239134311676025,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.7210500240325928,
            "answer": "spoon",
            "hit": false
          },
          {
            "score": 0.7207545042037964,
            "answer": "pitcher",
            "hit": false
          },
          {
            "score": 0.712388813495636,
            "answer": "pitchers",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 576,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6237703412771225,
        "b in neighbourhood of b_prime": 6558,
        "b_prime in neighbourhood of b": 577
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.7587792873382568,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7557521462440491,
            "answer": "cock",
            "hit": false
          },
          {
            "score": 0.7547875642776489,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.7535842657089233,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7535315752029419,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7435939311981201,
            "answer": "champagne",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7034143805503845,
        "b in neighbourhood of b_prime": 72,
        "b_prime in neighbourhood of b": 46
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7355085611343384,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.7308816313743591,
            "answer": "couch",
            "hit": false
          },
          {
            "score": 0.7293162941932678,
            "answer": "laptop",
            "hit": false
          },
          {
            "score": 0.7226908802986145,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.7218449115753174,
            "answer": "table",
            "hit": false
          },
          {
            "score": 0.7206054925918579,
            "answer": "office",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 2359,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6411310434341431,
        "b in neighbourhood of b_prime": 6003,
        "b_prime in neighbourhood of b": 2360
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7934760451316833,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7363552451133728,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.721310019493103,
            "answer": "crystal",
            "hit": false
          },
          {
            "score": 0.7143843173980713,
            "answer": "ruby",
            "hit": false
          },
          {
            "score": 0.7141548991203308,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7136791348457336,
            "answer": "platinum",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 9217,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6113995611667633,
        "b in neighbourhood of b_prime": 10327,
        "b_prime in neighbourhood of b": 9218
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.7527784109115601,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.7086685299873352,
            "answer": "hat",
            "hit": false
          },
          {
            "score": 0.7056788802146912,
            "answer": "supporters",
            "hit": false
          },
          {
            "score": 0.7048084735870361,
            "answer": "empty",
            "hit": false
          },
          {
            "score": 0.7038809657096863,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7037025094032288,
            "answer": "bomb",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 7735,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6325118243694305,
        "b in neighbourhood of b_prime": 5902,
        "b_prime in neighbourhood of b": 7736
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8707096576690674,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6986181735992432,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.6977949738502502,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6950170993804932,
            "answer": "farm",
            "hit": false
          },
          {
            "score": 0.6940896511077881,
            "answer": "cottage",
            "hit": false
          },
          {
            "score": 0.6862198114395142,
            "answer": "masters",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 537,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6342093348503113,
        "b in neighbourhood of b_prime": 7895,
        "b_prime in neighbourhood of b": 538
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7035649418830872,
            "answer": "jazz",
            "hit": false
          },
          {
            "score": 0.7018759250640869,
            "answer": "jem",
            "hit": false
          },
          {
            "score": 0.6966037750244141,
            "answer": "jihad",
            "hit": false
          },
          {
            "score": 0.6944223642349243,
            "answer": "jelly",
            "hit": false
          },
          {
            "score": 0.6888290643692017,
            "answer": "jamaica",
            "hit": false
          },
          {
            "score": 0.6886948347091675,
            "answer": "dare",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 1283,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6156298145651817,
        "b in neighbourhood of b_prime": 10758,
        "b_prime in neighbourhood of b": 1284
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7830404043197632,
            "answer": "porch",
            "hit": false
          },
          {
            "score": 0.7818670272827148,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7794281244277954,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7744858264923096,
            "answer": "grass",
            "hit": true
          },
          {
            "score": 0.7702744007110596,
            "answer": "gardens",
            "hit": false
          },
          {
            "score": 0.7695505619049072,
            "answer": "driveway",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7744857668876648,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7909444570541382,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.7219796180725098,
            "answer": "camera",
            "hit": false
          },
          {
            "score": 0.7093658447265625,
            "answer": "glasses",
            "hit": false
          },
          {
            "score": 0.7028088569641113,
            "answer": "device",
            "hit": false
          },
          {
            "score": 0.701109766960144,
            "answer": "instance",
            "hit": false
          },
          {
            "score": 0.7010012865066528,
            "answer": "gazed",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 183,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6750753670930862,
        "b in neighbourhood of b_prime": 49,
        "b_prime in neighbourhood of b": 184
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.7709598541259766,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7509458661079407,
            "answer": "mir",
            "hit": false
          },
          {
            "score": 0.7184593677520752,
            "answer": "telegraph",
            "hit": false
          },
          {
            "score": 0.7151064872741699,
            "answer": "mail",
            "hit": false
          },
          {
            "score": 0.7133830189704895,
            "answer": "shadow",
            "hit": false
          },
          {
            "score": 0.7131613492965698,
            "answer": "herald",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 1944,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6427139788866043,
        "b in neighbourhood of b_prime": 1872,
        "b_prime in neighbourhood of b": 1945
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7703497409820557,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.7575730085372925,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.7534412145614624,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7532325983047485,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7472202777862549,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7444458603858948,
            "answer": "finances",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 127,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6288639307022095,
        "b in neighbourhood of b_prime": 1370,
        "b_prime in neighbourhood of b": 128
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.772643506526947,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7487926483154297,
            "answer": "atlantic",
            "hit": false
          },
          {
            "score": 0.745417594909668,
            "answer": "sea",
            "hit": false
          },
          {
            "score": 0.7358400821685791,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7357785105705261,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7312405109405518,
            "answer": "coastal",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7142368108034134,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.7935176491737366,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7923052906990051,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.7797103524208069,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.7779548168182373,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.7739999890327454,
            "answer": "chefs",
            "hit": false
          },
          {
            "score": 0.7662019729614258,
            "answer": "cakes",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7288943827152252,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 36
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7604402303695679,
            "answer": "jenny",
            "hit": false
          },
          {
            "score": 0.723183274269104,
            "answer": "shirley",
            "hit": false
          },
          {
            "score": 0.7210848927497864,
            "answer": "stephanie",
            "hit": false
          },
          {
            "score": 0.7170957326889038,
            "answer": "molly",
            "hit": false
          },
          {
            "score": 0.7170018553733826,
            "answer": "rebecca",
            "hit": false
          },
          {
            "score": 0.7162176370620728,
            "answer": "erin",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 66,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6434935331344604,
        "b in neighbourhood of b_prime": 1907,
        "b_prime in neighbourhood of b": 67
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7650171518325806,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7484046816825867,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.7320539355278015,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.7010093927383423,
            "answer": "pillar",
            "hit": false
          },
          {
            "score": 0.6899508237838745,
            "answer": "walls",
            "hit": false
          },
          {
            "score": 0.6886768937110901,
            "answer": "medications",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 327,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6548458337783813,
        "b in neighbourhood of b_prime": 1084,
        "b_prime in neighbourhood of b": 328
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.8388575315475464,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7782367467880249,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.765828013420105,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.7633578181266785,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.752403974533081,
            "answer": "vinyl",
            "hit": false
          },
          {
            "score": 0.750489354133606,
            "answer": "rubber",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7474864721298218,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8247000575065613,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7876670360565186,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7542566061019897,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7526460886001587,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7473565936088562,
            "answer": "shore",
            "hit": false
          },
          {
            "score": 0.7466211318969727,
            "answer": "mediterranean",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7040783613920212,
        "b in neighbourhood of b_prime": 29,
        "b_prime in neighbourhood of b": 42
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7626832127571106,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.7334622144699097,
            "answer": "scoop",
            "hit": false
          },
          {
            "score": 0.7273234128952026,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7258062362670898,
            "answer": "knife",
            "hit": false
          },
          {
            "score": 0.7223283052444458,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.7210500240325928,
            "answer": "bowl",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 1993,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6566673368215561,
        "b in neighbourhood of b_prime": 3247,
        "b_prime in neighbourhood of b": 1994
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8887673616409302,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.7218449115753174,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.698991060256958,
            "answer": "dinner",
            "hit": false
          },
          {
            "score": 0.6978496313095093,
            "answer": "podium",
            "hit": false
          },
          {
            "score": 0.6959205269813538,
            "answer": "sheet",
            "hit": false
          },
          {
            "score": 0.6938838958740234,
            "answer": "dining",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 2086,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6193870007991791,
        "b in neighbourhood of b_prime": 11727,
        "b_prime in neighbourhood of b": 2087
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7225121259689331,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.6927031874656677,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.6890228986740112,
            "answer": "glared",
            "hit": false
          },
          {
            "score": 0.6856220960617065,
            "answer": "grinned",
            "hit": false
          },
          {
            "score": 0.6850537657737732,
            "answer": "sweater",
            "hit": false
          },
          {
            "score": 0.6834914684295654,
            "answer": "racist",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 5575,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6266739219427109,
        "b in neighbourhood of b_prime": 5709,
        "b_prime in neighbourhood of b": 5576
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.896327555179596,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.8112627267837524,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7983390688896179,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.7967343926429749,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7949100136756897,
            "answer": "grapes",
            "hit": true
          },
          {
            "score": 0.7769136428833008,
            "answer": "alcohol",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7949099838733673,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.8623363375663757,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.7876472473144531,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.7575142979621887,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.7285174131393433,
            "answer": "cables",
            "hit": false
          },
          {
            "score": 0.7012076377868652,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.698281466960907,
            "answer": "copper",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 239,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6511125564575195,
        "b in neighbourhood of b_prime": 1061,
        "b_prime in neighbourhood of b": 240
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 28,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "df75dc7d-3f34-47d8-b159-b98626bf9b4f",
      "timestamp": "2025-05-17T20:30:22.518540"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7909460663795471,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.746910035610199,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.7372390627861023,
            "answer": "bee",
            "hit": false
          },
          {
            "score": 0.7360087633132935,
            "answer": "wild",
            "hit": false
          },
          {
            "score": 0.729638934135437,
            "answer": "hawks",
            "hit": false
          },
          {
            "score": 0.7284546494483948,
            "answer": "poultry",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7014421671628952,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 36
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8745424747467041,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.8033553957939148,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.7710949182510376,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.7492865324020386,
            "answer": "forearm",
            "hit": false
          },
          {
            "score": 0.7485470175743103,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7395409345626831,
            "answer": "goat",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7337494492530823,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.837336003780365,
            "answer": "vehicle",
            "hit": false
          },
          {
            "score": 0.8140761256217957,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7697674036026001,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.76847904920578,
            "answer": "sedan",
            "hit": false
          },
          {
            "score": 0.7683590650558472,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.7633962631225586,
            "answer": "suv",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 262,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6520844846963882,
        "b in neighbourhood of b_prime": 1466,
        "b_prime in neighbourhood of b": 263
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.889541745185852,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8544097542762756,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7979356646537781,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7964886426925659,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7850570678710938,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.782273530960083,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7494883090257645,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.8690329790115356,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.8415420055389404,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.8142723441123962,
            "answer": "religious",
            "hit": false
          },
          {
            "score": 0.8078088760375977,
            "answer": "evangelical",
            "hit": false
          },
          {
            "score": 0.7909225225448608,
            "answer": "protestant",
            "hit": false
          },
          {
            "score": 0.7879562377929688,
            "answer": "theological",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6958581358194351,
        "b in neighbourhood of b_prime": 483,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.7756617665290833,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.756145715713501,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7541660070419312,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.750422477722168,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7476446628570557,
            "answer": "graduation",
            "hit": false
          },
          {
            "score": 0.7436228394508362,
            "answer": "ncaa",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7297074794769287,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.874400794506073,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7958857417106628,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.786202073097229,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7828850746154785,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.7697906494140625,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7638373970985413,
            "answer": "village",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7274282574653625,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7938112020492554,
            "answer": "cowboys",
            "hit": false
          },
          {
            "score": 0.7625972628593445,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7474524974822998,
            "answer": "stew",
            "hit": false
          },
          {
            "score": 0.7468686103820801,
            "answer": "dallas",
            "hit": false
          },
          {
            "score": 0.7403453588485718,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7347028255462646,
            "answer": "chicken",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 376,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6813803911209106,
        "b in neighbourhood of b_prime": 155,
        "b_prime in neighbourhood of b": 377
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7131459712982178,
            "answer": "claw",
            "hit": false
          },
          {
            "score": 0.7057920694351196,
            "answer": "cobb",
            "hit": false
          },
          {
            "score": 0.7028748989105225,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7022536396980286,
            "answer": "swan",
            "hit": false
          },
          {
            "score": 0.7006703615188599,
            "answer": "cousins",
            "hit": false
          },
          {
            "score": 0.7002443075180054,
            "answer": "hawks",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 7004,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6224183887243271,
        "b in neighbourhood of b_prime": 9534,
        "b_prime in neighbourhood of b": 7005
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8337458968162537,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7456834316253662,
            "answer": "circus",
            "hit": false
          },
          {
            "score": 0.7362308502197266,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.7314715385437012,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.731295108795166,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.727013885974884,
            "answer": "eagle",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 278,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6811273694038391,
        "b in neighbourhood of b_prime": 159,
        "b_prime in neighbourhood of b": 279
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.8977056741714478,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.8134363889694214,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.8070017099380493,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7861065864562988,
            "answer": "workers",
            "hit": false
          },
          {
            "score": 0.7717901468276978,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.7691885828971863,
            "answer": "workforce",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 122,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6991539597511292,
        "b in neighbourhood of b_prime": 50,
        "b_prime in neighbourhood of b": 123
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.7566804885864258,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7480127215385437,
            "answer": "trout",
            "hit": false
          },
          {
            "score": 0.7476122975349426,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.7438564300537109,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7365648150444031,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.7331106662750244,
            "answer": "seafood",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 4275,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6292567700147629,
        "b in neighbourhood of b_prime": 9724,
        "b_prime in neighbourhood of b": 4276
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8680959939956665,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.8038198947906494,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.7992708086967468,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.779939591884613,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.770258903503418,
            "answer": "planets",
            "hit": false
          },
          {
            "score": 0.7683886289596558,
            "answer": "universe",
            "hit": true
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7683886289596558,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.7876582145690918,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7374974489212036,
            "answer": "let",
            "hit": false
          },
          {
            "score": 0.724428117275238,
            "answer": "paragraph",
            "hit": false
          },
          {
            "score": 0.722111701965332,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7169109582901001,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.7124297618865967,
            "answer": "memo",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6879097521305084,
        "b in neighbourhood of b_prime": 33,
        "b_prime in neighbourhood of b": 33
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.7750688791275024,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7301279306411743,
            "answer": "owl",
            "hit": false
          },
          {
            "score": 0.7284584045410156,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7205050587654114,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7067831754684448,
            "answer": "shepherd",
            "hit": false
          },
          {
            "score": 0.7041024565696716,
            "answer": "legion",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6777542531490326,
        "b in neighbourhood of b_prime": 220,
        "b_prime in neighbourhood of b": 60
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8923685550689697,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.8038322925567627,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.7870676517486572,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7867078185081482,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7563309073448181,
            "answer": "viewers",
            "hit": false
          },
          {
            "score": 0.7446212768554688,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7404444664716721,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.8058068752288818,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7482587099075317,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7335193753242493,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7284931540489197,
            "answer": "founder",
            "hit": false
          },
          {
            "score": 0.7234022617340088,
            "answer": "director",
            "hit": false
          },
          {
            "score": 0.7193606495857239,
            "answer": "supporter",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 147,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6750243604183197,
        "b in neighbourhood of b_prime": 181,
        "b_prime in neighbourhood of b": 148
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8956514596939087,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.866009533405304,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.8535875082015991,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.8412564992904663,
            "answer": "rapper",
            "hit": false
          },
          {
            "score": 0.8376575708389282,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.8259117603302002,
            "answer": "comedian",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 78,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7376022040843964,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 79
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7580080032348633,
            "answer": "personal",
            "hit": false
          },
          {
            "score": 0.740565299987793,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.740017831325531,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7398248910903931,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7333598136901855,
            "answer": "individual",
            "hit": false
          },
          {
            "score": 0.7310640811920166,
            "answer": "personally",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 7942,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6293979585170746,
        "b in neighbourhood of b_prime": 4432,
        "b_prime in neighbourhood of b": 7943
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.7641343474388123,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.7620866298675537,
            "answer": "courtesy",
            "hit": false
          },
          {
            "score": 0.753458559513092,
            "answer": "photographed",
            "hit": false
          },
          {
            "score": 0.7502135038375854,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7482767105102539,
            "answer": "image",
            "hit": false
          },
          {
            "score": 0.7453253269195557,
            "answer": "photography",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 168,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.687014177441597,
        "b in neighbourhood of b_prime": 128,
        "b_prime in neighbourhood of b": 169
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.7793467044830322,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7610518932342529,
            "answer": "rookie",
            "hit": false
          },
          {
            "score": 0.7465474605560303,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.7397147417068481,
            "answer": "coach",
            "hit": false
          },
          {
            "score": 0.7295169234275818,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.7267248630523682,
            "answer": "footballer",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7172022461891174,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8218550086021423,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.8140235543251038,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7772164344787598,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7703607082366943,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.7671234011650085,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.7647951245307922,
            "answer": "soldier",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8218550086021423,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.779672384262085,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7781781554222107,
            "answer": "chair",
            "hit": false
          },
          {
            "score": 0.7702749967575073,
            "answer": "democratic",
            "hit": false
          },
          {
            "score": 0.770264744758606,
            "answer": "clinton",
            "hit": false
          },
          {
            "score": 0.7685591578483582,
            "answer": "mrs",
            "hit": false
          },
          {
            "score": 0.767655611038208,
            "answer": "republican",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 669,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6933121979236603,
        "b in neighbourhood of b_prime": 91,
        "b_prime in neighbourhood of b": 670
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8523257970809937,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8250523805618286,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.8107311725616455,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.8098154067993164,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.8068131804466248,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7951624393463135,
            "answer": "politician",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8068131804466248,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7554442286491394,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7448416948318481,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7437217235565186,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7419155836105347,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.7377200126647949,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7349313497543335,
            "answer": "cows",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7062907814979553,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8977797627449036,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7985820770263672,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.793250322341919,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.7808465957641602,
            "answer": "colonel",
            "hit": false
          },
          {
            "score": 0.7785893678665161,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.7769502997398376,
            "answer": "sailor",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7785893082618713,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.8430386781692505,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.8138841390609741,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7972941398620605,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7918250560760498,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7890109419822693,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7842716574668884,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6968022882938385,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7606652975082397,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7433717250823975,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.736628532409668,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7338653802871704,
            "answer": "general",
            "hit": false
          },
          {
            "score": 0.7274282574653625,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.7269054651260376,
            "answer": "legislature",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 426,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6572702825069427,
        "b in neighbourhood of b_prime": 336,
        "b_prime in neighbourhood of b": 427
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8511859178543091,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7880153059959412,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7793139219284058,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7724186778068542,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7723849415779114,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.7706869840621948,
            "answer": "classroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6691954880952835,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.7859495878219604,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7074263095855713,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.7062379121780396,
            "answer": "forest",
            "hit": true
          },
          {
            "score": 0.7046493291854858,
            "answer": "canopy",
            "hit": false
          },
          {
            "score": 0.7037867307662964,
            "answer": "timber",
            "hit": false
          },
          {
            "score": 0.7034673094749451,
            "answer": "forests",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7062379121780396,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.8918856382369995,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7515065670013428,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.7412285208702087,
            "answer": "canine",
            "hit": false
          },
          {
            "score": 0.7368810176849365,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.7340153455734253,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7306146621704102,
            "answer": "wild",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 3010,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6443244814872742,
        "b in neighbourhood of b_prime": 838,
        "b_prime in neighbourhood of b": 3011
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7323991060256958,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7137945890426636,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.7068684101104736,
            "answer": "sentence",
            "hit": true
          },
          {
            "score": 0.705073356628418,
            "answer": "noun",
            "hit": false
          },
          {
            "score": 0.7044750452041626,
            "answer": "terminology",
            "hit": false
          },
          {
            "score": 0.7020512223243713,
            "answer": "message",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6331484466791153,
        "b in neighbourhood of b_prime": 10603,
        "b_prime in neighbourhood of b": 3
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "66e35f65-a5d8-45a0-8daa-f8fc5aced492",
      "timestamp": "2025-05-17T20:30:22.820428"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.721430778503418,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.707438588142395,
            "answer": "business",
            "hit": false
          },
          {
            "score": 0.7068473100662231,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.7056300640106201,
            "answer": "wednesday",
            "hit": false
          },
          {
            "score": 0.7031998038291931,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.7026041150093079,
            "answer": "but",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6104854047298431,
        "b in neighbourhood of b_prime": 11159,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.7569984793663025,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.7301822304725647,
            "answer": "bits",
            "hit": false
          },
          {
            "score": 0.7186205387115479,
            "answer": "bit",
            "hit": true
          },
          {
            "score": 0.7154298424720764,
            "answer": "unix",
            "hit": false
          },
          {
            "score": 0.7109092473983765,
            "answer": "unicode",
            "hit": false
          },
          {
            "score": 0.7106006145477295,
            "answer": "scala",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7186204940080643,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.7033460736274719,
            "answer": "confront",
            "hit": false
          },
          {
            "score": 0.6987035274505615,
            "answer": "brushes",
            "hit": false
          },
          {
            "score": 0.6922702789306641,
            "answer": "brushing",
            "hit": false
          },
          {
            "score": 0.6911746263504028,
            "answer": "brushed",
            "hit": false
          },
          {
            "score": 0.6900549530982971,
            "answer": "battling",
            "hit": false
          },
          {
            "score": 0.6899387836456299,
            "answer": "combining",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 1346,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6295754909515381,
        "b in neighbourhood of b_prime": 4936,
        "b_prime in neighbourhood of b": 1347
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.8283220529556274,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7463141083717346,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7403696775436401,
            "answer": "gallon",
            "hit": false
          },
          {
            "score": 0.7289368510246277,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.724841833114624,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7223965525627136,
            "answer": "pound",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 1131,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6595754027366638,
        "b in neighbourhood of b_prime": 1107,
        "b_prime in neighbourhood of b": 1132
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "29434aaf-fc76-4cf8-b0ab-33027b0cd3a1",
      "timestamp": "2025-05-17T20:30:23.130145"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.8480520844459534,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8279761075973511,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.8212078809738159,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.8168294429779053,
            "answer": "intrigued",
            "hit": false
          },
          {
            "score": 0.8143864870071411,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.7978783845901489,
            "answer": "anxious",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.781694233417511,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8707096576690674,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6986181735992432,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.6977949738502502,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6950170993804932,
            "answer": "farm",
            "hit": false
          },
          {
            "score": 0.6940896511077881,
            "answer": "cottage",
            "hit": false
          },
          {
            "score": 0.6862198114395142,
            "answer": "masters",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6771144270896912,
        "b in neighbourhood of b_prime": 769,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7953075766563416,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.7744731903076172,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7667558193206787,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.7646485567092896,
            "answer": "reservoir",
            "hit": false
          },
          {
            "score": 0.7542566061019897,
            "answer": "sea",
            "hit": true
          },
          {
            "score": 0.7505373358726501,
            "answer": "canoe",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7542566061019897,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.7653170824050903,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.7609636187553406,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.7398484945297241,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.737297534942627,
            "answer": "nausea",
            "hit": false
          },
          {
            "score": 0.7354497909545898,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7329383492469788,
            "answer": "hurts",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7196743190288544,
        "b in neighbourhood of b_prime": 59,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.7201681137084961,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.7125144004821777,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.7070372104644775,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.7052246332168579,
            "answer": "pokemon",
            "hit": false
          },
          {
            "score": 0.7014458179473877,
            "answer": "bitch",
            "hit": false
          },
          {
            "score": 0.6989806294441223,
            "answer": "donkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7070372253656387,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.8247000575065613,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7876670360565186,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7542566061019897,
            "answer": "lake",
            "hit": false
          },
          {
            "score": 0.7526460886001587,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.7473565936088562,
            "answer": "shore",
            "hit": false
          },
          {
            "score": 0.7466211318969727,
            "answer": "mediterranean",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.745417594909668,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.907843828201294,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.7918277978897095,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7876709699630737,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7823717594146729,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.7782061100006104,
            "answer": "lunch",
            "hit": false
          },
          {
            "score": 0.7700235843658447,
            "answer": "beverages",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6714170277118683,
        "b in neighbourhood of b_prime": 77,
        "b_prime in neighbourhood of b": 31
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.8327357172966003,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8210627436637878,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.8031824231147766,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.788901686668396,
            "answer": "frustrated",
            "hit": false
          },
          {
            "score": 0.7811757922172546,
            "answer": "annoyed",
            "hit": false
          },
          {
            "score": 0.7683004140853882,
            "answer": "fatigue",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.803182452917099,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 8,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "8f6182b6-1b88-48dc-8c28-f3a4cda30b82",
      "timestamp": "2025-05-17T20:30:23.174051"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.7954496145248413,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.795438289642334,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7936727404594421,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.7875279188156128,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.7790809273719788,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.7556700706481934,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7790809869766235,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.77129065990448,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.7676810026168823,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.7672476768493652,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.76590895652771,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7590394020080566,
            "answer": "clothes",
            "hit": false
          },
          {
            "score": 0.7586914300918579,
            "answer": "clothing",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6643236726522446,
        "b in neighbourhood of b_prime": 480,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8283220529556274,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7573297023773193,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7555263042449951,
            "answer": "euros",
            "hit": false
          },
          {
            "score": 0.7534412145614624,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.7487246990203857,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7383056879043579,
            "answer": "gallons",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 494,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.678626075387001,
        "b in neighbourhood of b_prime": 77,
        "b_prime in neighbourhood of b": 495
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.8939676880836487,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.8505324125289917,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8422455787658691,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.833926796913147,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.8112624287605286,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7985389232635498,
            "answer": "mom",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8939677476882935,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7846853733062744,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.7748595476150513,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7690257430076599,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.766798734664917,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.7446959614753723,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7444212436676025,
            "answer": "support",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6910421252250671,
        "b in neighbourhood of b_prime": 44,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.7965024709701538,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7835504412651062,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.7776076197624207,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.7646268010139465,
            "answer": "intellect",
            "hit": false
          },
          {
            "score": 0.7630047798156738,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7617566585540771,
            "answer": "educated",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7835504710674286,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.881293535232544,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7827966213226318,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7468237280845642,
            "answer": "necklace",
            "hit": false
          },
          {
            "score": 0.7372623682022095,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7323193550109863,
            "answer": "treasures",
            "hit": false
          },
          {
            "score": 0.7305110692977905,
            "answer": "treasure",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7135481238365173,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.8226023316383362,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.7545231580734253,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7497507333755493,
            "answer": "cemetery",
            "hit": false
          },
          {
            "score": 0.7385145425796509,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.7324587106704712,
            "answer": "sculpture",
            "hit": false
          },
          {
            "score": 0.7320095300674438,
            "answer": "erected",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7545231580734253,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7617232203483582,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.7553791999816895,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.7195553779602051,
            "answer": "additional",
            "hit": false
          },
          {
            "score": 0.7101185321807861,
            "answer": "upcoming",
            "hit": false
          },
          {
            "score": 0.7077615857124329,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.6981748938560486,
            "answer": "former",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 165,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6391660571098328,
        "b in neighbourhood of b_prime": 3390,
        "b_prime in neighbourhood of b": 166
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.8973562717437744,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.7720719575881958,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7555386424064636,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.742517352104187,
            "answer": "packet",
            "hit": true
          },
          {
            "score": 0.7340151071548462,
            "answer": "parcel",
            "hit": true
          },
          {
            "score": 0.7204668521881104,
            "answer": "shipment",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7340151369571686,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8180062770843506,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.7486013174057007,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.7410512566566467,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7397844791412354,
            "answer": "transport",
            "hit": false
          },
          {
            "score": 0.7376412153244019,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.7376021146774292,
            "answer": "maritime",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8180062770843506,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.8251495957374573,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.7776215672492981,
            "answer": "reasonable",
            "hit": true
          },
          {
            "score": 0.7418074011802673,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.737738847732544,
            "answer": "liberal",
            "hit": false
          },
          {
            "score": 0.7372045516967773,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.736308753490448,
            "answer": "reasoned",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7275062054395676,
        "b in neighbourhood of b_prime": 17,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.8191365003585815,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7950650453567505,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7785040736198425,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7776215672492981,
            "answer": "rational",
            "hit": false
          },
          {
            "score": 0.7761174440383911,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7702973484992981,
            "answer": "sensible",
            "hit": true
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7702973484992981,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7544968128204346,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.7291464805603027,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7290255427360535,
            "answer": "jack",
            "hit": false
          },
          {
            "score": 0.7287408113479614,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.7284679412841797,
            "answer": "rocket",
            "hit": false
          },
          {
            "score": 0.7258884906768799,
            "answer": "love",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 982,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6628109663724899,
        "b in neighbourhood of b_prime": 198,
        "b_prime in neighbourhood of b": 983
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.8844486474990845,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.7852219939231873,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.7742664813995361,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.7713855504989624,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7671053409576416,
            "answer": "balcony",
            "hit": false
          },
          {
            "score": 0.7639145851135254,
            "answer": "fireplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8844486773014069,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.8548084497451782,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7725115418434143,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7560818195343018,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.7431085109710693,
            "answer": "type",
            "hit": false
          },
          {
            "score": 0.7412446737289429,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.7290688753128052,
            "answer": "manner",
            "hit": true
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7290688753128052,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "5f7f1baf-29c2-4472-b8b5-7706481739a8",
      "timestamp": "2025-05-17T20:30:23.244447"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8563438057899475,
            "answer": "before",
            "hit": true
          },
          {
            "score": 0.7721076011657715,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7688983678817749,
            "answer": "every",
            "hit": false
          },
          {
            "score": 0.7587836384773254,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.7500795722007751,
            "answer": "afterwards",
            "hit": false
          },
          {
            "score": 0.7494728565216064,
            "answer": "some",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8563438057899475,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.749165415763855,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.7395091652870178,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7325676679611206,
            "answer": "along",
            "hit": false
          },
          {
            "score": 0.7318764925003052,
            "answer": "beyond",
            "hit": false
          },
          {
            "score": 0.7285605669021606,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.7275464534759521,
            "answer": "shortly",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7491654753684998,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8775191307067871,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8350489139556885,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.8086647987365723,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.7981684803962708,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.7691252827644348,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.7680213451385498,
            "answer": "abdomen",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8775191307067871,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.8563438057899475,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.7843540906906128,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.773737907409668,
            "answer": "every",
            "hit": false
          },
          {
            "score": 0.7707012891769409,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.7545058727264404,
            "answer": "immediately",
            "hit": false
          },
          {
            "score": 0.7455636262893677,
            "answer": "shortly",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8563438057899475,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7963352203369141,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.7850008606910706,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7837607860565186,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.7791621685028076,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7758386135101318,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.7740234136581421,
            "answer": "begun",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 92,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6601580679416656,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 93
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7341223359107971,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.7333700656890869,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.722480833530426,
            "answer": "grateful",
            "hit": false
          },
          {
            "score": 0.7200631499290466,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7158937454223633,
            "answer": "deadline",
            "hit": false
          },
          {
            "score": 0.7066752910614014,
            "answer": "killing",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7040930092334747,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8686396479606628,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7629097700119019,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.756676197052002,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7266409993171692,
            "answer": "explore",
            "hit": false
          },
          {
            "score": 0.723236083984375,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.7213076949119568,
            "answer": "climb",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 4793,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6311698257923126,
        "b in neighbourhood of b_prime": 8381,
        "b_prime in neighbourhood of b": 4794
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.7856357097625732,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7617764472961426,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.7526758313179016,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.7435702681541443,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.7385756373405457,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7262536287307739,
            "answer": "summer",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6935977786779404,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.8234548568725586,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.7863354682922363,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.7654482126235962,
            "answer": "initially",
            "hit": false
          },
          {
            "score": 0.7639167308807373,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.763696551322937,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7634239196777344,
            "answer": "there",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.732735738158226,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 30
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.8294997215270996,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.7895634174346924,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.7712366580963135,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.7376307249069214,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.7360280752182007,
            "answer": "parameters",
            "hit": false
          },
          {
            "score": 0.7302444577217102,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7895634472370148,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7755070924758911,
            "answer": "behind",
            "hit": false
          },
          {
            "score": 0.7664152979850769,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.745055615901947,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.7348576784133911,
            "answer": "beyond",
            "hit": false
          },
          {
            "score": 0.7321951985359192,
            "answer": "into",
            "hit": false
          },
          {
            "score": 0.7306457757949829,
            "answer": "outside",
            "hit": true
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7306457608938217,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.7572909593582153,
            "answer": "irs",
            "hit": false
          },
          {
            "score": 0.7398197054862976,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.7325636148452759,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7251710295677185,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7201233506202698,
            "answer": "integrated",
            "hit": false
          },
          {
            "score": 0.704168975353241,
            "answer": "investigation",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7325636446475983,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7349836826324463,
            "answer": "fatal",
            "hit": false
          },
          {
            "score": 0.7198189496994019,
            "answer": "playstation",
            "hit": false
          },
          {
            "score": 0.7161346673965454,
            "answer": "venom",
            "hit": false
          },
          {
            "score": 0.709699273109436,
            "answer": "marvel",
            "hit": false
          },
          {
            "score": 0.7069557309150696,
            "answer": "heavenly",
            "hit": false
          },
          {
            "score": 0.7065291404724121,
            "answer": "kid",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.695102646946907,
        "b in neighbourhood of b_prime": 69,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.8443074822425842,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.8286863565444946,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8215467929840088,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8022760152816772,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7836248874664307,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.7563670873641968,
            "answer": "invaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7523911595344543,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.8706302642822266,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.6951323747634888,
            "answer": "down",
            "hit": false
          },
          {
            "score": 0.6823034286499023,
            "answer": "that",
            "hit": false
          },
          {
            "score": 0.6818106770515442,
            "answer": "from",
            "hit": false
          },
          {
            "score": 0.6793525218963623,
            "answer": "multiple",
            "hit": false
          },
          {
            "score": 0.6783396005630493,
            "answer": "ups",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6646485328674316,
        "b in neighbourhood of b_prime": 99,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.8223733305931091,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.7477465867996216,
            "answer": "traditionally",
            "hit": false
          },
          {
            "score": 0.7451141476631165,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7357051372528076,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.7341147661209106,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.7230777144432068,
            "answer": "normally",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7451141774654388,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8321157693862915,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.7797168493270874,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.760145902633667,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.727860152721405,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7199649214744568,
            "answer": "immediately",
            "hit": false
          },
          {
            "score": 0.7182946801185608,
            "answer": "profit",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 610,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6462322920560837,
        "b in neighbourhood of b_prime": 1908,
        "b_prime in neighbourhood of b": 611
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.7410428524017334,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7348808646202087,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7346632480621338,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7132570147514343,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.713094174861908,
            "answer": "rage",
            "hit": false
          },
          {
            "score": 0.712340235710144,
            "answer": "emergence",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6112400814890862,
        "b in neighbourhood of b_prime": 9651,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.7862376570701599,
            "answer": "southern",
            "hit": false
          },
          {
            "score": 0.7837522029876709,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.7726672887802124,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.7650490999221802,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7593463659286499,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.7583395838737488,
            "answer": "southwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7837522029876709,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.8445151448249817,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.7994192838668823,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7935749888420105,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.7857287526130676,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7726672887802124,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.7648402452468872,
            "answer": "midwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7935749590396881,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.9329940676689148,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.745661735534668,
            "answer": "tow",
            "hit": false
          },
          {
            "score": 0.7217246294021606,
            "answer": "upward",
            "hit": false
          },
          {
            "score": 0.7191572785377502,
            "answer": "leans",
            "hit": false
          },
          {
            "score": 0.7184658050537109,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7157455086708069,
            "answer": "downward",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.697208970785141,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 26
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7437814474105835,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.7120649814605713,
            "answer": "does",
            "hit": false
          },
          {
            "score": 0.706846296787262,
            "answer": "love",
            "hit": false
          },
          {
            "score": 0.7066303491592407,
            "answer": "before",
            "hit": false
          },
          {
            "score": 0.7001076936721802,
            "answer": "sincere",
            "hit": false
          },
          {
            "score": 0.6996253728866577,
            "answer": "non",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7437814474105835,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.934294581413269,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.8619669675827026,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.8186103105545044,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.7504010200500488,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.749559760093689,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.7458888292312622,
            "answer": "inland",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.934294581413269,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 23,
      "accuracy": 0.30434782608695654
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "b6f5b758-d676-495f-b6ce-174fc0e205fa",
      "timestamp": "2025-05-17T20:30:23.383931"
    }
  }
]