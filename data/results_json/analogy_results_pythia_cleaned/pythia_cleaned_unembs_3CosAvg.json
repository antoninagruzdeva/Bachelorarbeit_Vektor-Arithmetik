[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.8203579187393188,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.642168402671814,
            "answer": "artists",
            "hit": false
          },
          {
            "score": 0.6408578157424927,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.6257949471473694,
            "answer": "cds",
            "hit": false
          },
          {
            "score": 0.6210293769836426,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.6146206259727478,
            "answer": "poems",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8203579485416412
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.9164057970046997,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.7890052199363708,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7277244329452515,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.6978362202644348,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.696556568145752,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.6895262002944946,
            "answer": "applicant",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9164057672023773
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7705979943275452,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.655255138874054,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.6324583292007446,
            "answer": "zones",
            "hit": false
          },
          {
            "score": 0.6257926225662231,
            "answer": "territories",
            "hit": false
          },
          {
            "score": 0.6202832460403442,
            "answer": "perimeter",
            "hit": false
          },
          {
            "score": 0.6195459961891174,
            "answer": "region",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7705979943275452
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.688433051109314,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.6850115656852722,
            "answer": "caroline",
            "hit": false
          },
          {
            "score": 0.6689852476119995,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.6686557531356812,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.6549026966094971,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.646151602268219,
            "answer": "carriers",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6689852327108383
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.8328981399536133,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.7380257844924927,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7077878713607788,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.6972179412841797,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6775140762329102,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.6741060614585876,
            "answer": "student",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8328981399536133
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.828196108341217,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.633384108543396,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.6156055927276611,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.6102203726768494,
            "answer": "counsel",
            "hit": false
          },
          {
            "score": 0.608312726020813,
            "answer": "congress",
            "hit": false
          },
          {
            "score": 0.6080643534660339,
            "answer": "commission",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8281960487365723
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8852721452713013,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.708568811416626,
            "answer": "clients",
            "hit": false
          },
          {
            "score": 0.7004196047782898,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6908942461013794,
            "answer": "buyer",
            "hit": false
          },
          {
            "score": 0.6734213829040527,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.6603058576583862,
            "answer": "products",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8852720856666565
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7676265835762024,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.6927042007446289,
            "answer": "night",
            "hit": false
          },
          {
            "score": 0.6639308929443359,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.661035418510437,
            "answer": "daytime",
            "hit": false
          },
          {
            "score": 0.6555196046829224,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.6357241868972778,
            "answer": "weekend",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7676265835762024
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.806871771812439,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7192578911781311,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.6995509266853333,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6779009699821472,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.6687989234924316,
            "answer": "funeral",
            "hit": false
          },
          {
            "score": 0.6618508696556091,
            "answer": "dying",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.806871771812439
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8777859210968018,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.7356029748916626,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.6501081585884094,
            "answer": "division",
            "hit": false
          },
          {
            "score": 0.6349722743034363,
            "answer": "company",
            "hit": false
          },
          {
            "score": 0.6348575949668884,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.6337738633155823,
            "answer": "agency",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8777859807014465
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7438340187072754,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7396000623703003,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7282748818397522,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.7172136306762695,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7083473205566406,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7056456208229065,
            "answer": "develops",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7282748818397522
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7769083976745605,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.6545747518539429,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.6464146375656128,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.6419006586074829,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.6414325833320618,
            "answer": "different",
            "hit": false
          },
          {
            "score": 0.6378781199455261,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7769083976745605
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.7071138620376587,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.6376320719718933,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.6344227194786072,
            "answer": "directing",
            "hit": false
          },
          {
            "score": 0.6120758056640625,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.6117562055587769,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.6078267097473145,
            "answer": "dir",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7071138620376587
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.9046100378036499,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.6788365840911865,
            "answer": "incident",
            "hit": false
          },
          {
            "score": 0.6561627984046936,
            "answer": "incidents",
            "hit": false
          },
          {
            "score": 0.6396551132202148,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.6323016881942749,
            "answer": "episode",
            "hit": false
          },
          {
            "score": 0.6316611766815186,
            "answer": "activities",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9046100080013275
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.7577046751976013,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.6517506241798401,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.6384443044662476,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.6165773868560791,
            "answer": "illustrates",
            "hit": false
          },
          {
            "score": 0.6102705597877502,
            "answer": "analogy",
            "hit": false
          },
          {
            "score": 0.6088953018188477,
            "answer": "illustrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7577046751976013
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.659328818321228,
            "answer": "reality",
            "hit": false
          },
          {
            "score": 0.6579883098602295,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.6503923535346985,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.6321698427200317,
            "answer": "facto",
            "hit": false
          },
          {
            "score": 0.631655216217041,
            "answer": "indeed",
            "hit": false
          },
          {
            "score": 0.6203516125679016,
            "answer": "particular",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6503923833370209
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.7252123355865479,
            "answer": "friendly",
            "hit": false
          },
          {
            "score": 0.7221595048904419,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.707512378692627,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.6665627360343933,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.6208338141441345,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.6060260534286499,
            "answer": "hostile",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7221595644950867
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7168983221054077,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.681659460067749,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.6631379127502441,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.6600581407546997,
            "answer": "lord",
            "hit": false
          },
          {
            "score": 0.650367259979248,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.6501920819282532,
            "answer": "satan",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168983370065689
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.7825899124145508,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.7494516372680664,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.6539168357849121,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6509307622909546,
            "answer": "gov",
            "hit": false
          },
          {
            "score": 0.6256648302078247,
            "answer": "federal",
            "hit": false
          },
          {
            "score": 0.6192792057991028,
            "answer": "governance",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.782589852809906
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.7105531096458435,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.682706356048584,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.6326189637184143,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.6204208135604858,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6125693321228027,
            "answer": "minutes",
            "hit": false
          },
          {
            "score": 0.5997676849365234,
            "answer": "weeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7105531096458435
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.7109335064888,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.642877459526062,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.6246738433837891,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.6168492436408997,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.6157388091087341,
            "answer": "ideals",
            "hit": false
          },
          {
            "score": 0.6123890280723572,
            "answer": "concept",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7109334915876389
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.7841336131095886,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.6909891366958618,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.6620944738388062,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.648425817489624,
            "answer": "lang",
            "hit": false
          },
          {
            "score": 0.6291564702987671,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.6266191005706787,
            "answer": "grammar",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7841335535049438
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.7391707897186279,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7210766673088074,
            "answer": "lawrence",
            "hit": false
          },
          {
            "score": 0.6769066452980042,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.666323184967041,
            "answer": "lawson",
            "hit": false
          },
          {
            "score": 0.644111156463623,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.6425487995147705,
            "answer": "legal",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7391707599163055
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.7844379544258118,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7061923146247864,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.587360143661499,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.5859925746917725,
            "answer": "teammates",
            "hit": false
          },
          {
            "score": 0.5832164287567139,
            "answer": "constituents",
            "hit": false
          },
          {
            "score": 0.5829256772994995,
            "answer": "factions",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7844379544258118
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.7264423966407776,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.6974310874938965,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.6887612342834473,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.6826900839805603,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.6784927845001221,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6534187197685242,
            "answer": "day",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7264424264431
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.8247052431106567,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.7487041354179382,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7135878801345825,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7064251899719238,
            "answer": "daytime",
            "hit": false
          },
          {
            "score": 0.6928975582122803,
            "answer": "midnight",
            "hit": false
          },
          {
            "score": 0.6813907623291016,
            "answer": "day",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8247051537036896
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7582642436027527,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.6088786125183105,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.6025605797767639,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.5954389572143555,
            "answer": "firms",
            "hit": false
          },
          {
            "score": 0.5897541046142578,
            "answer": "classrooms",
            "hit": false
          },
          {
            "score": 0.5877013206481934,
            "answer": "universities",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7582642734050751
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8389309644699097,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.6927018165588379,
            "answer": "periodic",
            "hit": false
          },
          {
            "score": 0.6113932728767395,
            "answer": "intervals",
            "hit": false
          },
          {
            "score": 0.6095162034034729,
            "answer": "phases",
            "hit": false
          },
          {
            "score": 0.6057003140449524,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.6040025949478149,
            "answer": "months",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8389310240745544
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.7487992644309998,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.6509793996810913,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.6456096172332764,
            "answer": "gameplay",
            "hit": false
          },
          {
            "score": 0.6452938318252563,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.6339015364646912,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.6315343976020813,
            "answer": "multiplayer",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7487992644309998
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.7968646287918091,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.6248959302902222,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.6224924325942993,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.6115173101425171,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.6051886081695557,
            "answer": "govern",
            "hit": false
          },
          {
            "score": 0.6028550863265991,
            "answer": "pop",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7968646585941315
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.9001910090446472,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7733877897262573,
            "answer": "issue",
            "hit": false
          },
          {
            "score": 0.7322924137115479,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.7139909267425537,
            "answer": "trouble",
            "hit": false
          },
          {
            "score": 0.6980630159378052,
            "answer": "difficulties",
            "hit": false
          },
          {
            "score": 0.6952611804008484,
            "answer": "dilemma",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.900191068649292
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.7992161512374878,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.638746976852417,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6341491341590881,
            "answer": "productivity",
            "hit": false
          },
          {
            "score": 0.6243065595626831,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6233051419258118,
            "answer": "brands",
            "hit": false
          },
          {
            "score": 0.6157174706459045,
            "answer": "customer",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7992161810398102
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.8715355396270752,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.6457468867301941,
            "answer": "sources",
            "hit": false
          },
          {
            "score": 0.6305980682373047,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.6221506595611572,
            "answer": "facilities",
            "hit": false
          },
          {
            "score": 0.608475387096405,
            "answer": "information",
            "hit": false
          },
          {
            "score": 0.6023606061935425,
            "answer": "repository",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8715356290340424
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.700183629989624,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.6114650368690491,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.5955444574356079,
            "answer": "streams",
            "hit": false
          },
          {
            "score": 0.5919508337974548,
            "answer": "roads",
            "hit": false
          },
          {
            "score": 0.5917373895645142,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.5894306898117065,
            "answer": "reservoirs",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7001836746931076
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.7686569690704346,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.6960008144378662,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.6770997047424316,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.6457913517951965,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.6277123093605042,
            "answer": "streets",
            "hit": false
          },
          {
            "score": 0.6141886115074158,
            "answer": "routes",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686570584774017
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.7717207670211792,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.6407299637794495,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6178344488143921,
            "answer": "relations",
            "hit": false
          },
          {
            "score": 0.6109065413475037,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.59944748878479,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.5970737338066101,
            "answer": "relationships",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7717208862304688
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.7186273336410522,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.7172257900238037,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.6859458684921265,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.6826094388961792,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6357381343841553,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.621849536895752,
            "answer": "sci",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7186272740364075
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.7823315858840942,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.71872878074646,
            "answer": "solving",
            "hit": false
          },
          {
            "score": 0.7030539512634277,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.6403225660324097,
            "answer": "remedy",
            "hit": false
          },
          {
            "score": 0.6284513473510742,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.6122801899909973,
            "answer": "answers",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7823315858840942
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8759442567825317,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7503643035888672,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.7215268611907959,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.6920546889305115,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.6918992400169373,
            "answer": "musical",
            "hit": false
          },
          {
            "score": 0.6860109567642212,
            "answer": "melody",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8759442865848541
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.7440111637115479,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.6339259743690491,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.6171070337295532,
            "answer": "alley",
            "hit": false
          },
          {
            "score": 0.6160825490951538,
            "answer": "roads",
            "hit": false
          },
          {
            "score": 0.6050862669944763,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.5971121788024902,
            "answer": "highways",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7440111488103867
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.7714897990226746,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7061958312988281,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6896044015884399,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6895846724510193,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.6857652068138123,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.6817906498908997,
            "answer": "college",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7714897692203522
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.868110179901123,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.6928119659423828,
            "answer": "systemic",
            "hit": false
          },
          {
            "score": 0.6721938252449036,
            "answer": "systematic",
            "hit": false
          },
          {
            "score": 0.6113150119781494,
            "answer": "apparatus",
            "hit": false
          },
          {
            "score": 0.6049091815948486,
            "answer": "process",
            "hit": false
          },
          {
            "score": 0.6031109094619751,
            "answer": "institutions",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8681102097034454
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.6862994432449341,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.6051784157752991,
            "answer": "stuff",
            "hit": false
          },
          {
            "score": 0.598974347114563,
            "answer": "objects",
            "hit": false
          },
          {
            "score": 0.5934239625930786,
            "answer": "creatures",
            "hit": false
          },
          {
            "score": 0.5878049731254578,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.577008068561554,
            "answer": "creations",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6862994879484177
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.7430104613304138,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.6603987216949463,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.645106315612793,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.6407522559165955,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.6389121413230896,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6321550607681274,
            "answer": "village",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7430104613304138
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7200825810432434,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.6131558418273926,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6003531217575073,
            "answer": "use",
            "hit": false
          },
          {
            "score": 0.5981115102767944,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.5894527435302734,
            "answer": "hacker",
            "hit": false
          },
          {
            "score": 0.5886906981468201,
            "answer": "patients",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7200825810432434
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.681714653968811,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.6680995225906372,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.661061704158783,
            "answer": "edition",
            "hit": false
          },
          {
            "score": 0.6588133573532104,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.6178615689277649,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.6154893636703491,
            "answer": "copies",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817146241664886
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.7641181945800781,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.6937196254730225,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.6375378966331482,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.6293817758560181,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6284265518188477,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.6253054141998291,
            "answer": "cities",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7641181945800781
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.7936694025993347,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.6394302845001221,
            "answer": "web",
            "hit": false
          },
          {
            "score": 0.6339268684387207,
            "answer": "internet",
            "hit": false
          },
          {
            "score": 0.6241812705993652,
            "answer": "sites",
            "hit": false
          },
          {
            "score": 0.6174457669258118,
            "answer": "www",
            "hit": false
          },
          {
            "score": 0.6136168837547302,
            "answer": "site",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7936694025993347
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7456597089767456,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.7336174845695496,
            "answer": "weekly",
            "hit": false
          },
          {
            "score": 0.7028847336769104,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.696525514125824,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.6549341082572937,
            "answer": "weekends",
            "hit": false
          },
          {
            "score": 0.6482300758361816,
            "answer": "monthly",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7456597089767456
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.736483097076416,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.6731584668159485,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.664842426776886,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.6615273356437683,
            "answer": "yearly",
            "hit": false
          },
          {
            "score": 0.6512336730957031,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.6430621147155762,
            "answer": "seasons",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7364831566810608
      }
    ],
    "result": {
      "cnt_questions_correct": 46,
      "cnt_questions_total": 50,
      "accuracy": 0.92
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1886aed9-0195-4826-886b-61a1f3bbaca3",
      "timestamp": "2025-05-17T21:31:45.825941"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.7444502115249634,
            "answer": "able",
            "hit": false
          },
          {
            "score": 0.5917835831642151,
            "answer": "liability",
            "hit": false
          },
          {
            "score": 0.5884164571762085,
            "answer": "generated",
            "hit": false
          },
          {
            "score": 0.5860925912857056,
            "answer": "doors",
            "hit": false
          },
          {
            "score": 0.5854907035827637,
            "answer": "skirts",
            "hit": false
          },
          {
            "score": 0.5851118564605713,
            "answer": "goods",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5687241554260254
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.7655197381973267,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.6386220455169678,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.6319031119346619,
            "answer": "active",
            "hit": false
          },
          {
            "score": 0.6210444569587708,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.6199687123298645,
            "answer": "act",
            "hit": false
          },
          {
            "score": 0.6046820282936096,
            "answer": "fragment",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7655197381973267
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.8803004026412964,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.6589458584785461,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.6442283391952515,
            "answer": "organization",
            "hit": false
          },
          {
            "score": 0.6376034021377563,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.6348487138748169,
            "answer": "company",
            "hit": false
          },
          {
            "score": 0.6325638890266418,
            "answer": "institutions",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.880300372838974
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.7621554732322693,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7566056847572327,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.7445043325424194,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.7301883697509766,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.6848516464233398,
            "answer": "analysts",
            "hit": false
          },
          {
            "score": 0.6688073873519897,
            "answer": "analytical",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7445043474435806
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.7710997462272644,
            "answer": "navy",
            "hit": false
          },
          {
            "score": 0.7415169477462769,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.7175211906433105,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.690129280090332,
            "answer": "soldier",
            "hit": false
          },
          {
            "score": 0.6845415830612183,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.6576521992683411,
            "answer": "marines",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7415169477462769
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.6715750098228455,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.6501599550247192,
            "answer": "author",
            "hit": false
          },
          {
            "score": 0.6185160279273987,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.601712167263031,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.5962131023406982,
            "answer": "authorization",
            "hit": false
          },
          {
            "score": 0.5938308238983154,
            "answer": "authorized",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6715750098228455
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.6345664262771606,
            "answer": "purpose",
            "hit": false
          },
          {
            "score": 0.6124252080917358,
            "answer": "strict",
            "hit": false
          },
          {
            "score": 0.6062944531440735,
            "answer": "generated",
            "hit": false
          },
          {
            "score": 0.605419933795929,
            "answer": "profits",
            "hit": false
          },
          {
            "score": 0.6054145693778992,
            "answer": "hold",
            "hit": false
          },
          {
            "score": 0.601470410823822,
            "answer": "prof",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5991141200065613
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.8212920427322388,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.683763325214386,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.661054253578186,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.6517061591148376,
            "answer": "enterprises",
            "hit": false
          },
          {
            "score": 0.6492525339126587,
            "answer": "entrepreneur",
            "hit": false
          },
          {
            "score": 0.6324734687805176,
            "answer": "merchants",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8212921023368835
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.8399983644485474,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.6630468964576721,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.6376430988311768,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.6329598426818848,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.6186842322349548,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.6085565686225891,
            "answer": "classification",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.839998334646225
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.6983088254928589,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.6558948755264282,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6511167287826538,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.6422818899154663,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.6214030385017395,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6136179566383362,
            "answer": "generations",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6983088850975037
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.7518938779830933,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7416118383407593,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7196639776229858,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.7186200618743896,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.6939420700073242,
            "answer": "pediatric",
            "hit": false
          },
          {
            "score": 0.6888900995254517,
            "answer": "childhood",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7186200618743896
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8112921714782715,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.6832026243209839,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.6707205772399902,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6652044057846069,
            "answer": "urban",
            "hit": false
          },
          {
            "score": 0.6406887769699097,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.637559175491333,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8112922012805939
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.7749754190444946,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.640278160572052,
            "answer": "communal",
            "hit": false
          },
          {
            "score": 0.6091009378433228,
            "answer": "partnerships",
            "hit": false
          },
          {
            "score": 0.6054419875144958,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.5980802774429321,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.5975647568702698,
            "answer": "children",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7749754786491394
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.7420235872268677,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.6343973278999329,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6253149509429932,
            "answer": "countryside",
            "hit": false
          },
          {
            "score": 0.6189950108528137,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.6185391545295715,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.6174470782279968,
            "answer": "town",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7420235574245453
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8432022929191589,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.6741541028022766,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.6730315685272217,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.6574375629425049,
            "answer": "districts",
            "hit": false
          },
          {
            "score": 0.6528339982032776,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.6501519083976746,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8432022929191589
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7422143816947937,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.6497043371200562,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6381256580352783,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6360172033309937,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.6030341982841492,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.5941046476364136,
            "answer": "missions",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422143816947937
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.8304198384284973,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.7302414178848267,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.700259804725647,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.6611496210098267,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6495094895362854,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6422366499900818,
            "answer": "economics",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8304198980331421
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8190188407897949,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.691939651966095,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.665502667427063,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.6077812910079956,
            "answer": "power",
            "hit": false
          },
          {
            "score": 0.6070985794067383,
            "answer": "electric",
            "hit": false
          },
          {
            "score": 0.601610004901886,
            "answer": "fuels",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8190188407897949
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.6919675469398499,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.587903618812561,
            "answer": "enters",
            "hit": false
          },
          {
            "score": 0.5826693773269653,
            "answer": "entering",
            "hit": false
          },
          {
            "score": 0.5809354782104492,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.5781776905059814,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.5779181718826294,
            "answer": "enter",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6919675767421722
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.7684460878372192,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.6192208528518677,
            "answer": "procedures",
            "hit": false
          },
          {
            "score": 0.6053199172019958,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.600584089756012,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.6004967093467712,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.5971442461013794,
            "answer": "sites",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7684461176395416
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.7505229115486145,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7182232737541199,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.6765972375869751,
            "answer": "clan",
            "hit": false
          },
          {
            "score": 0.6586183905601501,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.6557997465133667,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.6539260745048523,
            "answer": "siblings",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7505229115486145
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8286041617393494,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7389321327209473,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7174206972122192,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.7080579996109009,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.650700569152832,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.627495288848877,
            "answer": "heritage",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8286041021347046
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.6960678696632385,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.6561734080314636,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.641460657119751,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.6379082202911377,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.635730504989624,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.6344534754753113,
            "answer": "factories",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6960678696632385
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.7688190937042236,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.6084566116333008,
            "answer": "books",
            "hit": false
          },
          {
            "score": 0.5990961790084839,
            "answer": "museums",
            "hit": false
          },
          {
            "score": 0.5897203087806702,
            "answer": "museum",
            "hit": false
          },
          {
            "score": 0.5876096487045288,
            "answer": "shelves",
            "hit": false
          },
          {
            "score": 0.5872291326522827,
            "answer": "textbooks",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.768819123506546
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.718324601650238,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.6759253144264221,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.6727664470672607,
            "answer": "lifespan",
            "hit": false
          },
          {
            "score": 0.6661868095397949,
            "answer": "lived",
            "hit": false
          },
          {
            "score": 0.6564090251922607,
            "answer": "survival",
            "hit": false
          },
          {
            "score": 0.6437821388244629,
            "answer": "lives",
            "hit": true
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6437821835279465
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8383950591087341,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7101615071296692,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.701533317565918,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.6853774189949036,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6850303411483765,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.616579532623291,
            "answer": "defeats",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8383950591087341
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.7798422574996948,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.6625280380249023,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.6439327001571655,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.6419631242752075,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6359633207321167,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.6203582286834717,
            "answer": "storage",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798423171043396
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8882656097412109,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.6956877708435059,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.6850938200950623,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.6824455857276917,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.6464920043945312,
            "answer": "option",
            "hit": false
          },
          {
            "score": 0.641273021697998,
            "answer": "occasion",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8882656097412109
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8391441702842712,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.6745380163192749,
            "answer": "pol",
            "hit": false
          },
          {
            "score": 0.6114095449447632,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.599565327167511,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.5988380908966064,
            "answer": "regulations",
            "hit": false
          },
          {
            "score": 0.597545862197876,
            "answer": "settings",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8391441106796265
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.7165321111679077,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.6746360063552856,
            "answer": "prop",
            "hit": false
          },
          {
            "score": 0.6410478949546814,
            "answer": "possessions",
            "hit": false
          },
          {
            "score": 0.6202882528305054,
            "answer": "belongings",
            "hit": false
          },
          {
            "score": 0.6184644103050232,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.6131393909454346,
            "answer": "props",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7165320813655853
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8571164011955261,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7179183959960938,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.7115513682365417,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.6953627467155457,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6911678314208984,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.671885073184967,
            "answer": "roles",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571164906024933
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7110199928283691,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.6660165786743164,
            "answer": "safety",
            "hit": false
          },
          {
            "score": 0.659007728099823,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6392457485198975,
            "answer": "guards",
            "hit": false
          },
          {
            "score": 0.6391255855560303,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.6378915905952454,
            "answer": "securities",
            "hit": true
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6378915756940842
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.6504786014556885,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.5942465662956238,
            "answer": "sequences",
            "hit": false
          },
          {
            "score": 0.5861616730690002,
            "answer": "sequence",
            "hit": false
          },
          {
            "score": 0.5849429368972778,
            "answer": "trio",
            "hit": false
          },
          {
            "score": 0.583594560623169,
            "answer": "succession",
            "hit": false
          },
          {
            "score": 0.5828088521957397,
            "answer": "pairs",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.977557361125946
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.77495938539505,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.6397896409034729,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.6176589727401733,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.6165961623191833,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.6102162003517151,
            "answer": "institute",
            "hit": false
          },
          {
            "score": 0.6057166457176208,
            "answer": "civilization",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.77495938539505
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.6616284251213074,
            "answer": "breeds",
            "hit": false
          },
          {
            "score": 0.6384376287460327,
            "answer": "breed",
            "hit": false
          },
          {
            "score": 0.6378204226493835,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.6338092684745789,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.6281121969223022,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.6241630911827087,
            "answer": "creatures",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9780523180961609
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.8910792469978333,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7845085859298706,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.7436380386352539,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7201477289199829,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.7017384171485901,
            "answer": "storyline",
            "hit": false
          },
          {
            "score": 0.6983655095100403,
            "answer": "narratives",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.891079306602478
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.7531471252441406,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.6713076233863831,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.6359299421310425,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.6339095830917358,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.6130085587501526,
            "answer": "schemes",
            "hit": false
          },
          {
            "score": 0.6102161407470703,
            "answer": "policies",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.753147155046463
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7959800958633423,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.7764356136322021,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7396659851074219,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7171116471290588,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.7072697281837463,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7072278261184692,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7959800362586975
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.8943569660186768,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8031957149505615,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7980914115905762,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.7385045886039734,
            "answer": "techniques",
            "hit": false
          },
          {
            "score": 0.7170349359512329,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.6958305835723877,
            "answer": "equipment",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8943569660186768
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8168348073959351,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.6861135363578796,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.6491400003433228,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.6327474117279053,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.63062584400177,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.6281861066818237,
            "answer": "doctrines",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8168347477912903
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.7799043655395508,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.6802781820297241,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.6779959201812744,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.6582608222961426,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.6561353206634521,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6549709439277649,
            "answer": "college",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7799044251441956
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8324800729751587,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7239008545875549,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7091717720031738,
            "answer": "diverse",
            "hit": false
          },
          {
            "score": 0.7028236985206604,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.6955947875976562,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.6947223544120789,
            "answer": "varied",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8324800729751587
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.7721134424209595,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7592539191246033,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7584089040756226,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7031373381614685,
            "answer": "widow",
            "hit": false
          },
          {
            "score": 0.6776166558265686,
            "answer": "bride",
            "hit": false
          },
          {
            "score": 0.6757943630218506,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6528618931770325
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.7195256948471069,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.6986396908760071,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.688738226890564,
            "answer": "person",
            "hit": false
          },
          {
            "score": 0.6755602359771729,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.6700097322463989,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6655803918838501,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6986396908760071
      }
    ],
    "result": {
      "cnt_questions_correct": 33,
      "cnt_questions_total": 44,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6e93f039-e130-486d-a85c-bfb2b0588f93",
      "timestamp": "2025-05-17T21:31:46.049001"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8599984645843506,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.7838801145553589,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.6974868774414062,
            "answer": "easier",
            "hit": false
          },
          {
            "score": 0.6922445297241211,
            "answer": "simpler",
            "hit": false
          },
          {
            "score": 0.6886656880378723,
            "answer": "quicker",
            "hit": false
          },
          {
            "score": 0.6853072643280029,
            "answer": "expensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8599984645843506
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.7223015427589417,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.6429999470710754,
            "answer": "cheaper",
            "hit": false
          },
          {
            "score": 0.6374199986457825,
            "answer": "quicker",
            "hit": false
          },
          {
            "score": 0.6353516578674316,
            "answer": "brighter",
            "hit": false
          },
          {
            "score": 0.6322362422943115,
            "answer": "faster",
            "hit": false
          },
          {
            "score": 0.6318551898002625,
            "answer": "richer",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.722301572561264
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.8257020711898804,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.7694351673126221,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.699464738368988,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6776425838470459,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6673585176467896,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6659011840820312,
            "answer": "brighter",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8257020711898804
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.874472975730896,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.8425557017326355,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7350799441337585,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.7081941366195679,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.6966544389724731,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.6861241459846497,
            "answer": "strongest",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.874472975730896
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4bd130ab-197f-4a22-86c0-c31b59ccbede",
      "timestamp": "2025-05-17T21:31:46.246121"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7367573976516724,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7211900353431702,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6721420288085938,
            "answer": "greatest",
            "hit": false
          },
          {
            "score": 0.6640453934669495,
            "answer": "biggest",
            "hit": false
          },
          {
            "score": 0.6614769697189331,
            "answer": "most",
            "hit": false
          },
          {
            "score": 0.6525648832321167,
            "answer": "fastest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7367574274539948
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.7646143436431885,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.749984622001648,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.6802539229393005,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6686524152755737,
            "answer": "brightest",
            "hit": false
          },
          {
            "score": 0.6506062746047974,
            "answer": "richest",
            "hit": false
          },
          {
            "score": 0.6436280012130737,
            "answer": "finest",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7646142840385437
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 2,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "eee77d3d-8351-43dc-9b72-0962f68e47d6",
      "timestamp": "2025-05-17T21:31:46.262160"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.8814113736152649,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.8116083741188049,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7933875322341919,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7676436305046082,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.679324209690094,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6750481128692627,
            "answer": "takes",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8814114332199097
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8140421509742737,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.6762011051177979,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6756361126899719,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.669879674911499,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6670008897781372,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.6621255278587341,
            "answer": "puts",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8140421509742737
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8991947174072266,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.7940910458564758,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7625764012336731,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7356339693069458,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.6688500046730042,
            "answer": "confirms",
            "hit": false
          },
          {
            "score": 0.6675698757171631,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8991946876049042
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8551602959632874,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.8131592273712158,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8102407455444336,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7905319929122925,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.7806550860404968,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.776955783367157,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.695223405957222
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9568201899528503,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8535260558128357,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8116552829742432,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7888045310974121,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7792603373527527,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7198835015296936,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9568202197551727
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8058812618255615,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7173529267311096,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6952501535415649,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6722882986068726,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6507735848426819,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6304932236671448,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8058812618255615
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.9109305739402771,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.8226401805877686,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8189283609390259,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7058433294296265,
            "answer": "request",
            "hit": false
          },
          {
            "score": 0.6930386424064636,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.6923928260803223,
            "answer": "tells",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9109305739402771
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8033731579780579,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.7549521327018738,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.7501658201217651,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7436972260475159,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.6896902322769165,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6488113403320312,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8033731579780579
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.9366837739944458,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8395506143569946,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8046342730522156,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7385974526405334,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6995545029640198,
            "answer": "comes",
            "hit": false
          },
          {
            "score": 0.695015549659729,
            "answer": "been",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.936683863401413
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.9040364027023315,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7786158323287964,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7430974841117859,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7408535480499268,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6769780516624451,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.6723910570144653,
            "answer": "feels",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9040363132953644
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7888669371604919,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7414077520370483,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.740584135055542,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6810246706008911,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6482831239700317,
            "answer": "takes",
            "hit": false
          },
          {
            "score": 0.6457459926605225,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888669371604919
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9109984636306763,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8294381499290466,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.797231912612915,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7557507157325745,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7293047308921814,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7235049605369568,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9109984636306763
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8140304088592529,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8121130466461182,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7690262794494629,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.7538268566131592,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7444767951965332,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7123213410377502,
            "answer": "possesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7690262794494629
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9514099359512329,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8349557518959045,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8046092987060547,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7572410106658936,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7355540990829468,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.707631528377533,
            "answer": "keeps",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9514098763465881
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.8145853877067566,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.7185153961181641,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6813963055610657,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6793138980865479,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6634517908096313,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.6598889827728271,
            "answer": "develops",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8145853877067566
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.7503070831298828,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.6666980385780334,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6534043550491333,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.6506026387214661,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6493185758590698,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.6403443217277527,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7503070831298828
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8161423802375793,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7615917921066284,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7455763220787048,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6926437616348267,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6830045580863953,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6726919412612915,
            "answer": "developer",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8161424398422241
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.7469190359115601,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.6809033751487732,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.6723232269287109,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.6442579627037048,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.6437669992446899,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.6429146528244019,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7469190657138824
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.7610129117965698,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.7022301554679871,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7016841173171997,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6783895492553711,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6471525430679321,
            "answer": "celebrates",
            "hit": false
          },
          {
            "score": 0.6399921774864197,
            "answer": "enjoyable",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7610129117965698
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.7332690954208374,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.6519249677658081,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6467105150222778,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6455615758895874,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.641770601272583,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.6416958570480347,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7332690954208374
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.774622917175293,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.731695294380188,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6766926050186157,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6577510833740234,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.653853178024292,
            "answer": "existing",
            "hit": false
          },
          {
            "score": 0.6523990631103516,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7746228873729706
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.918189287185669,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8186259865760803,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7988306879997253,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7824597358703613,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7526174783706665,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.7340644598007202,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9181893467903137
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.793476939201355,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7242852449417114,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6780446767807007,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6670013070106506,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6523386240005493,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6253417134284973,
            "answer": "serves",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.793476939201355
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9150311946868896,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8453298211097717,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8018770813941956,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8009947538375854,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7261409759521484,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.6998768448829651,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9150311946868896
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.7317653298377991,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.6939694881439209,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6880286931991577,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.6260552406311035,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.6172400116920471,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.6172111630439758,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7317653298377991
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.921747624874115,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8358913660049438,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8063095211982727,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7171227335929871,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.6963324546813965,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6942310929298401,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9217476844787598
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8229981660842896,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.7982611656188965,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7631713151931763,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7335771918296814,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7237679958343506,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.6462966799736023,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8229981958866119
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.756003737449646,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7079928517341614,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7065386772155762,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7059215903282166,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6946358680725098,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.6881058216094971,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.756003737449646
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9379320740699768,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7770034074783325,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7656593322753906,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7157450318336487,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.714878261089325,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.7144492864608765,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.937932014465332
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7577600479125977,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.6877366304397583,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.6773622632026672,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6546237468719482,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6493271589279175,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.6463751792907715,
            "answer": "develops",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7577599883079529
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.914972722530365,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8376734852790833,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.831204354763031,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7570412755012512,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7305405139923096,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.696867048740387,
            "answer": "kept",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.914972722530365
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.7967867851257324,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.7611241340637207,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7492086291313171,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7418075203895569,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.73162841796875,
            "answer": "occurrences",
            "hit": false
          },
          {
            "score": 0.7019411325454712,
            "answer": "happens",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7967867851257324
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.9349255561828613,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7750605940818787,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.6907962560653687,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.6879158020019531,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.684632420539856,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.6733477115631104,
            "answer": "operative",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9349256753921509
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.8963959217071533,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.7951796054840088,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7950046062469482,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7271238565444946,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.7194849252700806,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.70698082447052,
            "answer": "protects",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8963959515094757
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9190704822540283,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8133065104484558,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7758411169052124,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7380540370941162,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7359434962272644,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7265523076057434,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9190704822540283
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.8346299529075623,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.7525884509086609,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7338417172431946,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.6814360618591309,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6758675575256348,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.6713638305664062,
            "answer": "protector",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.834630012512207
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8171346783638,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.7215443849563599,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6736934185028076,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.67268306016922,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.66840660572052,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6678248643875122,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8171346783638
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.7473617792129517,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.6604421734809875,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.648781418800354,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6462982892990112,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6386979818344116,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6378551721572876,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7473617792129517
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.923526406288147,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8120543360710144,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8035588264465332,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7495057582855225,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7425375580787659,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.7366228103637695,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9235264658927917
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8988587260246277,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7998101711273193,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7993370890617371,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.713636040687561,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7082582116127014,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.7006216049194336,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8988587856292725
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.9209569096565247,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8524417877197266,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7788847088813782,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7581517696380615,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7526488304138184,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.7353739738464355,
            "answer": "continue",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9209569096565247
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.77629154920578,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7068349123001099,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.6870579123497009,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.6862446665763855,
            "answer": "recalls",
            "hit": false
          },
          {
            "score": 0.6854026317596436,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6614405512809753,
            "answer": "reminds",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7762914896011353
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.7328357100486755,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.726243257522583,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7234348058700562,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7077584862709045,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.6962722539901733,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6815789341926575,
            "answer": "representing",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.726243257522583
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7235939502716064,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7180465459823608,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7080566883087158,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.6583653092384338,
            "answer": "mandates",
            "hit": false
          },
          {
            "score": 0.6505110263824463,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6486135721206665,
            "answer": "demands",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.708056703209877
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.943812906742096,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8429888486862183,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8332827687263489,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7776618003845215,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7201098203659058,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7115728855133057,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9438129663467407
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.8114838600158691,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.7325913906097412,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.6568294763565063,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.6478357315063477,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6347031593322754,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.6309807300567627,
            "answer": "puts",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8114838600158691
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8155391216278076,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7542687654495239,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.7471194267272949,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7388268113136292,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.7237246036529541,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.6925402879714966,
            "answer": "indicates",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8155390918254852
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.9022529125213623,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7766628265380859,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7140652537345886,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.701738178730011,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.6917812824249268,
            "answer": "reveals",
            "hit": false
          },
          {
            "score": 0.6911193132400513,
            "answer": "suggests",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9022528529167175
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8697602152824402,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.813303530216217,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.8027042150497437,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7398894429206848,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7225350141525269,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.6921741962432861,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8697602450847626
      }
    ],
    "result": {
      "cnt_questions_correct": 45,
      "cnt_questions_total": 49,
      "accuracy": 0.9183673469387755
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "af7494f0-6304-4387-b594-a08d24d7a363",
      "timestamp": "2025-05-17T21:31:46.270655"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9061186909675598,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.8276481628417969,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7913482189178467,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.760402262210846,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7094253897666931,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7031342387199402,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9061186909675598
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7292275428771973,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.673414945602417,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.6691213250160217,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.6652833223342896,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6589899063110352,
            "answer": "addressing",
            "hit": false
          },
          {
            "score": 0.652759850025177,
            "answer": "additions",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6691213250160217
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.8897584676742554,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.8641626238822937,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.7857863903045654,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7836864590644836,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.7576078176498413,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.749397873878479,
            "answer": "permits",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8897584974765778
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8944556713104248,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8548616170883179,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8503879308700562,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.7806921601295471,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7440797090530396,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7387852668762207,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8503879904747009
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.7372269630432129,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.7284982204437256,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7179269194602966,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6825147271156311,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6560655832290649,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6205325722694397,
            "answer": "applicable",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7372269928455353
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.8951102495193481,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.8397257328033447,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.8277316093444824,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7417049407958984,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7173663377761841,
            "answer": "request",
            "hit": false
          },
          {
            "score": 0.6873081922531128,
            "answer": "seeking",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8951103091239929
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8646131753921509,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8104552030563354,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.7353070378303528,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.678524911403656,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6708739399909973,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6539964079856873,
            "answer": "visiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8646131455898285
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.8099215626716614,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.7629168033599854,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.748582124710083,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7105034589767456,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.6780045628547668,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6372011303901672,
            "answer": "eliminating",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8099215924739838
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8784344792366028,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8672839403152466,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8258025646209717,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7073456048965454,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.6590481996536255,
            "answer": "going",
            "hit": false
          },
          {
            "score": 0.6574569344520569,
            "answer": "giving",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8784345388412476
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8414579033851624,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8042508363723755,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7933995723724365,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.6715691685676575,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6479058861732483,
            "answer": "thinking",
            "hit": false
          },
          {
            "score": 0.6457690000534058,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042507767677307
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.7547987699508667,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7415070533752441,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.7025970816612244,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6883538961410522,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6685439348220825,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.6260955333709717,
            "answer": "taking",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6685438901185989
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8793162703514099,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8353279232978821,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7221993803977966,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7052655220031738,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.685150146484375,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6837012767791748,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8793162703514099
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.88826584815979,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8666311502456665,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.8653607368469238,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7364915013313293,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7238285541534424,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7070162296295166,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8666312098503113
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.7674580812454224,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.7106209993362427,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6867280006408691,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6616798639297485,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.6537622213363647,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.6527721285820007,
            "answer": "generating",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7674581408500671
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8139688968658447,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.752730667591095,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7314949035644531,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6979768872261047,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6843113303184509,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6741679906845093,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8139688968658447
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8284316062927246,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8036661148071289,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.7998135685920715,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7394787073135376,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.7151963710784912,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6947281360626221,
            "answer": "promoting",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8036661148071289
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.7618265151977539,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.6954683661460876,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6878955960273743,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6753503084182739,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6461883783340454,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6196332573890686,
            "answer": "celebrating",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7618264853954315
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.7102749347686768,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.639373779296875,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.6170654892921448,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.6126864552497864,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.6122832298278809,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.6087018251419067,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7102749794721603
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.8014275431632996,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.730230450630188,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.6958073377609253,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6935983300209045,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6794849634170532,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.6290497779846191,
            "answer": "constructing",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8014275431632996
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.7389920949935913,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7197958827018738,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6921392679214478,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6796062588691711,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.6783707141876221,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.600997269153595,
            "answer": "adapting",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6796062886714935
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.7706340551376343,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7632859349250793,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7613431215286255,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.7241301536560059,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6948795318603516,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.652982771396637,
            "answer": "hoping",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7613431215286255
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.7477806806564331,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7286573648452759,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6831621527671814,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6756047010421753,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.6702603101730347,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6199079155921936,
            "answer": "pursuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6756047010421753
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8553808927536011,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.8447415828704834,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8305011987686157,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7507593035697937,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7161189317703247,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7112947106361389,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8553809225559235
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.9156176447868347,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8428604602813721,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.830082893371582,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7362768054008484,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.6928883790969849,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.6835019588470459,
            "answer": "determining",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9156176447868347
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.8006182909011841,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.7999331951141357,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7728327512741089,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7370622158050537,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7281439304351807,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.6687347888946533,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8006182909011841
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.7155229449272156,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7154616713523865,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6914727687835693,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.6496506929397583,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.6428394913673401,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.6400609016418457,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6914727687835693
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.862670361995697,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8309251070022583,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7893445491790771,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7322542071342468,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6513050198554993,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.6460967659950256,
            "answer": "requiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8309251070022583
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.7236638069152832,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.6847401857376099,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.6565811634063721,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.638327419757843,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.6344893574714661,
            "answer": "studying",
            "hit": false
          },
          {
            "score": 0.6330035924911499,
            "answer": "learnt",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7236638218164444
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.8779921531677246,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.8512266874313354,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7312533259391785,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7116833925247192,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6938437223434448,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6599069833755493,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8779921531677246
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9156426191329956,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8501996994018555,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8298845887184143,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.75872802734375,
            "answer": "keeping",
            "hit": false
          },
          {
            "score": 0.7074243426322937,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7022092938423157,
            "answer": "kept",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9156425893306732
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8786101937294006,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.8289415836334229,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6715154051780701,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.6672307252883911,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6594724655151367,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6442455649375916,
            "answer": "achieving",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8786101937294006
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8641073703765869,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8304456472396851,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.7090696096420288,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.7060808539390564,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.6951987147331238,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.690070390701294,
            "answer": "operational",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8304457068443298
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.9117853045463562,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.8514431715011597,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8348755240440369,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7159254550933838,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6895136833190918,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6895062327384949,
            "answer": "conducting",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.911785364151001
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.8795965313911438,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.8064213991165161,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.793063759803772,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7450106143951416,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.6986405849456787,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.6930655241012573,
            "answer": "avoiding",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8795965313911438
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9054629802703857,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8334571123123169,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7940071821212769,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7648531198501587,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6923705339431763,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.6884146928787231,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9054629802703857
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.8109829425811768,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.7423776984214783,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7385793328285217,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.6857457160949707,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6710848808288574,
            "answer": "protector",
            "hit": false
          },
          {
            "score": 0.670304536819458,
            "answer": "protections",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8109829723834991
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.8043807744979858,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.7270268797874451,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.717544674873352,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6544616222381592,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.6523412466049194,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.6515708565711975,
            "answer": "delivering",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8043807744979858
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.708781898021698,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.6649956107139587,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6571956276893616,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.63479083776474,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.6278957724571228,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6198889017105103,
            "answer": "receipt",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7087818682193756
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.8995882272720337,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8399744629859924,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8310452699661255,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7561284303665161,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.754045844078064,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.7424637675285339,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8995882570743561
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8595724105834961,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.821488082408905,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8103065490722656,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6977589130401611,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6972689628601074,
            "answer": "references",
            "hit": false
          },
          {
            "score": 0.6751335859298706,
            "answer": "ref",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8595724105834961
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8768891096115112,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8567647933959961,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8037610054016113,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.7389591336250305,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.7255247235298157,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.7252293825149536,
            "answer": "continue",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8037609755992889
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.7531812191009521,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.7053644061088562,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.6869193315505981,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6826026439666748,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.6634525060653687,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.6462143659591675,
            "answer": "recalls",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7531812191009521
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.7362115383148193,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.7285997867584229,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7248644828796387,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7095199227333069,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.6959322690963745,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6607908010482788,
            "answer": "represented",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7285998165607452
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.7256389260292053,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7231404185295105,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7008365392684937,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.6718209981918335,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6591550707817078,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6526780128479004,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7008365392684937
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8897396922111511,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8440684080123901,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7787458896636963,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7765282392501831,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7680912017822266,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7344567775726318,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7765282988548279
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.810541033744812,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.7802376747131348,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.6661315560340881,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6528576016426086,
            "answer": "holding",
            "hit": false
          },
          {
            "score": 0.6493854522705078,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.6457012295722961,
            "answer": "taking",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8105410635471344
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8593226671218872,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.8364204168319702,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8285298347473145,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.6680087447166443,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.658961296081543,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6378523707389832,
            "answer": "wasting",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8593226969242096
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8628506064414978,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8406733274459839,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8205626606941223,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.6948505640029907,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6891858577728271,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.6772069334983826,
            "answer": "teacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8628505766391754
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.8259173631668091,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7814571857452393,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6934585571289062,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.6856237649917603,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.6720331907272339,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.6692612767219543,
            "answer": "giving",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6856237947940826
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8507062196731567,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.8119333386421204,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7999601364135742,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7356411218643188,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6776871681213379,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.6549031734466553,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8507062196731567
      }
    ],
    "result": {
      "cnt_questions_correct": 33,
      "cnt_questions_total": 50,
      "accuracy": 0.66
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "51763919-4a86-4e7b-96b1-435ae55e2fed",
      "timestamp": "2025-05-17T21:31:46.480862"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8485741019248962,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8238933086395264,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8129417300224304,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.7826524972915649,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6671758890151978,
            "answer": "rejected",
            "hit": false
          },
          {
            "score": 0.6592584252357483,
            "answer": "allowed",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8485741019248962
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.8814874887466431,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.8403604030609131,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7979127764701843,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7679077982902527,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7485237121582031,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7319670915603638,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8814874887466431
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7372047901153564,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6843759417533875,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6827818155288696,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.6566294431686401,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6547681093215942,
            "answer": "and",
            "hit": false
          },
          {
            "score": 0.6456151008605957,
            "answer": "was",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6843759417533875
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8441432118415833,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8360245227813721,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7756186723709106,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7452911138534546,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.6813902854919434,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6740756034851074,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8441431820392609
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.906518816947937,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.8255508542060852,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8230516910552979,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.788304328918457,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.7546522617340088,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.7148555517196655,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9065188765525818
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8611685633659363,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8269109129905701,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.818603515625,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.787476122379303,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7478197813034058,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6626403331756592,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8611685931682587
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.909400224685669,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.898112416267395,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.811548113822937,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7972051501274109,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7610914707183838,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7473363280296326,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8981124758720398
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.7653288841247559,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7339162230491638,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7053570747375488,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6916882991790771,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.661291241645813,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6309472322463989,
            "answer": "applicable",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7653288841247559
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8739914894104004,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8490332365036011,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.8462175130844116,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7254523634910583,
            "answer": "request",
            "hit": false
          },
          {
            "score": 0.719022810459137,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.7119989395141602,
            "answer": "inquired",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8739914894104004
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8432708978652954,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.825158417224884,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.7309939861297607,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6781381964683533,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6771482229232788,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.644661545753479,
            "answer": "participated",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8432708978652954
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8718757629394531,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8583309650421143,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8287783861160278,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7414251565933228,
            "answer": "been",
            "hit": false
          },
          {
            "score": 0.6966081857681274,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6916420459747314,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8583309948444366
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8475630879402161,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.835647702217102,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7494493126869202,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6760793328285217,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6705870628356934,
            "answer": "thought",
            "hit": false
          },
          {
            "score": 0.6576634645462036,
            "answer": "felt",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8356476724147797
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7536803483963013,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.73963463306427,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.7359853982925415,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7081417441368103,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6445844173431396,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6395469307899475,
            "answer": "regarded",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7359853982925415
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8995046615600586,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8859581351280212,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8344396352767944,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7499605417251587,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.730463445186615,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7219579815864563,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8859581351280212
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7340898513793945,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7209165096282959,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7055783271789551,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.6528640985488892,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6435823440551758,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.6415995359420776,
            "answer": "constructed",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055782973766327
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.865624189376831,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.814330518245697,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7433336973190308,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7158007025718689,
            "answer": "choose",
            "hit": false
          },
          {
            "score": 0.7102246284484863,
            "answer": "decisions",
            "hit": false
          },
          {
            "score": 0.6960355043411255,
            "answer": "chose",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 238,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5672000348567963
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.6782088279724121,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6754993200302124,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6567888259887695,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.6566153168678284,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6462571620941162,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.6093649864196777,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6567888408899307
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.7846075296401978,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7723416090011597,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7430733442306519,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7121983766555786,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6930517554283142,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6836819052696228,
            "answer": "developments",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7723416090011597
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.7003560662269592,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.6926997303962708,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.6909918785095215,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.6848167181015015,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.6828403472900391,
            "answer": "disc",
            "hit": false
          },
          {
            "score": 0.6514460444450378,
            "answer": "discovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.700356051325798
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.7396390438079834,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.7085110545158386,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.680658221244812,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6796501874923706,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6384317278862,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6160790920257568,
            "answer": "happy",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7396390438079834
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.6541351079940796,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.6429553031921387,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.6404311656951904,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.5931410789489746,
            "answer": "assured",
            "hit": false
          },
          {
            "score": 0.5857014060020447,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.5850098729133606,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6541351079940796
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.7439851760864258,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7358415722846985,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.732303261756897,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7063578367233276,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6854640245437622,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.6009616851806641,
            "answer": "founded",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7323032766580582
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7733609676361084,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7634344696998596,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7350599765777588,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7301182150840759,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7246501445770264,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.6682483553886414,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7301181852817535
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7547569274902344,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.753188967704773,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.6768676042556763,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6699233055114746,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6615211963653564,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6189444065093994,
            "answer": "preceded",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.753188967704773
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7090007662773132,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6937227845191956,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.6722416877746582,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6308547258377075,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.6168362498283386,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.597611129283905,
            "answer": "listening",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6308547407388687
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8670352697372437,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8519522547721863,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8349437713623047,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7560588717460632,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.6936596035957336,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.671850860118866,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7560588717460632
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.805137038230896,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7794406414031982,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7493957281112671,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7463242411613464,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7393826246261597,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.6468249559402466,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7493957430124283
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7598839402198792,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7195961475372314,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6708746552467346,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6644057631492615,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.6483523845672607,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.6400649547576904,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7598839700222015
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8854823708534241,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8556623458862305,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8526065349578857,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.6514040231704712,
            "answer": "intro",
            "hit": false
          },
          {
            "score": 0.6378910541534424,
            "answer": "inserted",
            "hit": false
          },
          {
            "score": 0.637188196182251,
            "answer": "brought",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8854823708534241
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8703932762145996,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8212658166885376,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.8039982318878174,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.736122190952301,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6696549654006958,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6643176078796387,
            "answer": "consisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8212658166885376
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8453092575073242,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7653350234031677,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.684952974319458,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6700807809829712,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.6448352336883545,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.6401873826980591,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7653350234031677
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8563739657402039,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8365976810455322,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7362241744995117,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.717503011226654,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7076525688171387,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.662238359451294,
            "answer": "loose",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7076525986194611
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8375403881072998,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.834007978439331,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6712418794631958,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6600052118301392,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6422663331031799,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.6355690360069275,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6120563447475433
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8193662166595459,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.7608110904693604,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7275229692459106,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.726213276386261,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.6572778224945068,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.6512323617935181,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7262132614850998
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.883376955986023,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8644163012504578,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.861260175704956,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7121481895446777,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7065114974975586,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.6930159330368042,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8833769857883453
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.7472394704818726,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7462831139564514,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6748409271240234,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.6581686735153198,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6569485664367676,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.6318175792694092,
            "answer": "provided",
            "hit": true
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6318175792694092
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.6577063798904419,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6514351963996887,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.6498013734817505,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.6328831911087036,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.6300442218780518,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.6246027946472168,
            "answer": "pub",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6498013734817505
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.6824237108230591,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.6723454594612122,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6649553179740906,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6261434555053711,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6181605458259583,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6143955588340759,
            "answer": "reception",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6824237406253815
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8556044101715088,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8498387932777405,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8431122899055481,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7640886902809143,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.7585070133209229,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7472810745239258,
            "answer": "decreased",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8556044399738312
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8488404750823975,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8380972743034363,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8190405964851379,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7061871290206909,
            "answer": "references",
            "hit": false
          },
          {
            "score": 0.7021673321723938,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.6856850385665894,
            "answer": "ref",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8488404750823975
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8629194498062134,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7779102325439453,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6803710460662842,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.667346715927124,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6588584184646606,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6535269618034363,
            "answer": "unrelated",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.667346715927124
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8985738754272461,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8895946741104126,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7945291996002197,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7445381283760071,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.7377839088439941,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7330716848373413,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8985739350318909
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8793485164642334,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.860801100730896,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8312064409255981,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8120647668838501,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7468869090080261,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7418529987335205,
            "answer": "substitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8793485760688782
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7331350445747375,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7295101881027222,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6724177002906799,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6524092555046082,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6519668102264404,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6386129856109619,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6724177002906799
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.901675820350647,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8816637992858887,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.792456865310669,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7847297191619873,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.739592969417572,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7374976873397827,
            "answer": "seeming",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8816637694835663
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.7463510036468506,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7296814322471619,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.6758729219436646,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6347007751464844,
            "answer": "communicated",
            "hit": false
          },
          {
            "score": 0.6277270317077637,
            "answer": "transmitted",
            "hit": false
          },
          {
            "score": 0.6177525520324707,
            "answer": "dispatched",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6758728921413422
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8646514415740967,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.838890552520752,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8296940326690674,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6675688028335571,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6557767391204834,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.640533983707428,
            "answer": "budget",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8646515011787415
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8368820548057556,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8239660263061523,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.6684666275978088,
            "answer": "said",
            "hit": false
          },
          {
            "score": 0.6615140438079834,
            "answer": "revealed",
            "hit": false
          },
          {
            "score": 0.6610642671585083,
            "answer": "was",
            "hit": false
          },
          {
            "score": 0.6576218605041504,
            "answer": "telling",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.82396599650383
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8517028093338013,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8269462585449219,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7992637753486633,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7281156778335571,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.6679099798202515,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.656841516494751,
            "answer": "knows",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.851702868938446
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.6893041133880615,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.6368904113769531,
            "answer": "unity",
            "hit": false
          },
          {
            "score": 0.6304432153701782,
            "answer": "merged",
            "hit": false
          },
          {
            "score": 0.6291223168373108,
            "answer": "joined",
            "hit": false
          },
          {
            "score": 0.6288579702377319,
            "answer": "union",
            "hit": false
          },
          {
            "score": 0.6199473738670349,
            "answer": "divided",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 334,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5471304692327976
      }
    ],
    "result": {
      "cnt_questions_correct": 21,
      "cnt_questions_total": 50,
      "accuracy": 0.42
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "19b2876f-aa60-4190-833d-fdcce2de58f4",
      "timestamp": "2025-05-17T21:31:46.697119"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7324878573417664,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.6403888463973999,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6341699361801147,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6316824555397034,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.6294665932655334,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.627345085144043,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7324878871440887
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8208309412002563,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8037960529327393,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7835469841957092,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7816029787063599,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.7579455971717834,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.7454761266708374,
            "answer": "letting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6885820478200912
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.842960774898529,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.7977955937385559,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7919166088104248,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7333483695983887,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7272781133651733,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.7042046785354614,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.842960774898529
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.7683824300765991,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7045329809188843,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.701077401638031,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6574909687042236,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6515432596206665,
            "answer": "utilizes",
            "hit": false
          },
          {
            "score": 0.6467517018318176,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7683823704719543
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8867189884185791,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.838701605796814,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7831339836120605,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7398495674133301,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.6952115297317505,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.6951669454574585,
            "answer": "tells",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8867190480232239
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8544449210166931,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8274563550949097,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.792080283164978,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.6961103677749634,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6692541241645813,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6620261073112488,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8544450104236603
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8227362632751465,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.756839394569397,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.7054208517074585,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.6953181028366089,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6712113618850708,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6683586835861206,
            "answer": "trusting",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8227362632751465
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7341982126235962,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7094783782958984,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.6914941072463989,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6492650508880615,
            "answer": "though",
            "hit": false
          },
          {
            "score": 0.6418756246566772,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.6351645588874817,
            "answer": "looks",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.734198197722435
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8812176585197449,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8074885606765747,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8038887977600098,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7961840629577637,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7906254529953003,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7762818932533264,
            "answer": "composed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8812176287174225
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8298683166503906,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7736679315567017,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7300624251365662,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.726604700088501,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7144465446472168,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7111181616783142,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7300624251365662
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8743387460708618,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.8236151933670044,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8157254457473755,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7298605442047119,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.729679524898529,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7072604894638062,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.874338686466217
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.7891865968704224,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.7317702174186707,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.6948672533035278,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6750702261924744,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6622751951217651,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6598958969116211,
            "answer": "creations",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7891865968704224
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.7296710014343262,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.6981649398803711,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.6678934693336487,
            "answer": "regardless",
            "hit": false
          },
          {
            "score": 0.6628415584564209,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6577825546264648,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.6534565687179565,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.729670986533165
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8967123627662659,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.7713897228240967,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.7609200477600098,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7228482961654663,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7116926908493042,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7101765275001526,
            "answer": "explaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8967123627662659
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8766595721244812,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7739851474761963,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7364569902420044,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7307119965553284,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6838306188583374,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6812996864318848,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8766595721244812
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8732185363769531,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.7715877294540405,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.7610036730766296,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.7453610897064209,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.7388856410980225,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.7229525446891785,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.873218446969986
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8684325814247131,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.7472020983695984,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7304681539535522,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7060452699661255,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7025349736213684,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.6991244554519653,
            "answer": "helps",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8684325814247131
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7176814675331116,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.6829251646995544,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.6748690605163574,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6663684844970703,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.6641416549682617,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6468678712844849,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6829251646995544
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8769762516021729,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8176025152206421,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.767757773399353,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7640629410743713,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7466087341308594,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.722963273525238,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8769763112068176
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7381783723831177,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.6480969786643982,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6385444402694702,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.6383671164512634,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.6333825588226318,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6256759762763977,
            "answer": "continues",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7381783425807953
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8500301241874695,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8031653165817261,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8001896739006042,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7826887369155884,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7632325887680054,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7070425748825073,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8500301241874695
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.7365939021110535,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7234841585159302,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.701811671257019,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6455646753311157,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6444661617279053,
            "answer": "deaf",
            "hit": false
          },
          {
            "score": 0.6315388083457947,
            "answer": "heard",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7365939021110535
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8942497968673706,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8147351741790771,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7949005365371704,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7489091157913208,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7161033153533936,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7034937143325806,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.894249826669693
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7217626571655273,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6852575540542603,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6801745295524597,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.6752681732177734,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6613459587097168,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.6596909165382385,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7217627018690109
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8491206765174866,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7836041450500488,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7026068568229675,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.6810767650604248,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.6809700727462769,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6719316244125366,
            "answer": "pertaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8491206765174866
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8234696388244629,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.7596773505210876,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7010742425918579,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.700482189655304,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6930986642837524,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6771326065063477,
            "answer": "teaching",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8234696388244629
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8534098863601685,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8162046670913696,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.725622296333313,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6937777996063232,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6933538913726807,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.6697897911071777,
            "answer": "gets",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8534099459648132
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8412624597549438,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.8196518421173096,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.6828618049621582,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6801885366439819,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6624751091003418,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.6414920091629028,
            "answer": "owns",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8412624597549438
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8761941194534302,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8014713525772095,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7702823877334595,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7601372599601746,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7553495168685913,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7433937788009644,
            "answer": "occurrence",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8761940896511078
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8266850709915161,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7889483571052551,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7332866787910461,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7033094763755798,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.669876217842102,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6589848399162292,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8266851305961609
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8991393446922302,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.848746657371521,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7877891659736633,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7133208513259888,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7021616101264954,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6952699422836304,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8991393744945526
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8889755606651306,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8407713174819946,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.7674845457077026,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.759799599647522,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7057911157608032,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7022350430488586,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8889755606651306
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.930712878704071,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.7694678902626038,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7460711002349854,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7394025325775146,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7376924157142639,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7321039438247681,
            "answer": "giving",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.930712878704071
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8927395343780518,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.7272401452064514,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7233888506889343,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6910474300384521,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6681098937988281,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6675148010253906,
            "answer": "recipient",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8927395343780518
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8794359564781189,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.830769956111908,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.7802106142044067,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7682220935821533,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7321142554283142,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7318425178527832,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8794360458850861
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8624860644340515,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8027915358543396,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7448265552520752,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7438429594039917,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7052971720695496,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7029790878295898,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8624860942363739
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8316280841827393,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.7961673140525818,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7685368061065674,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7248190641403198,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.6888231039047241,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.6735550165176392,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8316280245780945
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7960768938064575,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.767566442489624,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.76283860206604,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7501463890075684,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7273110151290894,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6848627924919128,
            "answer": "retains",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7960769236087799
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8944249153137207,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7790306806564331,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7477854490280151,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7085553407669067,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7078750133514404,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.6974446177482605,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8944249749183655
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7530639171600342,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.7389869689941406,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7291951179504395,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7207211256027222,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7032309174537659,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.6892156600952148,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7530639171600342
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.7709513902664185,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.753372848033905,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7417258024215698,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7390854358673096,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7311369180679321,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.666445255279541,
            "answer": "apparent",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7709514200687408
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8332751393318176,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7636775970458984,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.7306675910949707,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6526467800140381,
            "answer": "stands",
            "hit": false
          },
          {
            "score": 0.6521803736686707,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6510381102561951,
            "answer": "holds",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8332751989364624
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8145146369934082,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8087809681892395,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.7193784713745117,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7177926301956177,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7119021415710449,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.644987165927887,
            "answer": "budget",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8087809085845947
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8816335797309875,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8033294677734375,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7851042151451111,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.784833550453186,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.7260761260986328,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.7260225415229797,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8816336095333099
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8445847630500793,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8185734748840332,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7721604704856873,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.73824143409729,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6835050582885742,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.6820806264877319,
            "answer": "learning",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8445847630500793
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.716083288192749,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.6519639492034912,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6381810903549194,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.627424955368042,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.616736114025116,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.6143534183502197,
            "answer": "warns",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7160833179950714
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8134965300559998,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7982426881790161,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.748249888420105,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7138860821723938,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.6946439743041992,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.6843477487564087,
            "answer": "comprehend",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7982426285743713
      }
    ],
    "result": {
      "cnt_questions_correct": 42,
      "cnt_questions_total": 47,
      "accuracy": 0.8936170212765957
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5a3243a6-5ed6-48be-89fc-29ace87898e3",
      "timestamp": "2025-05-17T21:31:46.913828"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.6668589115142822,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6577223539352417,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6479641199111938,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.644300639629364,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6410635113716125,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6079120635986328,
            "answer": "additive",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6577223986387253
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8246954083442688,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8016963601112366,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7914519309997559,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7198115587234497,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.7062993049621582,
            "answer": "agreements",
            "hit": false
          },
          {
            "score": 0.6875138282775879,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8246954679489136
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8439762592315674,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8360149264335632,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7967990040779114,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7616033554077148,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7588021755218506,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7549949884414673,
            "answer": "letting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8360149562358856
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8221648931503296,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8098886013031006,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8021226525306702,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7927303314208984,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7644158601760864,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6522321105003357,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8098886013031006
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8320446014404297,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8021672964096069,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.783474326133728,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7419945001602173,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.7202033996582031,
            "answer": "appearances",
            "hit": false
          },
          {
            "score": 0.6833570003509521,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8320446014404297
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.750949501991272,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7081325054168701,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.6971839070320129,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6767959594726562,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6492024660110474,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6159963607788086,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7509494423866272
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8509112000465393,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8317813277244568,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8172482848167419,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7492719888687134,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.6999047994613647,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6915227174758911,
            "answer": "requested",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8317813277244568
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8288761377334595,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.7998027205467224,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7184253334999084,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6673217415809631,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6642380952835083,
            "answer": "visiting",
            "hit": false
          },
          {
            "score": 0.6619203090667725,
            "answer": "participating",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7998027503490448
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8442773222923279,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8086625337600708,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7840020060539246,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.6656827926635742,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.6583681106567383,
            "answer": "made",
            "hit": false
          },
          {
            "score": 0.6556121706962585,
            "answer": "considered",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8086625337600708
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7150183916091919,
            "answer": "assuming",
            "hit": false
          },
          {
            "score": 0.7009808421134949,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6570280194282532,
            "answer": "though",
            "hit": false
          },
          {
            "score": 0.6545916199684143,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.6535784006118774,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.652763843536377,
            "answer": "actually",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6545916199684143
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8236881494522095,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.816789448261261,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7423178553581238,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.71440589427948,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7137032747268677,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6896207332611084,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.816789448261261
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8593682050704956,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.822327733039856,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8103028535842896,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.757051944732666,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.732589066028595,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.710452675819397,
            "answer": "continuous",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8593681454658508
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7444263100624084,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7098627090454102,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.7043634653091431,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6961074471473694,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.6575492024421692,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.6489952802658081,
            "answer": "making",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6961074471473694
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8168907761573792,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7877650260925293,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7649065852165222,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7102901935577393,
            "answer": "decisions",
            "hit": false
          },
          {
            "score": 0.700008749961853,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6956261396408081,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 94,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.578307181596756
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8300689458847046,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.788457989692688,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.7806180119514465,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7727603912353516,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7263273596763611,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.6870031952857971,
            "answer": "stating",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7806180119514465
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8028980493545532,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7775490283966064,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7586214542388916,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7554066181182861,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6943092346191406,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6851540207862854,
            "answer": "developer",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.758621484041214
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8172463774681091,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8037580251693726,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.751044511795044,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.7437453269958496,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.6486250758171082,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.646202564239502,
            "answer": "defining",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8172464072704315
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7394824624061584,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.6952727437019348,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.6797661781311035,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6717267036437988,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.6564919352531433,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6555907726287842,
            "answer": "already",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6952727735042572
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7598297595977783,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7563782334327698,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.730657696723938,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.7284746170043945,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7063546180725098,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6886001229286194,
            "answer": "expectations",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7563782036304474
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.7869850993156433,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.7598142027854919,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7512782216072083,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7223621010780334,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.6647139191627502,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.660517692565918,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7598141729831696
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7097547054290771,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6700208187103271,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.6668866276741028,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6477636098861694,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.6460602879524231,
            "answer": "throughout",
            "hit": false
          },
          {
            "score": 0.6415332555770874,
            "answer": "before",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6700208485126495
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7274864315986633,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7086257934570312,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6824140548706055,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6598931550979614,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.6513888239860535,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6475410461425781,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6598931401968002
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8516947031021118,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8188971281051636,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8071637153625488,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7625290155410767,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.7283953428268433,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7201851606369019,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.851694643497467
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7086148262023926,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6874078512191772,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6645656228065491,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.662850558757782,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.6572305560112,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6442131996154785,
            "answer": "ranging",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.708614856004715
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8660849332809448,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8601818084716797,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8329576253890991,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.6434743404388428,
            "answer": "intro",
            "hit": false
          },
          {
            "score": 0.6329956650733948,
            "answer": "inserted",
            "hit": false
          },
          {
            "score": 0.63157057762146,
            "answer": "introductory",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8660849034786224
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.7845914363861084,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7668007016181946,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7467060089111328,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6852408647537231,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.684884786605835,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.6841732859611511,
            "answer": "pertaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7467059940099716
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8515774607658386,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7148941159248352,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.6770554780960083,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6626011729240417,
            "answer": "location",
            "hit": false
          },
          {
            "score": 0.6410923004150391,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.6298348307609558,
            "answer": "searched",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7148941606283188
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8258628845214844,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7957613468170166,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7237800359725952,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7033169269561768,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.6988319158554077,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6883173584938049,
            "answer": "lost",
            "hit": true
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6883173882961273
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.831640362739563,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7722522020339966,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6946065425872803,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6870954036712646,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6522656679153442,
            "answer": "controlling",
            "hit": false
          },
          {
            "score": 0.6400184631347656,
            "answer": "handled",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6010372936725616
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8288123607635498,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7385951280593872,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7243067622184753,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.6932387351989746,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.6612949371337891,
            "answer": "weddings",
            "hit": false
          },
          {
            "score": 0.6607534885406494,
            "answer": "bride",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6932387799024582
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7844753265380859,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.754889726638794,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7514680027961731,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7230833768844604,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.6773042678833008,
            "answer": "working",
            "hit": false
          },
          {
            "score": 0.6677460670471191,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6569117605686188
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8630024194717407,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8428084254264832,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8273181915283203,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7119746208190918,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7051200866699219,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6966185569763184,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8428085148334503
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8327181935310364,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8254915475845337,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7854930758476257,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.780554473400116,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7593256235122681,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.6779658198356628,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7854930758476257
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.859097421169281,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7555359601974487,
            "answer": "giving",
            "hit": false
          },
          {
            "score": 0.7419700026512146,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7382034659385681,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7370947003364563,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7189949750900269,
            "answer": "supplied",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 1190,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5620738677680492
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.6875950694084167,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.6711249351501465,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.663092851638794,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.6617630124092102,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6504177451133728,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.6289392113685608,
            "answer": "productions",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6107708662748337
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8206283450126648,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7617059350013733,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7281604409217834,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6779500842094421,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.6705361008644104,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6660488843917847,
            "answer": "recipients",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7617059946060181
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8380979299545288,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8256774544715881,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.7968891263008118,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7712380886077881,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.7546372413635254,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7258244752883911,
            "answer": "decrease",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8256774544715881
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8169799447059631,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7668307423591614,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7652629017829895,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7447992563247681,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.6876001358032227,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.6841966509819031,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6368101239204407
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.7786267995834351,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7763027548789978,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7683053016662598,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7490826845169067,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6937694549560547,
            "answer": "additional",
            "hit": false
          },
          {
            "score": 0.6937424540519714,
            "answer": "still",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7786268591880798
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8708192706108093,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8705925941467285,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8264236450195312,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8132525682449341,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7704302072525024,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7408430576324463,
            "answer": "substituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8705925941467285
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8259378671646118,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8256852626800537,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7613406181335449,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7019720077514648,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6848610639572144,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6670647859573364,
            "answer": "corresponding",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8259378969669342
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7578257322311401,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7431991100311279,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7348150610923767,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7016656398773193,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6846259236335754,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.6827819347381592,
            "answer": "demanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6521604061126709
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8402427434921265,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7566401362419128,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.655689001083374,
            "answer": "transmitting",
            "hit": false
          },
          {
            "score": 0.6519205570220947,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6508505344390869,
            "answer": "transmitted",
            "hit": false
          },
          {
            "score": 0.6486421823501587,
            "answer": "receiving",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6519205272197723
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8335037231445312,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.762953519821167,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7493260502815247,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7245028018951416,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7224924564361572,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6615172028541565,
            "answer": "budget",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.762953519821167
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.7904341220855713,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.7848345637321472,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.7257276773452759,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.6829081773757935,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.6623772382736206,
            "answer": "subjected",
            "hit": false
          },
          {
            "score": 0.6541452407836914,
            "answer": "experiencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7848345637321472
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8198138475418091,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8121412396430969,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.7738595604896545,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7453149557113647,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6972832083702087,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.694932222366333,
            "answer": "teacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8121411800384521
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.6665892601013184,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.6560057997703552,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6460050940513611,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.5927766561508179,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.5898869037628174,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.5862520337104797,
            "answer": "wrote",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6665892601013184
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8333067893981934,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7943323850631714,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7317820191383362,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.7306965589523315,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.6993586421012878,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.6873158812522888,
            "answer": "insight",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.794332355260849
      }
    ],
    "result": {
      "cnt_questions_correct": 11,
      "cnt_questions_total": 48,
      "accuracy": 0.22916666666666666
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2d750c6f-a4b7-4235-97a8-5dc1aff728de",
      "timestamp": "2025-05-17T21:31:47.112595"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7706018686294556,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.7504401206970215,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7442604899406433,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.7256736755371094,
            "answer": "additional",
            "hit": false
          },
          {
            "score": 0.6691818237304688,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6672822833061218,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7504401206970215
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8605804443359375,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8411580920219421,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.789493203163147,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.6990615129470825,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6822282075881958,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.6809087991714478,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8411580920219421
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.6850011348724365,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.6741435527801514,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6597920060157776,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.637661337852478,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6189736723899841,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.6132616400718689,
            "answer": "permits",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6850011646747589
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8564224243164062,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8409148454666138,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8043431639671326,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7645984888076782,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7356538772583008,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6720909476280212,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.856422483921051
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.9046220779418945,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.894335925579071,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8035223484039307,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7908118963241577,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7737540602684021,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7725121974945068,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.894335925579071
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8401327729225159,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7435853481292725,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7380205392837524,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7265470623970032,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6949453353881836,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.682523250579834,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8401327729225159
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.9059332609176636,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.8723747730255127,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.8347879648208618,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7550131678581238,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7335191369056702,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.723121166229248,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9059333205223083
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.9014500975608826,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8745385408401489,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8022793531417847,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6821025013923645,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6755157709121704,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6748121976852417,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8745385408401489
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8577588796615601,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.848874568939209,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7605307698249817,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7331739664077759,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7020191550254822,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6884761452674866,
            "answer": "thought",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8488745987415314
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.835350513458252,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7263565063476562,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7201575040817261,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.7185238003730774,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6726296544075012,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.6671237945556641,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8353505730628967
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9162874817848206,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.8692131042480469,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8321986794471741,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7958020567893982,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7766501307487488,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7375869750976562,
            "answer": "composed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9162874817848206
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.7156133055686951,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.707744836807251,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.6842531561851501,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.6203464865684509,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6139189004898071,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6054604053497314,
            "answer": "included",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7077448666095734
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8959759473800659,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.8918958902359009,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.831319272518158,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.737420380115509,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7343333959579468,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7240882515907288,
            "answer": "still",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8918958604335785
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.7557571530342102,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7225860953330994,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7107687592506409,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7014251947402954,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.6868041157722473,
            "answer": "produced",
            "hit": false
          },
          {
            "score": 0.6841484308242798,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6732517182826996
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8709987998008728,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7994354963302612,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7020193934440613,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.6927539706230164,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.6916441321372986,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.6813498735427856,
            "answer": "decisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5903868302702904
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8266985416412354,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8262656927108765,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7775090932846069,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.7479628324508667,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6927236318588257,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.6785401105880737,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8262657225131989
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8318743705749512,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7719730138778687,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.767325758934021,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7408487796783447,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6832674741744995,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6512171626091003,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7719730138778687
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8224782943725586,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8193265199661255,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7484986782073975,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.6920775175094604,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6606994867324829,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6471399664878845,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8193265199661255
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8226472735404968,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7707030773162842,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7540570497512817,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7392144203186035,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7325254082679749,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.730449914932251,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8226472735404968
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8126484751701355,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.802923321723938,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7615844011306763,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7178652286529541,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.6788171529769897,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.6690264344215393,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8029233515262604
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8085650205612183,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7594998478889465,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7103580236434937,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.649329662322998,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.6381075382232666,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.6319311261177063,
            "answer": "was",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.808565080165863
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.8864309787750244,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8697962760925293,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8054603338241577,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7668675780296326,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7654482126235962,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7101591229438782,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8864309787750244
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7528176307678223,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.703285813331604,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.690309464931488,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6871477365493774,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6600780487060547,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.6590402722358704,
            "answer": "hearings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7528176307678223
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7244576215744019,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7122191786766052,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.676478385925293,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.6691924929618835,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.6387726068496704,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.6201569437980652,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.724457636475563
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.836442232131958,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.7897628545761108,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.755253791809082,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7431825995445251,
            "answer": "intention",
            "hit": false
          },
          {
            "score": 0.7223882675170898,
            "answer": "intentions",
            "hit": false
          },
          {
            "score": 0.7066298723220825,
            "answer": "plans",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7897628843784332
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8613619208335876,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.851570725440979,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8298149704933167,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.6327848434448242,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6310099959373474,
            "answer": "intro",
            "hit": false
          },
          {
            "score": 0.6302194595336914,
            "answer": "inserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8515706658363342
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8840938806533813,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8107872009277344,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7950454354286194,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.6962294578552246,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.695274829864502,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.6923567056655884,
            "answer": "consisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8107872009277344
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.857561469078064,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8137936592102051,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7691407203674316,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7167404890060425,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7081884145736694,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6768292784690857,
            "answer": "gains",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7081884443759918
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8492411971092224,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7863445281982422,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6451932787895203,
            "answer": "succeeded",
            "hit": false
          },
          {
            "score": 0.6434231400489807,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.640788197517395,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6386696100234985,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6367485821247101
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9153848886489868,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8321224451065063,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7747713327407837,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7710309028625488,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7520569562911987,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7405392527580261,
            "answer": "happen",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.915384829044342
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8749582171440125,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7856196165084839,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7279794216156006,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.6835609674453735,
            "answer": "operative",
            "hit": false
          },
          {
            "score": 0.6788257956504822,
            "answer": "operation",
            "hit": false
          },
          {
            "score": 0.6726692318916321,
            "answer": "operational",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.727979451417923
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8824952840805054,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.8501321077346802,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.843224823474884,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7165894508361816,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7039068937301636,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6935142278671265,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8501321971416473
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8534419536590576,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8179188966751099,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8150036334991455,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.7657064199447632,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7498844265937805,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.6956048011779785,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8179188370704651
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8569902181625366,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7581460475921631,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7534998059272766,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7376206517219543,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7343728542327881,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7298667430877686,
            "answer": "gave",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 1993,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5542761571705341
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8466525077819824,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7893886566162109,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.700563907623291,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6775811910629272,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6542178392410278,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6487851142883301,
            "answer": "suffered",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7893886566162109
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8444633483886719,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.8257161378860474,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.8007782697677612,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7083500623703003,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7029836177825928,
            "answer": "references",
            "hit": false
          },
          {
            "score": 0.6973603367805481,
            "answer": "denotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8257161378860474
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8548716902732849,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7752079367637634,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6733871698379517,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6643211841583252,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.6502388715744019,
            "answer": "unrelated",
            "hit": false
          },
          {
            "score": 0.6461869478225708,
            "answer": "related",
            "hit": true
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6461869776248932
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8747117519378662,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8700205087661743,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7746097445487976,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7538273334503174,
            "answer": "still",
            "hit": false
          },
          {
            "score": 0.7103139162063599,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6979080438613892,
            "answer": "continue",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8700205087661743
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8598453998565674,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.843032717704773,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.825816810131073,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7625213861465454,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.7514462471008301,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.725883960723877,
            "answer": "substituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8598454594612122
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8657349348068237,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8336435556411743,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.739612877368927,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.696452260017395,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6952131390571594,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.6859514713287354,
            "answer": "constitutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8657349646091461
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7019937634468079,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6705203652381897,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6650990843772888,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6628122329711914,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6607414484024048,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.6387319564819336,
            "answer": "needed",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6628122478723526
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8946079015731812,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8925207853317261,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.797646701335907,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7637494802474976,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7538619637489319,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.742335855960846,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8925207853317261
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8594282865524292,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7664635181427002,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6688042879104614,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6478890180587769,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6364659070968628,
            "answer": "transmitted",
            "hit": false
          },
          {
            "score": 0.6338533163070679,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.668804258108139
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8599246144294739,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8275854587554932,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.766584038734436,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6676792502403259,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6541562676429749,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6251490712165833,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8275854885578156
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8750180006027222,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8172124624252319,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7944669723510742,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7732452750205994,
            "answer": "suggest",
            "hit": false
          },
          {
            "score": 0.7586755156517029,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.7398674488067627,
            "answer": "suggestion",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8750180900096893
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8746795654296875,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8514343500137329,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6783356666564941,
            "answer": "said",
            "hit": false
          },
          {
            "score": 0.6758590936660767,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.6612305641174316,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6594700813293457,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8746795654296875
      }
    ],
    "result": {
      "cnt_questions_correct": 16,
      "cnt_questions_total": 46,
      "accuracy": 0.34782608695652173
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3b702203-ccc2-42fd-abd1-3b6e43ddd533",
      "timestamp": "2025-05-17T21:31:47.326927"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.6694154739379883,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.6659839153289795,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.6088159084320068,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.601262629032135,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.5951681733131409,
            "answer": "fierce",
            "hit": false
          },
          {
            "score": 0.5949034094810486,
            "answer": "serious",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 1113,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5385270342230797
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7615905404090881,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.6536424160003662,
            "answer": "ruthless",
            "hit": true
          },
          {
            "score": 0.6132729053497314,
            "answer": "unemployed",
            "hit": false
          },
          {
            "score": 0.6110920906066895,
            "answer": "prostitution",
            "hit": false
          },
          {
            "score": 0.6007586121559143,
            "answer": "angrily",
            "hit": false
          },
          {
            "score": 0.5954771041870117,
            "answer": "transgender",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6536424309015274
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "18f42918-cf49-4336-a892-eae755b49598",
      "timestamp": "2025-05-17T21:31:47.521651"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.7449586987495422,
            "answer": "ability",
            "hit": false
          },
          {
            "score": 0.6115318536758423,
            "answer": "worthy",
            "hit": false
          },
          {
            "score": 0.5877562165260315,
            "answer": "eligible",
            "hit": false
          },
          {
            "score": 0.5824882984161377,
            "answer": "impossible",
            "hit": false
          },
          {
            "score": 0.5822185277938843,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.5804054141044617,
            "answer": "unreliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 121,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5482653602957726
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.776782751083374,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.6374735832214355,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.6286939382553101,
            "answer": "tolerated",
            "hit": false
          },
          {
            "score": 0.6266145706176758,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.6255870461463928,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.6247525215148926,
            "answer": "accept",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.776782751083374
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.7189942598342896,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.7163603901863098,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.6659289002418518,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.6643556952476501,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.6493743658065796,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.6253496408462524,
            "answer": "devastated",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7163603901863098
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8082098960876465,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.6366931200027466,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.6344708204269409,
            "answer": "avail",
            "hit": false
          },
          {
            "score": 0.6301332116127014,
            "answer": "accessible",
            "hit": false
          },
          {
            "score": 0.6253433227539062,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.624083399772644,
            "answer": "availability",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8082099556922913
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.7797442674636841,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.7129371166229248,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6877059936523438,
            "answer": "unable",
            "hit": false
          },
          {
            "score": 0.6808543801307678,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.6676463484764099,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.6579813361167908,
            "answer": "knows",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7797442674636841
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7284806966781616,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7180456519126892,
            "answer": "particular",
            "hit": false
          },
          {
            "score": 0.6709668040275574,
            "answer": "unknown",
            "hit": false
          },
          {
            "score": 0.6699091792106628,
            "answer": "sure",
            "hit": false
          },
          {
            "score": 0.6559208631515503,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.6541246175765991,
            "answer": "numerous",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.641801118850708
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.818352460861206,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.7582176923751831,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.730668842792511,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.7222521305084229,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.7140800952911377,
            "answer": "alterations",
            "hit": false
          },
          {
            "score": 0.7093989849090576,
            "answer": "modified",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6933811604976654
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8039133548736572,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.7428287267684937,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.6996566653251648,
            "answer": "comfort",
            "hit": false
          },
          {
            "score": 0.686224102973938,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.6749861240386963,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.6658655405044556,
            "answer": "cozy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8039133846759796
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.7318179607391357,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7284950017929077,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.7168391942977905,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.698828399181366,
            "answer": "aware",
            "hit": false
          },
          {
            "score": 0.6623456478118896,
            "answer": "intentional",
            "hit": false
          },
          {
            "score": 0.6578130722045898,
            "answer": "unaware",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7284950315952301
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.7123262286186218,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.7098022103309631,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.6797530651092529,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6353155374526978,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.6350265145301819,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.6344618797302246,
            "answer": "unemployment",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.712326243519783
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.8214153051376343,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.7490527629852295,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7256791591644287,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7230421900749207,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7225285172462463,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7154724597930908,
            "answer": "unexpected",
            "hit": true
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.715472474694252
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.7800984382629395,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.7467063665390015,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.7151854038238525,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.6796954870223999,
            "answer": "final",
            "hit": false
          },
          {
            "score": 0.6778890490531921,
            "answer": "completing",
            "hit": false
          },
          {
            "score": 0.6739275455474854,
            "answer": "ended",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7151854336261749
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.7586077451705933,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.6806737184524536,
            "answer": "luck",
            "hit": false
          },
          {
            "score": 0.6550067663192749,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.6415300369262695,
            "answer": "grateful",
            "hit": false
          },
          {
            "score": 0.6392824649810791,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.6371309757232666,
            "answer": "privileged",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7586077451705933
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.6975328922271729,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.6251407861709595,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6241887211799622,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6113921999931335,
            "answer": "birthday",
            "hit": false
          },
          {
            "score": 0.6081309914588928,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.6077725291252136,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6975328922271729
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.7300599217414856,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.7228401899337769,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7191141843795776,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.70871502161026,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7027900218963623,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.6953872442245483,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.730059951543808
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.6518568992614746,
            "answer": "unknown",
            "hit": true
          },
          {
            "score": 0.6232286691665649,
            "answer": "unpopular",
            "hit": false
          },
          {
            "score": 0.6209155321121216,
            "answer": "unidentified",
            "hit": false
          },
          {
            "score": 0.6072746515274048,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.6055504083633423,
            "answer": "unnamed",
            "hit": false
          },
          {
            "score": 0.6053940057754517,
            "answer": "unfamiliar",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6518568992614746
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.7898989915847778,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7023272514343262,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.681242823600769,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.6543382406234741,
            "answer": "legally",
            "hit": false
          },
          {
            "score": 0.6539379358291626,
            "answer": "improper",
            "hit": false
          },
          {
            "score": 0.6527396440505981,
            "answer": "illegally",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7898989915847778
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.7361332774162292,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.7148211002349854,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7030119895935059,
            "answer": "payment",
            "hit": false
          },
          {
            "score": 0.6874505877494812,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.6671516299247742,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.6279528141021729,
            "answer": "payments",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7148211151361465
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.7792510390281677,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.7477139234542847,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.740918755531311,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6850377917289734,
            "answer": "pleasing",
            "hit": false
          },
          {
            "score": 0.6737895011901855,
            "answer": "pleas",
            "hit": false
          },
          {
            "score": 0.6719664335250854,
            "answer": "lovely",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7792510688304901
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.716086745262146,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7127540111541748,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7011008262634277,
            "answer": "widely",
            "hit": false
          },
          {
            "score": 0.6896524429321289,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.6772638559341431,
            "answer": "commonly",
            "hit": false
          },
          {
            "score": 0.6728959083557129,
            "answer": "controversial",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.716086745262146
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.7877587080001831,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.6987029910087585,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.6563036441802979,
            "answer": "predict",
            "hit": false
          },
          {
            "score": 0.652466356754303,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.6360968351364136,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.6317495107650757,
            "answer": "disappointing",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7877587676048279
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.6469647288322449,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.6339980363845825,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.6320371031761169,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6274628043174744,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.6150660514831543,
            "answer": "posted",
            "hit": false
          },
          {
            "score": 0.608038067817688,
            "answer": "edited",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6469647288322449
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.7787745594978333,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7160278558731079,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.6962785720825195,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.6823804378509521,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.6805065274238586,
            "answer": "decent",
            "hit": false
          },
          {
            "score": 0.6613936424255371,
            "answer": "adequate",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7787745893001556
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.704624593257904,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.6399312615394592,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.6229328513145447,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.6188396215438843,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6153435111045837,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.6134258508682251,
            "answer": "allied",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7046246081590652
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.802966296672821,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.6867718696594238,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.6456291079521179,
            "answer": "inaccurate",
            "hit": false
          },
          {
            "score": 0.6288523077964783,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.6143787503242493,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.6143211126327515,
            "answer": "unavailable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.802966296672821
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.74754798412323,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7350237965583801,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.7256154417991638,
            "answer": "designated",
            "hit": false
          },
          {
            "score": 0.7194568514823914,
            "answer": "stated",
            "hit": false
          },
          {
            "score": 0.717578649520874,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.6971720457077026,
            "answer": "described",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7350237667560577
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8551135063171387,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.7867389917373657,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.753442108631134,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7322086095809937,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.707220196723938,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.669166088104248,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8551135659217834
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.6659133434295654,
            "answer": "use",
            "hit": false
          },
          {
            "score": 0.6656988859176636,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.6358381509780884,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.6096116304397583,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.599510908126831,
            "answer": "abused",
            "hit": false
          },
          {
            "score": 0.5962036848068237,
            "answer": "unwanted",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6656989008188248
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7715315818786621,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7272909879684448,
            "answer": "normal",
            "hit": false
          },
          {
            "score": 0.6999855637550354,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.697779655456543,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.6959866285324097,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.672124445438385,
            "answer": "unusual",
            "hit": true
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.672124445438385
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.7006185054779053,
            "answer": "wished",
            "hit": false
          },
          {
            "score": 0.6964004039764404,
            "answer": "unwanted",
            "hit": true
          },
          {
            "score": 0.6882902383804321,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.6814226508140564,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.6660342216491699,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.6547831892967224,
            "answer": "want",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6964003443717957
      }
    ],
    "result": {
      "cnt_questions_correct": 18,
      "cnt_questions_total": 30,
      "accuracy": 0.6
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9cda307c-4133-43f8-86d8-f248b563e743",
      "timestamp": "2025-05-17T21:31:47.531650"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7206656336784363,
            "answer": "accordingly",
            "hit": true
          },
          {
            "score": 0.6919386386871338,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.6441828012466431,
            "answer": "consequently",
            "hit": false
          },
          {
            "score": 0.6308708190917969,
            "answer": "appropriately",
            "hit": false
          },
          {
            "score": 0.6240713596343994,
            "answer": "reportedly",
            "hit": false
          },
          {
            "score": 0.6109654903411865,
            "answer": "without",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7206656187772751
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.6541763544082642,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.6539509892463684,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.6432173252105713,
            "answer": "literally",
            "hit": false
          },
          {
            "score": 0.6275884509086609,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.6256458759307861,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.6223605871200562,
            "answer": "honestly",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6539509892463684
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.7999295592308044,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.691872239112854,
            "answer": "significantly",
            "hit": false
          },
          {
            "score": 0.6912487745285034,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.6888916492462158,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6879380941390991,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.6850695610046387,
            "answer": "adds",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6691254377365112
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8096175789833069,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7514252662658691,
            "answer": "apparently",
            "hit": true
          },
          {
            "score": 0.7444714307785034,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7142400741577148,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7018346786499023,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6891953945159912,
            "answer": "evidently",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7514252066612244
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.6940447688102722,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.6879861354827881,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.667680025100708,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.6311666965484619,
            "answer": "beauty",
            "hit": false
          },
          {
            "score": 0.6307500600814819,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.6287437081336975,
            "answer": "amazing",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6940447688102722
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7479346990585327,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.6716513633728027,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6374486088752747,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.6172268390655518,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.6089670658111572,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.6022653579711914,
            "answer": "critique",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7479346990585327
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.7801294326782227,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.6959230899810791,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.6888763308525085,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.6489473581314087,
            "answer": "cult",
            "hit": false
          },
          {
            "score": 0.6074413061141968,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.6045696139335632,
            "answer": "socially",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7801294326782227
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.5914161205291748,
            "answer": "casually",
            "hit": false
          },
          {
            "score": 0.5903283953666687,
            "answer": "decidedly",
            "hit": true
          },
          {
            "score": 0.5893744230270386,
            "answer": "reluctantly",
            "hit": false
          },
          {
            "score": 0.5877926349639893,
            "answer": "submitted",
            "hit": false
          },
          {
            "score": 0.5849689245223999,
            "answer": "overwhelmingly",
            "hit": false
          },
          {
            "score": 0.5846807360649109,
            "answer": "consciously",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5903284177184105
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.753491222858429,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7116246819496155,
            "answer": "differential",
            "hit": false
          },
          {
            "score": 0.7103115320205688,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.7061119079589844,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.6837962865829468,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.6817793250083923,
            "answer": "differentiated",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.753491222858429
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8035080432891846,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7303106188774109,
            "answer": "electronic",
            "hit": false
          },
          {
            "score": 0.704993724822998,
            "answer": "computer",
            "hit": false
          },
          {
            "score": 0.6760762929916382,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6688841581344604,
            "answer": "web",
            "hit": false
          },
          {
            "score": 0.6642980575561523,
            "answer": "video",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8035080432891846
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7462409138679504,
            "answer": "effect",
            "hit": false
          },
          {
            "score": 0.7176727056503296,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.7072477340698242,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.690590500831604,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6430176496505737,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.6261194944381714,
            "answer": "efficacy",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7176726758480072
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.7567129731178284,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.6674337387084961,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.664974570274353,
            "answer": "epa",
            "hit": false
          },
          {
            "score": 0.6561784744262695,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.643765389919281,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6355512142181396,
            "answer": "climate",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.756712943315506
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.7979376316070557,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.7283253073692322,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7216882705688477,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.7210205793380737,
            "answer": "numerous",
            "hit": false
          },
          {
            "score": 0.718765139579773,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7051267027854919,
            "answer": "expansive",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7979376316070557
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.8178321123123169,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.8108320236206055,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7866154313087463,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7729477882385254,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7303507328033447,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7241343259811401,
            "answer": "celebrated",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7303507328033447
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7414759397506714,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.6706075668334961,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.6643832921981812,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6518771052360535,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.6514750719070435,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.6319917440414429,
            "answer": "monetary",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7414759546518326
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.7971324324607849,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.703289806842804,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6446507573127747,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.6441737413406372,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.6247009038925171,
            "answer": "locally",
            "hit": false
          },
          {
            "score": 0.6214436888694763,
            "answer": "local",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7971324324607849
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.7090489268302917,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7082589268684387,
            "answer": "history",
            "hit": false
          },
          {
            "score": 0.7056512832641602,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.705104410648346,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.6984284520149231,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.6539771556854248,
            "answer": "histories",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7051044255495071
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.872126579284668,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.8318606019020081,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.8278962969779968,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.8239741921424866,
            "answer": "large",
            "hit": false
          },
          {
            "score": 0.7744698524475098,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.7623748183250427,
            "answer": "tremendous",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7618902325630188
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.8282389044761658,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7417842745780945,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7153387665748596,
            "answer": "directly",
            "hit": false
          },
          {
            "score": 0.7116320133209229,
            "answer": "quickly",
            "hit": false
          },
          {
            "score": 0.6858983039855957,
            "answer": "instant",
            "hit": false
          },
          {
            "score": 0.6826634407043457,
            "answer": "promptly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8282389640808105
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.7279722690582275,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6708018183708191,
            "answer": "importantly",
            "hit": true
          },
          {
            "score": 0.6705843210220337,
            "answer": "essential",
            "hit": false
          },
          {
            "score": 0.6664406061172485,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.6637307405471802,
            "answer": "importance",
            "hit": false
          },
          {
            "score": 0.6589474678039551,
            "answer": "pivotal",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6708018481731415
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.7482367753982544,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7383407950401306,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.6900174617767334,
            "answer": "progressively",
            "hit": false
          },
          {
            "score": 0.680875301361084,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.6801221370697021,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.6746625900268555,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7383407950401306
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7592549324035645,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.7047303915023804,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6360120177268982,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.6336485147476196,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6158590316772461,
            "answer": "inside",
            "hit": false
          },
          {
            "score": 0.6127454042434692,
            "answer": "interior",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7592549920082092
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.8023315668106079,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7392629981040955,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7207157611846924,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.6880263090133667,
            "answer": "overseas",
            "hit": false
          },
          {
            "score": 0.665453314781189,
            "answer": "nationally",
            "hit": false
          },
          {
            "score": 0.6575313806533813,
            "answer": "nationwide",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8023315668106079
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.7424184083938599,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.6587037444114685,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6498626470565796,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.6410115361213684,
            "answer": "law",
            "hit": false
          },
          {
            "score": 0.6361966133117676,
            "answer": "lawful",
            "hit": false
          },
          {
            "score": 0.6325229406356812,
            "answer": "lawyer",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7424184381961823
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.7596709728240967,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7090277671813965,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.6732586026191711,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.6648011803627014,
            "answer": "psychiatrist",
            "hit": false
          },
          {
            "score": 0.6494830250740051,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.6483778953552246,
            "answer": "emotionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7596710026264191
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.6805582046508789,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.6368789076805115,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.6302400827407837,
            "answer": "looks",
            "hit": false
          },
          {
            "score": 0.6294432878494263,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.6190058588981628,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.6172628402709961,
            "answer": "neatly",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6805582046508789
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.8061261773109436,
            "answer": "obviously",
            "hit": true
          },
          {
            "score": 0.7660800218582153,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7398444414138794,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.6946186423301697,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6884415149688721,
            "answer": "easily",
            "hit": false
          },
          {
            "score": 0.6862866878509521,
            "answer": "readily",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8061261773109436
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.8141082525253296,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.6534451246261597,
            "answer": "physics",
            "hit": false
          },
          {
            "score": 0.6335041522979736,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.6310004591941833,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.6219885349273682,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.6202679872512817,
            "answer": "emotionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8141082525253296
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.7751554846763611,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.6966719627380371,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.6598268151283264,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6582460999488831,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.6505123972892761,
            "answer": "partisan",
            "hit": false
          },
          {
            "score": 0.6343016624450684,
            "answer": "ideological",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7751554846763611
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.6987990140914917,
            "answer": "practically",
            "hit": true
          },
          {
            "score": 0.6845684051513672,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.6711690425872803,
            "answer": "useful",
            "hit": false
          },
          {
            "score": 0.6477035880088806,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.6439782977104187,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.6415083408355713,
            "answer": "commercially",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6987990438938141
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7324057817459106,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.7073001861572266,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.6954823732376099,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6519173383712769,
            "answer": "recent",
            "hit": false
          },
          {
            "score": 0.6512628793716431,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.6498380899429321,
            "answer": "formerly",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.732405811548233
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7802460789680481,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7569314241409302,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.7151756286621094,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.693437933921814,
            "answer": "frequently",
            "hit": false
          },
          {
            "score": 0.6872777342796326,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.6743636131286621,
            "answer": "extremely",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.756931483745575
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.8102411031723022,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.7565761804580688,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7063689827919006,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.7039266228675842,
            "answer": "significantly",
            "hit": false
          },
          {
            "score": 0.6849642992019653,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.682835578918457,
            "answer": "truly",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8102411329746246
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.7855603098869324,
            "answer": "sex",
            "hit": false
          },
          {
            "score": 0.7802283763885498,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.7524714469909668,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7009937763214111,
            "answer": "erotic",
            "hit": false
          },
          {
            "score": 0.694753885269165,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.6848616600036621,
            "answer": "heterosexual",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7802283763885498
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.7768594026565552,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.7039927244186401,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6868283748626709,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.6812732219696045,
            "answer": "substantially",
            "hit": false
          },
          {
            "score": 0.673865020275116,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.6734923720359802,
            "answer": "noteworthy",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7768594026565552
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7577728629112244,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.7523038387298584,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7278632521629333,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.7081358432769775,
            "answer": "identical",
            "hit": false
          },
          {
            "score": 0.6993893980979919,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.6801851391792297,
            "answer": "like",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7577728927135468
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.7694607377052307,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.7489594221115112,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7178717851638794,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.6878128051757812,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6774919629096985,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6617214679718018,
            "answer": "strengthened",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7694607377052307
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8710120916366577,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.8018307685852051,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.7751855254173279,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.7371196746826172,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.7165703177452087,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7123880386352539,
            "answer": "resulting",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8710120916366577
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8500937819480896,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.7863276600837708,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7639002799987793,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7247742414474487,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7233074903488159,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.6946272253990173,
            "answer": "effectively",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8500937819480896
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.7415567636489868,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.6902674436569214,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.6460967063903809,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6288852095603943,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.6210430860519409,
            "answer": "tradition",
            "hit": false
          },
          {
            "score": 0.6128143668174744,
            "answer": "standard",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7415567934513092
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.6999708414077759,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.6609698534011841,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.6570061445236206,
            "answer": "traditionally",
            "hit": false
          },
          {
            "score": 0.6492630243301392,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.6487506628036499,
            "answer": "characteristic",
            "hit": false
          },
          {
            "score": 0.641620934009552,
            "answer": "normally",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6999708414077759
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.7342168092727661,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.6347170472145081,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.6060177683830261,
            "answer": "exclusively",
            "hit": false
          },
          {
            "score": 0.6011189818382263,
            "answer": "universally",
            "hit": false
          },
          {
            "score": 0.5978253483772278,
            "answer": "exclusive",
            "hit": false
          },
          {
            "score": 0.5941807627677917,
            "answer": "distinctly",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7342168092727661
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.6403552889823914,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.612974226474762,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.608583927154541,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6063129901885986,
            "answer": "abstract",
            "hit": false
          },
          {
            "score": 0.6044573783874512,
            "answer": "physically",
            "hit": false
          },
          {
            "score": 0.6042874455451965,
            "answer": "virtually",
            "hit": true
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6042874231934547
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.7534041404724121,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.6155858635902405,
            "answer": "visibly",
            "hit": false
          },
          {
            "score": 0.6079435348510742,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.6076520681381226,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.6023848056793213,
            "answer": "vision",
            "hit": false
          },
          {
            "score": 0.5969357490539551,
            "answer": "physically",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7534041702747345
      }
    ],
    "result": {
      "cnt_questions_correct": 31,
      "cnt_questions_total": 44,
      "accuracy": 0.7045454545454546
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ae731c0c-57ee-416a-8275-9f3b9a9edbf5",
      "timestamp": "2025-05-17T21:31:47.651841"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7564104795455933,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.7233667373657227,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.6602134108543396,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6552233099937439,
            "answer": "knowledge",
            "hit": false
          },
          {
            "score": 0.654329776763916,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.6491492986679077,
            "answer": "conscious",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7564105093479156
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.7758933901786804,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7311614155769348,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7072917222976685,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.683125376701355,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.6482910513877869,
            "answer": "conscience",
            "hit": false
          },
          {
            "score": 0.6278619170188904,
            "answer": "aware",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7758933901786804
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7366488575935364,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7185261249542236,
            "answer": "effect",
            "hit": false
          },
          {
            "score": 0.6690758466720581,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6477718353271484,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.6116030216217041,
            "answer": "implementation",
            "hit": false
          },
          {
            "score": 0.6066787242889404,
            "answer": "efficiency",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7366488873958588
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.6714135408401489,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.6276966333389282,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6229863166809082,
            "answer": "celebrations",
            "hit": false
          },
          {
            "score": 0.6211985349655151,
            "answer": "celebration",
            "hit": false
          },
          {
            "score": 0.6170501708984375,
            "answer": "hope",
            "hit": false
          },
          {
            "score": 0.6159281134605408,
            "answer": "prosperity",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6714135557413101
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7199890613555908,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.6789870858192444,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.6688423156738281,
            "answer": "insane",
            "hit": false
          },
          {
            "score": 0.6472738981246948,
            "answer": "insanity",
            "hit": false
          },
          {
            "score": 0.6282764673233032,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6241672039031982,
            "answer": "fury",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7199890911579132
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7731378078460693,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7020195722579956,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.6995596885681152,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.6905063390731812,
            "answer": "tragic",
            "hit": false
          },
          {
            "score": 0.6511015892028809,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6499397158622742,
            "answer": "misery",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7731378078460693
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.7352423071861267,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7236430644989014,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.7210739850997925,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.6615951061248779,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6375197172164917,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.6358728408813477,
            "answer": "profound",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7352422922849655
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.7774786949157715,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.77399080991745,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.7200751304626465,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.7075995206832886,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7003263235092163,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6937961578369141,
            "answer": "weaknesses",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7739907801151276
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 8,
      "accuracy": 0.875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "248cd3ca-5a29-446f-919d-49f67641c896",
      "timestamp": "2025-05-17T21:31:47.836941"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8112250566482544,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8010815382003784,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.800447404384613,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7608593702316284,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6711859703063965,
            "answer": "acceptable",
            "hit": true
          },
          {
            "score": 0.6520965099334717,
            "answer": "reject",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6711859405040741
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.7362587451934814,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7349857091903687,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.7215366959571838,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.7200314402580261,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.6837795972824097,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.591827929019928,
            "answer": "corrected",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6837795674800873
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.6960834264755249,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.6686749458312988,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.6219396591186523,
            "answer": "cheaper",
            "hit": false
          },
          {
            "score": 0.6139752864837646,
            "answer": "cheap",
            "hit": false
          },
          {
            "score": 0.6130656599998474,
            "answer": "accessibility",
            "hit": false
          },
          {
            "score": 0.608877420425415,
            "answer": "affordable",
            "hit": true
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6088774055242538
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7403032183647156,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7282744646072388,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.6825236678123474,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6567868590354919,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6335549354553223,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6146976947784424,
            "answer": "suppose",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5622985363006592
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.6995178461074829,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6965227127075195,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6816121935844421,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6780178546905518,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6751631498336792,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.6280980110168457,
            "answer": "happy",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6751631796360016
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8472432494163513,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8342413902282715,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8045908808708191,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7411512136459351,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7105969786643982,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.6717983484268188,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7105969935655594
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.7440381050109863,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.6933560967445374,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.6811718940734863,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.6736447811126709,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.6506519317626953,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.6022995710372925,
            "answer": "unpredictable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6933561265468597
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8329267501831055,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7956066131591797,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.7927424311637878,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.7599366903305054,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.71324223279953,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.6887456178665161,
            "answer": "utilize",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6200089231133461
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.7332861423492432,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.7300317287445068,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.6858543157577515,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.6112175583839417,
            "answer": "revival",
            "hit": false
          },
          {
            "score": 0.6021292209625244,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.6005829572677612,
            "answer": "affordable",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7332861423492432
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.7979841232299805,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.761486291885376,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7136038541793823,
            "answer": "sustainable",
            "hit": true
          },
          {
            "score": 0.6486337184906006,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.64434814453125,
            "answer": "maintain",
            "hit": false
          },
          {
            "score": 0.6321093440055847,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7136038690805435
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8697050213813782,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8126267790794373,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.7658251523971558,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.755458414554596,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7033073902130127,
            "answer": "variation",
            "hit": false
          },
          {
            "score": 0.6978500485420227,
            "answer": "differs",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6419055759906769
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 11,
      "accuracy": 0.09090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4474df49-c8a5-4c5b-86a2-de040725e8e4",
      "timestamp": "2025-05-17T21:31:47.866165"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.8298406004905701,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7726207375526428,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.746717095375061,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6662104725837708,
            "answer": "believer",
            "hit": true
          },
          {
            "score": 0.6628857254981995,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6440032124519348,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6662104725837708
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7843426465988159,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.6994913816452026,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6897482872009277,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.655677318572998,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.6468110680580139,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.5966479778289795,
            "answer": "counselor",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6897483319044113
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8083896636962891,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.8056603670120239,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.7521361112594604,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.6709961295127869,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.651354193687439,
            "answer": "eaten",
            "hit": false
          },
          {
            "score": 0.6401083469390869,
            "answer": "drank",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6231169328093529
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7074613571166992,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.664957582950592,
            "answer": "contender",
            "hit": true
          },
          {
            "score": 0.664458155632019,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.6485713720321655,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.6305370330810547,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.6213747262954712,
            "answer": "asserting",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6649575680494308
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8113222718238831,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.8062482476234436,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.7035513520240784,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.6947770118713379,
            "answer": "defenses",
            "hit": false
          },
          {
            "score": 0.6767030954360962,
            "answer": "defensive",
            "hit": false
          },
          {
            "score": 0.660782516002655,
            "answer": "defender",
            "hit": true
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.660782516002655
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.750982940196991,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7487694025039673,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7159000635147095,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7154117226600647,
            "answer": "developer",
            "hit": true
          },
          {
            "score": 0.7016693353652954,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.6943615674972534,
            "answer": "development",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7154117226600647
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8292612433433533,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8086252212524414,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8053551912307739,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.781220555305481,
            "answer": "examination",
            "hit": false
          },
          {
            "score": 0.7185910940170288,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6994366645812988,
            "answer": "analyze",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6880138218402863
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.828062117099762,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.7898162603378296,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.7890639901161194,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.7734499573707581,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6771673560142517,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.666459321975708,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6306652575731277
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7267138361930847,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7104017734527588,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.7020595073699951,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6707141995429993,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6508809924125671,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.5921709537506104,
            "answer": "ensued",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7104017585515976
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.7807580232620239,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.7807000875473022,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.7739708423614502,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.7484654784202576,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.6857736110687256,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.6029368042945862,
            "answer": "writer",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6857736110687256
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.8340916037559509,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.8331649303436279,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7136397361755371,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.648768424987793,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.6387165784835815,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.6274266242980957,
            "answer": "watching",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6487684100866318
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.8524957299232483,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.821751594543457,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7301089763641357,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7213135957717896,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6907156705856323,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6636248230934143,
            "answer": "loser",
            "hit": true
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6636248230934143
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8192003965377808,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8186781406402588,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.671941876411438,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6628732681274414,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6368708610534668,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.6169625520706177,
            "answer": "developer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6368708610534668
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.6738868355751038,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6639158725738525,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.6382343173027039,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.6377029418945312,
            "answer": "observer",
            "hit": true
          },
          {
            "score": 0.6272017359733582,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.6246713995933533,
            "answer": "noticing",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6377029418945312
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8008190393447876,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.7745519876480103,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.7445265054702759,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7138132452964783,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.6917251944541931,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.688261866569519,
            "answer": "arrange",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7745519578456879
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.8487253189086914,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8454001545906067,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8291873931884766,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7497284412384033,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.7140573263168335,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.7068251371383667,
            "answer": "performance",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7497285008430481
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8144130110740662,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.732320249080658,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.6943768262863159,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.6445976495742798,
            "answer": "missionary",
            "hit": false
          },
          {
            "score": 0.6310897469520569,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.6197854280471802,
            "answer": "missionaries",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.732320249080658
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8278521299362183,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8277755975723267,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7906545400619507,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.758576512336731,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6871363520622253,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.6845061182975769,
            "answer": "encourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6702601313591003
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.7003223896026611,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6930384635925293,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6444554328918457,
            "answer": "provider",
            "hit": true
          },
          {
            "score": 0.642812967300415,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6343243718147278,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6157014966011047,
            "answer": "providers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6444554179906845
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.6768442392349243,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.65715491771698,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.654875636100769,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6379648447036743,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.6253925561904907,
            "answer": "pub",
            "hit": false
          },
          {
            "score": 0.6174073219299316,
            "answer": "publishers",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6768442243337631
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.645637035369873,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6426008939743042,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6350470781326294,
            "answer": "receiver",
            "hit": true
          },
          {
            "score": 0.6271170973777771,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6203127503395081,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6120962500572205,
            "answer": "receipt",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6350470930337906
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8283571004867554,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7961746454238892,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.6936395168304443,
            "answer": "talking",
            "hit": false
          },
          {
            "score": 0.6863309741020203,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.6646120548248291,
            "answer": "talked",
            "hit": false
          },
          {
            "score": 0.66455078125,
            "answer": "talks",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6265657246112823
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8299439549446106,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8174386024475098,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8143001198768616,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7132179737091064,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.7104801535606384,
            "answer": "teacher",
            "hit": true
          },
          {
            "score": 0.6980094909667969,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7104801684617996
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.825711190700531,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7835404872894287,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.768437385559082,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.72613525390625,
            "answer": "writers",
            "hit": false
          },
          {
            "score": 0.7219502925872803,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.7186921834945679,
            "answer": "wrote",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7835404872894287
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 24,
      "accuracy": 0.041666666666666664
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4591cb9a-8898-48f9-8854-ab510ba57543",
      "timestamp": "2025-05-17T21:31:47.906957"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.7889670133590698,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.7633280158042908,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.7320951223373413,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.7214436531066895,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.6603710055351257,
            "answer": "alleging",
            "hit": false
          },
          {
            "score": 0.6588675379753113,
            "answer": "blaming",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.763327956199646
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.7471671104431152,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.7447402477264404,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.6546739339828491,
            "answer": "appreciation",
            "hit": false
          },
          {
            "score": 0.6293942928314209,
            "answer": "enthusiasts",
            "hit": false
          },
          {
            "score": 0.6218656301498413,
            "answer": "praise",
            "hit": false
          },
          {
            "score": 0.6137868165969849,
            "answer": "lovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7471670657396317
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.839465856552124,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.8045834302902222,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.7686797380447388,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.7426787614822388,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.7001457214355469,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.6950302124023438,
            "answer": "calculations",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8394658267498016
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.8867167830467224,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8748394250869751,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8350634574890137,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.750274658203125,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7385176420211792,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7267691493034363,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.750274658203125
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8158211708068848,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8133171796798706,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.8131017684936523,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.8115609884262085,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.6708196401596069,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.618034839630127,
            "answer": "assertion",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8133171796798706
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8579363822937012,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8420169353485107,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8291585445404053,
            "answer": "determination",
            "hit": true
          },
          {
            "score": 0.7236653566360474,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7184692621231079,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.6956053972244263,
            "answer": "deciding",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.82915860414505
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8501288294792175,
            "answer": "examination",
            "hit": true
          },
          {
            "score": 0.8379442691802979,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8289144039154053,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8005384206771851,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7401288747787476,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.7389419078826904,
            "answer": "investigation",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8501287996768951
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8445079326629639,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.8385927081108093,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.7992937564849854,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.7623416185379028,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6985201835632324,
            "answer": "investigation",
            "hit": false
          },
          {
            "score": 0.6831004023551941,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8445079922676086
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.7463467121124268,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.7270169258117676,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.643324613571167,
            "answer": "imagination",
            "hit": true
          },
          {
            "score": 0.6303794384002686,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.6255928874015808,
            "answer": "guess",
            "hit": false
          },
          {
            "score": 0.6237722635269165,
            "answer": "think",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6433245539665222
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.7763675451278687,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7492997050285339,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7277965545654297,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.6547900438308716,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6425249576568604,
            "answer": "motivation",
            "hit": false
          },
          {
            "score": 0.6244478225708008,
            "answer": "enthusiasm",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7492997050285339
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.6825342774391174,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.679079532623291,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.6743429899215698,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6629151105880737,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6478782892227173,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.6416484117507935,
            "answer": "recall",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.682534247636795
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8301898241043091,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8063168525695801,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7017363905906677,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.6864409446716309,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.6260141134262085,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.620938777923584,
            "answer": "inhabit",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7017363905906677
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8218324780464172,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.7559673190116882,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.726000964641571,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7219861149787903,
            "answer": "organization",
            "hit": true
          },
          {
            "score": 0.7059583067893982,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.6957405805587769,
            "answer": "organised",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7219861447811127
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8579193353652954,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.8434675931930542,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.818372368812561,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.8098254799842834,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.7558679580688477,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.6705853343009949,
            "answer": "readiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8579193353652954
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.8654375076293945,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.8376229405403137,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8348343372344971,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.6680494546890259,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.6646151542663574,
            "answer": "reconstruction",
            "hit": false
          },
          {
            "score": 0.6622259616851807,
            "answer": "preservation",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654375672340393
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8519701957702637,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8241719603538513,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.7259109020233154,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6702224016189575,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.6521224975585938,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.630473792552948,
            "answer": "unstable",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8519701361656189
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 16,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "15b2d1a0-9d48-4f45-b25c-6b989e5919a7",
      "timestamp": "2025-05-17T21:31:47.999924"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.787886381149292,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7791747450828552,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7431014776229858,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.6970876455307007,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.6918938159942627,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.691698431968689,
            "answer": "achievement",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.743101492524147
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.8363593816757202,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.8358312845230103,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7946877479553223,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7572500705718994,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7325068116188049,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7088209390640259,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7325067818164825
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.789008378982544,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.7582585215568542,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7418510913848877,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7371591329574585,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.6564196348190308,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.596886932849884,
            "answer": "corrected",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7890083491802216
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8330751657485962,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8160531520843506,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.778171956539154,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7354291677474976,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7025755643844604,
            "answer": "agreement",
            "hit": true
          },
          {
            "score": 0.6869713664054871,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7025755941867828
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.7520202994346619,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.6945844292640686,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.58579421043396,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.5828995704650879,
            "answer": "layout",
            "hit": false
          },
          {
            "score": 0.5760225653648376,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.5737009048461914,
            "answer": "width",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7520202994346619
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.7530046701431274,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.7519097924232483,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.6654255986213684,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.6521828174591064,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.628444492816925,
            "answer": "modification",
            "hit": false
          },
          {
            "score": 0.6257312893867493,
            "answer": "revisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6654256284236908
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8235172033309937,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8198471069335938,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.81880784034729,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8157837390899658,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.764989972114563,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6305513381958008,
            "answer": "declare",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8198471367359161
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.7972434759140015,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7429001331329346,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.6554025411605835,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.6001527309417725,
            "answer": "achievement",
            "hit": false
          },
          {
            "score": 0.5961341857910156,
            "answer": "agreement",
            "hit": false
          },
          {
            "score": 0.5956653952598572,
            "answer": "assignment",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7972434759140015
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8162013292312622,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8051586151123047,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.7728208899497986,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.7327438592910767,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.6872044205665588,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.6465473175048828,
            "answer": "organised",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7728208899497986
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8536591529846191,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.8156466484069824,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8106289505958557,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7716334462165833,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.7111030220985413,
            "answer": "evaluated",
            "hit": false
          },
          {
            "score": 0.7040000557899475,
            "answer": "evaluating",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8536591529846191
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.7422050833702087,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7313331365585327,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.6839276552200317,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.6817909479141235,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.6570916771888733,
            "answer": "ass",
            "hit": false
          },
          {
            "score": 0.5986062288284302,
            "answer": "allocation",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422051280736923
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.7527198195457458,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7269492149353027,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.672220766544342,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.6698228120803833,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.6680659055709839,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.6607532501220703,
            "answer": "commits",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7527198493480682
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.7793788313865662,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7609525322914124,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7332292199134827,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7263897061347961,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.6929173469543457,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6926137208938599,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.726389691233635
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.7901992797851562,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7606545686721802,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7263158559799194,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.6621378660202026,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.6563059091567993,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.634796142578125,
            "answer": "agreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7606545090675354
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8265992999076843,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8036293983459473,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7658637166023254,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.7521339654922485,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.7479217648506165,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.6819720268249512,
            "answer": "promote",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7479217648506165
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8239729404449463,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8104480504989624,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.7771155834197998,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.6371227502822876,
            "answer": "compliance",
            "hit": false
          },
          {
            "score": 0.6334139108657837,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.6209973692893982,
            "answer": "violation",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.81044802069664
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.839277982711792,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8351151943206787,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8250943422317505,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.7967049479484558,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.6530893445014954,
            "answer": "eng",
            "hit": false
          },
          {
            "score": 0.6449381709098816,
            "answer": "undertake",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7967049777507782
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8395451307296753,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.8377164602279663,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7307384014129639,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7161844372749329,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.6928958892822266,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.6928364038467407,
            "answer": "improved",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8395450711250305
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.7091429829597473,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.6980501413345337,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6938472986221313,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6701202392578125,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6327922344207764,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6159411072731018,
            "answer": "expect",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7091429978609085
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.7754871845245361,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7617396712303162,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.6474353075027466,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.6376316547393799,
            "answer": "amusement",
            "hit": false
          },
          {
            "score": 0.6047254800796509,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6041933298110962,
            "answer": "enjoyment",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6474353075027466
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.7348194122314453,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7292669415473938,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.7241371870040894,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.6907119154930115,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.6905900239944458,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6072092652320862,
            "answer": "formation",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7292669415473938
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8055716156959534,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.7991739511489868,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.7983791828155518,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.7401742935180664,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.6687729358673096,
            "answer": "satisfying",
            "hit": false
          },
          {
            "score": 0.65119868516922,
            "answer": "satisfied",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.805571585893631
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8114225268363953,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7924797534942627,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.7312764525413513,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7289157509803772,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7284742593765259,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.6782946586608887,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7924797534942627
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.7907174825668335,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7670482993125916,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7593340873718262,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7312555909156799,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.6609894633293152,
            "answer": "investors",
            "hit": false
          },
          {
            "score": 0.6585574150085449,
            "answer": "investor",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7312556207180023
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8639528155326843,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7851034998893738,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7781670093536377,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7615483999252319,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.6621347665786743,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.6478510499000549,
            "answer": "participation",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7615483999252319
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8275847434997559,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.8263388872146606,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6858763694763184,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.6635955572128296,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6211151480674744,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.6161783337593079,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6858763694763184
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8066046833992004,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7872458696365356,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.6792467832565308,
            "answer": "pun",
            "hit": false
          },
          {
            "score": 0.6558012366294861,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.6385911107063293,
            "answer": "revenge",
            "hit": false
          },
          {
            "score": 0.6318899989128113,
            "answer": "penalty",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8066046833992004
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.807339072227478,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.7520960569381714,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.6370648145675659,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.6330241560935974,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.6320454478263855,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6303578615188599,
            "answer": "encouragement",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.807339072227478
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.855737030506134,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.846136212348938,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.8396795988082886,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.8257846236228943,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7603696584701538,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.738181471824646,
            "answer": "substitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8396795392036438
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.7470960021018982,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.736099898815155,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6617939472198486,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6534985899925232,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6486953496932983,
            "answer": "necessity",
            "hit": false
          },
          {
            "score": 0.6392768621444702,
            "answer": "requiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7470960319042206
      }
    ],
    "result": {
      "cnt_questions_correct": 12,
      "cnt_questions_total": 30,
      "accuracy": 0.4
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d1e1779f-dc94-44c5-8565-524aa2291d15",
      "timestamp": "2025-05-17T21:31:48.068175"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8225985169410706,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7368356585502625,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7046548128128052,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7022668719291687,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6973909735679626,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.6957075595855713,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8225985169410706
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8020758628845215,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.7577250599861145,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7120966911315918,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7095465660095215,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.7030118703842163,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.6993522047996521,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8020759224891663
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.8749555945396423,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.7519035339355469,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.7478939294815063,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.7355629801750183,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.7246415615081787,
            "answer": "nepal",
            "hit": false
          },
          {
            "score": 0.7205613851547241,
            "answer": "indonesia",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8749555945396423
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.8088046908378601,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.7191274166107178,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7173964381217957,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.7114564180374146,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7101042866706848,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.7018051147460938,
            "answer": "chinese",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8088046908378601
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.7774935364723206,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7511048316955566,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7465255260467529,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7445245385169983,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7298023700714111,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.7277594208717346,
            "answer": "austria",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7774935960769653
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7112740278244019,
            "answer": "bernard",
            "hit": false
          },
          {
            "score": 0.6768155097961426,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.6627949476242065,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6528095602989197,
            "answer": "bernstein",
            "hit": false
          },
          {
            "score": 0.6321130990982056,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.6286634802818298,
            "answer": "switzerland",
            "hit": true
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.628663495182991
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8019982576370239,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.7468022108078003,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7361379861831665,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7339874505996704,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.7305759191513062,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7235023975372314,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8019982576370239
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.8570356369018555,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.7566827535629272,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7433556318283081,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7369674444198608,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7278069257736206,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7233562469482422,
            "answer": "bulgaria",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8570356369018555
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.7919459939002991,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.7249109745025635,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7027483582496643,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7011533975601196,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.6955898404121399,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.6879064440727234,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7919459939002991
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8202263712882996,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.7486304044723511,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7458425164222717,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.7440497279167175,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.6970819234848022,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.6960047483444214,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8202263414859772
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.7626221776008606,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.6963179111480713,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.6915794014930725,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.6914350390434265,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.6756983995437622,
            "answer": "serbia",
            "hit": false
          },
          {
            "score": 0.6741094589233398,
            "answer": "russia",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7626221776008606
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8346889615058899,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.7494897842407227,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7200488448143005,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.716892659664154,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7130115628242493,
            "answer": "scotland",
            "hit": false
          },
          {
            "score": 0.7111524343490601,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8346889913082123
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8023406863212585,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.7115350961685181,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7084604501724243,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.6842371821403503,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.6836106777191162,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.6831307411193848,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8023407161235809
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7007573246955872,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.6538162231445312,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.6483778953552246,
            "answer": "king",
            "hit": false
          },
          {
            "score": 0.6427823305130005,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6374769806861877,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.6303911209106445,
            "answer": "ontario",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7007573246955872
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8166988492012024,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.7415019869804382,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7192361354827881,
            "answer": "ireland",
            "hit": false
          },
          {
            "score": 0.7171230316162109,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7018440961837769,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.7017942070960999,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8166988790035248
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.852253258228302,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.7640201449394226,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7481037378311157,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7474755048751831,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7152245044708252,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7101944088935852,
            "answer": "greece",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.852253258228302
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.7951269149780273,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.77264803647995,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.7200020551681519,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7193297147750854,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.7193245887756348,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7190958857536316,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7951269447803497
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.7995813488960266,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.7693072557449341,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7402954697608948,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7212265729904175,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7193931341171265,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.7151118516921997,
            "answer": "ukraine",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7995813190937042
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8071931004524231,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.7350368499755859,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.7117601633071899,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7108203172683716,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6912515163421631,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.6840587854385376,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8071931600570679
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.7662491202354431,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.7529584169387817,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.726515531539917,
            "answer": "quebec",
            "hit": false
          },
          {
            "score": 0.7168588638305664,
            "answer": "alberta",
            "hit": false
          },
          {
            "score": 0.7113395929336548,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7110238671302795,
            "answer": "canadian",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7662491202354431
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.8645561337471008,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.7446163296699524,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.741330623626709,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7185731530189514,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.7184759378433228,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7134283185005188,
            "answer": "ireland",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8645561635494232
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.8118559718132019,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7554857134819031,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7521724104881287,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7458003759384155,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7087466716766357,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7075483798980713,
            "answer": "ireland",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8118559718132019
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.7336740493774414,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7332850098609924,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.6874828934669495,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.6856333017349243,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.6780850887298584,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6758661270141602,
            "answer": "portugal",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7332849949598312
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8559302091598511,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.7575951218605042,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7354912757873535,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7348747253417969,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7288613319396973,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7201892733573914,
            "answer": "switzerland",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8559302687644958
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8356384038925171,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.7663958072662354,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.7110930681228638,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7097978591918945,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.705119252204895,
            "answer": "pakistan",
            "hit": false
          },
          {
            "score": 0.6949290037155151,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8356384634971619
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.8126301765441895,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.7648435831069946,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7446596622467041,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.742692768573761,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7309020757675171,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.7168424129486084,
            "answer": "china",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8126301765441895
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8247992992401123,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.7436668872833252,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7400906085968018,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7341558933258057,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.723798394203186,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7206115126609802,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8247993290424347
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8191009759902954,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.7212642431259155,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7134471535682678,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7039335370063782,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6983473300933838,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6900042295455933,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8191010355949402
      }
    ],
    "result": {
      "cnt_questions_correct": 26,
      "cnt_questions_total": 28,
      "accuracy": 0.9285714285714286
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f38ea9a7-0430-4c30-bdc9-b3ffe57e295d",
      "timestamp": "2025-05-17T21:31:48.188451"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8308027386665344,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7945648431777954,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.74759840965271,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7427459359169006,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7357333898544312,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.7346941232681274,
            "answer": "argent",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7945648729801178
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7728552222251892,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7055127620697021,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.703822672367096,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.695004940032959,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6821472644805908,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6786247491836548,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6821472346782684
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8313866853713989,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7556260824203491,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7477365732192993,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7263340950012207,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7245479226112366,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7225209474563599,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7477365732192993
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8562213778495789,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8232835531234741,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7485589981079102,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7338792085647583,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7269008755683899,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7245906591415405,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7158946394920349
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.7970065474510193,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7018124461174011,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6947906613349915,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.6943067312240601,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.6827195882797241,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6811812520027161,
            "answer": "australia",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6701721549034119
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8197934627532959,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7482941746711731,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7353799343109131,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7348194718360901,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7320246696472168,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7103732824325562,
            "answer": "japanese",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8197934627532959
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7844887971878052,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7366420030593872,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.69481360912323,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.68724524974823,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6849128007888794,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6848572492599487,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7844887971878052
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8170932531356812,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7807815670967102,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.720172107219696,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6864398717880249,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6844154596328735,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6810970902442932,
            "answer": "castro",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7807815670967102
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.7361490726470947,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7320967316627502,
            "answer": "turkish",
            "hit": true
          },
          {
            "score": 0.7315279245376587,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6923248767852783,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6728326678276062,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.667279839515686,
            "answer": "romanian",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5422941073775291
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8517894148826599,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.77986741065979,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7363431453704834,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.706847608089447,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7057746648788452,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.6880183219909668,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798674702644348
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7556952238082886,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.719181478023529,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7064939737319946,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6738089323043823,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6734437942504883,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.6707996129989624,
            "answer": "indonesian",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7556952238082886
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8529933094978333,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.7720686793327332,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7597545385360718,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.7324413061141968,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7191051244735718,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7157896757125854,
            "answer": "tehran",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7597545385360718
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8121529817581177,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7687195539474487,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7262929677963257,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6963567733764648,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.6866300702095032,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6795213222503662,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7687195539474487
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8201448917388916,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.783987283706665,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.7465493679046631,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.7349891066551208,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7336828708648682,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7312126159667969,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7839873135089874
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7122572660446167,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.669297456741333,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6554794311523438,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6410552859306335,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6395819187164307,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6365252137184143,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7122572511434555
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7617459297180176,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7222903966903687,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7068297266960144,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7067016363143921,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.7017660140991211,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6871000528335571,
            "answer": "kurdish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7617459297180176
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7604503631591797,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.7488671541213989,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7007354497909546,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.6948797106742859,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6750662326812744,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.6723967790603638,
            "answer": "palestinians",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7488672137260437
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.773717999458313,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7180918455123901,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7049192190170288,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6921518445014954,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6830977201461792,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.6702771782875061,
            "answer": "portuguese",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7737180590629578
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8087100386619568,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.766968846321106,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7392252683639526,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7326482534408569,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.7206705808639526,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7186278700828552,
            "answer": "italian",
            "hit": true
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7392253428697586
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8340781331062317,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.7678884267807007,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7245003581047058,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6781821250915527,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6775287389755249,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.6717208027839661,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7678883969783783
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.7773656249046326,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7549065351486206,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7487726807594299,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7255135178565979,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.7197273969650269,
            "answer": "vietnamese",
            "hit": false
          },
          {
            "score": 0.7111274600028992,
            "answer": "thai",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7255135178565979
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7389154434204102,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.719260573387146,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6793737411499023,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6774908304214478,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6767218112945557,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6757087707519531,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6545072197914124
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7753119468688965,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7308613061904907,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6922296285629272,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.68501877784729,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.6821767091751099,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.6652063727378845,
            "answer": "latin",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7753119468688965
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 23,
      "accuracy": 0.30434782608695654
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3941d8ba-2ca9-475e-a963-3f9f2fa127c2",
      "timestamp": "2025-05-17T21:31:48.299764"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7773987054824829,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7112687230110168,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6715481877326965,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.647428035736084,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.6385325789451599,
            "answer": "bathroom",
            "hit": false
          },
          {
            "score": 0.6172622442245483,
            "answer": "somerset",
            "hit": true
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6172622069716454
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7727416157722473,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6978108882904053,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6752065420150757,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6646644473075867,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.6625187993049622,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.6417379379272461,
            "answer": "devon",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7727415561676025
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.7976662516593933,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7343289852142334,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7078129053115845,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.68262779712677,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.6763630509376526,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.6744333505630493,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7343289703130722
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.6753658652305603,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6365254521369934,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6183056831359863,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.5988703370094299,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.5951665043830872,
            "answer": "chassis",
            "hit": false
          },
          {
            "score": 0.5906304717063904,
            "answer": "yacht",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6753658801317215
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8657994270324707,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7316401600837708,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7188401818275452,
            "answer": "leicester",
            "hit": false
          },
          {
            "score": 0.7120004296302795,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7031753659248352,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.6955357789993286,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8657993674278259
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.781642496585846,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7327721118927002,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6993710994720459,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.683401882648468,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6687616109848022,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.6678086519241333,
            "answer": "hampshire",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6993711590766907
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.82997065782547,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7300705909729004,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7132883071899414,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.712500810623169,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7035777568817139,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6820666790008545,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.82997065782547
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7327565550804138,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6600778102874756,
            "answer": "well",
            "hit": false
          },
          {
            "score": 0.6492085456848145,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.6362665891647339,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6224761605262756,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.5983612537384033,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6492084860801697
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7790573835372925,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6708890199661255,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6455731391906738,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.6403834819793701,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6379216909408569,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.637902557849884,
            "answer": "scotia",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7790573537349701
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9439ec6d-87d6-46cd-9ca1-b3e9d2b26dfe",
      "timestamp": "2025-05-17T21:31:48.388263"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.690914511680603,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6798473000526428,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6759560704231262,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6720225811004639,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6710834503173828,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6633283495903015,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5874924957752228
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7087542414665222,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6871511340141296,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.676672637462616,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.6738583445549011,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.670759379863739,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6533299088478088,
            "answer": "egyptian",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6766726076602936
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7128943204879761,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6875203847885132,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.6541610360145569,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.653185248374939,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6509308815002441,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6479189991950989,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5928287878632545
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.6616165637969971,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6432618498802185,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6325335502624512,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6274991035461426,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.624021589756012,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6219773888587952,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.624021589756012
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.6627516150474548,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6608047485351562,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.6546642780303955,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6488761305809021,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6439670920372009,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6389082670211792,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5879642516374588
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.7826336622238159,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.7583630084991455,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.726834774017334,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7117119431495667,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.668694257736206,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6635738015174866,
            "answer": "stalin",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7583629488945007
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7053923010826111,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.676176905632019,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6621460914611816,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.649722158908844,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.6496483087539673,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.6455272436141968,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 116,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5652590841054916
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6661537885665894,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6648293733596802,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.6548248529434204,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6533306837081909,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6388518810272217,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.6273689866065979,
            "answer": "welsh",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6648293435573578
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.726829469203949,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6616612672805786,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.6586838960647583,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6564813256263733,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6519814729690552,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.6516414284706116,
            "answer": "danish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7268295139074326
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.6339737176895142,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6329114437103271,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6135263442993164,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6133136749267578,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6130576133728027,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.6128676533699036,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6329113841056824
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.6908582448959351,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.6798327565193176,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6737586259841919,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6716552376747131,
            "answer": "ukrainian",
            "hit": false
          },
          {
            "score": 0.6468969583511353,
            "answer": "communist",
            "hit": false
          },
          {
            "score": 0.6464464664459229,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.644556313753128
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7275713682174683,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6800953149795532,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6779536008834839,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6740537881851196,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6654096841812134,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.6642206907272339,
            "answer": "american",
            "hit": true
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6642206609249115
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6659992337226868,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6603071689605713,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6599646210670471,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6542127132415771,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6483332514762878,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.6404292583465576,
            "answer": "english",
            "hit": true
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6404292732477188
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7542540431022644,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.685569167137146,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.674612283706665,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.6397229433059692,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6367602348327637,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6360730528831482,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6855692267417908
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6893847584724426,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6474142074584961,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6388407349586487,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.6380082368850708,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.6328161954879761,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6287950277328491,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.638008251786232
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6592543125152588,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6533863544464111,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.6493229269981384,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6396950483322144,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6309503316879272,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6254724264144897,
            "answer": "portuguese",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6215598359704018
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.6951032280921936,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6817799806594849,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6683334112167358,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6605696678161621,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6590896844863892,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.6543731689453125,
            "answer": "aristotle",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 88,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5823625922203064
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.6695094704627991,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6586664319038391,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6405104398727417,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.6366826891899109,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.6365764737129211,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.6296579837799072,
            "answer": "roosevelt",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6586664170026779
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.735061764717102,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6686766147613525,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6546344757080078,
            "answer": "welsh",
            "hit": false
          },
          {
            "score": 0.6541079878807068,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6525553464889526,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6488454341888428,
            "answer": "polish",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7350617796182632
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 19,
      "accuracy": 0.21052631578947367
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "59cc2e73-8e12-42b2-92a1-7eed0c9314b1",
      "timestamp": "2025-05-17T21:31:48.421911"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7774877548217773,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7120298147201538,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6811237335205078,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6609554290771484,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.6577284336090088,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6490993499755859,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7774878144264221
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7157961130142212,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6411377191543579,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6327674388885498,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6316287517547607,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6314704418182373,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6216146945953369,
            "answer": "emperor",
            "hit": true
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6216147318482399
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.6931720972061157,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6439109444618225,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.6355593204498291,
            "answer": "ohio",
            "hit": false
          },
          {
            "score": 0.6324487924575806,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.6320922374725342,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6311669945716858,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 351,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5439746156334877
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.6871466040611267,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6771116852760315,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.6409767270088196,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6400513052940369,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.630479097366333,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6282702684402466,
            "answer": "giovanni",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6771116554737091
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.6991666555404663,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.653526782989502,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6411585211753845,
            "answer": "engineer",
            "hit": false
          },
          {
            "score": 0.6388711333274841,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6369069814682007,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6357593536376953,
            "answer": "economist",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6294775009155273
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7114152908325195,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6933133602142334,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6599463224411011,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.6395344138145447,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6246168613433838,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6243667006492615,
            "answer": "researcher",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6933133602142334
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.7358605265617371,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.7109323143959045,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7044085264205933,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6761664748191833,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6640625,
            "answer": "dictator",
            "hit": true
          },
          {
            "score": 0.6549650430679321,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6640624701976776
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.724886417388916,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6561595797538757,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6391826868057251,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6293342113494873,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6271223425865173,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6239733099937439,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7248864471912384
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.73146653175354,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6551241874694824,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6540411710739136,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6279451251029968,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6241112351417542,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6213382482528687,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7314665913581848
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.6955648064613342,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.63069748878479,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6299157738685608,
            "answer": "president",
            "hit": true
          },
          {
            "score": 0.6269552707672119,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6264629364013672,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.6241939067840576,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6299157738685608
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7253164052963257,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6540132761001587,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6375170946121216,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6198151707649231,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6184161305427551,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6085819005966187,
            "answer": "scientist",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7253164350986481
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.7737389802932739,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7067276239395142,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6586238145828247,
            "answer": "socialist",
            "hit": false
          },
          {
            "score": 0.6467487812042236,
            "answer": "economist",
            "hit": false
          },
          {
            "score": 0.6460275053977966,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6374168395996094,
            "answer": "socialism",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7067276537418365
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.6854908466339111,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6279672980308533,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6195398569107056,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6189706325531006,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6115589737892151,
            "answer": "max",
            "hit": false
          },
          {
            "score": 0.6079875230789185,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6195398569107056
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7043379545211792,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6519476175308228,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.6357817649841309,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6278757452964783,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.6233994960784912,
            "answer": "aaron",
            "hit": false
          },
          {
            "score": 0.6209464073181152,
            "answer": "solomon",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6519476026296616
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7351908683776855,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6529843211174011,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.6503362059593201,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.647573709487915,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.647468090057373,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6451916098594666,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6529843360185623
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7832946181297302,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7212580442428589,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6898272037506104,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.6842614412307739,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6593453884124756,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6479148268699646,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7832946181297302
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7068691253662109,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6647850275039673,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6345045566558838,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.629975438117981,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6285322308540344,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6224470138549805,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6033868864178658
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.71009761095047,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6460292339324951,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.639512300491333,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6364695429801941,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.634878396987915,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6130090951919556,
            "answer": "painter",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6395123451948166
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 18,
      "accuracy": 0.3333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "057d5173-5387-437f-aaad-7cc108b53a3a",
      "timestamp": "2025-05-17T21:31:48.493657"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.6649315357208252,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.636319637298584,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6044320464134216,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.5955436825752258,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.5910398364067078,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.5905863046646118,
            "answer": "infants",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5371756479144096
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6734097599983215,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6500719785690308,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.6484207510948181,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6168797612190247,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6135196089744568,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.6066253781318665,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6734097599983215
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7033549547195435,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6530448198318481,
            "answer": "chicago",
            "hit": false
          },
          {
            "score": 0.6460505723953247,
            "answer": "pittsburgh",
            "hit": false
          },
          {
            "score": 0.6440485119819641,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.6426498293876648,
            "answer": "denver",
            "hit": false
          },
          {
            "score": 0.6390235424041748,
            "answer": "rochester",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6077560633420944
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7529985904693604,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7228606939315796,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6883801221847534,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.637565016746521,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6323809623718262,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6238279938697815,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6883801072835922
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.7537276744842529,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7490237355232239,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7039728164672852,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6581302881240845,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.6575298309326172,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6552566289901733,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 55,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5682715475559235
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6924019455909729,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6833658218383789,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.626625657081604,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6251939535140991,
            "answer": "lamb",
            "hit": false
          },
          {
            "score": 0.6216958165168762,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6158236861228943,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6924019455909729
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7661603093147278,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7199296951293945,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6921270489692688,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6398693323135376,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6391528844833374,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.6330312490463257,
            "answer": "pup",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6220136880874634
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7990330457687378,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7540004253387451,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7238967418670654,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.7081761360168457,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6582583785057068,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6214545369148254,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 100,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.565891720354557
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7922016382217407,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.677279531955719,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.674418568611145,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6277750134468079,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6265195608139038,
            "answer": "pup",
            "hit": true
          },
          {
            "score": 0.6256498694419861,
            "answer": "shrimp",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6744186133146286
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7008951902389526,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6808668375015259,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6405279040336609,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6205949783325195,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6196036338806152,
            "answer": "child",
            "hit": false
          },
          {
            "score": 0.6176460981369019,
            "answer": "pup",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6808668971061707
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7749934196472168,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6923437118530273,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6845259666442871,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.626362681388855,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6247859597206116,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6195406913757324,
            "answer": "salmon",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6845259964466095
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 11,
      "accuracy": 0.18181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8ae80126-7cf9-49a7-bf6d-61d72243e494",
      "timestamp": "2025-05-17T21:31:48.563655"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7283663749694824,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.6697448492050171,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6672996282577515,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.6459875702857971,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6211567521095276,
            "answer": "honey",
            "hit": false
          },
          {
            "score": 0.5990349650382996,
            "answer": "been",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6672996580600739
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.6799002289772034,
            "answer": "flynn",
            "hit": false
          },
          {
            "score": 0.6631853580474854,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6623746752738953,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.655463457107544,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6240969300270081,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6191584467887878,
            "answer": "flying",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6623746603727341
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7427098155021667,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.726048469543457,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7149922847747803,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6865793466567993,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6303138136863708,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.5991610884666443,
            "answer": "fill",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 5104,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5126038771122694
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7504976391792297,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.743239164352417,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.6444376111030579,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6241130828857422,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.5996286869049072,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.5798048973083496,
            "answer": "elephant",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 6068,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.503740165848285
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8fac1b1d-3ce8-4334-bf01-37df08dc38ba",
      "timestamp": "2025-05-17T21:31:48.606245"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6712666153907776,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6489802002906799,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6122972369194031,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.602770209312439,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6004881858825684,
            "answer": "ace",
            "hit": false
          },
          {
            "score": 0.5867123603820801,
            "answer": "apr",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 2114,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.499916635453701
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6958351135253906,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6130408048629761,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6108925342559814,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6024273037910461,
            "answer": "bath",
            "hit": false
          },
          {
            "score": 0.5998890995979309,
            "answer": "battery",
            "hit": false
          },
          {
            "score": 0.5946632027626038,
            "answer": "batman",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5411972030997276
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6851099729537964,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6450806856155396,
            "answer": "bearing",
            "hit": false
          },
          {
            "score": 0.6215115785598755,
            "answer": "bore",
            "hit": false
          },
          {
            "score": 0.6040223836898804,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.604000449180603,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.5981237292289734,
            "answer": "den",
            "hit": true
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.598123736679554
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.7649166584014893,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7424024343490601,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6942161321640015,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6707984209060669,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6548418998718262,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.649177074432373,
            "answer": "dairy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 2949,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5215783827006817
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7315706014633179,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7160302996635437,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.7024773359298706,
            "answer": "soccer",
            "hit": false
          },
          {
            "score": 0.7017785310745239,
            "answer": "hockey",
            "hit": false
          },
          {
            "score": 0.6997999548912048,
            "answer": "basketball",
            "hit": false
          },
          {
            "score": 0.6934210062026978,
            "answer": "tennis",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6685149073600769
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7002483010292053,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6464807987213135,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.6404887437820435,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.6331592202186584,
            "answer": "crowds",
            "hit": false
          },
          {
            "score": 0.6284820437431335,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6037178635597229,
            "answer": "crowned",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7002483010292053
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6955142021179199,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6784838438034058,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.6202200651168823,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6151360273361206,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6017182469367981,
            "answer": "dunn",
            "hit": false
          },
          {
            "score": 0.6011971831321716,
            "answer": "dennis",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5590664446353912
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6672373414039612,
            "answer": "flynn",
            "hit": false
          },
          {
            "score": 0.6667883992195129,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6602102518081665,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6402259469032288,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.6367760896682739,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6228964924812317,
            "answer": "flight",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6602102220058441
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7210879921913147,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6268349289894104,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6068563461303711,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6060258150100708,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.6033071875572205,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.598967432975769,
            "answer": "hedge",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6068563461303711
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.6870397329330444,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6777951717376709,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.6448965072631836,
            "answer": "herb",
            "hit": false
          },
          {
            "score": 0.6228935718536377,
            "answer": "pest",
            "hit": false
          },
          {
            "score": 0.6088013052940369,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.6087184548377991,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.687039703130722
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6937447786331177,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6345438957214355,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6114577651023865,
            "answer": "mound",
            "hit": false
          },
          {
            "score": 0.6097058057785034,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5834484696388245,
            "answer": "molecule",
            "hit": false
          },
          {
            "score": 0.581129789352417,
            "answer": "molecular",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5741210132837296
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7717342376708984,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.711708128452301,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6340956687927246,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.6193711757659912,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6173606514930725,
            "answer": "mon",
            "hit": false
          },
          {
            "score": 0.6113290190696716,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5203020479530096
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7305930852890015,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.6816733479499817,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6137239336967468,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6118369102478027,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.6114977598190308,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.6085910201072693,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6816733777523041
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6829285025596619,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6392782330513,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6256127953529358,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6152841448783875,
            "answer": "ras",
            "hit": false
          },
          {
            "score": 0.6116733551025391,
            "answer": "rating",
            "hit": false
          },
          {
            "score": 0.6006138920783997,
            "answer": "ratio",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6829284876585007
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6899556517601013,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6840757727622986,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.6114768981933594,
            "answer": "rosen",
            "hit": false
          },
          {
            "score": 0.6051546335220337,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5978843569755554,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5970889329910278,
            "answer": "aurora",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6899556517601013
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7146485447883606,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7034651637077332,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6221927404403687,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6196684837341309,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.6005123257637024,
            "answer": "tree",
            "hit": false
          },
          {
            "score": 0.5970278978347778,
            "answer": "sandy",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5814473479986191
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8078283071517944,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6986731290817261,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6337829828262329,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6301581263542175,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6170312166213989,
            "answer": "boat",
            "hit": false
          },
          {
            "score": 0.6091008186340332,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 124,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5524891503155231
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6948990225791931,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6268429160118103,
            "answer": "sun",
            "hit": false
          },
          {
            "score": 0.6140204071998596,
            "answer": "mar",
            "hit": false
          },
          {
            "score": 0.6087340712547302,
            "answer": "peter",
            "hit": false
          },
          {
            "score": 0.6068685054779053,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6063892841339111,
            "answer": "hole",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6019339561462402
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 18,
      "accuracy": 0.3333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8dc07f34-6cbf-4785-9ebf-5304986b71d1",
      "timestamp": "2025-05-17T21:31:48.626480"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7236050367355347,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7007095813751221,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6997284889221191,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6921595931053162,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6892632246017456,
            "answer": "anti",
            "hit": false
          },
          {
            "score": 0.6767361164093018,
            "answer": "black",
            "hit": true
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6767360866069794
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7225618362426758,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7213159203529358,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6506627798080444,
            "answer": "iphone",
            "hit": false
          },
          {
            "score": 0.6454038619995117,
            "answer": "orange",
            "hit": true
          },
          {
            "score": 0.6430980563163757,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.639285147190094,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6349804997444153
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7286853194236755,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7139071226119995,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.658659815788269,
            "answer": "bloody",
            "hit": false
          },
          {
            "score": 0.6322031021118164,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6285959482192993,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6209838390350342,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6322030872106552
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.6859467029571533,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6849329471588135,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6518670916557312,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6461925506591797,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6459544897079468,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6293189525604248,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6459545195102692
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.6957101821899414,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.67235267162323,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6634441614151001,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6633708477020264,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6591834425926208,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.657410204410553,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6574101746082306
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7182462215423584,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7097971439361572,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6797950863838196,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6791501045227051,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6617717742919922,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6570911407470703,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6797950714826584
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7398265600204468,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7230125665664673,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7045861482620239,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.6956274509429932,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.690287709236145,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6800395250320435,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6956274956464767
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.791567325592041,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7257504463195801,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7192405462265015,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7032763957977295,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7020516991615295,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7014535665512085,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7032764554023743
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7121914029121399,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6969258785247803,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6962860822677612,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6953145265579224,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6817870140075684,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6642849445343018,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7121914029121399
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7117279767990112,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7044566869735718,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6985167860984802,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6902259588241577,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6865921020507812,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6827400326728821,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6902259737253189
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7227072715759277,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6929281949996948,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.659803032875061,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.6442224979400635,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6427849531173706,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6419577598571777,
            "answer": "pink",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7227072715759277
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.6818830966949463,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6753658056259155,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6735752820968628,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6709842681884766,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6705388426780701,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6595060229301453,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6753658056259155
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8320790529251099,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.6817403435707092,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6769602298736572,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6230505704879761,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6209098100662231,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6204029321670532,
            "answer": "kitchen",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817403733730316
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.6986532211303711,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6843003034591675,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6574621200561523,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.6510015726089478,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6473913192749023,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6412109732627869,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6473913490772247
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.7417091727256775,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.7048099040985107,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6696045398712158,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6392580270767212,
            "answer": "blacks",
            "hit": false
          },
          {
            "score": 0.6349234580993652,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6342250108718872,
            "answer": "wines",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6696045696735382
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7212960720062256,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7212709784507751,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6989915370941162,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.69246506690979,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6839289665222168,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6830126643180847,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7212960124015808
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7266016006469727,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.7232214212417603,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6990834474563599,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6958280801773071,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.688767671585083,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6841902732849121,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6841902434825897
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.707854688167572,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6962662935256958,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6939191818237305,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6915594339370728,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6889216303825378,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6858392953872681,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6939192116260529
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.7065233588218689,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7031782269477844,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7021124362945557,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6913435459136963,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6898386478424072,
            "answer": "newspaper",
            "hit": false
          },
          {
            "score": 0.6894108057022095,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7021124809980392
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7191798686981201,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6892526149749756,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6483352184295654,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6469359397888184,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6435993909835815,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6427322626113892,
            "answer": "pink",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6892526298761368
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.763423502445221,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.6891627907752991,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6888477206230164,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6661862134933472,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6586150527000427,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6585206985473633,
            "answer": "orange",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6549063920974731
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.711406409740448,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7002818584442139,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6749587059020996,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.6681745052337646,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6548371315002441,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6535742282867432,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7002818286418915
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7208868861198425,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7112963199615479,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6988808512687683,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6960163116455078,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6952180862426758,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.6938613653182983,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6829047203063965
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7072960138320923,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7066649198532104,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6923391819000244,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6748663187026978,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6635720729827881,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6585565805435181,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6923391819000244
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.6864272356033325,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.67989182472229,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6668472290039062,
            "answer": "salts",
            "hit": false
          },
          {
            "score": 0.6269362568855286,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6264258027076721,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.6247425079345703,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6798918396234512
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6806756258010864,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6768962144851685,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6523445248603821,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6447000503540039,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6437923312187195,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6382137537002563,
            "answer": "ocean",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6437923014163971
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7167855501174927,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6967830061912537,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6455640196800232,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6391324400901794,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6365257501602173,
            "answer": "skies",
            "hit": false
          },
          {
            "score": 0.6310963034629822,
            "answer": "blue",
            "hit": true
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6310963034629822
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7306966781616211,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7191035747528076,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6996485590934753,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6995448470115662,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6986499428749084,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6863107085227966,
            "answer": "winter",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7306967228651047
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.7730149626731873,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7045503258705139,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6957822442054749,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6853735446929932,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6823031902313232,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6798501014709473,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7045503258705139
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7200654149055481,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6908599138259888,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6819968819618225,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6550605893135071,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6454888582229614,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6389288902282715,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7200654298067093
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7469700574874878,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7133095264434814,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7112237215042114,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7045196890830994,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6968823671340942,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6878464818000793,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6638887971639633
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7122281193733215,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7053117752075195,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6614260673522949,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6572741270065308,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.655666708946228,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6392377614974976,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7122281193733215
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7204475402832031,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6810824871063232,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6603971123695374,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6496543288230896,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6470656394958496,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6468754410743713,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6810825169086456
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7599759101867676,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.6921054124832153,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6852941513061523,
            "answer": "orange",
            "hit": false
          },
          {
            "score": 0.6802138686180115,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6775527596473694,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6751829385757446,
            "answer": "white",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6516676843166351
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 34,
      "accuracy": 0.2647058823529412
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "15357225-bb5f-4334-9396-e14221904aa1",
      "timestamp": "2025-05-17T21:31:48.698418"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.8938655853271484,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.8347890377044678,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.7306314706802368,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6671038269996643,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.658627450466156,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.6521373987197876,
            "answer": "filmmaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.893865555524826
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.7139617204666138,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.6661726236343384,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.6498216390609741,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.626487135887146,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.620696485042572,
            "answer": "women",
            "hit": false
          },
          {
            "score": 0.6182844042778015,
            "answer": "child",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7139617204666138
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.7093633413314819,
            "answer": "sister",
            "hit": true
          },
          {
            "score": 0.7057339549064636,
            "answer": "sisters",
            "hit": false
          },
          {
            "score": 0.6861283779144287,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.6608332991600037,
            "answer": "sibling",
            "hit": false
          },
          {
            "score": 0.6534081697463989,
            "answer": "bros",
            "hit": false
          },
          {
            "score": 0.6493486166000366,
            "answer": "aunt",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7093633711338043
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.6237417459487915,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.6198108196258545,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6168802976608276,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6132153272628784,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6131640076637268,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6086788177490234,
            "answer": "duchess",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 3704,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5073557952418923
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.6340599060058594,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6322517395019531,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.6298829913139343,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6292177438735962,
            "answer": "bullying",
            "hit": false
          },
          {
            "score": 0.6281901001930237,
            "answer": "bully",
            "hit": false
          },
          {
            "score": 0.6252560019493103,
            "answer": "princess",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5694801136851311
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.7143946886062622,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.7035778760910034,
            "answer": "mum",
            "hit": true
          },
          {
            "score": 0.6924565434455872,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.6778039932250977,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6741728782653809,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.6681040525436401,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7143946588039398
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7556973099708557,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.682127833366394,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6386277675628662,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.6203899383544922,
            "answer": "bishop",
            "hit": false
          },
          {
            "score": 0.6203561425209045,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.6170604825019836,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7556973397731781
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.7552123069763184,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.7408599853515625,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7123230695724487,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.6823498010635376,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6659752130508423,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.660812258720398,
            "answer": "maternal",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7552123367786407
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.6969557404518127,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.6941946148872375,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.680042564868927,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.6585211753845215,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.6568741798400879,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.6552424430847168,
            "answer": "women",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6969557404518127
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8726382851600647,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.797579288482666,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.7649394273757935,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.7022320032119751,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.6951509714126587,
            "answer": "uncle",
            "hit": false
          },
          {
            "score": 0.6923021078109741,
            "answer": "mothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8726383149623871
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.6668258905410767,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.6118655800819397,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6074856519699097,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6010733842849731,
            "answer": "mistress",
            "hit": false
          },
          {
            "score": 0.5997973680496216,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.5997495055198669,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.666825920343399
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8063834309577942,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.7990049719810486,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7566301822662354,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7430892586708069,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.6825886964797974,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.6754686832427979,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8063834011554718
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7502002120018005,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.6952540278434753,
            "answer": "kingdom",
            "hit": false
          },
          {
            "score": 0.691991925239563,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.6845864057540894,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6517151594161987,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.6442749500274658,
            "answer": "royal",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7502002418041229
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.6817556619644165,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.6382228136062622,
            "answer": "manuel",
            "hit": false
          },
          {
            "score": 0.6366783380508423,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6331021785736084,
            "answer": "mans",
            "hit": false
          },
          {
            "score": 0.6316849589347839,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.63060462474823,
            "answer": "manual",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817556619644165
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9043270945549011,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.7883470058441162,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7749924063682556,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.7569499015808105,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.734892725944519,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7294929027557373,
            "answer": "sister",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9043271243572235
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.7308788299560547,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6839178800582886,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.6728875041007996,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.6497148275375366,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.6189638376235962,
            "answer": "king",
            "hit": false
          },
          {
            "score": 0.612396776676178,
            "answer": "actress",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.683917909860611
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.6823234558105469,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.678052544593811,
            "answer": "sons",
            "hit": false
          },
          {
            "score": 0.6654735803604126,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.650151252746582,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6373171210289001,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6293137073516846,
            "answer": "grandson",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6823234558105469
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8654977679252625,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.7677823305130005,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7450952529907227,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7398658990859985,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7387087345123291,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7036737203598022,
            "answer": "grandfather",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654977679252625
      }
    ],
    "result": {
      "cnt_questions_correct": 15,
      "cnt_questions_total": 18,
      "accuracy": 0.8333333333333334
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e01313eb-a7b7-4352-8879-497f547d7b05",
      "timestamp": "2025-05-17T21:31:48.835185"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7261601090431213,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.71897292137146,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.6524436473846436,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6363880634307861,
            "answer": "ambient",
            "hit": false
          },
          {
            "score": 0.6320545077323914,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.6216640472412109,
            "answer": "vibe",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5979472994804382
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7538316249847412,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.6301864385604858,
            "answer": "baggage",
            "hit": false
          },
          {
            "score": 0.60518479347229,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.5929331183433533,
            "answer": "sack",
            "hit": false
          },
          {
            "score": 0.5847795009613037,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.5828665494918823,
            "answer": "wood",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5701823085546494
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6626299023628235,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.6214045286178589,
            "answer": "hairs",
            "hit": false
          },
          {
            "score": 0.6126476526260376,
            "answer": "facial",
            "hit": false
          },
          {
            "score": 0.6056238412857056,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.5974646806716919,
            "answer": "robe",
            "hit": false
          },
          {
            "score": 0.597244381904602,
            "answer": "robes",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6626298874616623
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.8442075848579407,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.6757586002349854,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.6641267538070679,
            "answer": "head",
            "hit": false
          },
          {
            "score": 0.6524443626403809,
            "answer": "weight",
            "hit": false
          },
          {
            "score": 0.6459120512008667,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.6437526941299438,
            "answer": "text",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6217406764626503
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7610556483268738,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7080486416816711,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.6744381785392761,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.6502965688705444,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.6470561623573303,
            "answer": "feet",
            "hit": false
          },
          {
            "score": 0.6424741148948669,
            "answer": "trousers",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.622208409011364
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8436771035194397,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.6539931893348694,
            "answer": "alcohol",
            "hit": false
          },
          {
            "score": 0.6513386964797974,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.6391021013259888,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6388021111488342,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.634308934211731,
            "answer": "beverage",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6391021609306335
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8317902684211731,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.6446332335472107,
            "answer": "bow",
            "hit": false
          },
          {
            "score": 0.6303900480270386,
            "answer": "dish",
            "hit": false
          },
          {
            "score": 0.6112699508666992,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.6094009280204773,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.6079413890838623,
            "answer": "bowling",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6007354855537415
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.6845836639404297,
            "answer": "cock",
            "hit": false
          },
          {
            "score": 0.6361656785011292,
            "answer": "mixture",
            "hit": false
          },
          {
            "score": 0.631145179271698,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.6307618021965027,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6230841279029846,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.6225154399871826,
            "answer": "mix",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5946489050984383
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6486583948135376,
            "answer": "desktop",
            "hit": false
          },
          {
            "score": 0.6387349367141724,
            "answer": "des",
            "hit": false
          },
          {
            "score": 0.6221798658370972,
            "answer": "staff",
            "hit": false
          },
          {
            "score": 0.6200615167617798,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.6173087358474731,
            "answer": "computer",
            "hit": false
          },
          {
            "score": 0.6148827075958252,
            "answer": "bureau",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5579236671328545
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7586583495140076,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.6185917258262634,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.6089911460876465,
            "answer": "jewel",
            "hit": false
          },
          {
            "score": 0.5997015237808228,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.598767101764679,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.5938823223114014,
            "answer": "gems",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 455,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5320049859583378
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.690534770488739,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.5787636041641235,
            "answer": "flagship",
            "hit": false
          },
          {
            "score": 0.5782815217971802,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.577927827835083,
            "answer": "byte",
            "hit": false
          },
          {
            "score": 0.5773755311965942,
            "answer": "flint",
            "hit": false
          },
          {
            "score": 0.5744786858558655,
            "answer": "glass",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 1859,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5197043661028147
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.7080562114715576,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6794939041137695,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.663308322429657,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.6227571964263916,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.6180612444877625,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6111165881156921,
            "answer": "wood",
            "hit": true
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5282236505299807
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7489109635353088,
            "answer": "jamie",
            "hit": false
          },
          {
            "score": 0.6416546106338501,
            "answer": "jay",
            "hit": false
          },
          {
            "score": 0.6126952171325684,
            "answer": "jen",
            "hit": false
          },
          {
            "score": 0.6074326634407043,
            "answer": "james",
            "hit": false
          },
          {
            "score": 0.6017722487449646,
            "answer": "jordan",
            "hit": false
          },
          {
            "score": 0.5972689390182495,
            "answer": "jim",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 427,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5342840179800987
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.6781657934188843,
            "answer": "grass",
            "hit": true
          },
          {
            "score": 0.6673856973648071,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.6254713535308838,
            "answer": "gardens",
            "hit": false
          },
          {
            "score": 0.6180838346481323,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.6162036657333374,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.6143001317977905,
            "answer": "carpet",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6781658232212067
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8556079268455505,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.6465610265731812,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6303992867469788,
            "answer": "eyes",
            "hit": false
          },
          {
            "score": 0.6129549741744995,
            "answer": "hair",
            "hit": false
          },
          {
            "score": 0.6100238561630249,
            "answer": "glasses",
            "hit": false
          },
          {
            "score": 0.6077948808670044,
            "answer": "light",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6465610414743423
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.6779576539993286,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.6106824278831482,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6067134141921997,
            "answer": "reflection",
            "hit": false
          },
          {
            "score": 0.6065220832824707,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5997343063354492,
            "answer": "reflect",
            "hit": false
          },
          {
            "score": 0.579879641532898,
            "answer": "reflective",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6106824800372124
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6604610681533813,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.6523053646087646,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.6519749760627747,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.6480381488800049,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6399497985839844,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.6253110766410828,
            "answer": "cash",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5135565884411335
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7767260670661926,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.68332839012146,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.667829155921936,
            "answer": "beach",
            "hit": false
          },
          {
            "score": 0.66130530834198,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.6528815031051636,
            "answer": "coastal",
            "hit": false
          },
          {
            "score": 0.6520505547523499,
            "answer": "atlantic",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6070509403944016
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.6747855544090271,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.6413669586181641,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.6390306949615479,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.6277458071708679,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.6182078123092651,
            "answer": "bread",
            "hit": false
          },
          {
            "score": 0.6136795878410339,
            "answer": "cakes",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 162,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.555112786591053
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.613072395324707,
            "answer": "jenny",
            "hit": false
          },
          {
            "score": 0.6127389073371887,
            "answer": "pine",
            "hit": false
          },
          {
            "score": 0.6045231223106384,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5997148752212524,
            "answer": "mint",
            "hit": false
          },
          {
            "score": 0.5988811254501343,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.5930783748626709,
            "answer": "porter",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 115,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.543130062520504
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.6434913873672485,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.6324389576911926,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.625514566898346,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.6162165999412537,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5969958305358887,
            "answer": "pillar",
            "hit": false
          },
          {
            "score": 0.5865012407302856,
            "answer": "metal",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5306921489536762
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.743878960609436,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.6605898141860962,
            "answer": "rubber",
            "hit": false
          },
          {
            "score": 0.6602795124053955,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.6556005477905273,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6547282934188843,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.6486393809318542,
            "answer": "metal",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5361927933990955
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.6707870364189148,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6465862393379211,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.6190937161445618,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.6029040813446045,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6024144887924194,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.591954231262207,
            "answer": "beach",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5779179781675339
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6309750080108643,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.6223903298377991,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5949876308441162,
            "answer": "tong",
            "hit": false
          },
          {
            "score": 0.5943571329116821,
            "answer": "wooden",
            "hit": false
          },
          {
            "score": 0.5927645564079285,
            "answer": "sugar",
            "hit": false
          },
          {
            "score": 0.5923942923545837,
            "answer": "bowl",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5111752431839705
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.6940929889678955,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6039904356002808,
            "answer": "fig",
            "hit": false
          },
          {
            "score": 0.5930505990982056,
            "answer": "figure",
            "hit": false
          },
          {
            "score": 0.5926317572593689,
            "answer": "tablet",
            "hit": false
          },
          {
            "score": 0.5909437537193298,
            "answer": "tablets",
            "hit": false
          },
          {
            "score": 0.5874141454696655,
            "answer": "tab",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5354372225701809
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6287975907325745,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.6034717559814453,
            "answer": "wand",
            "hit": false
          },
          {
            "score": 0.58903968334198,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5846471786499023,
            "answer": "lumber",
            "hit": false
          },
          {
            "score": 0.5832811594009399,
            "answer": "feathers",
            "hit": false
          },
          {
            "score": 0.5750510692596436,
            "answer": "robes",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6287975758314133
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.7002170085906982,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.6244133114814758,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6163976788520813,
            "answer": "alcohol",
            "hit": false
          },
          {
            "score": 0.6138895153999329,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.6133666038513184,
            "answer": "grape",
            "hit": true
          },
          {
            "score": 0.6110600829124451,
            "answer": "liquor",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6087285429239273
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.7009166479110718,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.6853091716766357,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.6528875231742859,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.6333326101303101,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6306695342063904,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.6102288365364075,
            "answer": "cable",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5938461497426033
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 28,
      "accuracy": 0.10714285714285714
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5a3c6781-534f-4961-8232-f85d2efa1f89",
      "timestamp": "2025-05-17T21:31:48.905541"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7154942154884338,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.6362497806549072,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.617051899433136,
            "answer": "butter",
            "hit": false
          },
          {
            "score": 0.6148504018783569,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.6101630330085754,
            "answer": "duck",
            "hit": false
          },
          {
            "score": 0.6092937588691711,
            "answer": "boat",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5882684141397476
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7997456192970276,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6378306150436401,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6365635991096497,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.6303261518478394,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.614849328994751,
            "answer": "goat",
            "hit": false
          },
          {
            "score": 0.5956137776374817,
            "answer": "knee",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5811403393745422
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.6900514364242554,
            "answer": "caroline",
            "hit": false
          },
          {
            "score": 0.6872656345367432,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.6616359353065491,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.6573580503463745,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.6502188444137573,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.640105664730072,
            "answer": "carrier",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 1575,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.49702202808111906
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8044142127037048,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7635097503662109,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7094723582267761,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6791476607322693,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.6775233149528503,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6765878200531006,
            "answer": "poultry",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6548725515604019
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.7693198919296265,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.756583571434021,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.6878359317779541,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.6802494525909424,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.6676145792007446,
            "answer": "protestant",
            "hit": false
          },
          {
            "score": 0.645679235458374,
            "answer": "evangelical",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5840073227882385
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.7955814599990845,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7640285491943359,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6933362483978271,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6848264336585999,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.6727261543273926,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.668853759765625,
            "answer": "student",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6552688777446747
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.798490583896637,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6937659382820129,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.6674344539642334,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.6565985679626465,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.6410515308380127,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.6344602108001709,
            "answer": "rural",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5787010937929153
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.6640673279762268,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6304395198822021,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.6290671229362488,
            "answer": "cowboys",
            "hit": false
          },
          {
            "score": 0.6189498901367188,
            "answer": "cock",
            "hit": false
          },
          {
            "score": 0.6131032109260559,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6039742231369019,
            "answer": "milk",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6131031811237335
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.6750224232673645,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.6616030335426331,
            "answer": "crowds",
            "hit": false
          },
          {
            "score": 0.6612761616706848,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.6158633232116699,
            "answer": "crowned",
            "hit": false
          },
          {
            "score": 0.6051675081253052,
            "answer": "crown",
            "hit": false
          },
          {
            "score": 0.5943946838378906,
            "answer": "flock",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 12660,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4802056569606066
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8188446760177612,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6262497901916504,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.6242475509643555,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.6210640072822571,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.6152097582817078,
            "answer": "horse",
            "hit": false
          },
          {
            "score": 0.6141778230667114,
            "answer": "herd",
            "hit": true
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6141777858138084
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.7516611218452454,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.6931725740432739,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.6754813194274902,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.6499580144882202,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.6469539999961853,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.6452974081039429,
            "answer": "workforce",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.584220290184021
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.6325821876525879,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.6303186416625977,
            "answer": "fisher",
            "hit": false
          },
          {
            "score": 0.6182685494422913,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.6165292859077454,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.6042454838752747,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.5903941988945007,
            "answer": "ferry",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 12225,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4774526935070753
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.7964519262313843,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.7031571269035339,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.6656888127326965,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.6509017944335938,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.6262983083724976,
            "answer": "planets",
            "hit": false
          },
          {
            "score": 0.6256908774375916,
            "answer": "universe",
            "hit": true
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6256908774375916
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.7480680346488953,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.619574785232544,
            "answer": "email",
            "hit": false
          },
          {
            "score": 0.6075525879859924,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.6000207662582397,
            "answer": "alphabet",
            "hit": true
          },
          {
            "score": 0.5956782102584839,
            "answer": "emails",
            "hit": false
          },
          {
            "score": 0.5887619256973267,
            "answer": "newsletter",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6000207811594009
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.6412745714187622,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.6238478422164917,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.6159735918045044,
            "answer": "dragon",
            "hit": false
          },
          {
            "score": 0.6153802871704102,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6072284579277039,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6054642796516418,
            "answer": "flock",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 872,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5306635461747646
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.6875690817832947,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.613745391368866,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.6045759320259094,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.5989447236061096,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.5822034478187561,
            "answer": "audience",
            "hit": true
          },
          {
            "score": 0.5766764879226685,
            "answer": "herd",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5822034329175949
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.7715085744857788,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7165833115577698,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.6062991619110107,
            "answer": "group",
            "hit": true
          },
          {
            "score": 0.5824439525604248,
            "answer": "teammates",
            "hit": false
          },
          {
            "score": 0.5810650587081909,
            "answer": "faction",
            "hit": false
          },
          {
            "score": 0.5804498195648193,
            "answer": "committee",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5576004311442375
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8405950665473938,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.7371013760566711,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.7281990051269531,
            "answer": "musical",
            "hit": false
          },
          {
            "score": 0.7248207926750183,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.715555727481842,
            "answer": "artist",
            "hit": false
          },
          {
            "score": 0.7139915823936462,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6718739718198776
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7532099485397339,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.6861337423324585,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.6630856394767761,
            "answer": "persona",
            "hit": false
          },
          {
            "score": 0.6627985239028931,
            "answer": "personnel",
            "hit": false
          },
          {
            "score": 0.6504528522491455,
            "answer": "personality",
            "hit": false
          },
          {
            "score": 0.6395139694213867,
            "answer": "individuals",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5057896738871932
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.836014986038208,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.7482682466506958,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7163320779800415,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.6923325657844543,
            "answer": "video",
            "hit": false
          },
          {
            "score": 0.6707451343536377,
            "answer": "image",
            "hit": false
          },
          {
            "score": 0.6646305918693542,
            "answer": "photographers",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 1175,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5426992811262608
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.7429842948913574,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.6502249836921692,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.6447678804397583,
            "answer": "gameplay",
            "hit": false
          },
          {
            "score": 0.6324827671051025,
            "answer": "play",
            "hit": false
          },
          {
            "score": 0.6308844089508057,
            "answer": "multiplayer",
            "hit": false
          },
          {
            "score": 0.6300710439682007,
            "answer": "played",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 48,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5689935386180878
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.7594054937362671,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.7295052409172058,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.6665942668914795,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6435559988021851,
            "answer": "detective",
            "hit": false
          },
          {
            "score": 0.6418148875236511,
            "answer": "officer",
            "hit": false
          },
          {
            "score": 0.6380078792572021,
            "answer": "detectives",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7594054639339447
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7158713936805725,
            "answer": "secret",
            "hit": false
          },
          {
            "score": 0.6451961398124695,
            "answer": "assistant",
            "hit": false
          },
          {
            "score": 0.6409116983413696,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6233126521110535,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.6229802370071411,
            "answer": "clerk",
            "hit": false
          },
          {
            "score": 0.6202456951141357,
            "answer": "department",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5656362548470497
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.7599974870681763,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.7512163519859314,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.745353639125824,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7370631694793701,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.6760291457176208,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.6627577543258667,
            "answer": "congressional",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7453536689281464
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7181291580200195,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.6937656402587891,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.6916221380233765,
            "answer": "lamb",
            "hit": false
          },
          {
            "score": 0.6872187852859497,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.6686224937438965,
            "answer": "pigs",
            "hit": false
          },
          {
            "score": 0.6653653979301453,
            "answer": "flock",
            "hit": true
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6653653979301453
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8607096076011658,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7556055784225464,
            "answer": "sold",
            "hit": false
          },
          {
            "score": 0.7273049354553223,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7228796482086182,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.6547973155975342,
            "answer": "armies",
            "hit": false
          },
          {
            "score": 0.6531143188476562,
            "answer": "sailor",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7228796780109406
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.7684688568115234,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.7402219772338867,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7027071118354797,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6745704412460327,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.6533437967300415,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.6468636393547058,
            "answer": "boyfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5682830959558487
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7052224278450012,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.6556510925292969,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.6160991787910461,
            "answer": "commonwealth",
            "hit": false
          },
          {
            "score": 0.5952490568161011,
            "answer": "provincial",
            "hit": false
          },
          {
            "score": 0.5944035649299622,
            "answer": "stat",
            "hit": false
          },
          {
            "score": 0.5939424633979797,
            "answer": "county",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5492640845477581
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.764143168926239,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7352040410041809,
            "answer": "school",
            "hit": true
          },
          {
            "score": 0.6986261010169983,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.6917487978935242,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.6916382312774658,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6893819570541382,
            "answer": "pupil",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5886649936437607
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.7814485430717468,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.6453448534011841,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.6363869309425354,
            "answer": "forest",
            "hit": true
          },
          {
            "score": 0.6331973075866699,
            "answer": "node",
            "hit": false
          },
          {
            "score": 0.6158968806266785,
            "answer": "trunk",
            "hit": false
          },
          {
            "score": 0.615151584148407,
            "answer": "branch",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6363869458436966
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.6424784064292908,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.632347583770752,
            "answer": "sun",
            "hit": false
          },
          {
            "score": 0.6077986359596252,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.6052154302597046,
            "answer": "hans",
            "hit": false
          },
          {
            "score": 0.6019241213798523,
            "answer": "wal",
            "hit": false
          },
          {
            "score": 0.5991677045822144,
            "answer": "hugh",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 574,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5488861091434956
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.8239408731460571,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.6678389310836792,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.6276749968528748,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.6108266115188599,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.5984622240066528,
            "answer": "sentence",
            "hit": true
          },
          {
            "score": 0.5967428088188171,
            "answer": "verbal",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5604999475181103
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6edd66c5-900c-4380-81e8-9856f6a0ee9c",
      "timestamp": "2025-05-17T21:31:49.018901"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.7259255051612854,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.6909056305885315,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6509647369384766,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6375338435173035,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.6375161409378052,
            "answer": "busy",
            "hit": false
          },
          {
            "score": 0.6333767771720886,
            "answer": "was",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 779,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5532545447349548
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.6609387397766113,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.6314539909362793,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.61726975440979,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6170744895935059,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.5834957361221313,
            "answer": "bits",
            "hit": false
          },
          {
            "score": 0.5714593529701233,
            "answer": "buck",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 1240,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5229222625494003
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.711864709854126,
            "answer": "combined",
            "hit": false
          },
          {
            "score": 0.7079636454582214,
            "answer": "combining",
            "hit": false
          },
          {
            "score": 0.7011347413063049,
            "answer": "combination",
            "hit": false
          },
          {
            "score": 0.699924647808075,
            "answer": "combines",
            "hit": false
          },
          {
            "score": 0.6799514293670654,
            "answer": "combo",
            "hit": false
          },
          {
            "score": 0.6691122055053711,
            "answer": "combine",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 2751,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.517743494361639
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.6799808740615845,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6538537740707397,
            "answer": "doll",
            "hit": false
          },
          {
            "score": 0.6424560546875,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6367902755737305,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6291792988777161,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.5955278873443604,
            "answer": "dentist",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 4535,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5067614959552884
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d747a0c1-3498-480d-8284-2890efce07d3",
      "timestamp": "2025-05-17T21:31:49.161097"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.7067812085151672,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.7033362984657288,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.6998565196990967,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.6727759838104248,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.6552385091781616,
            "answer": "pleased",
            "hit": false
          },
          {
            "score": 0.6543838977813721,
            "answer": "shocked",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6474994271993637
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.7260109186172485,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6679994463920593,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.6665358543395996,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.6371991038322449,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.6298244595527649,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6092554926872253,
            "answer": "kitchen",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6023357585072517
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7165747284889221,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.6346375942230225,
            "answer": "rivers",
            "hit": false
          },
          {
            "score": 0.6308441162109375,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6163990497589111,
            "answer": "beach",
            "hit": false
          },
          {
            "score": 0.6135658025741577,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.6118299961090088,
            "answer": "pond",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5078552300110459
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.6554682850837708,
            "answer": "painter",
            "hit": false
          },
          {
            "score": 0.6468843221664429,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.6458317041397095,
            "answer": "painting",
            "hit": false
          },
          {
            "score": 0.6360256671905518,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.6309804916381836,
            "answer": "paint",
            "hit": false
          },
          {
            "score": 0.6182661056518555,
            "answer": "pains",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5580562017858028
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.6543424129486084,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.6332229971885681,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6331168413162231,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6263018846511841,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.5983358025550842,
            "answer": "wagon",
            "hit": false
          },
          {
            "score": 0.5930291414260864,
            "answer": "monkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6543423980474472
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.6601161956787109,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6477089524269104,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6158002614974976,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.6129270792007446,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.5861994028091431,
            "answer": "beach",
            "hit": false
          },
          {
            "score": 0.5857263207435608,
            "answer": "sailing",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6477089375257492
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8171356916427612,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.6498234272003174,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.6405017971992493,
            "answer": "lunch",
            "hit": false
          },
          {
            "score": 0.6387759447097778,
            "answer": "burger",
            "hit": false
          },
          {
            "score": 0.6350233554840088,
            "answer": "pizza",
            "hit": false
          },
          {
            "score": 0.6344735622406006,
            "answer": "meals",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5684595480561256
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.7687428593635559,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.7081937789916992,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.6695839166641235,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.6556333899497986,
            "answer": "fatigue",
            "hit": false
          },
          {
            "score": 0.6451057195663452,
            "answer": "sleepy",
            "hit": false
          },
          {
            "score": 0.6342343091964722,
            "answer": "frustrated",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7081937193870544
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 8,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "cdb2d2ba-3379-47e5-b2d7-ab232be142d4",
      "timestamp": "2025-05-17T21:31:49.181518"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8369661569595337,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.7456790804862976,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.718216598033905,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7111141085624695,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.6961408257484436,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.6850849390029907,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8369661867618561
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.5998274683952332,
            "answer": "brush",
            "hit": false
          },
          {
            "score": 0.5986931324005127,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.5954536199569702,
            "answer": "boats",
            "hit": false
          },
          {
            "score": 0.5947834849357605,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.5834807753562927,
            "answer": "bands",
            "hit": false
          },
          {
            "score": 0.5829652547836304,
            "answer": "garments",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5664601847529411
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.6932940483093262,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.6914491057395935,
            "answer": "doll",
            "hit": false
          },
          {
            "score": 0.6818128228187561,
            "answer": "pounds",
            "hit": false
          },
          {
            "score": 0.6674520373344421,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.658935010433197,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.6571915149688721,
            "answer": "usd",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 165,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.55042415112257
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.7470913529396057,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.7027028203010559,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6836883425712585,
            "answer": "daddy",
            "hit": true
          },
          {
            "score": 0.6694799661636353,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.6598974466323853,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.6470217704772949,
            "answer": "parent",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6694799959659576
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7031077146530151,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.7024219632148743,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7000097036361694,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.6911018490791321,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.6727735996246338,
            "answer": "assist",
            "hit": true
          },
          {
            "score": 0.6553224325180054,
            "answer": "assisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5599247217178345
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.683965802192688,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.6701620221138,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.6558756828308105,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.6532737612724304,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.646265983581543,
            "answer": "intelligence",
            "hit": false
          },
          {
            "score": 0.6428431272506714,
            "answer": "sophisticated",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6701620221138
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.760502815246582,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.6844878196716309,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.665746808052063,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.6623272895812988,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.6227695941925049,
            "answer": "pear",
            "hit": false
          },
          {
            "score": 0.620752215385437,
            "answer": "necklace",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5755032896995544
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.7680231928825378,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.6868234276771545,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.6336376667022705,
            "answer": "landmark",
            "hit": false
          },
          {
            "score": 0.6250350475311279,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.6218369007110596,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.6166732907295227,
            "answer": "museum",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6868234276771545
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7317343354225159,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.6592327952384949,
            "answer": "fresh",
            "hit": false
          },
          {
            "score": 0.6549924612045288,
            "answer": "nyc",
            "hit": false
          },
          {
            "score": 0.6498316526412964,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.6265046000480652,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.6246241927146912,
            "answer": "manhattan",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5474497601389885
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.6919201612472534,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.6727460622787476,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.6570727825164795,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.6135852336883545,
            "answer": "pack",
            "hit": true
          },
          {
            "score": 0.6120091080665588,
            "answer": "packs",
            "hit": false
          },
          {
            "score": 0.596298098564148,
            "answer": "bundle",
            "hit": true
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5838533043861389
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.6977435946464539,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.6374061703681946,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.6166188716888428,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.6165595650672913,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.6012284755706787,
            "answer": "airport",
            "hit": false
          },
          {
            "score": 0.5959852337837219,
            "answer": "ferry",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6977435946464539
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.695810854434967,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.6165197491645813,
            "answer": "reasoning",
            "hit": false
          },
          {
            "score": 0.5993592739105225,
            "answer": "logical",
            "hit": true
          },
          {
            "score": 0.5970504283905029,
            "answer": "reasoned",
            "hit": false
          },
          {
            "score": 0.589185893535614,
            "answer": "reason",
            "hit": false
          },
          {
            "score": 0.5823961496353149,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5993592590093613
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.730704665184021,
            "answer": "sensible",
            "hit": true
          },
          {
            "score": 0.7232825756072998,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7076833844184875,
            "answer": "decent",
            "hit": false
          },
          {
            "score": 0.7072572112083435,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7066715955734253,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.681332528591156,
            "answer": "realistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.730704665184021
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.663499653339386,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.640822172164917,
            "answer": "rocket",
            "hit": false
          },
          {
            "score": 0.6348012685775757,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6115388870239258,
            "answer": "rockets",
            "hit": false
          },
          {
            "score": 0.603107213973999,
            "answer": "rocky",
            "hit": false
          },
          {
            "score": 0.5974912643432617,
            "answer": "stone",
            "hit": true
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5974913015961647
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.8157404661178589,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.6495568752288818,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.6488909721374512,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.6296111941337585,
            "answer": "bedroom",
            "hit": false
          },
          {
            "score": 0.6252226829528809,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.6207035779953003,
            "answer": "fireplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8157404661178589
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.8148897290229797,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7024669647216797,
            "answer": "fashion",
            "hit": true
          },
          {
            "score": 0.6993132829666138,
            "answer": "type",
            "hit": false
          },
          {
            "score": 0.6836399435997009,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.673534631729126,
            "answer": "shape",
            "hit": false
          },
          {
            "score": 0.6726915240287781,
            "answer": "technique",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6666077673435211
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 16,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e85ec8fc-ef98-4a6c-968f-77dc69d19ad5",
      "timestamp": "2025-05-17T21:31:49.211743"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7141439914703369,
            "answer": "afterward",
            "hit": false
          },
          {
            "score": 0.6567167639732361,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.6518031358718872,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6431314945220947,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.6399257183074951,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.6394172310829163,
            "answer": "during",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6352661699056625
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.6751348972320557,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.6746492981910706,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.6413313150405884,
            "answer": "alongside",
            "hit": false
          },
          {
            "score": 0.63388592004776,
            "answer": "away",
            "hit": false
          },
          {
            "score": 0.6280980706214905,
            "answer": "advance",
            "hit": false
          },
          {
            "score": 0.6172930598258972,
            "answer": "earlier",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6746493130922318
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8021688461303711,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.664179801940918,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.647942841053009,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.6351320743560791,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.6166326403617859,
            "answer": "inferior",
            "hit": false
          },
          {
            "score": 0.6097144484519958,
            "answer": "abdominal",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8021688759326935
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.6668956279754639,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.6523029804229736,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.650259256362915,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.6477457284927368,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.6419481039047241,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6411548852920532,
            "answer": "since",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6523029655218124
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7729282379150391,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.6867053508758545,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.6785510778427124,
            "answer": "starting",
            "hit": false
          },
          {
            "score": 0.6680448055267334,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.6658676862716675,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.6510648727416992,
            "answer": "commence",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.573396235704422
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.6910456418991089,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.6852858066558838,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.6557782292366028,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.6533002853393555,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6453683376312256,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.6356800198554993,
            "answer": "deadly",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6289567351341248
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8066380620002747,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.6634787321090698,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.6260015368461609,
            "answer": "leap",
            "hit": false
          },
          {
            "score": 0.6221336126327515,
            "answer": "climb",
            "hit": false
          },
          {
            "score": 0.62047278881073,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.6161565184593201,
            "answer": "tackle",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 492,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5418183952569962
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.748275876045227,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.7196859121322632,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.7177585363388062,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7107576727867126,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.6880419254302979,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.6417891979217529,
            "answer": "winter",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5988039895892143
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.754374086856842,
            "answer": "last",
            "hit": true
          },
          {
            "score": 0.7304790616035461,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7123198509216309,
            "answer": "most",
            "hit": false
          },
          {
            "score": 0.702303409576416,
            "answer": "then",
            "hit": false
          },
          {
            "score": 0.7020950317382812,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.7006582021713257,
            "answer": "later",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7543740570545197
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.7218987941741943,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.6350796818733215,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.6206048727035522,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.5808730721473694,
            "answer": "source",
            "hit": false
          },
          {
            "score": 0.5706823468208313,
            "answer": "incoming",
            "hit": false
          },
          {
            "score": 0.5672276616096497,
            "answer": "assume",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6350797116756439
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.8096128702163696,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7290239334106445,
            "answer": "interior",
            "hit": false
          },
          {
            "score": 0.7168288230895996,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.6965608596801758,
            "answer": "beneath",
            "hit": false
          },
          {
            "score": 0.6953554153442383,
            "answer": "behind",
            "hit": false
          },
          {
            "score": 0.6824932098388672,
            "answer": "across",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6786139607429504
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.7105127573013306,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.6628144979476929,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6490942239761353,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.6215294003486633,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.6190350651741028,
            "answer": "interior",
            "hit": false
          },
          {
            "score": 0.6046247482299805,
            "answer": "private",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6490942537784576
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.6376543045043945,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.6259360909461975,
            "answer": "human",
            "hit": false
          },
          {
            "score": 0.6191924214363098,
            "answer": "lethal",
            "hit": false
          },
          {
            "score": 0.6146277189254761,
            "answer": "deadly",
            "hit": false
          },
          {
            "score": 0.6143900156021118,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.6093207597732544,
            "answer": "humans",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6376543045043945
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.6883355975151062,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.6741396188735962,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.6702503561973572,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.666170597076416,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.6391482353210449,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.6354801654815674,
            "answer": "vacant",
            "hit": true
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6354801654815674
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.6727218627929688,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.6095020771026611,
            "answer": "overtime",
            "hit": false
          },
          {
            "score": 0.5988481640815735,
            "answer": "overhead",
            "hit": false
          },
          {
            "score": 0.5945366621017456,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.5942150950431824,
            "answer": "back",
            "hit": false
          },
          {
            "score": 0.5851725339889526,
            "answer": "overlap",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5643376857042313
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.6980037689208984,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.6860251426696777,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.6630924940109253,
            "answer": "recently",
            "hit": false
          },
          {
            "score": 0.6539990901947021,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.6452860832214355,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.6174033284187317,
            "answer": "before",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 142,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5442073121666908
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8078327178955078,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7518130540847778,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7485923767089844,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.687972903251648,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6695046424865723,
            "answer": "commence",
            "hit": false
          },
          {
            "score": 0.6671723127365112,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 116,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5302169770002365
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.6966774463653564,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.6742024421691895,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.6595457196235657,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.6565052270889282,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.6099766492843628,
            "answer": "raise",
            "hit": false
          },
          {
            "score": 0.6073642373085022,
            "answer": "decline",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5296102035790682
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.6876696944236755,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.6858742833137512,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.6765826940536499,
            "answer": "southern",
            "hit": false
          },
          {
            "score": 0.6743274927139282,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.6581782102584839,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.6553010940551758,
            "answer": "west",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6743274927139282
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.7622097730636597,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.7002734541893005,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.678054928779602,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.6655266284942627,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.6611213088035583,
            "answer": "midwest",
            "hit": false
          },
          {
            "score": 0.6320551633834839,
            "answer": "east",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.678054928779602
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.9256159067153931,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.6823064088821411,
            "answer": "against",
            "hit": false
          },
          {
            "score": 0.6490025520324707,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.6477266550064087,
            "answer": "across",
            "hit": false
          },
          {
            "score": 0.6377490758895874,
            "answer": "closer",
            "hit": false
          },
          {
            "score": 0.6341186761856079,
            "answer": "away",
            "hit": true
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6341186761856079
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.6899173259735107,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.6561673879623413,
            "answer": "null",
            "hit": false
          },
          {
            "score": 0.609461784362793,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.6082748770713806,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.6082090139389038,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.5956295728683472,
            "answer": "realism",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6899173259735107
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.8239529132843018,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8183600306510925,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7556084990501404,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.7229342460632324,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.7190865278244019,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.6421843767166138,
            "answer": "south",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7229342311620712
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 23,
      "accuracy": 0.2608695652173913
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f54bb38d-e186-4a48-8c1d-1f63c28346be",
      "timestamp": "2025-05-17T21:31:49.272509"
    }
  }
]