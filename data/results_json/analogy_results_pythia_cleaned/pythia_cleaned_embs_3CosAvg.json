[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.7281943559646606,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.6180632710456848,
            "answer": "cds",
            "hit": false
          },
          {
            "score": 0.6030420064926147,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.6004838943481445,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.5983281135559082,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.591072678565979,
            "answer": "guitarist",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7281943410634995
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.7753807306289673,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.710447371006012,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6849980354309082,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.6602400541305542,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.648059606552124,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.6394026279449463,
            "answer": "applicant",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7753807306289673
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7468967437744141,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.6181791424751282,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.6092320680618286,
            "answer": "zones",
            "hit": false
          },
          {
            "score": 0.602910041809082,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.5952115654945374,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.5937005281448364,
            "answer": "groups",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7468968033790588
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.6034584045410156,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.579899787902832,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.5798577070236206,
            "answer": "circuits",
            "hit": false
          },
          {
            "score": 0.5797455906867981,
            "answer": "bus",
            "hit": false
          },
          {
            "score": 0.5787763595581055,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.5768049359321594,
            "answer": "carriers",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6034584492444992
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.7260487675666809,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.6690363883972168,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.6515733003616333,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6436303853988647,
            "answer": "university",
            "hit": false
          },
          {
            "score": 0.640846848487854,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.6189283728599548,
            "answer": "campus",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7260487824678421
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8169076442718506,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.6225018501281738,
            "answer": "board",
            "hit": false
          },
          {
            "score": 0.6211368441581726,
            "answer": "committee",
            "hit": false
          },
          {
            "score": 0.6186440587043762,
            "answer": "committees",
            "hit": false
          },
          {
            "score": 0.6174958944320679,
            "answer": "advisers",
            "hit": false
          },
          {
            "score": 0.6165176033973694,
            "answer": "commissioners",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8169077038764954
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.7444725036621094,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.6199463605880737,
            "answer": "clients",
            "hit": false
          },
          {
            "score": 0.6186812520027161,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6181337833404541,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.6125215291976929,
            "answer": "users",
            "hit": false
          },
          {
            "score": 0.6124393343925476,
            "answer": "patient",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7444725036621094
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.696439802646637,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.6916746497154236,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.6792248487472534,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.6578533053398132,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.6563557386398315,
            "answer": "hours",
            "hit": false
          },
          {
            "score": 0.6526390910148621,
            "answer": "mornings",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.691674679517746
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.791617751121521,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7022044658660889,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.664554238319397,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.6611586809158325,
            "answer": "dead",
            "hit": false
          },
          {
            "score": 0.6565864086151123,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.6469494104385376,
            "answer": "dying",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7916176915168762
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.7921717166900635,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.7570048570632935,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.6502967476844788,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.6500105857849121,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.6381281018257141,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.6152982711791992,
            "answer": "institute",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7921717166900635
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7037393450737,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6956765651702881,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.6934095621109009,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.687203586101532,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6830618381500244,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6760950684547424,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6934095621109009
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7498038411140442,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.6523823738098145,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.6519059538841248,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.6432180404663086,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.6339970827102661,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.6294935941696167,
            "answer": "differs",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7498038709163666
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.7399276494979858,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.6597384214401245,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.6475743651390076,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.6433629393577576,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.6351998448371887,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.6314091682434082,
            "answer": "president",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7399276196956635
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.646165668964386,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.5898518562316895,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.5894187688827515,
            "answer": "vents",
            "hit": false
          },
          {
            "score": 0.586785078048706,
            "answer": "workshops",
            "hit": false
          },
          {
            "score": 0.584694504737854,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.584433376789093,
            "answer": "accomplishments",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.646165668964386
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.7384800910949707,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.6515034437179565,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.6457849144935608,
            "answer": "exemplary",
            "hit": false
          },
          {
            "score": 0.6378375291824341,
            "answer": "illustration",
            "hit": false
          },
          {
            "score": 0.6322914361953735,
            "answer": "illustrate",
            "hit": false
          },
          {
            "score": 0.613754391670227,
            "answer": "illustrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7384800761938095
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.6962565183639526,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.6603435277938843,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.601119875907898,
            "answer": "indeed",
            "hit": false
          },
          {
            "score": 0.5994495749473572,
            "answer": "actually",
            "hit": false
          },
          {
            "score": 0.5927752256393433,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.5922878980636597,
            "answer": "truths",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6962565183639526
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.6910271048545837,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.6357706189155579,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.6318550109863281,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.6295192241668701,
            "answer": "friendly",
            "hit": false
          },
          {
            "score": 0.6062905788421631,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.6029032468795776,
            "answer": "cousin",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6910271048545837
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7755513191223145,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.6897475719451904,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.6886335611343384,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.634661853313446,
            "answer": "heaven",
            "hit": false
          },
          {
            "score": 0.6240679025650024,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.6209200620651245,
            "answer": "allah",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7755512893199921
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.7607026100158691,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.6908048987388611,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.6458722352981567,
            "answer": "authorities",
            "hit": false
          },
          {
            "score": 0.6268414258956909,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6245409846305847,
            "answer": "commonwealth",
            "hit": false
          },
          {
            "score": 0.6245256662368774,
            "answer": "officials",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7607026696205139
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.802590012550354,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.6617671251296997,
            "answer": "minutes",
            "hit": false
          },
          {
            "score": 0.6525364518165588,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.6466453671455383,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.6296118497848511,
            "answer": "nights",
            "hit": false
          },
          {
            "score": 0.6293335556983948,
            "answer": "weeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8025899529457092
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.6570299863815308,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.6334248781204224,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.6202573180198669,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.606680691242218,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.5946958065032959,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.5890086889266968,
            "answer": "ideals",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6570299714803696
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.8392231464385986,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.6822298765182495,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.6482683420181274,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.6435627937316895,
            "answer": "terminology",
            "hit": false
          },
          {
            "score": 0.6277844905853271,
            "answer": "dialect",
            "hit": false
          },
          {
            "score": 0.6249105334281921,
            "answer": "grammar",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8392231464385986
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.6553131937980652,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.6033065915107727,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.5988330245018005,
            "answer": "statutes",
            "hit": false
          },
          {
            "score": 0.5952521562576294,
            "answer": "lawsuits",
            "hit": false
          },
          {
            "score": 0.5934069752693176,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.5923106074333191,
            "answer": "courts",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6553131937980652
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.7346399426460266,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.6360733509063721,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.6003249287605286,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.5874439477920532,
            "answer": "governments",
            "hit": false
          },
          {
            "score": 0.5853923559188843,
            "answer": "citizens",
            "hit": false
          },
          {
            "score": 0.5842483043670654,
            "answer": "teammates",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.734639972448349
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8005321025848389,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.7075292468070984,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.6926512122154236,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.6582071185112,
            "answer": "hour",
            "hit": false
          },
          {
            "score": 0.6458774209022522,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.635289192199707,
            "answer": "hours",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8005321025848389
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.7249677181243896,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.6532571315765381,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.6531760692596436,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.6464362144470215,
            "answer": "tonight",
            "hit": false
          },
          {
            "score": 0.637021005153656,
            "answer": "midnight",
            "hit": false
          },
          {
            "score": 0.6211975812911987,
            "answer": "dusk",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7249677181243896
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7367062568664551,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.6177420616149902,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.6087310314178467,
            "answer": "headquarters",
            "hit": false
          },
          {
            "score": 0.5992885828018188,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.5984171628952026,
            "answer": "deputies",
            "hit": false
          },
          {
            "score": 0.596576452255249,
            "answer": "ministry",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7367062568664551
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.7933173775672913,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.6095362305641174,
            "answer": "periodic",
            "hit": false
          },
          {
            "score": 0.6086028814315796,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.6037237644195557,
            "answer": "periodically",
            "hit": false
          },
          {
            "score": 0.5995811820030212,
            "answer": "intervals",
            "hit": false
          },
          {
            "score": 0.598740816116333,
            "answer": "years",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7933173775672913
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.7296130061149597,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.6745216846466064,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.6712011098861694,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.6500436067581177,
            "answer": "plays",
            "hit": false
          },
          {
            "score": 0.6384660601615906,
            "answer": "footballer",
            "hit": false
          },
          {
            "score": 0.6322494745254517,
            "answer": "teammates",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7296129763126373
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.7229831218719482,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.64238041639328,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.6195615530014038,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.6190433502197266,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.6160417795181274,
            "answer": "populated",
            "hit": false
          },
          {
            "score": 0.6099575757980347,
            "answer": "individuals",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7229831665754318
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.7284108996391296,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.6462104916572571,
            "answer": "problematic",
            "hit": false
          },
          {
            "score": 0.6258813738822937,
            "answer": "trouble",
            "hit": false
          },
          {
            "score": 0.6179400086402893,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.6164261698722839,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.6163926124572754,
            "answer": "worries",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7284108996391296
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.7654582858085632,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.6385470628738403,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6164299249649048,
            "answer": "merchandise",
            "hit": false
          },
          {
            "score": 0.6150828003883362,
            "answer": "devices",
            "hit": false
          },
          {
            "score": 0.6117681264877319,
            "answer": "components",
            "hit": false
          },
          {
            "score": 0.6096845865249634,
            "answer": "consumers",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7654582858085632
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.7186864614486694,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.5909480452537537,
            "answer": "response",
            "hit": false
          },
          {
            "score": 0.5883134007453918,
            "answer": "service",
            "hit": false
          },
          {
            "score": 0.5865126252174377,
            "answer": "reserves",
            "hit": false
          },
          {
            "score": 0.5849425792694092,
            "answer": "providers",
            "hit": false
          },
          {
            "score": 0.5843506455421448,
            "answer": "assets",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7186864465475082
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.6495954394340515,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.640251636505127,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.6376633644104004,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.6366287469863892,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6291128396987915,
            "answer": "streams",
            "hit": false
          },
          {
            "score": 0.6266580820083618,
            "answer": "pond",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6495954394340515
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.6962041854858398,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.6376906037330627,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.6228095889091492,
            "answer": "streets",
            "hit": false
          },
          {
            "score": 0.6178903579711914,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.6074534058570862,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.603850781917572,
            "answer": "railroad",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6962041705846786
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.7605934143066406,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.59546959400177,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.5937813520431519,
            "answer": "functions",
            "hit": false
          },
          {
            "score": 0.5933525562286377,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.5909718871116638,
            "answer": "status",
            "hit": false
          },
          {
            "score": 0.5888963341712952,
            "answer": "importance",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7605934143066406
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.6988503932952881,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.6845360994338989,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.6551430225372314,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6472882032394409,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.6273928880691528,
            "answer": "astronomy",
            "hit": false
          },
          {
            "score": 0.6214045882225037,
            "answer": "physics",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6988503634929657
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.8019185066223145,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.675093948841095,
            "answer": "solving",
            "hit": false
          },
          {
            "score": 0.6654007434844971,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.6046152114868164,
            "answer": "answer",
            "hit": false
          },
          {
            "score": 0.6024670600891113,
            "answer": "dissolved",
            "hit": false
          },
          {
            "score": 0.6022493243217468,
            "answer": "alternatives",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8019185066223145
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.7085956335067749,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.6298506259918213,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.6161497235298157,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.6103548407554626,
            "answer": "melody",
            "hit": false
          },
          {
            "score": 0.608477771282196,
            "answer": "albums",
            "hit": false
          },
          {
            "score": 0.6052823066711426,
            "answer": "singers",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7085956633090973
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.7399247884750366,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.628353476524353,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.6164775490760803,
            "answer": "pavement",
            "hit": false
          },
          {
            "score": 0.6082077622413635,
            "answer": "road",
            "hit": false
          },
          {
            "score": 0.6020981073379517,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.6015129089355469,
            "answer": "neighborhood",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7399247288703918
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.7707217931747437,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.6484400033950806,
            "answer": "classmates",
            "hit": false
          },
          {
            "score": 0.6270913481712341,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.6220813989639282,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6185863614082336,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.6174631118774414,
            "answer": "educational",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7707217931747437
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.6366955637931824,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.5831310749053955,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.5829595327377319,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.582524299621582,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.5802019238471985,
            "answer": "platforms",
            "hit": false
          },
          {
            "score": 0.5780981779098511,
            "answer": "organizations",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6366955637931824
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.6828563213348389,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.5956810712814331,
            "answer": "everything",
            "hit": false
          },
          {
            "score": 0.5945205092430115,
            "answer": "nothing",
            "hit": false
          },
          {
            "score": 0.5875387787818909,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.5831725001335144,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.5810246467590332,
            "answer": "toys",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6828563511371613
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.7066859602928162,
            "answer": "towns",
            "hit": true
          },
          {
            "score": 0.6278598308563232,
            "answer": "borough",
            "hit": false
          },
          {
            "score": 0.624239444732666,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.6065565347671509,
            "answer": "downtown",
            "hit": false
          },
          {
            "score": 0.6060801148414612,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.6008370518684387,
            "answer": "hometown",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.706685945391655
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7247528433799744,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.6195010542869568,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.6192945837974548,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6019260883331299,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.5999313592910767,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.5957258343696594,
            "answer": "player",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7247528731822968
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.666195273399353,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.6442462801933289,
            "answer": "edition",
            "hit": false
          },
          {
            "score": 0.6433151960372925,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.6403568983078003,
            "answer": "variant",
            "hit": false
          },
          {
            "score": 0.6346715688705444,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.6223936676979065,
            "answer": "copies",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6661953032016754
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.6862572431564331,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.6540274620056152,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.6303970813751221,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6227024793624878,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.6159959435462952,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.6105160713195801,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6862572431564331
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.6774306297302246,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.5982303619384766,
            "answer": "site",
            "hit": false
          },
          {
            "score": 0.59730064868927,
            "answer": "blogs",
            "hit": false
          },
          {
            "score": 0.5927402377128601,
            "answer": "sites",
            "hit": false
          },
          {
            "score": 0.5923851132392883,
            "answer": "forums",
            "hit": false
          },
          {
            "score": 0.5884566903114319,
            "answer": "blogger",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6774305999279022
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.671450674533844,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.6499034762382507,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.6271520853042603,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.617927074432373,
            "answer": "weekends",
            "hit": false
          },
          {
            "score": 0.6169734001159668,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.6094218492507935,
            "answer": "hours",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.671450674533844
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7440754175186157,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7099454402923584,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.6853455305099487,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.6692639589309692,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6624657511711121,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.6531897783279419,
            "answer": "weeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7440754026174545
      }
    ],
    "result": {
      "cnt_questions_correct": 48,
      "cnt_questions_total": 50,
      "accuracy": 0.96
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "42e49564-b469-49db-92f8-f818585342d9",
      "timestamp": "2025-05-17T21:30:05.583863"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.7055391073226929,
            "answer": "able",
            "hit": false
          },
          {
            "score": 0.6399095058441162,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6169661283493042,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.6097850799560547,
            "answer": "probability",
            "hit": false
          },
          {
            "score": 0.6066837906837463,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.6048374176025391,
            "answer": "consistency",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6066838130354881
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.70549476146698,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.6251850724220276,
            "answer": "fragment",
            "hit": false
          },
          {
            "score": 0.5944502353668213,
            "answer": "participation",
            "hit": false
          },
          {
            "score": 0.5936548113822937,
            "answer": "behaviour",
            "hit": false
          },
          {
            "score": 0.5925677418708801,
            "answer": "active",
            "hit": false
          },
          {
            "score": 0.5889623761177063,
            "answer": "behaviors",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.70549476146698
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.7649127244949341,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.6068088412284851,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.6051986813545227,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.6021387577056885,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.600723147392273,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.5991960167884827,
            "answer": "commissioners",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7649127244949341
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.8797183036804199,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.779086172580719,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.7647473216056824,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7619379162788391,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.6633114814758301,
            "answer": "analysts",
            "hit": false
          },
          {
            "score": 0.6492180824279785,
            "answer": "analytical",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8797182738780975
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8382593989372253,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.7189009785652161,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.714419960975647,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7135546803474426,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.684456467628479,
            "answer": "cavalry",
            "hit": false
          },
          {
            "score": 0.6573046445846558,
            "answer": "generals",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8382593989372253
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7050716280937195,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.6570147275924683,
            "answer": "authorized",
            "hit": false
          },
          {
            "score": 0.6495729684829712,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.6426383256912231,
            "answer": "jurisdiction",
            "hit": false
          },
          {
            "score": 0.6313419938087463,
            "answer": "authorization",
            "hit": false
          },
          {
            "score": 0.6244403123855591,
            "answer": "agencies",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7050716280937195
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7188526391983032,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.6319149732589722,
            "answer": "grounds",
            "hit": false
          },
          {
            "score": 0.6127260327339172,
            "answer": "foundations",
            "hit": false
          },
          {
            "score": 0.6064426302909851,
            "answer": "based",
            "hit": false
          },
          {
            "score": 0.5957362055778503,
            "answer": "origins",
            "hit": false
          },
          {
            "score": 0.5950020551681519,
            "answer": "generators",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.718852624297142
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.7663238048553467,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.6475085616111755,
            "answer": "enterprise",
            "hit": false
          },
          {
            "score": 0.6449098587036133,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.6405774354934692,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.6348766684532166,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.6338872313499451,
            "answer": "businessman",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7663238644599915
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.6650834083557129,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.6578568816184998,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.6248151659965515,
            "answer": "classification",
            "hit": false
          },
          {
            "score": 0.6205822229385376,
            "answer": "groups",
            "hit": false
          },
          {
            "score": 0.6149895191192627,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.6083285808563232,
            "answer": "industries",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6650834381580353
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.7536537051200867,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.6799442768096924,
            "answer": "medieval",
            "hit": false
          },
          {
            "score": 0.6675498485565186,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.6505136489868164,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6468087434768677,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.625455379486084,
            "answer": "renaissance",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7536537051200867
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.7009709477424622,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.6314494609832764,
            "answer": "childhood",
            "hit": false
          },
          {
            "score": 0.6272175908088684,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.6218991875648499,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6180500388145447,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.6118889451026917,
            "answer": "adolescents",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7009709179401398
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.6742773056030273,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.6315300464630127,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.631177544593811,
            "answer": "towns",
            "hit": false
          },
          {
            "score": 0.6264112591743469,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6252192854881287,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.6094827651977539,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6742773056030273
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.8692335486412048,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.6285859942436218,
            "answer": "ecosystem",
            "hit": false
          },
          {
            "score": 0.622544527053833,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.6221098899841309,
            "answer": "residents",
            "hit": false
          },
          {
            "score": 0.6205376386642456,
            "answer": "societies",
            "hit": false
          },
          {
            "score": 0.6176176071166992,
            "answer": "communal",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8692335486412048
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.7106640338897705,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.6582701802253723,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.6403942108154297,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.6200385093688965,
            "answer": "countryside",
            "hit": false
          },
          {
            "score": 0.6190797090530396,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6091243028640747,
            "answer": "districts",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7106640636920929
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8010677695274353,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.637175977230072,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6309766173362732,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.6281969547271729,
            "answer": "provinces",
            "hit": false
          },
          {
            "score": 0.6258660554885864,
            "answer": "districts",
            "hit": false
          },
          {
            "score": 0.6189091205596924,
            "answer": "township",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8010677695274353
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7752523422241211,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.6624748706817627,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6403031349182129,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6376821994781494,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.6005440950393677,
            "answer": "liability",
            "hit": false
          },
          {
            "score": 0.6002706289291382,
            "answer": "responsibility",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7752523422241211
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.8158891201019287,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.6671743392944336,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6628806591033936,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.6615114808082581,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.659038245677948,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.6479873657226562,
            "answer": "recession",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8158891499042511
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8659060001373291,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7171493768692017,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.6541391611099243,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.6380428075790405,
            "answer": "momentum",
            "hit": false
          },
          {
            "score": 0.6312282681465149,
            "answer": "fuels",
            "hit": false
          },
          {
            "score": 0.613821804523468,
            "answer": "electrons",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8659060299396515
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.609626829624176,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.5787782669067383,
            "answer": "info",
            "hit": false
          },
          {
            "score": 0.5768265128135681,
            "answer": "entered",
            "hit": false
          },
          {
            "score": 0.5725900530815125,
            "answer": "elders",
            "hit": false
          },
          {
            "score": 0.5710737109184265,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.5698279142379761,
            "answer": "hunters",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.609626829624176
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.8727431297302246,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.6374601125717163,
            "answer": "buildings",
            "hit": false
          },
          {
            "score": 0.6249186396598816,
            "answer": "hospitals",
            "hit": false
          },
          {
            "score": 0.6241694092750549,
            "answer": "institution",
            "hit": false
          },
          {
            "score": 0.6197583675384521,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.6192121505737305,
            "answer": "centres",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.872743159532547
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.7080696225166321,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.6615942716598511,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.621633768081665,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.6135350465774536,
            "answer": "women",
            "hit": false
          },
          {
            "score": 0.6113182902336121,
            "answer": "parent",
            "hit": false
          },
          {
            "score": 0.6100923418998718,
            "answer": "households",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7080696523189545
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8142334818840027,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.6878829002380371,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.6782203912734985,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6691523194313049,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.654194712638855,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.6350833773612976,
            "answer": "traditions",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8142335116863251
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.8099518418312073,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.689233660697937,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.6622865200042725,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.6603723764419556,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.6325191259384155,
            "answer": "profession",
            "hit": false
          },
          {
            "score": 0.6304162740707397,
            "answer": "technologies",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8099518418312073
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.7702599763870239,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.6142299771308899,
            "answer": "archives",
            "hit": false
          },
          {
            "score": 0.6063641905784607,
            "answer": "museums",
            "hit": false
          },
          {
            "score": 0.6002274751663208,
            "answer": "laboratories",
            "hit": false
          },
          {
            "score": 0.597489058971405,
            "answer": "manuscripts",
            "hit": false
          },
          {
            "score": 0.5933499336242676,
            "answer": "museum",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7702600061893463
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.6494441032409668,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.6355365514755249,
            "answer": "lived",
            "hit": false
          },
          {
            "score": 0.6341527700424194,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.6315822601318359,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.6287916898727417,
            "answer": "live",
            "hit": false
          },
          {
            "score": 0.6202646493911743,
            "answer": "civilization",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6341527998447418
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.7636956572532654,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.6723949909210205,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.6583975553512573,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.656557559967041,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.6103193163871765,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6061272025108337,
            "answer": "gains",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7636956572532654
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.7136059999465942,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.6180242300033569,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6177721619606018,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.6033192276954651,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.5933740139007568,
            "answer": "ram",
            "hit": false
          },
          {
            "score": 0.5929388999938965,
            "answer": "storage",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7136059999465942
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8769532442092896,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.6567962765693665,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.6419774293899536,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.6359856724739075,
            "answer": "occasions",
            "hit": false
          },
          {
            "score": 0.6272026896476746,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.6257451772689819,
            "answer": "initiatives",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8769532740116119
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.7411065101623535,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.6062876582145691,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.6030412316322327,
            "answer": "guidelines",
            "hit": false
          },
          {
            "score": 0.5990311503410339,
            "answer": "practices",
            "hit": false
          },
          {
            "score": 0.5964844822883606,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.5946515798568726,
            "answer": "protocols",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7411065250635147
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.6835146546363831,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.5904942750930786,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.5882475972175598,
            "answer": "parameters",
            "hit": false
          },
          {
            "score": 0.5881140828132629,
            "answer": "parameter",
            "hit": false
          },
          {
            "score": 0.5864309072494507,
            "answer": "relationships",
            "hit": false
          },
          {
            "score": 0.5846824645996094,
            "answer": "benefits",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6835146844387054
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8175886869430542,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7353591918945312,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.6839670538902283,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.68283611536026,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6688473224639893,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.6441183686256409,
            "answer": "duties",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8175887167453766
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.6128565669059753,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.6074348092079163,
            "answer": "vulnerability",
            "hit": false
          },
          {
            "score": 0.6058868169784546,
            "answer": "authentication",
            "hit": false
          },
          {
            "score": 0.6037830114364624,
            "answer": "safety",
            "hit": false
          },
          {
            "score": 0.6031914949417114,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.6004159450531006,
            "answer": "surveillance",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 119,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5684886202216148
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.6670554876327515,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.6169329881668091,
            "answer": "films",
            "hit": false
          },
          {
            "score": 0.6090699434280396,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.6082954406738281,
            "answer": "thriller",
            "hit": false
          },
          {
            "score": 0.60728919506073,
            "answer": "programmes",
            "hit": false
          },
          {
            "score": 0.6037490963935852,
            "answer": "show",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9835384488105774
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.7036126852035522,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.6804683208465576,
            "answer": "association",
            "hit": false
          },
          {
            "score": 0.6259902715682983,
            "answer": "organisations",
            "hit": false
          },
          {
            "score": 0.6248412132263184,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.6176414489746094,
            "answer": "federation",
            "hit": false
          },
          {
            "score": 0.6104094386100769,
            "answer": "committees",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.703612670302391
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.6531858444213867,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.6475874781608582,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.6459953784942627,
            "answer": "specimens",
            "hit": false
          },
          {
            "score": 0.6428411602973938,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.6358476281166077,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.6331208944320679,
            "answer": "ecosystems",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9838976263999939
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.8672356605529785,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7395191192626953,
            "answer": "tale",
            "hit": false
          },
          {
            "score": 0.7073342204093933,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.6934565305709839,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.6889382600784302,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.6815165877342224,
            "answer": "storytelling",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8672356903553009
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.7357351183891296,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.6241879463195801,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.6175864934921265,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.6047543287277222,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.6025711297988892,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.6010787487030029,
            "answer": "technologies",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7357351183891296
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7049360275268555,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.6890202760696411,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.6569867730140686,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6534585952758789,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.6462197303771973,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.6330060362815857,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6890202760696411
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.7415026426315308,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.6861618757247925,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.6367545127868652,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.6321032047271729,
            "answer": "techniques",
            "hit": false
          },
          {
            "score": 0.6201784014701843,
            "answer": "telecommunications",
            "hit": false
          },
          {
            "score": 0.6200606822967529,
            "answer": "industries",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7415026128292084
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.6927503347396851,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.6258877515792847,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.6025043725967407,
            "answer": "theoretically",
            "hit": false
          },
          {
            "score": 0.6003769636154175,
            "answer": "technologies",
            "hit": false
          },
          {
            "score": 0.5960415601730347,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.5912511348724365,
            "answer": "doctrines",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6927503198385239
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.7483833432197571,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.655340850353241,
            "answer": "institute",
            "hit": false
          },
          {
            "score": 0.6299995183944702,
            "answer": "harvard",
            "hit": false
          },
          {
            "score": 0.6299357414245605,
            "answer": "college",
            "hit": false
          },
          {
            "score": 0.6262357831001282,
            "answer": "institutes",
            "hit": false
          },
          {
            "score": 0.6246004104614258,
            "answer": "undergraduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7483833283185959
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.818155825138092,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.6758722066879272,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.66773521900177,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.6522666215896606,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.6301948428153992,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.6251646876335144,
            "answer": "varied",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.818155825138092
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.7252845764160156,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.6499439477920532,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.646169900894165,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.6437015533447266,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6370102763175964,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.628643810749054,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7252845913171768
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.6923006772994995,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.6578829288482666,
            "answer": "man",
            "hit": false
          },
          {
            "score": 0.6496546864509583,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6466512680053711,
            "answer": "oman",
            "hit": false
          },
          {
            "score": 0.627898097038269,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.627678632736206,
            "answer": "ladies",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6923006772994995
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 44,
      "accuracy": 0.8636363636363636
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b5f1a988-8b33-4d99-a33a-0322eb04a8df",
      "timestamp": "2025-05-17T21:30:05.802700"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.7864154577255249,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.7060650587081909,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.6719203591346741,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6639010906219482,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.6581916213035583,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.655756950378418,
            "answer": "stronger",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7864154279232025
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.6983707547187805,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.670262336730957,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6656280755996704,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6597813367843628,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.6427998542785645,
            "answer": "cheaper",
            "hit": false
          },
          {
            "score": 0.6312502026557922,
            "answer": "brighter",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6983707547187805
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.7747247219085693,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.7332377433776855,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7043324112892151,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6738928556442261,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.6595155596733093,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6565729379653931,
            "answer": "strengthen",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7747247219085693
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.7421337366104126,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.7239036560058594,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6564033627510071,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6431289911270142,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.6418113708496094,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.636084258556366,
            "answer": "softer",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7421337366104126
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1e122724-6ac6-452d-ad16-f812f1b33edd",
      "timestamp": "2025-05-17T21:30:06.000114"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7245187759399414,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6760677099227905,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.6123875975608826,
            "answer": "fastest",
            "hit": false
          },
          {
            "score": 0.5999190807342529,
            "answer": "lowest",
            "hit": false
          },
          {
            "score": 0.5995736122131348,
            "answer": "easiest",
            "hit": false
          },
          {
            "score": 0.5973361730575562,
            "answer": "brightest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6760677248239517
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.7414548397064209,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.6945282220840454,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.6656420230865479,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6462804079055786,
            "answer": "strongly",
            "hit": false
          },
          {
            "score": 0.621870756149292,
            "answer": "powerful",
            "hit": false
          },
          {
            "score": 0.6202596426010132,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6945282369852066
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "31d39ca8-3f96-4ba3-a4ba-5fc2b4dc4de5",
      "timestamp": "2025-05-17T21:30:06.015633"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.7206711769104004,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.7060476541519165,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7047455310821533,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.6768300533294678,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6017436385154724,
            "answer": "acknowledged",
            "hit": false
          },
          {
            "score": 0.5994150042533875,
            "answer": "acknowledges",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7206712067127228
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7189643383026123,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.696792721748352,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6488127708435059,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6078283786773682,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.6065974235534668,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6012881994247437,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7189643085002899
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.7764098048210144,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.7588626146316528,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7409793734550476,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7223517894744873,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.6982719898223877,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6411471366882324,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.776409775018692
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.7585606575012207,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.7011047601699829,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.682827353477478,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6462084054946899,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6243758201599121,
            "answer": "allowance",
            "hit": false
          },
          {
            "score": 0.6189894676208496,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7585605978965759
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.9104475378990173,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.8561070561408997,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8211382627487183,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7334862351417542,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6810130476951599,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.679113507270813,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9104475975036621
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8705885410308838,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8521095514297485,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6828083992004395,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6758641004562378,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6360065340995789,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.629288911819458,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870588481426239
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7326224446296692,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7275333404541016,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6161929368972778,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6152573823928833,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6121023893356323,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.6084861159324646,
            "answer": "requires",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6121024042367935
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8865370154380798,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.8651631474494934,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8242641687393188,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.6875799298286438,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.6797106266021729,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6538226008415222,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8865370452404022
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8955931067466736,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.8786847591400146,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8533756732940674,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6600483059883118,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6475584506988525,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6463971138000488,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.895593136548996
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.7218450903892517,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.6921020746231079,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.691026508808136,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6378347873687744,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.620130181312561,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6181305050849915,
            "answer": "beliefs",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7218451350927353
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8536362648010254,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7563836574554443,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7073338627815247,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.674757719039917,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6423923969268799,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.632146418094635,
            "answer": "examines",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8536362648010254
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.6571016311645508,
            "answer": "consistency",
            "hit": false
          },
          {
            "score": 0.6394256353378296,
            "answer": "consistently",
            "hit": false
          },
          {
            "score": 0.6338567733764648,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.6328796744346619,
            "answer": "inconsistent",
            "hit": false
          },
          {
            "score": 0.6210618019104004,
            "answer": "consistent",
            "hit": false
          },
          {
            "score": 0.6162251830101013,
            "answer": "consisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6338567733764648
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8293612003326416,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8022736310958862,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6939728856086731,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.68526291847229,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.658458948135376,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6568824648857117,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6852629333734512
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.7255589962005615,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.6779817342758179,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.661474347114563,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6257542371749878,
            "answer": "return",
            "hit": false
          },
          {
            "score": 0.6217963695526123,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.6070138216018677,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7255589962005615
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.6672882437705994,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.6393309831619263,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.5946985483169556,
            "answer": "destroys",
            "hit": false
          },
          {
            "score": 0.5912351012229919,
            "answer": "select",
            "hit": false
          },
          {
            "score": 0.5906870365142822,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.5881421566009521,
            "answer": "sql",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6672882288694382
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.6497739553451538,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.6286129355430603,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6092195510864258,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.6081160306930542,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.5997664332389832,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.5932683944702148,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.649773895740509
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8779408931732178,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8471522331237793,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8359615206718445,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6877652406692505,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6630107164382935,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6416239738464355,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8779408931732178
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.872871994972229,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8345153331756592,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8184056282043457,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.678338885307312,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6380165219306946,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6345398426055908,
            "answer": "allowed",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8728720247745514
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.8722007870674133,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.8421030640602112,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.8396266102790833,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6906571388244629,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.683733344078064,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6628473997116089,
            "answer": "loves",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8722007870674133
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.668385922908783,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.6658631563186646,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.6389585733413696,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.607808530330658,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.5980520844459534,
            "answer": "guarantees",
            "hit": false
          },
          {
            "score": 0.5929780006408691,
            "answer": "requires",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6683858931064606
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.693081259727478,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6782015562057495,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6561912894248962,
            "answer": "existing",
            "hit": false
          },
          {
            "score": 0.6503180861473083,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.6289587020874023,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.62361079454422,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6503181010484695
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8672383427619934,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8587859869003296,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8414099216461182,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7624221444129944,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7361471056938171,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.664535403251648,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8672383427619934
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7571558952331543,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7466713190078735,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.6438398361206055,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6075448989868164,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.603990912437439,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.6011821031570435,
            "answer": "pursued",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7466713637113571
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8839163184165955,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.846983015537262,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7821479439735413,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7133809328079224,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7032124996185303,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6807045340538025,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8839163184165955
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8480704426765442,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.838912844657898,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7224732637405396,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6635309457778931,
            "answer": "see",
            "hit": false
          },
          {
            "score": 0.653412938117981,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.6468678712844849,
            "answer": "sounds",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.848070502281189
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.8762459754943848,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8561273217201233,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7225149869918823,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7073332667350769,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6644758582115173,
            "answer": "recognizes",
            "hit": false
          },
          {
            "score": 0.6556847095489502,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8762460052967072
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.767989993095398,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.7627217769622803,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7603991627693176,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7543238401412964,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.717585563659668,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6430832743644714,
            "answer": "increases",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7679900527000427
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.6910200715065002,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6298614740371704,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.6208981275558472,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6073838472366333,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.6065313816070557,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6033535003662109,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6910201013088226
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9165706634521484,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8250023126602173,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7852423191070557,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.6887731552124023,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6817619800567627,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6719057559967041,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9165706634521484
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7147545218467712,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.700265645980835,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.6910272836685181,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6618375778198242,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6491336822509766,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6258057951927185,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7147545218467712
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.8897557258605957,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8699016571044922,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8453953266143799,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7134420871734619,
            "answer": "maintenance",
            "hit": false
          },
          {
            "score": 0.6597585678100586,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.6406744718551636,
            "answer": "keeping",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8699016571044922
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9244768619537354,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8217120170593262,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8002920150756836,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7125813364982605,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.6877230405807495,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.6757403016090393,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.924476832151413
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8994348645210266,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7216961979866028,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.6785641312599182,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.6473547220230103,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6396565437316895,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6348910927772522,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.899434894323349
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.7285265922546387,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.7237250804901123,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7010646462440491,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.6796026825904846,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.6415531635284424,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.6279293298721313,
            "answer": "avoids",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7285266667604446
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9065349102020264,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8964877724647522,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8143638968467712,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7367249131202698,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6845883131027222,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.6839767694473267,
            "answer": "promotions",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9065349400043488
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.7441130876541138,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7418996691703796,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.6732302904129028,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.652313768863678,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.6405635476112366,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.6305244565010071,
            "answer": "protector",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7418996691703796
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.7613538503646851,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.7315223217010498,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6911442279815674,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6260055303573608,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6259527802467346,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.6245788335800171,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7613538503646851
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.7446778416633606,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.7209477424621582,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7205121517181396,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6088342666625977,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6063385009765625,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.604512095451355,
            "answer": "observes",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7446778863668442
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.6843855977058411,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.6579517126083374,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.6520423889160156,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.6406456232070923,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6375666856765747,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6065207719802856,
            "answer": "replaces",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6843855977058411
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8246976733207703,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.788652241230011,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7779582738876343,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6256789565086365,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6093261241912842,
            "answer": "denote",
            "hit": false
          },
          {
            "score": 0.606512188911438,
            "answer": "referenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8246976733207703
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8691843152046204,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8471795916557312,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7162501215934753,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6961737871170044,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6611477732658386,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.6605454683303833,
            "answer": "continues",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.869184285402298
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.7484825849533081,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7476335167884827,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7315934896469116,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.6574909687042236,
            "answer": "forgetting",
            "hit": false
          },
          {
            "score": 0.6564993858337402,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.6519158482551575,
            "answer": "forget",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7476335167884827
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.7447915077209473,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7287376523017883,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7270481586456299,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7217620611190796,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7169403433799744,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.6199319362640381,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7169403433799744
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7182830572128296,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.717025637626648,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.70655357837677,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6988948583602905,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.625758171081543,
            "answer": "needs",
            "hit": false
          },
          {
            "score": 0.620058536529541,
            "answer": "needing",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7170256227254868
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8482125997543335,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7639116644859314,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.7569347620010376,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7409281730651855,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7369974851608276,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6958824396133423,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7639116644859314
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.8789834976196289,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8705491423606873,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.6582430601119995,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.6420928239822388,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6255468130111694,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.624801516532898,
            "answer": "transmit",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8705491423606873
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.6723001599311829,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.6676931381225586,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.6632606983184814,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.6591651439666748,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.6553812623023987,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.6369622945785522,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6632607281208038
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8348056674003601,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.787529468536377,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7181491255760193,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6517300009727478,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.6485763788223267,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6448928117752075,
            "answer": "say",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8348057270050049
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.854155421257019,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.838651716709137,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.756447970867157,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7307958006858826,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.6686962842941284,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.6592440605163574,
            "answer": "misunderstanding",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.854155421257019
      }
    ],
    "result": {
      "cnt_questions_correct": 36,
      "cnt_questions_total": 49,
      "accuracy": 0.7346938775510204
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "cc482d46-c640-4d90-884a-ea5f72901a1c",
      "timestamp": "2025-05-17T21:30:06.024002"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9156386852264404,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.8500587344169617,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7299301624298096,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7019668221473694,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.69138503074646,
            "answer": "achievement",
            "hit": false
          },
          {
            "score": 0.689446210861206,
            "answer": "attained",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9156386256217957
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7135010361671448,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.6906312108039856,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6546351313591003,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6147087812423706,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6038005948066711,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.5973911285400391,
            "answer": "additions",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.713501051068306
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.7461127042770386,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7128276228904724,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.67265385389328,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6251741647720337,
            "answer": "allowance",
            "hit": false
          },
          {
            "score": 0.6205832958221436,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.6179912686347961,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7128276228904724
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8855613470077515,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8541964292526245,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8515847325325012,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.7254900932312012,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6895976066589355,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.6757745742797852,
            "answer": "seemed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8515847027301788
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.8792918920516968,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.8474389314651489,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6920984983444214,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6851497292518616,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6382110714912415,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6233447790145874,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8792919218540192
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.7502822875976562,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7216563820838928,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6165645122528076,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6085394620895386,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6073509454727173,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.607026994228363,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7502822875976562
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8863159418106079,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8469263315200806,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.6791496872901917,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6727145910263062,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6383826732635498,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6158108711242676,
            "answer": "visiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8863159120082855
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.8891662359237671,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.8676637411117554,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.8317887187004089,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7014819979667664,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.6789903044700623,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6496573686599731,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8891662657260895
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.8759945034980774,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.8718768954277039,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8706514835357666,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.6469603776931763,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.634807825088501,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6334216594696045,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8759944438934326
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.7103104591369629,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.6987283825874329,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6907651424407959,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.6402097940444946,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6168789267539978,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.605744481086731,
            "answer": "disbelief",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7103104889392853
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.8339353799819946,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.765197217464447,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.7230878472328186,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.6937838792800903,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.636620819568634,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.628801167011261,
            "answer": "discussed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7230878174304962
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8536010980606079,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.808286726474762,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6789836883544922,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.6619710922241211,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6538065671920776,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6412217617034912,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8536010682582855
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.7036161422729492,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7021012306213379,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.6680495738983154,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6276441812515259,
            "answer": "return",
            "hit": false
          },
          {
            "score": 0.6170256733894348,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6144514679908752,
            "answer": "returning",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7021012008190155
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.6550658941268921,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.6324053406715393,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.5980060696601868,
            "answer": "select",
            "hit": false
          },
          {
            "score": 0.593738317489624,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.5857404470443726,
            "answer": "sql",
            "hit": false
          },
          {
            "score": 0.5841198563575745,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6550658643245697
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8647710680961609,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.8544803261756897,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8418477773666382,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7007797360420227,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6722899675369263,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6430025100708008,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8647710084915161
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8392536640167236,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7996910810470581,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.7983394265174866,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7214291095733643,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.7173110246658325,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.6675207614898682,
            "answer": "urging",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7996910810470581
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.8674594759941101,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.8587011098861694,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8462672829627991,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6986716389656067,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6976159811019897,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6371477842330933,
            "answer": "loves",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8674594461917877
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.6817854046821594,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.639130175113678,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.6301756501197815,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.6045387983322144,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.5992965698242188,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.5896996855735779,
            "answer": "determining",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817854195833206
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.9115869402885437,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8632070422172546,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8387699723243713,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.6994069814682007,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6653299331665039,
            "answer": "proving",
            "hit": false
          },
          {
            "score": 0.6577980518341064,
            "answer": "determining",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9115869700908661
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.7017017006874084,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6781250238418579,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.6688874959945679,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.637703537940979,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.6339032649993896,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.5935114026069641,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6781249940395355
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.7045203447341919,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.69537353515625,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.6859143376350403,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.665576159954071,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6646798849105835,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.5969942808151245,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7045203298330307
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.7547479271888733,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7173973321914673,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6494291424751282,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.6058400273323059,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6056278944015503,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.5967028141021729,
            "answer": "pursued",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6494291573762894
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8639300465583801,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8462711572647095,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7945705652236938,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.6826169490814209,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6764706969261169,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.6689774990081787,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7945705652236938
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.883686363697052,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8517009615898132,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7312867045402527,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7212894558906555,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6646259427070618,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.6572290062904358,
            "answer": "identifiable",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.883686363697052
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.7830890417098999,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.7605866193771362,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7513592839241028,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7365269660949707,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7276689410209656,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6308573484420776,
            "answer": "proved",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7830891013145447
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.6624183654785156,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6448076367378235,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.6268637776374817,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6215648651123047,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.6211673617362976,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.6207353472709656,
            "answer": "containing",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6448076367378235
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.893028736114502,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8492093682289124,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7924966812133789,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7016097903251648,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6481121778488159,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6411997675895691,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8492093682289124
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.7184348106384277,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.688439667224884,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6837122440338135,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.6634423732757568,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.6357870101928711,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.6251308917999268,
            "answer": "teaches",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7184348106384277
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.8790996074676514,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.8771668672561646,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.698838472366333,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.672029972076416,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.671552836894989,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6521010994911194,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8790996670722961
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9095165729522705,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8472157120704651,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8460928201675415,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7192060947418213,
            "answer": "maintenance",
            "hit": false
          },
          {
            "score": 0.6593581438064575,
            "answer": "keeping",
            "hit": false
          },
          {
            "score": 0.6521515846252441,
            "answer": "establishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9095165729522705
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8451772928237915,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.8400331735610962,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8389641642570496,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6748147010803223,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6454852223396301,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6309671401977539,
            "answer": "maintaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8451772928237915
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.880743682384491,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7437246441841125,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.6870642900466919,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.6575206518173218,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6469255685806274,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6284862756729126,
            "answer": "occurring",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7437246739864349
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.7449771165847778,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.7163336277008057,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.6977161765098572,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.6543951034545898,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6356327533721924,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6335134506225586,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.744977131485939
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.7441291809082031,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.6979987025260925,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6926524639129639,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.6838517189025879,
            "answer": "prevention",
            "hit": false
          },
          {
            "score": 0.632746696472168,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.6242179274559021,
            "answer": "prohibiting",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7441291958093643
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9213472604751587,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8850364089012146,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8112636208534241,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7463901042938232,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6852549314498901,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.6720720529556274,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9213472604751587
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.7641555070877075,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.7167160511016846,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.6790220737457275,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.6501507759094238,
            "answer": "protected",
            "hit": false
          },
          {
            "score": 0.6385614275932312,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.6354995369911194,
            "answer": "protector",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7641555070877075
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.7542089223861694,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.7322754263877869,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6967569589614868,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6297494173049927,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.628462553024292,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.6232078075408936,
            "answer": "establishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7542089819908142
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.7449830174446106,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.7202372550964355,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7176792025566101,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6217654943466187,
            "answer": "collecting",
            "hit": false
          },
          {
            "score": 0.6183689832687378,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.613111138343811,
            "answer": "accepting",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7449830174446106
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.6769213676452637,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.6516100764274597,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.6480976939201355,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6473299264907837,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.6411651372909546,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6081275343894958,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6769213378429413
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.8083749413490295,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.7975336313247681,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7799839377403259,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6245241165161133,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.611367404460907,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.60337233543396,
            "answer": "references",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8083750009536743
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8537864685058594,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.842707097530365,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.735651433467865,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.6819095611572266,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6766297817230225,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.6689277291297913,
            "answer": "becoming",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7356514632701874
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.7679935097694397,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.7287846207618713,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.7229382395744324,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.6750073432922363,
            "answer": "forgetting",
            "hit": false
          },
          {
            "score": 0.6535593867301941,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.6523295640945435,
            "answer": "recalling",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7679935097694397
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.7455537915229797,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.742601752281189,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7347286939620972,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7250688076019287,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.689294695854187,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.6288725137710571,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7426017224788666
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.721933901309967,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7199809551239014,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.7156786918640137,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6819356679916382,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6405131220817566,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6106890439987183,
            "answer": "required",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7199809849262238
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8474629521369934,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7789034843444824,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.753398060798645,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7323412299156189,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7044879198074341,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.7023286819458008,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.77890345454216
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.8474469184875488,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.833041250705719,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.6841319799423218,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6323391199111938,
            "answer": "seating",
            "hit": false
          },
          {
            "score": 0.623827338218689,
            "answer": "stood",
            "hit": false
          },
          {
            "score": 0.6236341595649719,
            "answer": "seats",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8474469184875488
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8825727701187134,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8786450624465942,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.8692604303359985,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.6889721155166626,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6735508441925049,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6296206712722778,
            "answer": "paying",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8692603707313538
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8624668121337891,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8584275245666504,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8459563255310059,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.6671358346939087,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6585238575935364,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.650930643081665,
            "answer": "instructor",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8459563255310059
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.803385853767395,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7840628623962402,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7425358891487122,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.6595721244812012,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.6442376375198364,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6359158754348755,
            "answer": "say",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7425358891487122
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8408055901527405,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.8377639055252075,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7566856145858765,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.750038743019104,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.6763868927955627,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.6579329967498779,
            "answer": "interpreting",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.750038743019104
      }
    ],
    "result": {
      "cnt_questions_correct": 31,
      "cnt_questions_total": 50,
      "accuracy": 0.62
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "af50541f-7843-464a-a231-93141da372fd",
      "timestamp": "2025-05-17T21:30:06.234210"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.7248619198799133,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.6928327083587646,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.6850183606147766,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.6823253631591797,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6154977083206177,
            "answer": "acknowledged",
            "hit": false
          },
          {
            "score": 0.6037687063217163,
            "answer": "acceptable",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7248619794845581
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.8961319327354431,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8707755208015442,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.7329583168029785,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7078943252563477,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7019548416137695,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.6988707184791565,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.870775580406189
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.6808667778968811,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6802767515182495,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6634091734886169,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6115777492523193,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.5978269577026367,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.5807344913482666,
            "answer": "additive",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6634091734886169
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.757232666015625,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7523899078369141,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7402672171592712,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7349856495857239,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7041376829147339,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6377982497215271,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7349856495857239
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.7507902979850769,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6926316022872925,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.6858898401260376,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6330953240394592,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6183132529258728,
            "answer": "allowance",
            "hit": false
          },
          {
            "score": 0.6034164428710938,
            "answer": "permit",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6926316022872925
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8566573262214661,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8529502153396606,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8471215963363647,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7606936693191528,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.720241367816925,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6518464088439941,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8529501557350159
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8881564140319824,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.8720220327377319,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8329415917396545,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7299137115478516,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6893725991249084,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.68402099609375,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8720220923423767
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8501710891723633,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8482544422149658,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6890095472335815,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6865600347518921,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6494700908660889,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.6178248524665833,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6494700610637665
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7383686304092407,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.7228237390518188,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.6256461143493652,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6029052138328552,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6011233925819397,
            "answer": "prompted",
            "hit": false
          },
          {
            "score": 0.5974133014678955,
            "answer": "begged",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7383686602115631
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8632750511169434,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.8581674695014954,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.6737412214279175,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6688133478164673,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.6354648470878601,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6220719814300537,
            "answer": "visited",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8581674993038177
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8820627331733704,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8682888746261597,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8515825271606445,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6592259407043457,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6405090093612671,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6374220848083496,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8820627629756927
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.7028801441192627,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.691594123840332,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6840437650680542,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6372429728507996,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6108555793762207,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6053453683853149,
            "answer": "disbelief",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7028801739215851
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8297094106674194,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7837696671485901,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7075187563896179,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6917563676834106,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6455765962600708,
            "answer": "discussed",
            "hit": false
          },
          {
            "score": 0.634178102016449,
            "answer": "contemplated",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7837696671485901
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7000195980072021,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6811151504516602,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6746630072593689,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.6241841912269592,
            "answer": "return",
            "hit": false
          },
          {
            "score": 0.6109406352043152,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6016685962677002,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6746630221605301
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.6220588684082031,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6192445755004883,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.5976101756095886,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.5908287763595581,
            "answer": "select",
            "hit": false
          },
          {
            "score": 0.5860391855239868,
            "answer": "sql",
            "hit": false
          },
          {
            "score": 0.5770136117935181,
            "answer": "populated",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5976101383566856
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8397619724273682,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8211303353309631,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.6988979578018188,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6814337372779846,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.6624248623847961,
            "answer": "decisions",
            "hit": false
          },
          {
            "score": 0.6564629673957825,
            "answer": "chooses",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5877475738525391
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.6228148341178894,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.6207273602485657,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6147288680076599,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6099836826324463,
            "answer": "description",
            "hit": false
          },
          {
            "score": 0.5930849313735962,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.5893145203590393,
            "answer": "testing",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6228148564696312
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8696384429931641,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8580077886581421,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8414170742034912,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7029361724853516,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6663110256195068,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6327259540557861,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8696385025978088
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.6881577372550964,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.682137131690979,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.6443835496902466,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.6386794447898865,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.6302804946899414,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.619088888168335,
            "answer": "uncovered",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6821371018886566
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.861902117729187,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.859829843044281,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8468602895736694,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7004401683807373,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6885997653007507,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6421657800674438,
            "answer": "loved",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.861902117729187
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.6487652063369751,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.6418185234069824,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.6287943720817566,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.5948805809020996,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.5886631608009338,
            "answer": "assured",
            "hit": false
          },
          {
            "score": 0.5886151194572449,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6418185532093048
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8860244750976562,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8620466589927673,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8578253984451294,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.6950674057006836,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6571074724197388,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6496835947036743,
            "answer": "demonstrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8578253984451294
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7103597521781921,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6832185387611389,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6828897595405579,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.6624211668968201,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.657680869102478,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6055045127868652,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7103597521781921
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.769443929195404,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7223826050758362,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6364078521728516,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6052588820457458,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.6052488088607788,
            "answer": "pursued",
            "hit": false
          },
          {
            "score": 0.6027381420135498,
            "answer": "follower",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7694439888000488
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8600531220436096,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8287733793258667,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7316365242004395,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6567056775093079,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6524292230606079,
            "answer": "see",
            "hit": false
          },
          {
            "score": 0.6443658471107483,
            "answer": "listening",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8600530624389648
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8541858196258545,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8510119915008545,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7456087470054626,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.7160310745239258,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6648790836334229,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.6417691111564636,
            "answer": "detected",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7456087321043015
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.7661428451538086,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7621393203735352,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7547113299369812,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7311720848083496,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7263171672821045,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.645645260810852,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7661429345607758
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.6648820042610168,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6424049139022827,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6268392205238342,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.6092663407325745,
            "answer": "inclusion",
            "hit": false
          },
          {
            "score": 0.5982496738433838,
            "answer": "exclude",
            "hit": false
          },
          {
            "score": 0.5973412394523621,
            "answer": "containing",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6424049437046051
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8972798585891724,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8784667253494263,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8632566332817078,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.6357606053352356,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6260297298431396,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.6227834820747375,
            "answer": "introduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.878466784954071
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8967530727386475,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8275828957557678,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8043349385261536,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6995933055877686,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6455326676368713,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.643710732460022,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8043348789215088
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8450103998184204,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7220062017440796,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.6397008895874023,
            "answer": "found",
            "hit": false
          },
          {
            "score": 0.6349302530288696,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6343293786048889,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.6312143206596375,
            "answer": "finds",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7220062166452408
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8735551834106445,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8560850620269775,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7015376091003418,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6876010894775391,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6669994592666626,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.6537618637084961,
            "answer": "loss",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6876011192798615
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.860859751701355,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8398838043212891,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8214372396469116,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6692772507667542,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6420009136199951,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6239436268806458,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.860859751701355
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.871987521648407,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.7244464755058289,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.6960288882255554,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.6494323015213013,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.6305019855499268,
            "answer": "wed",
            "hit": false
          },
          {
            "score": 0.6253818869590759,
            "answer": "divorced",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7244464755058289
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7177082300186157,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.714623749256134,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7135993838310242,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.6541300415992737,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6324334144592285,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6238382458686829,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7146237641572952
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.7239126563072205,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7197256088256836,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7110843658447266,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.6206932663917542,
            "answer": "provision",
            "hit": false
          },
          {
            "score": 0.6074803471565247,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.6072877645492554,
            "answer": "supplying",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7110843658447266
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.7512215971946716,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.6586042642593384,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.6459774971008301,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.6233500242233276,
            "answer": "released",
            "hit": false
          },
          {
            "score": 0.6128221154212952,
            "answer": "authored",
            "hit": false
          },
          {
            "score": 0.6097079515457153,
            "answer": "uploaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6586042493581772
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.738913357257843,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7250844240188599,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7168192863464355,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6194390058517456,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6137351989746094,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.6079131960868835,
            "answer": "recipient",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7389133870601654
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.6608995795249939,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.6467447876930237,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.6448558568954468,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.6402940154075623,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6300660371780396,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.5862644910812378,
            "answer": "enhanced",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6608996093273163
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.7990644574165344,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7957611083984375,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.7894806861877441,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.618207573890686,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.6009339094161987,
            "answer": "references",
            "hit": false
          },
          {
            "score": 0.6005937457084656,
            "answer": "corresponds",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7957610785961151
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8206863403320312,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7761746644973755,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6520509719848633,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6135851144790649,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6098642349243164,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6058304905891418,
            "answer": "connects",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6520509421825409
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8602593541145325,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8538964986801147,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7284691333770752,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6731579303741455,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6641076803207397,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.6542242765426636,
            "answer": "staying",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8602593541145325
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8794515132904053,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8621630668640137,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8407565355300903,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.706477165222168,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7030717134475708,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.6472498178482056,
            "answer": "placed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8621631264686584
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7184739112854004,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7109854221343994,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6907464265823364,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6820930242538452,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6312868595123291,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6139570474624634,
            "answer": "mandated",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6312868595123291
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8573644161224365,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.7616466879844666,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7496519088745117,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7402945756912231,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.71219801902771,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6973458528518677,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8573644161224365
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8810070753097534,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.843133807182312,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.6752305030822754,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6352670192718506,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.6305243968963623,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6266202330589294,
            "answer": "transmitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.675230547785759
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.893631100654602,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8775115609169006,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.845967710018158,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6865018606185913,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6698634624481201,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6387887001037598,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8936310410499573
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8032494783401489,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.802817702293396,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7268555164337158,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6311755776405334,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6304992437362671,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.6301582455635071,
            "answer": "say",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8032494783401489
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8555768132209778,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8363020420074463,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7514053583145142,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7283556461334229,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.6637815833091736,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.661128044128418,
            "answer": "misunderstood",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8555768132209778
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.6885792016983032,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.6244752407073975,
            "answer": "joined",
            "hit": false
          },
          {
            "score": 0.6156444549560547,
            "answer": "joins",
            "hit": false
          },
          {
            "score": 0.6073795557022095,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.6016209721565247,
            "answer": "together",
            "hit": false
          },
          {
            "score": 0.5988247394561768,
            "answer": "divided",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 626,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5454283989965916
      }
    ],
    "result": {
      "cnt_questions_correct": 19,
      "cnt_questions_total": 50,
      "accuracy": 0.38
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6480022d-aef8-4158-a721-37e8eda5deec",
      "timestamp": "2025-05-17T21:30:06.451637"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8401736617088318,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.6842798590660095,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6733686923980713,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6589802503585815,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6525145769119263,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6361353397369385,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.840173602104187
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8222291469573975,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.727428138256073,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7231416702270508,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7144502997398376,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6969326734542847,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6884072422981262,
            "answer": "permit",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6761327087879181
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8400102257728577,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8331115245819092,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8319608569145203,
            "answer": "appears",
            "hit": true
          },
          {
            "score": 0.6847310066223145,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.6605343222618103,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6605031490325928,
            "answer": "appearances",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8319608569145203
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8634430170059204,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.8061483502388,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.6967246532440186,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6523933410644531,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6475868225097656,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.633725643157959,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8061483502388
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8301166296005249,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7302390336990356,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6444284915924072,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.6403915882110596,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6379031538963318,
            "answer": "wondering",
            "hit": false
          },
          {
            "score": 0.6302489042282104,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6216264814138412
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8587389588356018,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8397372961044312,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.8333075046539307,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.6768425703048706,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6514381170272827,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6482377052307129,
            "answer": "being",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8333075046539307
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8053920269012451,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7837713956832886,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7208636999130249,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.69515460729599,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.6698872447013855,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6633825898170471,
            "answer": "believer",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8053920865058899
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7179161310195923,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7061742544174194,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.6653532385826111,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6480556726455688,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6313346028327942,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.6144444942474365,
            "answer": "considerations",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7179161012172699
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8706653118133545,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8320478796958923,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7181425094604492,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6912936568260193,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6908403635025024,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6890379190444946,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8706653118133545
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8396835327148438,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7758071422576904,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6768542528152466,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6671487092971802,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.6482903361320496,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6480914950370789,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6671487241983414
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.7892831563949585,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.6795962452888489,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6631253957748413,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.6623837947845459,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6488325595855713,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6325989961624146,
            "answer": "begins",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7892831861972809
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.8792860507965088,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.6868423223495483,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.6795869469642639,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6768650412559509,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.6674306988716125,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6645365953445435,
            "answer": "adds",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8792860507965088
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8001681566238403,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.744492769241333,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.6711610555648804,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6701933145523071,
            "answer": "depend",
            "hit": false
          },
          {
            "score": 0.6509798765182495,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.6383243799209595,
            "answer": "rely",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8001681566238403
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.847262442111969,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.7971062660217285,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7193925380706787,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6554334163665771,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.6531658172607422,
            "answer": "defines",
            "hit": false
          },
          {
            "score": 0.6529374122619629,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8472625017166138
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8514310121536255,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8231403827667236,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8064675331115723,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6967429518699646,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6625528335571289,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6571336984634399,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8231404423713684
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8249384164810181,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.802616536617279,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.7025970220565796,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.6905684471130371,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.6887218952178955,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.6725726127624512,
            "answer": "reveals",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.802616536617279
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8566091060638428,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8291820287704468,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7953881025314331,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.6645488739013672,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6474802494049072,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.6433559656143188,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8566091656684875
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.6690046191215515,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.66748046875,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.6549957990646362,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.6510300636291504,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6056567430496216,
            "answer": "currently",
            "hit": false
          },
          {
            "score": 0.5980622172355652,
            "answer": "prevailing",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.585539273917675
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8566728830337524,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.8555060029029846,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8491971492767334,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7461013793945312,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.7203752994537354,
            "answer": "explanations",
            "hit": false
          },
          {
            "score": 0.654577910900116,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8555059432983398
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.6972693204879761,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.6736416816711426,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.637955367565155,
            "answer": "below",
            "hit": false
          },
          {
            "score": 0.6303828358650208,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6189379692077637,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.6106732487678528,
            "answer": "after",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6972693055868149
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.7999559640884399,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.7894598245620728,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7821211814880371,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.6921836137771606,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.6759192943572998,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.6683041453361511,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7999559938907623
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.7951837182044983,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.745360255241394,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7350691556930542,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7344072461128235,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6213233470916748,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6096225380897522,
            "answer": "learns",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7453602254390717
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8805650472640991,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8173345327377319,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7723840475082397,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7589606046676636,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7577423453330994,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.6753940582275391,
            "answer": "better",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8805650472640991
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7748902440071106,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6670562028884888,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.6474871039390564,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6334894895553589,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.63160640001297,
            "answer": "except",
            "hit": false
          },
          {
            "score": 0.6285929083824158,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7748902440071106
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8423775434494019,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8350338935852051,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7356777787208557,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.6474047899246216,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6460394263267517,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6438407301902771,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8423775732517242
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7460112571716309,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.7102716565132141,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7040717005729675,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6861582398414612,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.646356999874115,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.643824577331543,
            "answer": "learners",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7460112273693085
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8678855299949646,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8631482124328613,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.6939700245857239,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6802130937576294,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6678766012191772,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6535501480102539,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.867885559797287
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8323162794113159,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8088831901550293,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7675753831863403,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.6490988731384277,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6278316974639893,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.624302089214325,
            "answer": "maintains",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8088831901550293
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8321313858032227,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.824094831943512,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7719231247901917,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.6852036714553833,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.682568371295929,
            "answer": "occurrence",
            "hit": false
          },
          {
            "score": 0.6822834610939026,
            "answer": "occurrences",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8321313858032227
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.7412411570549011,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7260947227478027,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.6444709300994873,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6277644038200378,
            "answer": "operated",
            "hit": false
          },
          {
            "score": 0.6253706216812134,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6056227684020996,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7260947525501251
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8691157102584839,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.8170500993728638,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7222517728805542,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.6868255138397217,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6860244274139404,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6827270984649658,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8691157102584839
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9092820882797241,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8702542781829834,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8037030100822449,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7438276410102844,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6924843788146973,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.6672704815864563,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8702543079853058
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8489478230476379,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.751021146774292,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.7229509949684143,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6807800531387329,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6657543778419495,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6655032634735107,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489478230476379
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.846738874912262,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8053879737854004,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.718518853187561,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6694939136505127,
            "answer": "receiver",
            "hit": false
          },
          {
            "score": 0.6646849513053894,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6622865796089172,
            "answer": "receivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8467389345169067
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8359286785125732,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.7769237756729126,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7627021074295044,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.7146326303482056,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6733128428459167,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.6602440476417542,
            "answer": "decrease",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8359286785125732
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.807427167892456,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7980561256408691,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7519115805625916,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6389827728271484,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6126971244812012,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6126258373260498,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.807427167892456
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.7934588193893433,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.757032036781311,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.6877807378768921,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6323649883270264,
            "answer": "related",
            "hit": false
          },
          {
            "score": 0.615547776222229,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6147672533988953,
            "answer": "refers",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.757032036781311
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7248305678367615,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7124921083450317,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7094324827194214,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6443313956260681,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.6253037452697754,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.6238149404525757,
            "answer": "residual",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7124921232461929
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8581887483596802,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.814749002456665,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7110055685043335,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.680950403213501,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6690243482589722,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6545714139938354,
            "answer": "reflects",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.858188807964325
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8414958119392395,
            "answer": "requires",
            "hit": true
          },
          {
            "score": 0.7003419995307922,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6931383013725281,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.6771038770675659,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6663800477981567,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6513016819953918,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8414958119392395
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.7783188819885254,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7694277763366699,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7106149196624756,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.6912267208099365,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.6735656261444092,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6631309390068054,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6912267059087753
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8296398520469666,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.8272989988327026,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7252315282821655,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.6446126699447632,
            "answer": "standing",
            "hit": false
          },
          {
            "score": 0.6442289352416992,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.6375421285629272,
            "answer": "stood",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8272989988327026
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8551226854324341,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8331254720687866,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.802649199962616,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7159669995307922,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.68651282787323,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6490424871444702,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8331254720687866
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8687353730201721,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7984174489974976,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7588688135147095,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7412071228027344,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.7135466933250427,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.7077957987785339,
            "answer": "indicates",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8687354326248169
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8407654762268066,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8207005262374878,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8016272783279419,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.6782742738723755,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6694150567054749,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.6420673727989197,
            "answer": "instructor",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8207005858421326
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.7255052924156189,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7237154841423035,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7033378481864929,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6414426565170288,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6211954355239868,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.6173567771911621,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7255053073167801
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.737573504447937,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7099576592445374,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.6919585466384888,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.6559496521949768,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.6347564458847046,
            "answer": "misunderstood",
            "hit": false
          },
          {
            "score": 0.6323723793029785,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7099576890468597
      }
    ],
    "result": {
      "cnt_questions_correct": 26,
      "cnt_questions_total": 47,
      "accuracy": 0.5531914893617021
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f8982324-dfcd-48b1-afd0-12a5b71f7905",
      "timestamp": "2025-05-17T21:30:06.668744"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.815864086151123,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.6940252780914307,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6874385476112366,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6711814403533936,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6620093584060669,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6121332049369812,
            "answer": "removing",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6940252631902695
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8262818455696106,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7834330201148987,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.737180233001709,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.6933515071868896,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6745829582214355,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.6665260195732117,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8262818157672882
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8444726467132568,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7286062836647034,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.717900276184082,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.6970140933990479,
            "answer": "permits",
            "hit": false
          },
          {
            "score": 0.6918867826461792,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6901476383209229,
            "answer": "permit",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8444726467132568
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8610109686851501,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8471053838729858,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8300446271896362,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7536906003952026,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.709062933921814,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.656735360622406,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8610109388828278
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8402029275894165,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.829243004322052,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8005586862564087,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6874854564666748,
            "answer": "appearance",
            "hit": false
          },
          {
            "score": 0.6569094061851501,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.6563753485679626,
            "answer": "appearances",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8402029275894165
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8610957860946655,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7837268114089966,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7034212350845337,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6625499725341797,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.6625109910964966,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.626423180103302,
            "answer": "applicants",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6625499874353409
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8500771522521973,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.724711537361145,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.6551427841186523,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.639909029006958,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.6395951509475708,
            "answer": "wondered",
            "hit": false
          },
          {
            "score": 0.6382304430007935,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8500771522521973
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8724958896636963,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.8715840578079224,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.6654758453369141,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.654221773147583,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.6463139653205872,
            "answer": "attendant",
            "hit": false
          },
          {
            "score": 0.6280804872512817,
            "answer": "visited",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8715840578079224
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8572688698768616,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8452944755554199,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.805652916431427,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.6558634042739868,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6515175104141235,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6509581804275513,
            "answer": "being",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8452944159507751
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.6989952325820923,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.6920305490493774,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.6897971630096436,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.6614176630973816,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6260040998458862,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.6142030954360962,
            "answer": "considerations",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.68979711830616
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8231094479560852,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7914246320724487,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.6500637531280518,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.6398085355758667,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6395083665847778,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.6377713680267334,
            "answer": "consisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7914246320724487
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7659213542938232,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6830278635025024,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6808587908744812,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.6688185930252075,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.6514293551445007,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.6335425972938538,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.68085877597332
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8520444631576538,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6878576278686523,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.6797850131988525,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.6655100584030151,
            "answer": "creation",
            "hit": false
          },
          {
            "score": 0.6547374129295349,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.6501559019088745,
            "answer": "creators",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6878576874732971
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8203248977661133,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7667579054832458,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.6904705762863159,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6747082471847534,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.6487741470336914,
            "answer": "decisions",
            "hit": false
          },
          {
            "score": 0.6336202025413513,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5872394293546677
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8195569515228271,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.818049967288971,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7207432985305786,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6531354188919067,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.649442732334137,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.6485500335693359,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8180499374866486
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8411704897880554,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.823643684387207,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7967116236686707,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7105365991592407,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6625785827636719,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6513818502426147,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.823643684387207
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.894399881362915,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8474977612495422,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8406426906585693,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7088611125946045,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6441831588745117,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6412861943244934,
            "answer": "proving",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8474977612495422
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.6742706894874573,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.6663424968719482,
            "answer": "exist",
            "hit": false
          },
          {
            "score": 0.6605479717254639,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.6483506560325623,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.6090513467788696,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.608770489692688,
            "answer": "prevailing",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6605480462312698
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7411789298057556,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6914902925491333,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6827132701873779,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.6482356786727905,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.642891526222229,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.63833087682724,
            "answer": "hoping",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6914903372526169
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.7767587900161743,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.7408807873725891,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.6889530420303345,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.6867871284484863,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.6464375853538513,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.6097185611724854,
            "answer": "declined",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7408807575702667
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.6932945251464844,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.6819849610328674,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6393204927444458,
            "answer": "below",
            "hit": false
          },
          {
            "score": 0.6373987793922424,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6197028160095215,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.6167932748794556,
            "answer": "according",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6932945549488068
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7931872606277466,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7478050589561462,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7225986123085022,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7182539701461792,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.626715362071991,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.6108574271202087,
            "answer": "proceeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7478050887584686
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8526416420936584,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8353169560432434,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.785330057144165,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7636227607727051,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7568048238754272,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.6791428327560425,
            "answer": "better",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8353169560432434
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7471810579299927,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.6893090605735779,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6247381567955017,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6233103275299072,
            "answer": "except",
            "hit": false
          },
          {
            "score": 0.6230440139770508,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6222772598266602,
            "answer": "excluding",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6893091201782227
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9004165530204773,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8895748853683472,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8448002934455872,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.6387040019035339,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6238275766372681,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.6217095255851746,
            "answer": "inserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8895748853683472
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8250569105148315,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8150043487548828,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7520374059677124,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6550990343093872,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6434942483901978,
            "answer": "concerning",
            "hit": false
          },
          {
            "score": 0.6331995725631714,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7520374059677124
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8555252552032471,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7351392507553101,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.6416470408439636,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.6313509941101074,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.6232380867004395,
            "answer": "localized",
            "hit": false
          },
          {
            "score": 0.6213793754577637,
            "answer": "found",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7351392507553101
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8581141233444214,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8465393781661987,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7032268047332764,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.6969934105873108,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6777533888816833,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.663286566734314,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.703226774930954
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8306725025177002,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7870548963546753,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7865558862686157,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.647000789642334,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6403525471687317,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6219655871391296,
            "answer": "controlling",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.786555826663971
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8794602155685425,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7360736131668091,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.6904098987579346,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.6566973328590393,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.6411591172218323,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.6361678838729858,
            "answer": "wed",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7360736429691315
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7255460023880005,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.6959935426712036,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.6454695463180542,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6431342363357544,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.6358929872512817,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6033730506896973,
            "answer": "operation",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6431342214345932
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8456968665122986,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8371840715408325,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.717499852180481,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.6907323598861694,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6845203638076782,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6840958595275879,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8371840715408325
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8507593870162964,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.850207507610321,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8499445915222168,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7390955686569214,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7225181460380554,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.6802476644515991,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8502075374126434
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8208292722702026,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7786351442337036,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.7191614508628845,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6710233688354492,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.6620516777038574,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6562302112579346,
            "answer": "offers",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.778635174036026
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.7510243654251099,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.6617962121963501,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.6314161419868469,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.6102452278137207,
            "answer": "released",
            "hit": false
          },
          {
            "score": 0.6090376973152161,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.6078089475631714,
            "answer": "publication",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6314161419868469
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8239898681640625,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8171576261520386,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7170120477676392,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6740608811378479,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.668430745601654,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6618709564208984,
            "answer": "receiver",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8239898979663849
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8036376237869263,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7933746576309204,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.7690410614013672,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.712169349193573,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.6625590324401855,
            "answer": "decreased",
            "hit": false
          },
          {
            "score": 0.6547033786773682,
            "answer": "decrease",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7933747172355652
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.7780318260192871,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.735206127166748,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.6929158568382263,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.6489377021789551,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6134718060493469,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6105481386184692,
            "answer": "unrelated",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6489376574754715
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.715580940246582,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7132618427276611,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.6860684156417847,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6429507732391357,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.6229932308197021,
            "answer": "residual",
            "hit": false
          },
          {
            "score": 0.6227327585220337,
            "answer": "surviving",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7155809551477432
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8826352953910828,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8683176636695862,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8390408158302307,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7161024212837219,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7094485759735107,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.638785719871521,
            "answer": "placed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8683176636695862
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8363757133483887,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.8337903022766113,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7165006399154663,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6981388330459595,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6800081729888916,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.6600712537765503,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8363756537437439
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8120371103286743,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.7108017802238464,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.6871603727340698,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.6804157495498657,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6564382314682007,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6557397842407227,
            "answer": "demanded",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.625015065073967
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8802745938301086,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.8489723801612854,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.6780714988708496,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.627600908279419,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.624373197555542,
            "answer": "transmit",
            "hit": false
          },
          {
            "score": 0.6220707297325134,
            "answer": "shipped",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6780714988708496
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8527676463127136,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8175777196884155,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8100440502166748,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7217329144477844,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6932075023651123,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6357277035713196,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8175776600837708
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8250092267990112,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8162766695022583,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.7939994931221008,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.6195304989814758,
            "answer": "endured",
            "hit": false
          },
          {
            "score": 0.6191987991333008,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.6185057759284973,
            "answer": "undergone",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8162766695022583
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8265581130981445,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8078007102012634,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.7941097021102905,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6765130758285522,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.6737054586410522,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.6415539979934692,
            "answer": "teachers",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8078007102012634
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7161272764205933,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.714091420173645,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.6898304224014282,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6173512935638428,
            "answer": "informed",
            "hit": false
          },
          {
            "score": 0.616774320602417,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.611873984336853,
            "answer": "assured",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7161272466182709
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.7351968288421631,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7067362070083618,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.6918780207633972,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.6589064598083496,
            "answer": "misunderstanding",
            "hit": false
          },
          {
            "score": 0.6500365734100342,
            "answer": "misunderstood",
            "hit": false
          },
          {
            "score": 0.6392752528190613,
            "answer": "comprehension",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.706736221909523
      }
    ],
    "result": {
      "cnt_questions_correct": 10,
      "cnt_questions_total": 48,
      "accuracy": 0.20833333333333334
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "24e2b2ca-885b-46b7-9f45-7bb2db217aca",
      "timestamp": "2025-05-17T21:30:06.870339"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8141828179359436,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.699507474899292,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6921278238296509,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6582834720611572,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6483252644538879,
            "answer": "additions",
            "hit": false
          },
          {
            "score": 0.6234819889068604,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6995075345039368
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.832777738571167,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7821927070617676,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7548011541366577,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7037433981895447,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6860702037811279,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.6788440942764282,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.832777738571167
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.7403579950332642,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.6715235710144043,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.6469038724899292,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6243492960929871,
            "answer": "swallow",
            "hit": false
          },
          {
            "score": 0.6122339367866516,
            "answer": "swallowed",
            "hit": false
          },
          {
            "score": 0.605624258518219,
            "answer": "permitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6715235710144043
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8621746301651001,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.8468737602233887,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.8367190361022949,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7331565618515015,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7072077989578247,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6397585868835449,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8621745705604553
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8898268938064575,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8678615689277649,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.802386999130249,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7094206809997559,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6888628005981445,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.6828956604003906,
            "answer": "appearance",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8678616285324097
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8462970852851868,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7703713178634644,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.700239360332489,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6574416160583496,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.6457977890968323,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.5999590158462524,
            "answer": "lies",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6457977741956711
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.6242175102233887,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.6094316244125366,
            "answer": "mask",
            "hit": false
          },
          {
            "score": 0.602301299571991,
            "answer": "masks",
            "hit": false
          },
          {
            "score": 0.6020349264144897,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.5940860509872437,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.592725932598114,
            "answer": "task",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6242175102233887
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8805599212646484,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.8633102178573608,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.8074624538421631,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6529704332351685,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6247480511665344,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6233581900596619,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8633101582527161
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8389557600021362,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.784946858882904,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7264018654823303,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6913383603096008,
            "answer": "believe",
            "hit": false
          },
          {
            "score": 0.6823387742042542,
            "answer": "beliefs",
            "hit": false
          },
          {
            "score": 0.6743694543838501,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8389557898044586
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8306175470352173,
            "answer": "consider",
            "hit": false
          },
          {
            "score": 0.7872276306152344,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.698400616645813,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6816822290420532,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6719743013381958,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.6497697830200195,
            "answer": "regarded",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7872276902198792
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.8795766830444336,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.8460971117019653,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7090103030204773,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6993268728256226,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6936345100402832,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.6665506958961487,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8795767426490784
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.6649904847145081,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.6584740877151489,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.6518612504005432,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.5934494733810425,
            "answer": "equals",
            "hit": false
          },
          {
            "score": 0.5893442630767822,
            "answer": "containment",
            "hit": false
          },
          {
            "score": 0.5891583561897278,
            "answer": "exists",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6649904996156693
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7732394337654114,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7180411219596863,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.7028862237930298,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.6469628810882568,
            "answer": "persisted",
            "hit": false
          },
          {
            "score": 0.6460875868797302,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.641557514667511,
            "answer": "began",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7180411219596863
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8500184416770935,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6684960126876831,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.6584716439247131,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.6556203961372375,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.6556171774864197,
            "answer": "creations",
            "hit": false
          },
          {
            "score": 0.6397078633308411,
            "answer": "creation",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6584716737270355
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8333138227462769,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7665709257125854,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.6712353229522705,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6475671529769897,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.6469058394432068,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.6465522646903992,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 36,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5836146026849747
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8208035826683044,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.8155081272125244,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6931838989257812,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.6499045491218567,
            "answer": "discussed",
            "hit": false
          },
          {
            "score": 0.6445859670639038,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.6400026082992554,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8208035826683044
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8524698615074158,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8122345209121704,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7929957509040833,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6922937631607056,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.668042004108429,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6410309076309204,
            "answer": "evolved",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8122345209121704
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.860785186290741,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8383215665817261,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8295081257820129,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.6707189083099365,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.6601660847663879,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.6367906332015991,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8295081257820129
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7468804121017456,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.707855224609375,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.687328577041626,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.6576278209686279,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6498026847839355,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6398248076438904,
            "answer": "anticipated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7078552395105362
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.7939307689666748,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7735449075698853,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.7018666863441467,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.6973261833190918,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.6636835336685181,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.6189979910850525,
            "answer": "refused",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7939307689666748
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7482549548149109,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7286295890808105,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6688218116760254,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6165313124656677,
            "answer": "shown",
            "hit": false
          },
          {
            "score": 0.6049812436103821,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.5972654819488525,
            "answer": "pursued",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7482550144195557
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.8621455430984497,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8587656617164612,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.7747747898101807,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.6785960793495178,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.6763064861297607,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.6751145124435425,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8587656915187836
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8391788005828857,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.8264862298965454,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7300012707710266,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.6504875421524048,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.6443032622337341,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.6432919502258301,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8391788601875305
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7480183839797974,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7273406982421875,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7271122932434082,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.6896254420280457,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.6879825592041016,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.6852588057518005,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7271123081445694
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8134371042251587,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.7544854283332825,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.7011966109275818,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.6822741031646729,
            "answer": "intention",
            "hit": false
          },
          {
            "score": 0.6614067554473877,
            "answer": "intentions",
            "hit": false
          },
          {
            "score": 0.6568780541419983,
            "answer": "planned",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7544854283332825
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8696296811103821,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.850236177444458,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.850152313709259,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.6428922414779663,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6274353265762329,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.6272841691970825,
            "answer": "introduction",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8502362072467804
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8926826119422913,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8152511119842529,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7875419855117798,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.6675260066986084,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6489155292510986,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.645882248878479,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.787541925907135
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8764864206314087,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.8453904986381531,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7149695158004761,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7004821300506592,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6538313031196594,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.649207353591919,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7149695158004761
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8506050705909729,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.8388460874557495,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.78026282787323,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6324253678321838,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6202070713043213,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.6192131042480469,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8506050705909729
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9037154316902161,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8462192416191101,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8029230833053589,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.6854054927825928,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.6785841584205627,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.6771442890167236,
            "answer": "happened",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8462193012237549
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8777745962142944,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7082291841506958,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.6949834823608398,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.6500778794288635,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.6258126497268677,
            "answer": "worked",
            "hit": false
          },
          {
            "score": 0.6255420446395874,
            "answer": "operators",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6949834674596786
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8403676748275757,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.8157588839530945,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7136224508285522,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.6952475309371948,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6611353158950806,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6595202684402466,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8157589435577393
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8608191013336182,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8606921434402466,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8403700590133667,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.7272956371307373,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7111393809318542,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.69547438621521,
            "answer": "suggested",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8608191013336182
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8202318549156189,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7611258029937744,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.726435661315918,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6735368371009827,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.6614158749580383,
            "answer": "provision",
            "hit": false
          },
          {
            "score": 0.6512392163276672,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7611258029937744
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8321496844291687,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.8314979672431946,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7234843969345093,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.6525806188583374,
            "answer": "reception",
            "hit": false
          },
          {
            "score": 0.6474523544311523,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6354914903640747,
            "answer": "recipient",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8321497142314911
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8034855723381042,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7779976725578308,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7668214440345764,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.6140142679214478,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6116132736206055,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.6082128882408142,
            "answer": "reference",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7668214440345764
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8055513501167297,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7314080595970154,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6167722940444946,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6057114005088806,
            "answer": "disclosed",
            "hit": false
          },
          {
            "score": 0.5983765721321106,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.597493052482605,
            "answer": "referred",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.616772323846817
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8460017442703247,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8292579054832458,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.69692063331604,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6481350660324097,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6405891180038452,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.639648973941803,
            "answer": "becoming",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8292579650878906
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8446404933929443,
            "answer": "replace",
            "hit": false
          },
          {
            "score": 0.8393253087997437,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8361845016479492,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.693275511264801,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.6805408596992493,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.651250958442688,
            "answer": "placed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8393253087997437
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8282155394554138,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.8241875171661377,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.68861985206604,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6689901947975159,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.6632301807403564,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6449090838432312,
            "answer": "constitutes",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8241875469684601
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8061773180961609,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7025655508041382,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.682238757610321,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.6794406175613403,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6555019617080688,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.6490359902381897,
            "answer": "requested",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.642192080616951
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.7510250806808472,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.7479426860809326,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.6763747930526733,
            "answer": "looks",
            "hit": false
          },
          {
            "score": 0.6744461059570312,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.6408621072769165,
            "answer": "appears",
            "hit": false
          },
          {
            "score": 0.6301161050796509,
            "answer": "sounded",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7510250806808472
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8537972569465637,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.8471524119377136,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.67818284034729,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.6413091421127319,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6411420702934265,
            "answer": "transmit",
            "hit": false
          },
          {
            "score": 0.6343252658843994,
            "answer": "transmitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6781828701496124
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.883389413356781,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.87842857837677,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8123291730880737,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.674286961555481,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6617038249969482,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6309522986412048,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8784286081790924
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8424987196922302,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8407471179962158,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7182806730270386,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7084462642669678,
            "answer": "indicate",
            "hit": false
          },
          {
            "score": 0.7030916810035706,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7022405862808228,
            "answer": "suggestion",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.842498779296875
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8410671353340149,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.8081889152526855,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7082087993621826,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6774517893791199,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6668314337730408,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.6382483243942261,
            "answer": "warns",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8410671949386597
      }
    ],
    "result": {
      "cnt_questions_correct": 16,
      "cnt_questions_total": 46,
      "accuracy": 0.34782608695652173
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c26d759a-d75d-434a-9d79-7ffb85c07a9a",
      "timestamp": "2025-05-17T21:30:07.076320"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7727758288383484,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.6099388599395752,
            "answer": "relentless",
            "hit": false
          },
          {
            "score": 0.6040605306625366,
            "answer": "brutal",
            "hit": false
          },
          {
            "score": 0.5891638994216919,
            "answer": "luxurious",
            "hit": false
          },
          {
            "score": 0.5858850479125977,
            "answer": "ambitious",
            "hit": false
          },
          {
            "score": 0.5851194262504578,
            "answer": "oversee",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 162,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.557074248790741
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.771451473236084,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.5783119201660156,
            "answer": "tuberculosis",
            "hit": false
          },
          {
            "score": 0.5760293006896973,
            "answer": "teresa",
            "hit": false
          },
          {
            "score": 0.5755380392074585,
            "answer": "esther",
            "hit": false
          },
          {
            "score": 0.575364887714386,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.5744125247001648,
            "answer": "kathy",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 89,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5552454739809036
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ba9b2ab7-6051-4abe-bc2e-9a1c62347cd9",
      "timestamp": "2025-05-17T21:30:07.274598"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.7059448957443237,
            "answer": "ability",
            "hit": false
          },
          {
            "score": 0.625985860824585,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.62239670753479,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.6095417141914368,
            "answer": "unknown",
            "hit": false
          },
          {
            "score": 0.6029510498046875,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.6010828018188477,
            "answer": "acceptable",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5947204530239105
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.7820887565612793,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.6568827629089355,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.6461899876594543,
            "answer": "uncomfortable",
            "hit": false
          },
          {
            "score": 0.6433331966400146,
            "answer": "disappointing",
            "hit": false
          },
          {
            "score": 0.6346307992935181,
            "answer": "unpleasant",
            "hit": false
          },
          {
            "score": 0.6341836452484131,
            "answer": "inappropriate",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7820888161659241
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.7194346189498901,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.6767674088478088,
            "answer": "affecting",
            "hit": false
          },
          {
            "score": 0.6752638816833496,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.6700559854507446,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.6503921747207642,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.634178876876831,
            "answer": "influenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7194346636533737
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.698738694190979,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.645154595375061,
            "answer": "availability",
            "hit": false
          },
          {
            "score": 0.6055135130882263,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.6029143333435059,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.5990760922431946,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.5987537503242493,
            "answer": "unpublished",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6987387239933014
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.7842816114425659,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.670643150806427,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6481072306632996,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.6458761692047119,
            "answer": "knew",
            "hit": false
          },
          {
            "score": 0.6429466009140015,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.6314260959625244,
            "answer": "realise",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7842815816402435
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.6522049903869629,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.6298137903213501,
            "answer": "uncertain",
            "hit": true
          },
          {
            "score": 0.6197264790534973,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.6184501647949219,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.6155851483345032,
            "answer": "certainty",
            "hit": false
          },
          {
            "score": 0.6085258722305298,
            "answer": "definite",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6298138052225113
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.6908303499221802,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.645599365234375,
            "answer": "unchanged",
            "hit": true
          },
          {
            "score": 0.6443542242050171,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.6273608207702637,
            "answer": "changes",
            "hit": false
          },
          {
            "score": 0.6223292946815491,
            "answer": "exchanged",
            "hit": false
          },
          {
            "score": 0.6084452271461487,
            "answer": "altered",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6455994099378586
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.807431161403656,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.6996119022369385,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.6963181495666504,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.6870481371879578,
            "answer": "comfort",
            "hit": false
          },
          {
            "score": 0.6710265278816223,
            "answer": "comforting",
            "hit": false
          },
          {
            "score": 0.650600254535675,
            "answer": "unhappy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.807431161403656
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.7456530332565308,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7367008328437805,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7181068062782288,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.6474287509918213,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6425179839134216,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.6284085512161255,
            "answer": "aware",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.71810682117939
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.7315771579742432,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.6742579936981201,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6674684882164001,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.6652802228927612,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.6562185287475586,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.6467286348342896,
            "answer": "unemployment",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7315772026777267
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.6811636090278625,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6768726706504822,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.6670382618904114,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.6615893840789795,
            "answer": "unexpected",
            "hit": true
          },
          {
            "score": 0.6544289588928223,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.651264488697052,
            "answer": "unexpectedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6615893691778183
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.8144991397857666,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.8043215274810791,
            "answer": "finish",
            "hit": false
          },
          {
            "score": 0.7891901731491089,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.6910911798477173,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.6531157493591309,
            "answer": "completing",
            "hit": false
          },
          {
            "score": 0.6456685662269592,
            "answer": "completes",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6910911500453949
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.812730073928833,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7219454050064087,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.6601435542106628,
            "answer": "blessed",
            "hit": false
          },
          {
            "score": 0.6425853967666626,
            "answer": "fortunately",
            "hit": false
          },
          {
            "score": 0.641928493976593,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.6408522129058838,
            "answer": "luckily",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7219453901052475
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7025967836380005,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.6654007434844971,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6350952386856079,
            "answer": "unfortunate",
            "hit": false
          },
          {
            "score": 0.6300132274627686,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.6241538524627686,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6191074848175049,
            "answer": "miserable",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7025967538356781
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.7122070789337158,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7109948396682739,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7061440348625183,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.6900596618652344,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.6569708585739136,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.6537699699401855,
            "answer": "identification",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6900596916675568
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.6790916323661804,
            "answer": "famous",
            "hit": false
          },
          {
            "score": 0.6743016839027405,
            "answer": "unknown",
            "hit": true
          },
          {
            "score": 0.6637341976165771,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.636418342590332,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6296457648277283,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.6223295331001282,
            "answer": "knew",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6743017435073853
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.6880155801773071,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.6259057521820068,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.6177294254302979,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.6138618588447571,
            "answer": "unconstitutional",
            "hit": false
          },
          {
            "score": 0.6119199395179749,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.611414909362793,
            "answer": "unauthorized",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6880155503749847
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.8243937492370605,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.7710490226745605,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7222509384155273,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7124943733215332,
            "answer": "pay",
            "hit": false
          },
          {
            "score": 0.6952890157699585,
            "answer": "payments",
            "hit": false
          },
          {
            "score": 0.6940131187438965,
            "answer": "payment",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7222509980201721
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.796606719493866,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.7028605341911316,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.6591781377792358,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6558209657669067,
            "answer": "uncomfortable",
            "hit": false
          },
          {
            "score": 0.6412923336029053,
            "answer": "dreadful",
            "hit": false
          },
          {
            "score": 0.6310552954673767,
            "answer": "pleasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.796606719493866
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.6910375356674194,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.6751049160957336,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.6057008504867554,
            "answer": "controversial",
            "hit": false
          },
          {
            "score": 0.6037482023239136,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6015058159828186,
            "answer": "widespread",
            "hit": false
          },
          {
            "score": 0.5949569344520569,
            "answer": "affordable",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.691037580370903
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.7314873337745667,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.6430619955062866,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.6406290531158447,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.6359317302703857,
            "answer": "disappointing",
            "hit": false
          },
          {
            "score": 0.6248590350151062,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.6240649223327637,
            "answer": "predict",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7314873188734055
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.6296578645706177,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.6263913512229919,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.6161314249038696,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.6144195795059204,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.60756915807724,
            "answer": "unspecified",
            "hit": false
          },
          {
            "score": 0.603840172290802,
            "answer": "unexpected",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6263913661241531
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.7798411846160889,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7737386226654053,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.6368335485458374,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.6359879970550537,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6350605487823486,
            "answer": "rational",
            "hit": false
          },
          {
            "score": 0.6321797370910645,
            "answer": "realistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798411846160889
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.7084925174713135,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.6574915647506714,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.6308308243751526,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.630366861820221,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.6272985935211182,
            "answer": "correlated",
            "hit": false
          },
          {
            "score": 0.6137341856956482,
            "answer": "dependent",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7084924876689911
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.7937270998954773,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.7486026883125305,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.648835301399231,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.6421809792518616,
            "answer": "inaccurate",
            "hit": false
          },
          {
            "score": 0.6380458474159241,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.6326884031295776,
            "answer": "unavailable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7937271595001221
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.7752127647399902,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7474071979522705,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.6761098504066467,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.6641318798065186,
            "answer": "specifications",
            "hit": false
          },
          {
            "score": 0.6577197909355164,
            "answer": "specification",
            "hit": false
          },
          {
            "score": 0.6142711043357849,
            "answer": "defined",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6761098653078079
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.7976464629173279,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.7679923176765442,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.6925345659255981,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.6909375786781311,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.6762228012084961,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6686120629310608,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7976464629173279
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.6334426403045654,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.629828691482544,
            "answer": "use",
            "hit": false
          },
          {
            "score": 0.6185687780380249,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.61822909116745,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.6180489659309387,
            "answer": "unwanted",
            "hit": false
          },
          {
            "score": 0.6139679551124573,
            "answer": "usage",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6334426701068878
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7326020002365112,
            "answer": "unusual",
            "hit": true
          },
          {
            "score": 0.6565187573432922,
            "answer": "unusually",
            "hit": false
          },
          {
            "score": 0.6352794170379639,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.630089521408081,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.6186776161193848,
            "answer": "rare",
            "hit": false
          },
          {
            "score": 0.6155251264572144,
            "answer": "unfamiliar",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7326019704341888
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.7421135306358337,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.7118546962738037,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.685077428817749,
            "answer": "unwanted",
            "hit": true
          },
          {
            "score": 0.652654767036438,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.637731671333313,
            "answer": "desired",
            "hit": false
          },
          {
            "score": 0.6343435049057007,
            "answer": "wished",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6850774586200714
      }
    ],
    "result": {
      "cnt_questions_correct": 17,
      "cnt_questions_total": 30,
      "accuracy": 0.5666666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2f27ac11-dd15-418c-965b-138e20fe39e2",
      "timestamp": "2025-05-17T21:30:07.283796"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.6485333442687988,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.6448943018913269,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.6296405792236328,
            "answer": "accordingly",
            "hit": true
          },
          {
            "score": 0.6279206275939941,
            "answer": "reportedly",
            "hit": false
          },
          {
            "score": 0.6245755553245544,
            "answer": "specifically",
            "hit": false
          },
          {
            "score": 0.6231986284255981,
            "answer": "unfortunately",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.629640594124794
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.6797943711280823,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.6081390380859375,
            "answer": "allegedly",
            "hit": false
          },
          {
            "score": 0.6076043248176575,
            "answer": "currently",
            "hit": false
          },
          {
            "score": 0.6046487092971802,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.6013862490653992,
            "answer": "actively",
            "hit": false
          },
          {
            "score": 0.6008154153823853,
            "answer": "intentionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6797943711280823
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.6596019268035889,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.6499978303909302,
            "answer": "supplementary",
            "hit": false
          },
          {
            "score": 0.6171480417251587,
            "answer": "previously",
            "hit": false
          },
          {
            "score": 0.6170519590377808,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.6144848465919495,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.6109732389450073,
            "answer": "importantly",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6596019119024277
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.7102936506271362,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.6848644614219666,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.680234968662262,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.6621682643890381,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6576455235481262,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.6416863203048706,
            "answer": "clearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6342783868312836
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.782011091709137,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.760478138923645,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.7423340082168579,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.7269682884216309,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.6973792314529419,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.6793908476829529,
            "answer": "handsome",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7604781687259674
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7173488736152649,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.629877507686615,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6247254610061646,
            "answer": "negatively",
            "hit": false
          },
          {
            "score": 0.6095200181007385,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6053797602653503,
            "answer": "positively",
            "hit": false
          },
          {
            "score": 0.6013703346252441,
            "answer": "critics",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7173488736152649
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.7541567087173462,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.6731745004653931,
            "answer": "cultures",
            "hit": false
          },
          {
            "score": 0.637398362159729,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.6366549730300903,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.6223891973495483,
            "answer": "politically",
            "hit": false
          },
          {
            "score": 0.6181130409240723,
            "answer": "literary",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.754156768321991
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.659289538860321,
            "answer": "argued",
            "hit": false
          },
          {
            "score": 0.6120707988739014,
            "answer": "supreme",
            "hit": false
          },
          {
            "score": 0.6077778935432434,
            "answer": "appeals",
            "hit": false
          },
          {
            "score": 0.5951310396194458,
            "answer": "judges",
            "hit": false
          },
          {
            "score": 0.5930204391479492,
            "answer": "unanimously",
            "hit": false
          },
          {
            "score": 0.5919862389564514,
            "answer": "submitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5758214443922043
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7697649598121643,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.694934606552124,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.6937093734741211,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.6840687990188599,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.6737549304962158,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.669329047203064,
            "answer": "differ",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7697649300098419
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.7293063402175903,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.6198025941848755,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6157954335212708,
            "answer": "digit",
            "hit": false
          },
          {
            "score": 0.6073083877563477,
            "answer": "financially",
            "hit": false
          },
          {
            "score": 0.6029040813446045,
            "answer": "commercially",
            "hit": false
          },
          {
            "score": 0.6013031601905823,
            "answer": "internationally",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7293063104152679
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7390691041946411,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.6831533908843994,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6830568909645081,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.6372264623641968,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.6362212896347046,
            "answer": "adequately",
            "hit": false
          },
          {
            "score": 0.6349887847900391,
            "answer": "efficiently",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7390691041946411
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.7412821054458618,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.7258274555206299,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.6786832809448242,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6474809646606445,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.6330357789993286,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.6300872564315796,
            "answer": "ecology",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7412821352481842
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.7492031455039978,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.6600402593612671,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.6583670377731323,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.6577849984169006,
            "answer": "thoroughly",
            "hit": false
          },
          {
            "score": 0.6510849595069885,
            "answer": "widespread",
            "hit": false
          },
          {
            "score": 0.6485426425933838,
            "answer": "comprehensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7492031753063202
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.764593780040741,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.747820258140564,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7384543418884277,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7203119993209839,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7074431777000427,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6618070602416992,
            "answer": "known",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7203120589256287
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7478766441345215,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.6534308195114136,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6442187428474426,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.6412395238876343,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.619652509689331,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.6183645129203796,
            "answer": "environmentally",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7478766143321991
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.7082901000976562,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.6569180488586426,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6285269260406494,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.6069599986076355,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.6044935584068298,
            "answer": "local",
            "hit": false
          },
          {
            "score": 0.6010645627975464,
            "answer": "locally",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7082901149988174
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.7051229476928711,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.6601392030715942,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.6466872096061707,
            "answer": "history",
            "hit": false
          },
          {
            "score": 0.642692506313324,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.635076642036438,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.6349736452102661,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7051230072975159
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.7778266668319702,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.7498117685317993,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7402913570404053,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.7208435535430908,
            "answer": "big",
            "hit": false
          },
          {
            "score": 0.7191617488861084,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.7087283134460449,
            "answer": "massive",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7402913421392441
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.7257604598999023,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.6946713924407959,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.6462279558181763,
            "answer": "readily",
            "hit": false
          },
          {
            "score": 0.6427632570266724,
            "answer": "directly",
            "hit": false
          },
          {
            "score": 0.6374346613883972,
            "answer": "promptly",
            "hit": false
          },
          {
            "score": 0.6317468881607056,
            "answer": "quickly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7257604449987411
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.6746063232421875,
            "answer": "importance",
            "hit": false
          },
          {
            "score": 0.6428744196891785,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6214879751205444,
            "answer": "importantly",
            "hit": true
          },
          {
            "score": 0.6185256242752075,
            "answer": "significantly",
            "hit": false
          },
          {
            "score": 0.6162991523742676,
            "answer": "insignificant",
            "hit": false
          },
          {
            "score": 0.6075252294540405,
            "answer": "overwhelmingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6214879602193832
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.723118782043457,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.6844473481178284,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.67946457862854,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.6586006879806519,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.6411842703819275,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.640501856803894,
            "answer": "progressively",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6794645488262177
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7221720814704895,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.6489167809486389,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6030949354171753,
            "answer": "centrally",
            "hit": false
          },
          {
            "score": 0.6030723452568054,
            "answer": "locally",
            "hit": false
          },
          {
            "score": 0.6014865636825562,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.5970300436019897,
            "answer": "interior",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7221720814704895
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.7303630113601685,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.6548483967781067,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6320820450782776,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.6102973222732544,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.6041032075881958,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.6037998795509338,
            "answer": "overseas",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7303630411624908
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.732049822807312,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.6675137281417847,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.6576467752456665,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.608755886554718,
            "answer": "criminal",
            "hit": false
          },
          {
            "score": 0.6085278987884521,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6052902936935425,
            "answer": "technically",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7320498526096344
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.7470419406890869,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.6671794652938843,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.6386293172836304,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.6330716609954834,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.6125713586807251,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.608757495880127,
            "answer": "psychologists",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7470419704914093
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.7327951192855835,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.6936435103416443,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.6493635773658752,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.642462968826294,
            "answer": "neat",
            "hit": false
          },
          {
            "score": 0.6418007016181946,
            "answer": "cute",
            "hit": false
          },
          {
            "score": 0.6371667385101318,
            "answer": "neatly",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7327950894832611
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.7060357332229614,
            "answer": "obviously",
            "hit": true
          },
          {
            "score": 0.6860834360122681,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.6830146908760071,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.6781011819839478,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.6638956069946289,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.6474103927612305,
            "answer": "plainly",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7060357630252838
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.7848790884017944,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.6216971278190613,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.6196188926696777,
            "answer": "financially",
            "hit": false
          },
          {
            "score": 0.6178826093673706,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.6133230924606323,
            "answer": "mechanically",
            "hit": false
          },
          {
            "score": 0.6127540469169617,
            "answer": "economically",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7848790884017944
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.7996779680252075,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.6654280424118042,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6652967929840088,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.6582884788513184,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.6388015151023865,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.6376159191131592,
            "answer": "politician",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7996780276298523
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.6811836361885071,
            "answer": "practically",
            "hit": true
          },
          {
            "score": 0.640148401260376,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6225261092185974,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.6190317869186401,
            "answer": "economically",
            "hit": false
          },
          {
            "score": 0.6147009134292603,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.6133004426956177,
            "answer": "realistic",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6811836361885071
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7745243310928345,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.7161819934844971,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.6481832265853882,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.6466288566589355,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.6391540765762329,
            "answer": "past",
            "hit": false
          },
          {
            "score": 0.6356781721115112,
            "answer": "earlier",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7745243310928345
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7154819369316101,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7123817801475525,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.6605948805809021,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.6456155776977539,
            "answer": "unusually",
            "hit": false
          },
          {
            "score": 0.6451619863510132,
            "answer": "seldom",
            "hit": false
          },
          {
            "score": 0.6329249739646912,
            "answer": "scarce",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7123818248510361
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.6929764151573181,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.6689541339874268,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.659574568271637,
            "answer": "severely",
            "hit": false
          },
          {
            "score": 0.6423596143722534,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.6168097257614136,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.615042507648468,
            "answer": "significantly",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6689541339874268
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8237941861152649,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.6991015672683716,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.660801887512207,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.6582176685333252,
            "answer": "sex",
            "hit": false
          },
          {
            "score": 0.649925947189331,
            "answer": "heterosexual",
            "hit": false
          },
          {
            "score": 0.6474195122718811,
            "answer": "erotic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8237941861152649
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.843906819820404,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.7333000898361206,
            "answer": "significance",
            "hit": false
          },
          {
            "score": 0.6934521794319153,
            "answer": "insignificant",
            "hit": false
          },
          {
            "score": 0.6740031242370605,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.6665035486221313,
            "answer": "dramatically",
            "hit": false
          },
          {
            "score": 0.6626709699630737,
            "answer": "substantially",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8439068496227264
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7157987952232361,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.6342753767967224,
            "answer": "likewise",
            "hit": false
          },
          {
            "score": 0.6289209723472595,
            "answer": "identical",
            "hit": false
          },
          {
            "score": 0.6286458969116211,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.6244950890541077,
            "answer": "akin",
            "hit": false
          },
          {
            "score": 0.6230793595314026,
            "answer": "similarities",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7157987803220749
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.7368792295455933,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.6966976523399353,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6769160628318787,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6397851705551147,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.6391867399215698,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6349226236343384,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7368791997432709
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.7870683670043945,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7012252807617188,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.6686347723007202,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.6535675525665283,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.652004599571228,
            "answer": "previously",
            "hit": false
          },
          {
            "score": 0.6486815810203552,
            "answer": "resultant",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7870684266090393
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.808081328868866,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.75416100025177,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.6950627565383911,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.6842367649078369,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.6832790374755859,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.6719858646392822,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8080812692642212
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.7911826372146606,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.7041827440261841,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.6805448532104492,
            "answer": "traditions",
            "hit": false
          },
          {
            "score": 0.6747512221336365,
            "answer": "tradition",
            "hit": false
          },
          {
            "score": 0.6527644991874695,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.651331901550293,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7911826074123383
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.7485247254371643,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.6679569482803345,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.644209086894989,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.6425696611404419,
            "answer": "characteristic",
            "hit": false
          },
          {
            "score": 0.6365092992782593,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.6307328939437866,
            "answer": "traditionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7485247254371643
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.7809699773788452,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.6754563450813293,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.6464511156082153,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.6293349266052246,
            "answer": "peculiar",
            "hit": false
          },
          {
            "score": 0.6128348112106323,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.6102792620658875,
            "answer": "unusual",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.78097003698349
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.6447147130966187,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.629709005355835,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.6014974117279053,
            "answer": "automatically",
            "hit": false
          },
          {
            "score": 0.6000849604606628,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.5885142683982849,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.585407018661499,
            "answer": "electronically",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6447147130966187
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.719171941280365,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.6192715764045715,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.610459566116333,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.5995693206787109,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.5953969359397888,
            "answer": "culturally",
            "hit": false
          },
          {
            "score": 0.5903484225273132,
            "answer": "vision",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.719171941280365
      }
    ],
    "result": {
      "cnt_questions_correct": 34,
      "cnt_questions_total": 44,
      "accuracy": 0.7727272727272727
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "a1889db2-4329-498d-81b7-d3079142bfba",
      "timestamp": "2025-05-17T21:30:07.405757"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7281137108802795,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7004260420799255,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.6470064520835876,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6395362615585327,
            "answer": "knew",
            "hit": false
          },
          {
            "score": 0.6275240778923035,
            "answer": "realize",
            "hit": false
          },
          {
            "score": 0.6265931129455566,
            "answer": "realise",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7004260718822479
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.7705308198928833,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.737628698348999,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.707787811756134,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6712545156478882,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.6478334069252014,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6225351691246033,
            "answer": "conscience",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7705308198928833
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7101415991783142,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.6879093647003174,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6806843280792236,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6397638320922852,
            "answer": "efficiency",
            "hit": false
          },
          {
            "score": 0.6165610551834106,
            "answer": "excellence",
            "hit": false
          },
          {
            "score": 0.6132110953330994,
            "answer": "weakness",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7101415693759918
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.6664021015167236,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.6507055163383484,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.6376857757568359,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.6271657347679138,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6200627088546753,
            "answer": "happily",
            "hit": false
          },
          {
            "score": 0.6124210953712463,
            "answer": "sweetness",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.666402131319046
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.672979474067688,
            "answer": "crazy",
            "hit": false
          },
          {
            "score": 0.6609774231910706,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.6579993963241577,
            "answer": "insane",
            "hit": false
          },
          {
            "score": 0.6168242692947388,
            "answer": "angry",
            "hit": false
          },
          {
            "score": 0.6150377988815308,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6090888977050781,
            "answer": "sadness",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6609774380922318
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7462513446807861,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.6534124612808228,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6533634066581726,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.6476832032203674,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.6391884088516235,
            "answer": "sadly",
            "hit": false
          },
          {
            "score": 0.6383074522018433,
            "answer": "tragedy",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7462513595819473
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.7067086696624756,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.6339207887649536,
            "answer": "severe",
            "hit": false
          },
          {
            "score": 0.6294543147087097,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.627654492855072,
            "answer": "madness",
            "hit": false
          },
          {
            "score": 0.6254764199256897,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6233748197555542,
            "answer": "sadness",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7067086696624756
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.671320915222168,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.6612452268600464,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6429943442344666,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.6336896419525146,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.6250667572021484,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.6139370203018188,
            "answer": "stronger",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.671320915222168
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 8,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7b680642-adbd-49ff-a185-03ae59ee5b29",
      "timestamp": "2025-05-17T21:30:07.592682"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.6943122744560242,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.6789215803146362,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.6657688617706299,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.6611543893814087,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.631382405757904,
            "answer": "acceptable",
            "hit": true
          },
          {
            "score": 0.6155336499214172,
            "answer": "unacceptable",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.631382405757904
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.7233654260635376,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.7128680944442749,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.7034157514572144,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.690544843673706,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.6662005186080933,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.6184922456741333,
            "answer": "acceptable",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6662005484104156
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.7411987781524658,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.6769481897354126,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.6303602457046509,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.6228471398353577,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.6154537200927734,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.6133775115013123,
            "answer": "expensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.676948145031929
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7940720915794373,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7630672454833984,
            "answer": "considered",
            "hit": false
          },
          {
            "score": 0.6916722059249878,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.6848920583724976,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6384195685386658,
            "answer": "considerations",
            "hit": false
          },
          {
            "score": 0.6293203234672546,
            "answer": "discussed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5862483829259872
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.8237109184265137,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.823693037033081,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8205074071884155,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7263843417167664,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.6960718035697937,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.648456335067749,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7263844162225723
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8337615132331848,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.820279598236084,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7290016412734985,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7149301171302795,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.6813210844993591,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.637993574142456,
            "answer": "unidentified",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6813210844993591
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8534214496612549,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.7880243062973022,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7521316409111023,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.7355539798736572,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.677230954170227,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.6398099660873413,
            "answer": "unpredictable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.677230954170227
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8502510190010071,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8107074499130249,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8058081865310669,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.7439358830451965,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.6663058996200562,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.6564003229141235,
            "answer": "depends",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6172241419553757
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.6494138240814209,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.6419756412506104,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.636046290397644,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.6130232810974121,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.6067548394203186,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.585298478603363,
            "answer": "immortal",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6419756710529327
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8164564371109009,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.7785276174545288,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.6723744869232178,
            "answer": "sustainable",
            "hit": true
          },
          {
            "score": 0.6222970485687256,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.6169939637184143,
            "answer": "upheld",
            "hit": false
          },
          {
            "score": 0.6098157167434692,
            "answer": "uphold",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6723745167255402
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8486195206642151,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.7983930110931396,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.7469230890274048,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.6829720139503479,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.6767548322677612,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.6699005365371704,
            "answer": "differs",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6058370098471642
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "59e5c5c1-2e77-40ea-acf6-25aa9e31e4c7",
      "timestamp": "2025-05-17T21:30:07.622590"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.6651837825775146,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.659232497215271,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.6590648889541626,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.624502420425415,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6098014116287231,
            "answer": "believers",
            "hit": false
          },
          {
            "score": 0.6089250445365906,
            "answer": "disbelief",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6029318571090698
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8423435091972351,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.7408511638641357,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.6616607904434204,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.6581307649612427,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6500517725944519,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.6060271263122559,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6581307947635651
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.7929727435112,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.7332995533943176,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.6810890436172485,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6485735774040222,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.6390169858932495,
            "answer": "consumer",
            "hit": true
          },
          {
            "score": 0.6267395615577698,
            "answer": "eats",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6390170156955719
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7278916239738464,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.7088576555252075,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.6799612045288086,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.666243851184845,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.6394096612930298,
            "answer": "arguing",
            "hit": false
          },
          {
            "score": 0.6263217926025391,
            "answer": "asserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.610450804233551
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8208144903182983,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8207463026046753,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.6900309324264526,
            "answer": "defence",
            "hit": false
          },
          {
            "score": 0.6688486933708191,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.6596941351890564,
            "answer": "defenses",
            "hit": false
          },
          {
            "score": 0.6496968865394592,
            "answer": "defense",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5946098566055298
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.8322869539260864,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8315457105636597,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8235740661621094,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.6969336271286011,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6620165109634399,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6558317542076111,
            "answer": "developers",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 183,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5635311156511307
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.847728967666626,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.828762412071228,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7883129119873047,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.6816112399101257,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.6760618686676025,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.661774754524231,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6297557950019836
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8685146570205688,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8560248613357544,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.7853249311447144,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7692769765853882,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.6825059056282043,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.654036283493042,
            "answer": "investigating",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6044294834136963
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7284930944442749,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6915779113769531,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6248654127120972,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.6177522540092468,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6171017289161682,
            "answer": "followers",
            "hit": false
          },
          {
            "score": 0.5863670706748962,
            "answer": "after",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6248654276132584
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8217227458953857,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.8060076236724854,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.7900434136390686,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.7630166411399841,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.6720641255378723,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.6080418825149536,
            "answer": "observers",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6720641255378723
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.7550516128540039,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.735478401184082,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.684449315071106,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6201115250587463,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.5932596921920776,
            "answer": "speakers",
            "hit": false
          },
          {
            "score": 0.58855140209198,
            "answer": "teacher",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6201115250587463
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.8522580862045288,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8403460383415222,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.6903519630432129,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6722555160522461,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6569967865943909,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.6428552865982056,
            "answer": "gaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6369133144617081
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.82830810546875,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.820148229598999,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8068512082099915,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.671027421951294,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.6612066030502319,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6128125786781311,
            "answer": "manager",
            "hit": true
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6128125935792923
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.6822980642318726,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.6674281358718872,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6565781831741333,
            "answer": "notice",
            "hit": false
          },
          {
            "score": 0.6312556266784668,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.6278771162033081,
            "answer": "remark",
            "hit": false
          },
          {
            "score": 0.6259592175483704,
            "answer": "observer",
            "hit": true
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6259592473506927
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8470053672790527,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8097476363182068,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7438815832138062,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.7338076829910278,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.7111314535140991,
            "answer": "organization",
            "hit": false
          },
          {
            "score": 0.6992124915122986,
            "answer": "organizers",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7338076680898666
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.6915757656097412,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.6812013387680054,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.6633177995681763,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.6516229510307312,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.6463885307312012,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6353585124015808,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6516229659318924
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8198956847190857,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.708702564239502,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.6749454140663147,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.6281704306602478,
            "answer": "missionaries",
            "hit": false
          },
          {
            "score": 0.6268078684806824,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.6219210624694824,
            "answer": "believer",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7087025940418243
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8852542638778687,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.861170768737793,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7993438243865967,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7457386255264282,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.6883782744407654,
            "answer": "promotions",
            "hit": false
          },
          {
            "score": 0.637694776058197,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.608383409678936
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.6997231841087341,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.6965583562850952,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6761731505393982,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6144498586654663,
            "answer": "provision",
            "hit": false
          },
          {
            "score": 0.6138162612915039,
            "answer": "provider",
            "hit": true
          },
          {
            "score": 0.6084803342819214,
            "answer": "providers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6138163208961487
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.7406905293464661,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.6720261573791504,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.6291107535362244,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.6265056729316711,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.6007307171821594,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.5983401536941528,
            "answer": "editors",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6720261871814728
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.7113274335861206,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.6999794244766235,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.694837212562561,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6280356645584106,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.6235809326171875,
            "answer": "recipients",
            "hit": false
          },
          {
            "score": 0.6161594390869141,
            "answer": "reception",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.614163413643837
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.8230947852134705,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.8038402795791626,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.7861325740814209,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.6561652421951294,
            "answer": "spoken",
            "hit": false
          },
          {
            "score": 0.6510904431343079,
            "answer": "speakers",
            "hit": false
          },
          {
            "score": 0.6489819288253784,
            "answer": "speaker",
            "hit": true
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6489819437265396
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8463606834411621,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8352919220924377,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8142856955528259,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.6937309503555298,
            "answer": "teacher",
            "hit": true
          },
          {
            "score": 0.6756046414375305,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.6550014019012451,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6937309801578522
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.66459059715271,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.6466823816299438,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.635341227054596,
            "answer": "read",
            "hit": false
          },
          {
            "score": 0.6322060823440552,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.6258035898208618,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.6058561205863953,
            "answer": "written",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6258036345243454
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "91cc1948-8aec-47ce-b20c-e3b49faac4a6",
      "timestamp": "2025-05-17T21:30:07.664373"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8367496728897095,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8055517077445984,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.7227360606193542,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.7218582630157471,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.646862268447876,
            "answer": "suspected",
            "hit": false
          },
          {
            "score": 0.6357585191726685,
            "answer": "allegations",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7227360755205154
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8046135902404785,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.7372227311134338,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.6132744550704956,
            "answer": "praised",
            "hit": false
          },
          {
            "score": 0.6130487322807312,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.6119444370269775,
            "answer": "appreciated",
            "hit": false
          },
          {
            "score": 0.6082017421722412,
            "answer": "inspiration",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7372227311134338
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.6760761737823486,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.6574581861495972,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.6510469317436218,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.6343678832054138,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.623677670955658,
            "answer": "calculating",
            "hit": false
          },
          {
            "score": 0.6232090592384338,
            "answer": "calculate",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6760761737823486
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.6761200428009033,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6623200178146362,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.6595635414123535,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.6310181617736816,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.6263577938079834,
            "answer": "return",
            "hit": false
          },
          {
            "score": 0.5999251008033752,
            "answer": "continual",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6310181766748428
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8079214096069336,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8028019666671753,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.7919347882270813,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.734292209148407,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.6425118446350098,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.611096203327179,
            "answer": "statements",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.734292209148407
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8385166525840759,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7991518974304199,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7826720476150513,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7250787019729614,
            "answer": "determination",
            "hit": true
          },
          {
            "score": 0.6638467311859131,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.6482549905776978,
            "answer": "calculate",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.725078672170639
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8472248315811157,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8306894898414612,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.794822096824646,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7117737531661987,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.6876773834228516,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6650665402412415,
            "answer": "investigated",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6584013998508453
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8724260330200195,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8535708785057068,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.793109118938446,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.7854341268539429,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6937853097915649,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.6615790128707886,
            "answer": "investigating",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.793109118938446
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.764507532119751,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.7634168863296509,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.6361591219902039,
            "answer": "envisioned",
            "hit": false
          },
          {
            "score": 0.6317827701568604,
            "answer": "imagination",
            "hit": true
          },
          {
            "score": 0.6116161346435547,
            "answer": "pictured",
            "hit": false
          },
          {
            "score": 0.6071742177009583,
            "answer": "possibility",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6317827701568604
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.7740219235420227,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7372024059295654,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.6940335035324097,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.6254462599754333,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6244570016860962,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.6179424524307251,
            "answer": "motivation",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7372023612260818
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.688118040561676,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.6737328767776489,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.6629517078399658,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.6597638130187988,
            "answer": "notice",
            "hit": false
          },
          {
            "score": 0.6510981321334839,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6399581432342529,
            "answer": "remark",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6629516929388046
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8630663156509399,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8339537382125854,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8025321364402771,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.6984254717826843,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.6671611070632935,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.6155871152877808,
            "answer": "inhabit",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6984255015850067
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8450496792793274,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8136143684387207,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7494922280311584,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.7183609008789062,
            "answer": "organization",
            "hit": true
          },
          {
            "score": 0.7046102285385132,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.6764135956764221,
            "answer": "organizers",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7183609157800674
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.67975914478302,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.672635555267334,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.6610344052314758,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.6608915328979492,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.6590509414672852,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.6367107033729553,
            "answer": "prep",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6608915627002716
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.8517366647720337,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8082979917526245,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.8030052185058594,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.6438113451004028,
            "answer": "recovery",
            "hit": false
          },
          {
            "score": 0.6328662633895874,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.63173508644104,
            "answer": "rebuilding",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.803005188703537
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8267760276794434,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8220365047454834,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.7217870950698853,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6735719442367554,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.6157276034355164,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.6064417362213135,
            "answer": "maintenance",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8267760276794434
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 16,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d2b703be-ed1d-41a8-bef4-6426aa1655a4",
      "timestamp": "2025-05-17T21:30:07.760115"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8011640310287476,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.728146493434906,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.6974241137504578,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.6835300922393799,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.6698354482650757,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.6613219976425171,
            "answer": "achievement",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.728146493434906
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.8840512633323669,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8373395800590515,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7223680019378662,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7181799411773682,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.6830927133560181,
            "answer": "achievements",
            "hit": false
          },
          {
            "score": 0.6809025406837463,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7223680019378662
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.767470121383667,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.7286785840988159,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.727439284324646,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.707137942314148,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.6267849802970886,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.5912817120552063,
            "answer": "improvement",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.767470121383667
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.7479446530342102,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7353439927101135,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7284461259841919,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7054166793823242,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.691728949546814,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6659387350082397,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6399928331375122
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.697524905204773,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.5871832966804504,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.5823578238487244,
            "answer": "fulfillment",
            "hit": false
          },
          {
            "score": 0.5810283422470093,
            "answer": "registration",
            "hit": false
          },
          {
            "score": 0.5774785280227661,
            "answer": "attributes",
            "hit": false
          },
          {
            "score": 0.5768742561340332,
            "answer": "setting",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.697524905204773
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.7304974794387817,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.7138757705688477,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7111838459968567,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.6062890291213989,
            "answer": "modification",
            "hit": false
          },
          {
            "score": 0.601290225982666,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.5904392600059509,
            "answer": "adjustment",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7304974496364594
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8434606790542603,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8338527679443359,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.8336686491966248,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7897548675537109,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.748863935470581,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6287712454795837,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7897549271583557
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8136575222015381,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.7385863065719604,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.6987821459770203,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.6111607551574707,
            "answer": "election",
            "hit": false
          },
          {
            "score": 0.6088473796844482,
            "answer": "hire",
            "hit": false
          },
          {
            "score": 0.6038473844528198,
            "answer": "assignment",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7385863214731216
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8749326467514038,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8328460454940796,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.723624587059021,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.7228807210922241,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.6418681144714355,
            "answer": "organised",
            "hit": false
          },
          {
            "score": 0.6271874904632568,
            "answer": "organize",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7236246466636658
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8486579060554504,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8301069736480713,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8172614574432373,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.7840672731399536,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.7304770350456238,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.6944832801818848,
            "answer": "evaluated",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8172614574432373
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8177496194839478,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.8009506464004517,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.7658584117889404,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.741210401058197,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.6367077827453613,
            "answer": "allocated",
            "hit": false
          },
          {
            "score": 0.6167778372764587,
            "answer": "allocation",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7658584415912628
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.7339898347854614,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.7305910587310791,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.7204959392547607,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.7137352228164673,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.6796680092811584,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.6139929890632629,
            "answer": "committee",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7137352079153061
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.8393210172653198,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8377033472061157,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8352450132369995,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7290823459625244,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.6920285224914551,
            "answer": "developments",
            "hit": false
          },
          {
            "score": 0.6420488357543945,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.729082316160202
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8167643547058105,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7428811192512512,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7307621836662292,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.6653546094894409,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.6614955067634583,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.6365824937820435,
            "answer": "agreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7428811192512512
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8177412748336792,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7966299057006836,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7797043323516846,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.7432851195335388,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.7060638666152954,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.6595684289932251,
            "answer": "discouraged",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7432850897312164
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.858744204044342,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.7759313583374023,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7405805587768555,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.6379953622817993,
            "answer": "forcing",
            "hit": false
          },
          {
            "score": 0.6219930052757263,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.6131651997566223,
            "answer": "punishment",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7405805885791779
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.8781641125679016,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8770198822021484,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8443901538848877,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.7805080413818359,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.6410692930221558,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6233171224594116,
            "answer": "participation",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7805080413818359
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.84470534324646,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.815073549747467,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.7836824059486389,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.6539188623428345,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6509696245193481,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.6497811079025269,
            "answer": "increases",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7836824059486389
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.8390871286392212,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.8302807211875916,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.8299490213394165,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7190452814102173,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.6997594237327576,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6282920837402344,
            "answer": "loves",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7190453261137009
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8292528986930847,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7843481302261353,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.6511474251747131,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.6156847476959229,
            "answer": "amusement",
            "hit": false
          },
          {
            "score": 0.5985227227210999,
            "answer": "television",
            "hit": false
          },
          {
            "score": 0.5981853008270264,
            "answer": "hospitality",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6511474251747131
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8800083994865417,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8441526293754578,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.841846227645874,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7213503122329712,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.6447186470031738,
            "answer": "demonstrate",
            "hit": false
          },
          {
            "score": 0.6329367160797119,
            "answer": "demonstrated",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7213503420352936
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.813363254070282,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.7978177666664124,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.7437843084335327,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.6834515333175659,
            "answer": "fills",
            "hit": false
          },
          {
            "score": 0.6430799961090088,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.62958163022995,
            "answer": "satisfying",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7437843382358551
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.777607798576355,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7515311241149902,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.7407069206237793,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7375259399414062,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7114554047584534,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.6377331018447876,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7515310943126678
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.8463262319564819,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.8295849561691284,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7730261087417603,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7230550050735474,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.7007615566253662,
            "answer": "investors",
            "hit": false
          },
          {
            "score": 0.6838345527648926,
            "answer": "investor",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7230550348758698
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8803397417068481,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8135249018669128,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7824212908744812,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.7243454456329346,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.6321458220481873,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6282814145088196,
            "answer": "includes",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7243454456329346
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8310627937316895,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.8195344805717468,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8109873533248901,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.6990678310394287,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.6525251865386963,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6085970401763916,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6990678459405899
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8108976483345032,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.7769719362258911,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.6382609605789185,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.6260541081428528,
            "answer": "penalty",
            "hit": false
          },
          {
            "score": 0.6248579025268555,
            "answer": "imprisonment",
            "hit": false
          },
          {
            "score": 0.6231939792633057,
            "answer": "reward",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7769719660282135
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.7967125177383423,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.7509442567825317,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.6728919744491577,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.664472222328186,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6593961715698242,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.6299773454666138,
            "answer": "encouragement",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.750944197177887
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.8697834610939026,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8373273015022278,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.8243957161903381,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.730462908744812,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7238735556602478,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.651618480682373,
            "answer": "placement",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7238735556602478
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.7372379899024963,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7300283908843994,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.671323299407959,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6603220105171204,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6198402643203735,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6053035259246826,
            "answer": "obligation",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7300284057855606
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 30,
      "accuracy": 0.1
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "548685ed-8a19-4b4a-ba1e-e83fabd792b2",
      "timestamp": "2025-05-17T21:30:07.821844"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.7783243060112,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7086174488067627,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.707473635673523,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.670951783657074,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.6693071722984314,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6637812852859497,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7783243060112
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.7493621110916138,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.739499568939209,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7092685699462891,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.679878830909729,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.6744990348815918,
            "answer": "kuwait",
            "hit": false
          },
          {
            "score": 0.6664462685585022,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.749362051486969
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.817287802696228,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.7166200876235962,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.7024542689323425,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.6877116560935974,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.6757724285125732,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.6722301840782166,
            "answer": "japan",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8172878623008728
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.774121880531311,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.6777862310409546,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.6724106073379517,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.6711870431900024,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.669079601764679,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.6686357855796814,
            "answer": "taiwan",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.774121880531311
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.7540137767791748,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.691665768623352,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.6875432729721069,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6854824423789978,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.6825598478317261,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.6754870414733887,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.75401371717453
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.625595211982727,
            "answer": "bernard",
            "hit": false
          },
          {
            "score": 0.6206116676330566,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.6152807474136353,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.6121018528938293,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6078168153762817,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.600472092628479,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6078168451786041
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.7196598052978516,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.6787959337234497,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6686186790466309,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.667186975479126,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6657990217208862,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.662778377532959,
            "answer": "netherlands",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.719659835100174
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.7879049777984619,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.7592385411262512,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.6780219078063965,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.6773838996887207,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6770782470703125,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.6732462048530579,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7879048883914948
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.7384883761405945,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.701657772064209,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.6692571043968201,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.6539338827133179,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6537289619445801,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.6527546644210815,
            "answer": "greece",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7384883910417557
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.751772940158844,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.72141432762146,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7039892077445984,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.6989738941192627,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.6675512790679932,
            "answer": "netherlands",
            "hit": false
          },
          {
            "score": 0.6660338640213013,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.751772940158844
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.7268248200416565,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.6743253469467163,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.661966860294342,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.6618121862411499,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.6583821177482605,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.6565238237380981,
            "answer": "lebanon",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7268248498439789
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.7967402935028076,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.6822023391723633,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.6698335409164429,
            "answer": "scotland",
            "hit": false
          },
          {
            "score": 0.665924072265625,
            "answer": "australia",
            "hit": false
          },
          {
            "score": 0.6647080183029175,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.6634141206741333,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7967402935028076
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.7259277701377869,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.6901487112045288,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.6763944029808044,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6672801375389099,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.6513093709945679,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.6510153412818909,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7259277701377869
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.651552677154541,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.6266708970069885,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.6219049692153931,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.6170400381088257,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.6152795553207397,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.6125848889350891,
            "answer": "ireland",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6515526175498962
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.7544288635253906,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.7027475237846375,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6956002116203308,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6806731224060059,
            "answer": "brazil",
            "hit": false
          },
          {
            "score": 0.6713125109672546,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6644989848136902,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7544288635253906
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.7561157941818237,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.6991019248962402,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6941598653793335,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.6795319318771362,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.6745312213897705,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6631575226783752,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7561158239841461
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.7853673696517944,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.7427817583084106,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.6809552907943726,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.6708526015281677,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.6605170965194702,
            "answer": "india",
            "hit": false
          },
          {
            "score": 0.6560152769088745,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7853673696517944
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.791530966758728,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.7121516466140747,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.707805335521698,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7055484056472778,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.6923971176147461,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6862756013870239,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7915310263633728
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.7488587498664856,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.7137861251831055,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.6875511407852173,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.685440182685852,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.6645711064338684,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6576591730117798,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7488587498664856
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.7179821133613586,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.7005303502082825,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.6940704584121704,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.6938766837120056,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.6867293119430542,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.6858292818069458,
            "answer": "toronto",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7179820984601974
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.7420506477355957,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.707702100276947,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6837522983551025,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6736266613006592,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6586374640464783,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.656451404094696,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7420506030321121
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.737964928150177,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.6909797787666321,
            "answer": "romans",
            "hit": false
          },
          {
            "score": 0.6845836639404297,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6833990812301636,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6791382431983948,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.6742587089538574,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7379649430513382
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.6508468985557556,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.6484330892562866,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.646653413772583,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6366453766822815,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.6337826251983643,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.629503607749939,
            "answer": "croatia",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6508469581604004
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.7685855031013489,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.739305853843689,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7195698022842407,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7137494087219238,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.680520236492157,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6757204532623291,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7685855329036713
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.796542763710022,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.7622123956680298,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.6667208671569824,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6649837493896484,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.6648862361907959,
            "answer": "turkey",
            "hit": false
          },
          {
            "score": 0.6631209850311279,
            "answer": "russia",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.796542763710022
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.7514117360115051,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.6829659938812256,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6813466548919678,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6711577773094177,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.657379150390625,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.6545982956886292,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7514117360115051
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.7337917685508728,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.701269268989563,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.692834734916687,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6853835582733154,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6845268607139587,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6819723844528198,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7337917983531952
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.7505347728729248,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.6817861795425415,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.6804616451263428,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6771355271339417,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.6699224710464478,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6664270162582397,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7505348026752472
      }
    ],
    "result": {
      "cnt_questions_correct": 27,
      "cnt_questions_total": 28,
      "accuracy": 0.9642857142857143
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "849f6730-ab16-4c2e-941d-369d91989946",
      "timestamp": "2025-05-17T21:30:07.942329"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7486065626144409,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7485870122909546,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6866965293884277,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6857237219810486,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6769263744354248,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6705321073532104,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7485870718955994
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7516913414001465,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7163500189781189,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7054163217544556,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6629167795181274,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6626852750778198,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6617847084999084,
            "answer": "english",
            "hit": true
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6617847084999084
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7432308197021484,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6971112489700317,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6951432228088379,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6817132830619812,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6767106652259827,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6619809865951538,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817132830619812
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.76627117395401,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7337607145309448,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6930027008056641,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.6863544583320618,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6797049641609192,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6611121892929077,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6930026859045029
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.7399240732192993,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7168962359428406,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7022445201873779,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.6768336296081543,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.6566831469535828,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6505602598190308,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6566831767559052
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7325101494789124,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6828675270080566,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.66558438539505,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6636125445365906,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6607833504676819,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6605770587921143,
            "answer": "argentine",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7325101494789124
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7389104962348938,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.696079671382904,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6770926713943481,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.667556881904602,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6589587926864624,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6514522433280945,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7389104813337326
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7556671500205994,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7385392189025879,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6695437431335449,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6589212417602539,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6565084457397461,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6482493877410889,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7385391891002655
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.7098193168640137,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6770447492599487,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6534100770950317,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6502880454063416,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.64333176612854,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6341724395751953,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5707847625017166
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8153610825538635,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7076060771942139,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7031381130218506,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6884183883666992,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6683387756347656,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6625884771347046,
            "answer": "cairo",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7031381130218506
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7323802709579468,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6879714131355286,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6535304188728333,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6489103436470032,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6486963629722595,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6470564007759094,
            "answer": "mexico",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7323802709579468
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.7854177951812744,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.706379771232605,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7038387060165405,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.6829639673233032,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6786506175994873,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.6669638156890869,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6786505877971649
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.7837072610855103,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7054231762886047,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6838691234588623,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6693234443664551,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.6532793641090393,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6523061990737915,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7054231762886047
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7603884935379028,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7045416235923767,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6881958842277527,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.6874139904975891,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6760120391845703,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6720014810562134,
            "answer": "arabic",
            "hit": true
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6590352803468704
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.6929758787155151,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6601141691207886,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6527457237243652,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6465951204299927,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6320048570632935,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6277313828468323,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6601141691207886
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7101536393165588,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6941379308700562,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6643917560577393,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6558368802070618,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6421709060668945,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.6413875818252563,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6941379308700562
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7467352151870728,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.6929869651794434,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6909213066101074,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.6820595860481262,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6669713854789734,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6520532369613647,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6820595860481262
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7056996822357178,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6731712222099304,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6625068187713623,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6568064093589783,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6388457417488098,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.6270515322685242,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7056997120380402
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.7290383577346802,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.717650294303894,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6861507296562195,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.6800869703292847,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6773385405540466,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6620206236839294,
            "answer": "italian",
            "hit": true
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6773385107517242
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8061184287071228,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.7086434364318848,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.682974636554718,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6610122919082642,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.6553603410720825,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6535842418670654,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6829746216535568
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.7033343315124512,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.668286919593811,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6668801307678223,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6607110500335693,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.6583348512649536,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6580274105072021,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.660711020231247
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.6923441886901855,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6497066020965576,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6410436630249023,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6232705116271973,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6232198476791382,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6192445755004883,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6497065722942352
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7469812631607056,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.6857970952987671,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6771858334541321,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6614513397216797,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6534078121185303,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6494390964508057,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.746981292963028
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 23,
      "accuracy": 0.21739130434782608
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b817842f-6eb5-44e4-8f3b-45c7f80ed914",
      "timestamp": "2025-05-17T21:30:08.055605"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.767869770526886,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.736404538154602,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6318860054016113,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.6286701560020447,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.6163226962089539,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.6145406365394592,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6286701560020447
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.797768771648407,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6904854774475098,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6549791097640991,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6516217589378357,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6351321935653687,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.633875846862793,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.797768771648407
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8162657022476196,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7411586046218872,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7032579183578491,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.6909276247024536,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.679265558719635,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.6791033744812012,
            "answer": "shire",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7032579034566879
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7004594802856445,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6406845450401306,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6209843158721924,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6103200316429138,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6081891059875488,
            "answer": "cockpit",
            "hit": false
          },
          {
            "score": 0.6059975624084473,
            "answer": "shire",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7004594802856445
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.822556734085083,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7281021475791931,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7102618217468262,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6943797469139099,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.6906424760818481,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6890185475349426,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.822556734085083
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.7917014956474304,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7165555953979492,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6678699254989624,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6637173891067505,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.6423994898796082,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.6408035159111023,
            "answer": "cornwall",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.642399474978447
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8109172582626343,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7444825172424316,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7162887454032898,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7009289264678955,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.6932753324508667,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.6895421147346497,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8109172582626343
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.725794792175293,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6090507507324219,
            "answer": "shire",
            "hit": false
          },
          {
            "score": 0.6039513349533081,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.5981369018554688,
            "answer": "well",
            "hit": false
          },
          {
            "score": 0.5979863405227661,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.5968756079673767,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6039513573050499
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7686485648155212,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.6823473572731018,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6557959318161011,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6499395966529846,
            "answer": "london",
            "hit": false
          },
          {
            "score": 0.6475680470466614,
            "answer": "angeles",
            "hit": false
          },
          {
            "score": 0.6455751061439514,
            "answer": "nyc",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686485648155212
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0ee84fa8-8c0c-476f-853b-476c79d3c7d3",
      "timestamp": "2025-05-17T21:30:08.146435"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.6905537247657776,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6615855693817139,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6559756994247437,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6504493951797485,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6493401527404785,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6443065404891968,
            "answer": "greeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.606203243136406
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.6852127909660339,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6469423770904541,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6417129039764404,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6343787908554077,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.630304217338562,
            "answer": "romans",
            "hit": false
          },
          {
            "score": 0.6284254789352417,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6155848652124405
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6685030460357666,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6488909721374512,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6352328658103943,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.6198912858963013,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6198394894599915,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6137721538543701,
            "answer": "victorian",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6488909721374512
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.6438734531402588,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6226863861083984,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6184061169624329,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6116994023323059,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.5991310477256775,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.5978301763534546,
            "answer": "swedish",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6226863712072372
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7115464806556702,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.659921407699585,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6424256563186646,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.639495313167572,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6304881572723389,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6284884810447693,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5848030000925064
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.7383712530136108,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.7324354648590088,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.728692889213562,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7121092677116394,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.6851683259010315,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.6393969058990479,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.73243547976017
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.689644992351532,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6430114507675171,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6248295307159424,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6239692568778992,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6230127811431885,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6214324831962585,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6054531186819077
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6843158602714539,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6466089487075806,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6421849727630615,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6285409927368164,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6208981871604919,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.6083123087882996,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6041945964097977
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.6926605701446533,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6298638582229614,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6241045594215393,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6231191158294678,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6149752736091614,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.6138350963592529,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6926605850458145
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.6467646956443787,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6245741248130798,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6082788705825806,
            "answer": "planetary",
            "hit": false
          },
          {
            "score": 0.6030082106590271,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6026382446289062,
            "answer": "planets",
            "hit": false
          },
          {
            "score": 0.5999281406402588,
            "answer": "scottish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6467646658420563
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.6978880763053894,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6758474111557007,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6578378677368164,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.6510834097862244,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.636602520942688,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.6215444803237915,
            "answer": "communist",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6578378528356552
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.6847723722457886,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6679267287254333,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6453334093093872,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.623568058013916,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6220967173576355,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6203008890151978,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6453333795070648
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6521346569061279,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6406994462013245,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.6348135471343994,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6342512369155884,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6294506788253784,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.6071463823318481,
            "answer": "british",
            "hit": true
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6406994462013245
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7207043170928955,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.6731332540512085,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6288213729858398,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6268014311790466,
            "answer": "bourgeois",
            "hit": false
          },
          {
            "score": 0.6261065006256104,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.6249788403511047,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6731332838535309
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6624783277511597,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6366527080535889,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6279447674751282,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6102433800697327,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6100506782531738,
            "answer": "dutch",
            "hit": false
          },
          {
            "score": 0.6086779832839966,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.58453269302845
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6567121744155884,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6323002576828003,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.620733916759491,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6109887957572937,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.602692723274231,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6023546457290649,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6323002576828003
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.6834425926208496,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6713873147964478,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6595752835273743,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6484889984130859,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6480125188827515,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.644302248954773,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6083802059292793
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.6932798624038696,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6337266564369202,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6328630447387695,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.6327768564224243,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6219944357872009,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.6151435971260071,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6328630149364471
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.6935409307479858,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6406399011611938,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6364636421203613,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6192895174026489,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6116991639137268,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.609812319278717,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6935409307479858
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 19,
      "accuracy": 0.21052631578947367
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7151e404-3a6f-4b10-95a4-80be690fbdf7",
      "timestamp": "2025-05-17T21:30:08.179845"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7460609674453735,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7101083397865295,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6646256446838379,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.6615425944328308,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.6565931439399719,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6454014182090759,
            "answer": "philosophical",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7460609078407288
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7207295894622803,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6547768115997314,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6299021244049072,
            "answer": "romans",
            "hit": false
          },
          {
            "score": 0.6241407990455627,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.6147618293762207,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6110604405403137,
            "answer": "president",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6241408288478851
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.6677533388137817,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6282986402511597,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.6204438209533691,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6089393496513367,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.604414165019989,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6013319492340088,
            "answer": "rochester",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 1989,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5317716971039772
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7025467753410339,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6341277360916138,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.630291223526001,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.608735203742981,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6072547435760498,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6018682718276978,
            "answer": "philosophical",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6302912086248398
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.6674870252609253,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6034613847732544,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.602803111076355,
            "answer": "engineer",
            "hit": false
          },
          {
            "score": 0.6022515296936035,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.598660409450531,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.5964839458465576,
            "answer": "philosophers",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5928772613406181
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.6984444856643677,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6428935527801514,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6323539018630981,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6099714040756226,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.6098644733428955,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.606724739074707,
            "answer": "president",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6428935080766678
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.72902911901474,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.727061927318573,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.6975116729736328,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6710532307624817,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.6523271799087524,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6402885317802429,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6398337185382843
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7146813869476318,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6652412414550781,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6433117389678955,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6211739778518677,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.618327260017395,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.6172444224357605,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7146813571453094
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7202381491661072,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6613709926605225,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6295747756958008,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6249571442604065,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.6195008158683777,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.6063289046287537,
            "answer": "hume",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7202381193637848
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.6831902265548706,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6046227812767029,
            "answer": "presidents",
            "hit": false
          },
          {
            "score": 0.6021476984024048,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6020586490631104,
            "answer": "president",
            "hit": true
          },
          {
            "score": 0.6007614135742188,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.5977230072021484,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6020586043596268
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7063068151473999,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6628961563110352,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6385279893875122,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6108840703964233,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6040558218955994,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.6020117998123169,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7063068151473999
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.7286603450775146,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7169899940490723,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6547210216522217,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.6436368227005005,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.6434363126754761,
            "answer": "communism",
            "hit": false
          },
          {
            "score": 0.643272876739502,
            "answer": "philosophers",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.716990053653717
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.6733543872833252,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6270065903663635,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6105356216430664,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6020034551620483,
            "answer": "electromagnetic",
            "hit": false
          },
          {
            "score": 0.5915648937225342,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.5910509824752808,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6270065754652023
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.6964179873466492,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6387763023376465,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.6343066096305847,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.619892954826355,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.6164954304695129,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6154123544692993,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.594494566321373
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7133865356445312,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6430857181549072,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.636476457118988,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6340261697769165,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.6283245086669922,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6234508156776428,
            "answer": "dictator",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6340261399745941
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7624041438102722,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7194491624832153,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6939741373062134,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.667837381362915,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.6468663811683655,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.6391100883483887,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7624041140079498
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.670965313911438,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6292809247970581,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.627894937992096,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.6213617324829102,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6174759864807129,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.6165992617607117,
            "answer": "nixon",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6148404777050018
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.6925994157791138,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6250892281532288,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6199414134025574,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6061577796936035,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.6049914956092834,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6048367023468018,
            "answer": "emperor",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.604991503059864
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5ae1bb1e-ea40-4c83-9b4e-7f0919c883e5",
      "timestamp": "2025-05-17T21:30:08.253525"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.6567754745483398,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6255794763565063,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6086269021034241,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.5729888677597046,
            "answer": "tape",
            "hit": false
          },
          {
            "score": 0.567157506942749,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.5644763708114624,
            "answer": "cap",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 794,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5175522901117802
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6869721412658691,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6515149474143982,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6505981683731079,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6295166611671448,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6155561208724976,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.5968188047409058,
            "answer": "kid",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6869721710681915
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7098428010940552,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6355831623077393,
            "answer": "albany",
            "hit": false
          },
          {
            "score": 0.6338887810707092,
            "answer": "syracuse",
            "hit": false
          },
          {
            "score": 0.6280074119567871,
            "answer": "pittsburgh",
            "hit": false
          },
          {
            "score": 0.6272940039634705,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.625952959060669,
            "answer": "cleveland",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6272940039634705
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7803952693939209,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7072089910507202,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.655082106590271,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6204655766487122,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.614217221736908,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.6111642718315125,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6550820767879486
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.7280235290527344,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7211273908615112,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6898818016052246,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6703969836235046,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6466113328933716,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.630664587020874,
            "answer": "sheep",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5755214765667915
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6734238862991333,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6535246968269348,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6058334708213806,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.5863086581230164,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.5855493545532227,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.5819389820098877,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6734238862991333
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7492483854293823,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.6892465353012085,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6659924983978271,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6230438351631165,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6192550659179688,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6185080409049988,
            "answer": "babies",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5877997130155563
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8106637001037598,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7441580295562744,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6896266341209412,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6893445253372192,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.667332112789154,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.597815990447998,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5641970634460449
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7722838521003723,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6584087610244751,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6346184015274048,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6106868982315063,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.6052858233451843,
            "answer": "pup",
            "hit": true
          },
          {
            "score": 0.6028648614883423,
            "answer": "kid",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6346183717250824
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.667807936668396,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6572858691215515,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6146648526191711,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6124728918075562,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.6068187952041626,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6051073670387268,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6572858989238739
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7657400369644165,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6982623338699341,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6580614447593689,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6337686777114868,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6291840076446533,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6109951138496399,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6580614447593689
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 11,
      "accuracy": 0.18181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6607baf2-3c18-4841-9763-eedbd563fae5",
      "timestamp": "2025-05-17T21:30:08.323179"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.6529440879821777,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6388296484947205,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6350389719009399,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.579380989074707,
            "answer": "bert",
            "hit": false
          },
          {
            "score": 0.578407347202301,
            "answer": "bane",
            "hit": false
          },
          {
            "score": 0.5774865746498108,
            "answer": "bees",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6350389420986176
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.6720091104507446,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.663740336894989,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6428830027580261,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6336122155189514,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6157191395759583,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6083891987800598,
            "answer": "flying",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.672009140253067
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7526541352272034,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.72267746925354,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.70656418800354,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6684548854827881,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6024293899536133,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.5793411731719971,
            "answer": "stamp",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 11317,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.484968114644289
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7560790181159973,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7235903739929199,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6488775014877319,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6194722652435303,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6156800389289856,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.5961881875991821,
            "answer": "elephant",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 9733,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.49460553005337715
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 4,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8bc4eaa1-2f38-4eb6-a8be-98e530881298",
      "timestamp": "2025-05-17T21:30:08.365174"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.681686282157898,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6279730200767517,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6106080412864685,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.580038845539093,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5797849893569946,
            "answer": "pose",
            "hit": false
          },
          {
            "score": 0.5738443732261658,
            "answer": "ale",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 50,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.512833253480494
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7266373634338379,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.709774374961853,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6482788324356079,
            "answer": "batting",
            "hit": false
          },
          {
            "score": 0.6250125169754028,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6201398372650146,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5961163640022278,
            "answer": "bed",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 114,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5426971614360809
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.698421835899353,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6604009866714478,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.5987991690635681,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5973940491676331,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.5937231779098511,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.5889554619789124,
            "answer": "bore",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5937231630086899
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.7077355980873108,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.6906929612159729,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6717060804367065,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6661370992660522,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6537508964538574,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.6387032866477966,
            "answer": "herd",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5786937922239304
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6526778340339661,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.652437686920166,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.6506925821304321,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6192215085029602,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.6188112497329712,
            "answer": "soccer",
            "hit": false
          },
          {
            "score": 0.6047075986862183,
            "answer": "football",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6506925523281097
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6899552345275879,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.628919243812561,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6177037954330444,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6073241829872131,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5894616842269897,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.5760297775268555,
            "answer": "penn",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6899552792310715
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7478212714195251,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.7211878895759583,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6591833829879761,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6358113288879395,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6188279986381531,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.6157280802726746,
            "answer": "goose",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5520643629133701
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6829603314399719,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6816620826721191,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.6390170454978943,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6205539703369141,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.6175219416618347,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6117827296257019,
            "answer": "flies",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6829603314399719
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6710068583488464,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6365740299224854,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.6094186902046204,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.6076992154121399,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6049911975860596,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.6026582717895508,
            "answer": "den",
            "hit": true
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.602658286690712
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.7549852132797241,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7021941542625427,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.640816330909729,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6314481496810913,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.6227613687515259,
            "answer": "moth",
            "hit": false
          },
          {
            "score": 0.6156313419342041,
            "answer": "den",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7021941840648651
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7008494138717651,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6309043169021606,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6116521954536438,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5934629440307617,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5834337472915649,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.568606972694397,
            "answer": "residence",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5447307527065277
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.750229001045227,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7097362279891968,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6290788054466248,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.619544267654419,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6066665649414062,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.6063438057899475,
            "answer": "donkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5192657150328159
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7557192444801331,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.6703712940216064,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6479868292808533,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6292459964752197,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.615584135055542,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6102285385131836,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6703712940216064
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6626364588737488,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6430875062942505,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6145097017288208,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6009488105773926,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5829864740371704,
            "answer": "mouse",
            "hit": false
          },
          {
            "score": 0.5760335922241211,
            "answer": "ratings",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6626364588737488
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6763206720352173,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6317892074584961,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5972003936767578,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5907803773880005,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.5772110819816589,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.5764178037643433,
            "answer": "trent",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6763206422328949
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6776201128959656,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6228755116462708,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.6109293699264526,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6089705228805542,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.5953537225723267,
            "answer": "zoo",
            "hit": false
          },
          {
            "score": 0.5945850610733032,
            "answer": "tree",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5631913542747498
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.7869203686714172,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.715067446231842,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6412267684936523,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.614876389503479,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.6122209429740906,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6081703305244446,
            "answer": "nesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 75,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5562004148960114
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6992173194885254,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6141138672828674,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.5968824028968811,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.5922485589981079,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.5796046257019043,
            "answer": "hunter",
            "hit": false
          },
          {
            "score": 0.5695471167564392,
            "answer": "lau",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5556919686496258
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1da01027-5f8f-4c58-b8da-1de1710477c8",
      "timestamp": "2025-05-17T21:30:08.388650"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.691109299659729,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6793234348297119,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6602083444595337,
            "answer": "anti",
            "hit": false
          },
          {
            "score": 0.6262887716293335,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6262010931968689,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.5991830229759216,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6793234199285507
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7293173670768738,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7150896191596985,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6258864998817444,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6107311844825745,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6094133257865906,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.605155348777771,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6094133406877518
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7404460906982422,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7176885604858398,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6191298961639404,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6157419085502625,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6147617697715759,
            "answer": "bloody",
            "hit": false
          },
          {
            "score": 0.6098373532295227,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6098373532295227
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.6997019052505493,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6739455461502075,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6489371657371521,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6390960216522217,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6364957094192505,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6096789836883545,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6096790060400963
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.6918302774429321,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.667658805847168,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6359833478927612,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6357017159461975,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6274662017822266,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.624336838722229,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6207178235054016
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7188416123390198,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7088763117790222,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6464297771453857,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6390690207481384,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6300336122512817,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6293184757232666,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6293184757232666
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.6995207667350769,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6871703267097473,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.661069929599762,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6513421535491943,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6390690207481384,
            "answer": "orange",
            "hit": false
          },
          {
            "score": 0.6297818422317505,
            "answer": "pink",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6871703267097473
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7088509798049927,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7044060826301575,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.6673794984817505,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6315765380859375,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6313672065734863,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6081534028053284,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6673795580863953
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7038123607635498,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.664097785949707,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6306928396224976,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6247597932815552,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6156377792358398,
            "answer": "charcoal",
            "hit": false
          },
          {
            "score": 0.6085049510002136,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.664097785949707
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.6968451738357544,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6901897192001343,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6341568827629089,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6167867183685303,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6130315065383911,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6092605590820312,
            "answer": "tea",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.696845144033432
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.689001202583313,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6886553764343262,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.649368405342102,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6415325403213501,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.6299797892570496,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6293590664863586,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.688655361533165
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7002660036087036,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.670378565788269,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6290542483329773,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6122946739196777,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6048344373703003,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6031358242034912,
            "answer": "gray",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.670378565788269
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7964009046554565,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.667789101600647,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6649578809738159,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6145859956741333,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6124955415725708,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.5978774428367615,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6677891612052917
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.6812539100646973,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6510504484176636,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6201508045196533,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6147299408912659,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6139807105064392,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6044492125511169,
            "answer": "pink",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6147299557924271
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.714279055595398,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6985335350036621,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.6623792052268982,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6292014122009277,
            "answer": "whites",
            "hit": false
          },
          {
            "score": 0.6255677938461304,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6210741400718689,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6623792052268982
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7180862426757812,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6821705102920532,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6483067870140076,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6280105113983154,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6261001229286194,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6100578904151917,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6483067870140076
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7487707138061523,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.7057552337646484,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6890772581100464,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6820273399353027,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.6742841005325317,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.6363184452056885,
            "answer": "left",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.606448620557785
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7107153534889221,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6937336921691895,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6396719217300415,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6202255487442017,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6113801002502441,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6083970665931702,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.693733736872673
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.71807861328125,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.666352391242981,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6284703016281128,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.5983483791351318,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.597694993019104,
            "answer": "newspaper",
            "hit": false
          },
          {
            "score": 0.5953435301780701,
            "answer": "papers",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7180786728858948
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7031062841415405,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6982652544975281,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.6934091448783875,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6381352543830872,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6184629201889038,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6159051656723022,
            "answer": "orange",
            "hit": true
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6934091597795486
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.718116044998169,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.7031155228614807,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6791317462921143,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6415464282035828,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.6248323321342468,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6199041604995728,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5719441473484039
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.6928608417510986,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6850553154945374,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6486649513244629,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6282150745391846,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.6185125112533569,
            "answer": "gray",
            "hit": false
          },
          {
            "score": 0.6148102283477783,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6850553452968597
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7163063883781433,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7007912397384644,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6401146650314331,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6321966648101807,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6320264339447021,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6294993162155151,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6294993460178375
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7045049667358398,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7033064365386963,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.625721275806427,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6096370816230774,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6087256073951721,
            "answer": "blacks",
            "hit": false
          },
          {
            "score": 0.6078231334686279,
            "answer": "python",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6018576174974442
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.6988060474395752,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6859192252159119,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6239335536956787,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.620310366153717,
            "answer": "salts",
            "hit": false
          },
          {
            "score": 0.616593062877655,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6054902672767639,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6859192401170731
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6832510828971863,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6544816493988037,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6324252486228943,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6186882853507996,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.616951048374176,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6112392544746399,
            "answer": "seas",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.616951048374176
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6984696388244629,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6877838373184204,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6395487785339355,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.635940432548523,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6253114938735962,
            "answer": "grey",
            "hit": true
          },
          {
            "score": 0.6188478469848633,
            "answer": "blue",
            "hit": true
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6188478618860245
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7065309882164001,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6929901838302612,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6474905014038086,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6471198201179504,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6304371356964111,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6226962208747864,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.692990243434906
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.8031483292579651,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.693006157875061,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6530134677886963,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6305398941040039,
            "answer": "dirt",
            "hit": false
          },
          {
            "score": 0.6216743588447571,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6192600131034851,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6530134379863739
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7087836265563965,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6876661777496338,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.639423131942749,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6319119334220886,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.622627854347229,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6111938953399658,
            "answer": "blacks",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7087836861610413
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7073065042495728,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7008295655250549,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6284513473510742,
            "answer": "sunlight",
            "hit": false
          },
          {
            "score": 0.6149468421936035,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6140173077583313,
            "answer": "mon",
            "hit": false
          },
          {
            "score": 0.6091171503067017,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5799140632152557
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6962193846702576,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6861645579338074,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6233379244804382,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6180444955825806,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6176400184631348,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6081598401069641,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6861645877361298
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7061448693275452,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6626895070075989,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6335669755935669,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6328348517417908,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6181680560112,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.614945650100708,
            "answer": "yellow",
            "hit": true
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6626895219087601
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7306999564170837,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.720447301864624,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7000539302825928,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6598029136657715,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.656619668006897,
            "answer": "orange",
            "hit": false
          },
          {
            "score": 0.6257385015487671,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6146732866764069
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 34,
      "accuracy": 0.23529411764705882
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "999d0456-4f72-48e6-9427-79c433c6bdad",
      "timestamp": "2025-05-17T21:30:08.458470"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.8605858683586121,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.8318070769309998,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.7001383900642395,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.6681916117668152,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6563246250152588,
            "answer": "dancer",
            "hit": false
          },
          {
            "score": 0.6397160291671753,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8605858683586121
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.6997838020324707,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.6917043924331665,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.66485995054245,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6619603037834167,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.6577914953231812,
            "answer": "teenager",
            "hit": false
          },
          {
            "score": 0.6437791585922241,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6917044222354889
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.7375674247741699,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7010754346847534,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6767160892486572,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6750127077102661,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.6729308366775513,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.6689167022705078,
            "answer": "aunt",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6392921954393387
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.603741466999054,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.5875201225280762,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.584367573261261,
            "answer": "kitty",
            "hit": false
          },
          {
            "score": 0.5828837156295776,
            "answer": "cass",
            "hit": false
          },
          {
            "score": 0.5820855498313904,
            "answer": "bow",
            "hit": false
          },
          {
            "score": 0.577006995677948,
            "answer": "bride",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 5199,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5073390854522586
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.6616249084472656,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.6031491756439209,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.5934048891067505,
            "answer": "bulletin",
            "hit": false
          },
          {
            "score": 0.5878217220306396,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.5838658809661865,
            "answer": "cow",
            "hit": true
          },
          {
            "score": 0.5834341049194336,
            "answer": "mill",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5838658660650253
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.6816330552101135,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.6751176714897156,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.657406747341156,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.6497242450714111,
            "answer": "mama",
            "hit": false
          },
          {
            "score": 0.643203854560852,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.6419961452484131,
            "answer": "grandmother",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6816330552101135
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.6923884153366089,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.6412628889083862,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.6353152990341187,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6321283578872681,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6246030926704407,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.6216765642166138,
            "answer": "goddess",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6923884600400925
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.7661627531051636,
            "answer": "mother",
            "hit": true
          },
          {
            "score": 0.7076901197433472,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.703016459941864,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6901779174804688,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.6797233819961548,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.6708363890647888,
            "answer": "mothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7661628127098083
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7589799165725708,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7152312397956848,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.6872204542160034,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.626336932182312,
            "answer": "heaven",
            "hit": false
          },
          {
            "score": 0.6246376037597656,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.6142842173576355,
            "answer": "divine",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.715231254696846
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8436101675033569,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.7741134166717529,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.7177215814590454,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7045618891716003,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7036769986152649,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.6909592747688293,
            "answer": "aunt",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8436101377010345
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.5993494987487793,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.5949536561965942,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.5861409902572632,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.5855584144592285,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.5853267908096313,
            "answer": "glands",
            "hit": false
          },
          {
            "score": 0.582068920135498,
            "answer": "trainer",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5861409977078438
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.7106255292892456,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6672247648239136,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.6619439125061035,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.6595922112464905,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.6516869068145752,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.6508136987686157,
            "answer": "wives",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6672248244285583
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7568866610527039,
            "answer": "ked",
            "hit": false
          },
          {
            "score": 0.5892764329910278,
            "answer": "ling",
            "hit": false
          },
          {
            "score": 0.5796627402305603,
            "answer": "owing",
            "hit": false
          },
          {
            "score": 0.5737125873565674,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.5717869997024536,
            "answer": "walking",
            "hit": false
          },
          {
            "score": 0.5708357691764832,
            "answer": "ting",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5647754892706871
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.6976582407951355,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.6501544713973999,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.611566960811615,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.6033550500869751,
            "answer": "oman",
            "hit": false
          },
          {
            "score": 0.60177081823349,
            "answer": "boy",
            "hit": false
          },
          {
            "score": 0.5929756164550781,
            "answer": "dude",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6976582407951355
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.8494668006896973,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.7594615817070007,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7424919009208679,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7315418720245361,
            "answer": "aunt",
            "hit": false
          },
          {
            "score": 0.7239078283309937,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.6851081848144531,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8494667708873749
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.751733660697937,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7077468633651733,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.6514173746109009,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.642517626285553,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.6296828389167786,
            "answer": "bride",
            "hit": false
          },
          {
            "score": 0.6295397281646729,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7077468633651733
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.6415154933929443,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.620576024055481,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6157714128494263,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.606078565120697,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.6014295816421509,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.591338038444519,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.641515463590622
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.6973578333854675,
            "answer": "aunt",
            "hit": true
          },
          {
            "score": 0.6677489876747131,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.654245138168335,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6509764194488525,
            "answer": "mama",
            "hit": false
          },
          {
            "score": 0.6340801119804382,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.6298373937606812,
            "answer": "papa",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6973578184843063
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 18,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e22e37b3-b7b4-499f-a3d2-af7b2a60147a",
      "timestamp": "2025-05-17T21:30:08.597299"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7356665134429932,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.6317274570465088,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.6249313354492188,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.6239310503005981,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.6173439621925354,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.616051197052002,
            "answer": "gases",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 68,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5626619160175323
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8292571306228638,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.6240238547325134,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.615486204624176,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.6111139059066772,
            "answer": "baggage",
            "hit": false
          },
          {
            "score": 0.6087620854377747,
            "answer": "pouch",
            "hit": false
          },
          {
            "score": 0.6067603230476379,
            "answer": "backpack",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.582687646150589
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6986962556838989,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.634560227394104,
            "answer": "hairs",
            "hit": false
          },
          {
            "score": 0.6125015020370483,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6031246185302734,
            "answer": "eyebrows",
            "hit": false
          },
          {
            "score": 0.6011084318161011,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.5978127121925354,
            "answer": "haired",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6986962556838989
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.8326729536056519,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.6393614411354065,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.6312108635902405,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.6238810420036316,
            "answer": "skin",
            "hit": false
          },
          {
            "score": 0.605556070804596,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.601515531539917,
            "answer": "tissues",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5826497077941895
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7052772641181946,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.6525453329086304,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.6487774848937988,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.6326352953910828,
            "answer": "shoe",
            "hit": false
          },
          {
            "score": 0.6262034177780151,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.6183492541313171,
            "answer": "leather",
            "hit": true
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.618349239230156
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8580494523048401,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.6335322856903076,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6172183156013489,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.6149898767471313,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.6101780533790588,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.6082919239997864,
            "answer": "drinking",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6335322558879852
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.776663064956665,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.6121185421943665,
            "answer": "flour",
            "hit": false
          },
          {
            "score": 0.6061562895774841,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6042520999908447,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.6009011268615723,
            "answer": "vinegar",
            "hit": false
          },
          {
            "score": 0.5979547500610352,
            "answer": "dish",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6061563193798065
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.6464949250221252,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6352970600128174,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.6276055574417114,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.6223030090332031,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.618748664855957,
            "answer": "cigar",
            "hit": false
          },
          {
            "score": 0.6180171370506287,
            "answer": "glass",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 58,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5656692087650299
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6313079595565796,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.6192956566810608,
            "answer": "sofa",
            "hit": false
          },
          {
            "score": 0.6039883494377136,
            "answer": "room",
            "hit": false
          },
          {
            "score": 0.6029665470123291,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5972983241081238,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.5971262454986572,
            "answer": "couch",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5517397150397301
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.7441459894180298,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.630615234375,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.6187453269958496,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6146072745323181,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6142104864120483,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.605213463306427,
            "answer": "golden",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 339,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.544684212654829
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.609061598777771,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.5714926719665527,
            "answer": "alcohol",
            "hit": false
          },
          {
            "score": 0.5713801980018616,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5685893297195435,
            "answer": "ata",
            "hit": false
          },
          {
            "score": 0.5659798979759216,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.5654554963111877,
            "answer": "glass",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 710,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5165378451347351
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.7086182832717896,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6340348720550537,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.628322422504425,
            "answer": "cottage",
            "hit": false
          },
          {
            "score": 0.608494758605957,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6043931245803833,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5998381972312927,
            "answer": "buildings",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5409091264009476
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.5930213332176208,
            "answer": "jem",
            "hit": false
          },
          {
            "score": 0.5758787393569946,
            "answer": "hem",
            "hit": false
          },
          {
            "score": 0.5743550062179565,
            "answer": "ham",
            "hit": false
          },
          {
            "score": 0.5736123919487,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.573040246963501,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5725032687187195,
            "answer": "cargo",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 422,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5249118041247129
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.6284630298614502,
            "answer": "yard",
            "hit": false
          },
          {
            "score": 0.6250038743019104,
            "answer": "hair",
            "hit": false
          },
          {
            "score": 0.6249140501022339,
            "answer": "driveway",
            "hit": false
          },
          {
            "score": 0.6234047412872314,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6101599931716919,
            "answer": "backyard",
            "hit": false
          },
          {
            "score": 0.6095801591873169,
            "answer": "patio",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5993311256170273
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7075803279876709,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.6228626370429993,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.6038665771484375,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.5854228138923645,
            "answer": "glasses",
            "hit": false
          },
          {
            "score": 0.5825884342193604,
            "answer": "lamps",
            "hit": false
          },
          {
            "score": 0.5808521509170532,
            "answer": "optics",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6228626593947411
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.6728301048278809,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.6118841767311096,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.5948945879936218,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.585176408290863,
            "answer": "reflecting",
            "hit": false
          },
          {
            "score": 0.583809494972229,
            "answer": "chronicle",
            "hit": false
          },
          {
            "score": 0.582588255405426,
            "answer": "telegraph",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6118841767311096
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6904292702674866,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.6795477867126465,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6726754307746887,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.6378418803215027,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.6230385303497314,
            "answer": "profits",
            "hit": false
          },
          {
            "score": 0.6160345077514648,
            "answer": "financing",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 49,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5606928989291191
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7718221545219421,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6647311449050903,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6427624821662903,
            "answer": "marine",
            "hit": false
          },
          {
            "score": 0.6392734050750732,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.6315051317214966,
            "answer": "waters",
            "hit": false
          },
          {
            "score": 0.6270442605018616,
            "answer": "water",
            "hit": true
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6270442605018616
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.6790623068809509,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.6271570324897766,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.6244959235191345,
            "answer": "cakes",
            "hit": false
          },
          {
            "score": 0.624178946018219,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.6170201301574707,
            "answer": "flour",
            "hit": true
          },
          {
            "score": 0.6158879399299622,
            "answer": "leather",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6170201450586319
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6069786548614502,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.6034654974937439,
            "answer": "nickel",
            "hit": true
          },
          {
            "score": 0.5968629121780396,
            "answer": "copper",
            "hit": true
          },
          {
            "score": 0.5874210000038147,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.5853312611579895,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.5844749808311462,
            "answer": "tin",
            "hit": true
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5620058476924896
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7176797389984131,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.6107079386711121,
            "answer": "medication",
            "hit": false
          },
          {
            "score": 0.5986008048057556,
            "answer": "medications",
            "hit": false
          },
          {
            "score": 0.5932156443595886,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.589960515499115,
            "answer": "tablets",
            "hit": false
          },
          {
            "score": 0.5867158770561218,
            "answer": "alcohol",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5290365628898144
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.7544864416122437,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.6557952165603638,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.6454063057899475,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.6380308866500854,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6333823204040527,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.6321539282798767,
            "answer": "steel",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5921762883663177
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.6421241760253906,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6200194358825684,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6032192707061768,
            "answer": "water",
            "hit": true
          },
          {
            "score": 0.6029519438743591,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6020497679710388,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.6010837554931641,
            "answer": "ocean",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6032192558050156
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6227447390556335,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.615973949432373,
            "answer": "syrup",
            "hit": false
          },
          {
            "score": 0.5983760952949524,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.5959773659706116,
            "answer": "sugar",
            "hit": false
          },
          {
            "score": 0.5922240614891052,
            "answer": "bowl",
            "hit": false
          },
          {
            "score": 0.5865833759307861,
            "answer": "knife",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5341218709945679
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.6894984245300293,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.5809916853904724,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.579310953617096,
            "answer": "sql",
            "hit": false
          },
          {
            "score": 0.5757346153259277,
            "answer": "columns",
            "hit": false
          },
          {
            "score": 0.5747816562652588,
            "answer": "database",
            "hit": false
          },
          {
            "score": 0.5727732181549072,
            "answer": "from",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5253506656736135
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6298707723617554,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.6085296869277954,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.5788593292236328,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.5675489902496338,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.5672063827514648,
            "answer": "textile",
            "hit": false
          },
          {
            "score": 0.5659117698669434,
            "answer": "snow",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5675490200519562
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.8150901198387146,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.6863270401954651,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.6536498069763184,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6522678136825562,
            "answer": "beers",
            "hit": false
          },
          {
            "score": 0.650978684425354,
            "answer": "grape",
            "hit": true
          },
          {
            "score": 0.6410747766494751,
            "answer": "champagne",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6373727917671204
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.6686353087425232,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.6129751205444336,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6110413074493408,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.6076505184173584,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.5967825651168823,
            "answer": "water",
            "hit": false
          },
          {
            "score": 0.5926411151885986,
            "answer": "glass",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5795377790927887
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 28,
      "accuracy": 0.03571428571428571
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d8411a8b-8535-4de3-954e-141571aa8796",
      "timestamp": "2025-05-17T21:30:08.668684"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.6870719194412231,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.5950467586517334,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.5945045948028564,
            "answer": "hunt",
            "hit": false
          },
          {
            "score": 0.5916587710380554,
            "answer": "wildlife",
            "hit": false
          },
          {
            "score": 0.5878128409385681,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.5842443108558655,
            "answer": "species",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5744372606277466
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7561386227607727,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6173553466796875,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.6164811849594116,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6094833612442017,
            "answer": "lamb",
            "hit": false
          },
          {
            "score": 0.5981568694114685,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.596112072467804,
            "answer": "goat",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5867315977811813
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.5845206379890442,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.5833943486213684,
            "answer": "bus",
            "hit": false
          },
          {
            "score": 0.581264078617096,
            "answer": "circuit",
            "hit": false
          },
          {
            "score": 0.5776234269142151,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.5754866600036621,
            "answer": "circuits",
            "hit": false
          },
          {
            "score": 0.5731784701347351,
            "answer": "cargo",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 3317,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5129430219531059
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7273211479187012,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.713281512260437,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7054851055145264,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6799249649047852,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6664509773254395,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.655079185962677,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6799249798059464
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.7356036901473999,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.7223775386810303,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.6581137776374817,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.6457160711288452,
            "answer": "religious",
            "hit": false
          },
          {
            "score": 0.6304551362991333,
            "answer": "christ",
            "hit": false
          },
          {
            "score": 0.6271919012069702,
            "answer": "evangelical",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5707873776555061
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.7061436176300049,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.6699733734130859,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.6455975770950317,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.637110710144043,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.6364190578460693,
            "answer": "university",
            "hit": true
          },
          {
            "score": 0.6176643967628479,
            "answer": "graduation",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.636419028043747
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.7771292924880981,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6452866792678833,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.6287311315536499,
            "answer": "country",
            "hit": true
          },
          {
            "score": 0.6220903992652893,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.621106743812561,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6193698048591614,
            "answer": "municipalities",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5663341581821442
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.6278181076049805,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.597779393196106,
            "answer": "cowboys",
            "hit": false
          },
          {
            "score": 0.5950177907943726,
            "answer": "bow",
            "hit": false
          },
          {
            "score": 0.594340980052948,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.5877459049224854,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.5856597423553467,
            "answer": "cab",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5852435007691383
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.598751962184906,
            "answer": "crowded",
            "hit": false
          },
          {
            "score": 0.5959482192993164,
            "answer": "crowd",
            "hit": false
          },
          {
            "score": 0.5933213233947754,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.5919640064239502,
            "answer": "crowds",
            "hit": false
          },
          {
            "score": 0.5809537768363953,
            "answer": "crowned",
            "hit": false
          },
          {
            "score": 0.5787544250488281,
            "answer": "swarm",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 13847,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4666438065469265
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8297803997993469,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6347848773002625,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.619749903678894,
            "answer": "camel",
            "hit": false
          },
          {
            "score": 0.6190609335899353,
            "answer": "whale",
            "hit": false
          },
          {
            "score": 0.6122778654098511,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6044451594352722,
            "answer": "horse",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6122778803110123
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.7297515869140625,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.691535472869873,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.6626712083816528,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.6490950584411621,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.6487593650817871,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.646756649017334,
            "answer": "employers",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6225446909666061
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.6911363005638123,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.6494908928871155,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.6483763456344604,
            "answer": "trout",
            "hit": false
          },
          {
            "score": 0.6336058974266052,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.632172703742981,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.6197125315666199,
            "answer": "sharks",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 1492,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.526425376534462
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.646990180015564,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.6172062158584595,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.6125267744064331,
            "answer": "samsung",
            "hit": false
          },
          {
            "score": 0.6120282411575317,
            "answer": "nexus",
            "hit": false
          },
          {
            "score": 0.6002616882324219,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.5991993546485901,
            "answer": "stars",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5792502909898758
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.8206673264503479,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.6416223049163818,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.6047593355178833,
            "answer": "memo",
            "hit": false
          },
          {
            "score": 0.6012471914291382,
            "answer": "emails",
            "hit": false
          },
          {
            "score": 0.5979565382003784,
            "answer": "mail",
            "hit": false
          },
          {
            "score": 0.5918533802032471,
            "answer": "memorandum",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5726238638162613
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.6102064847946167,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.5955612659454346,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.5872650146484375,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.5847911834716797,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.5847094058990479,
            "answer": "golden",
            "hit": false
          },
          {
            "score": 0.5832357406616211,
            "answer": "symphony",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 77,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5541810244321823
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.6553212404251099,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6290119886398315,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.6092824935913086,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.6016805171966553,
            "answer": "congregation",
            "hit": false
          },
          {
            "score": 0.5929509997367859,
            "answer": "handler",
            "hit": false
          },
          {
            "score": 0.5864576697349548,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5696265697479248
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.713028609752655,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6376959681510925,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.5813795328140259,
            "answer": "representatives",
            "hit": false
          },
          {
            "score": 0.5748932361602783,
            "answer": "voting",
            "hit": false
          },
          {
            "score": 0.5743054151535034,
            "answer": "follower",
            "hit": false
          },
          {
            "score": 0.5737788081169128,
            "answer": "staff",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 107,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5501247718930244
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8098896741867065,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.697982668876648,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.6733411550521851,
            "answer": "music",
            "hit": false
          },
          {
            "score": 0.6732192039489746,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.6722939610481262,
            "answer": "musical",
            "hit": false
          },
          {
            "score": 0.6583224534988403,
            "answer": "singers",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.625688225030899
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.6815963387489319,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.6347000002861023,
            "answer": "persona",
            "hit": false
          },
          {
            "score": 0.6245625019073486,
            "answer": "individuals",
            "hit": false
          },
          {
            "score": 0.6229671239852905,
            "answer": "personality",
            "hit": false
          },
          {
            "score": 0.608204185962677,
            "answer": "personnel",
            "hit": false
          },
          {
            "score": 0.6051126718521118,
            "answer": "people",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5553165003657341
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.6530373096466064,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.6377270221710205,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.632756233215332,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.6211046576499939,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.6174073219299316,
            "answer": "photographer",
            "hit": false
          },
          {
            "score": 0.6129867434501648,
            "answer": "photography",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 148,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5480822063982487
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.7168840169906616,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.6790763139724731,
            "answer": "game",
            "hit": false
          },
          {
            "score": 0.6748855113983154,
            "answer": "playing",
            "hit": false
          },
          {
            "score": 0.6382888555526733,
            "answer": "plays",
            "hit": false
          },
          {
            "score": 0.6306037902832031,
            "answer": "play",
            "hit": false
          },
          {
            "score": 0.6296157836914062,
            "answer": "footballer",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 64,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5777342095971107
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.6858184933662415,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.6772257089614868,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.6578772664070129,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6458107233047485,
            "answer": "officer",
            "hit": false
          },
          {
            "score": 0.6337578296661377,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.6301199197769165,
            "answer": "bureaucracy",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6772257387638092
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.6771097183227539,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.6629846096038818,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.6484430432319641,
            "answer": "director",
            "hit": false
          },
          {
            "score": 0.6357080936431885,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.6244757771492004,
            "answer": "president",
            "hit": false
          },
          {
            "score": 0.6181976199150085,
            "answer": "governor",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 281,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5512117855250835
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.7883327603340149,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.7033572793006897,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.6714464426040649,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.6703044176101685,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.6270802021026611,
            "answer": "legislators",
            "hit": false
          },
          {
            "score": 0.6270215511322021,
            "answer": "congressional",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7033572643995285
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.6828490495681763,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.6817480325698853,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.6740654110908508,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6611418724060059,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.6595063209533691,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6483982801437378,
            "answer": "cows",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6038571074604988
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.8376586437225342,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.6791582107543945,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.6726347804069519,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.6661679148674011,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.6562356948852539,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.6457484364509583,
            "answer": "warriors",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6791581958532333
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.6529271006584167,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.6524499654769897,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.6424489617347717,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6390658020973206,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6358237266540527,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.6308133602142334,
            "answer": "marriages",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5544193908572197
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.600862443447113,
            "answer": "states",
            "hit": false
          },
          {
            "score": 0.5966504812240601,
            "answer": "wealth",
            "hit": false
          },
          {
            "score": 0.5861167907714844,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.5846590995788574,
            "answer": "commonwealth",
            "hit": false
          },
          {
            "score": 0.5783194899559021,
            "answer": "level",
            "hit": false
          },
          {
            "score": 0.5782128572463989,
            "answer": "estate",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 449,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5245546568185091
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.7549855709075928,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.6295232176780701,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.6273175477981567,
            "answer": "classmates",
            "hit": false
          },
          {
            "score": 0.6233916282653809,
            "answer": "educational",
            "hit": false
          },
          {
            "score": 0.6221056580543518,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.6192957162857056,
            "answer": "school",
            "hit": true
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5237075351178646
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.7263032793998718,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.6146340370178223,
            "answer": "rees",
            "hit": false
          },
          {
            "score": 0.6081427335739136,
            "answer": "hierarchy",
            "hit": false
          },
          {
            "score": 0.6058902740478516,
            "answer": "heap",
            "hit": false
          },
          {
            "score": 0.6052382588386536,
            "answer": "forest",
            "hit": true
          },
          {
            "score": 0.5854879021644592,
            "answer": "tables",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6052382662892342
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.6278176307678223,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.5912311673164368,
            "answer": "wild",
            "hit": false
          },
          {
            "score": 0.5911076664924622,
            "answer": "rose",
            "hit": false
          },
          {
            "score": 0.5893523693084717,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.5860574841499329,
            "answer": "hughes",
            "hit": false
          },
          {
            "score": 0.5849330425262451,
            "answer": "staff",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 1548,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5270466543734074
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.647545576095581,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.5942633152008057,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.5891801118850708,
            "answer": "verbs",
            "hit": false
          },
          {
            "score": 0.5857019424438477,
            "answer": "language",
            "hit": false
          },
          {
            "score": 0.5856086015701294,
            "answer": "book",
            "hit": false
          },
          {
            "score": 0.5819197297096252,
            "answer": "languages",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5339005701243877
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 32,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c6a1dfd8-6128-47e3-abd4-dfea9b18f816",
      "timestamp": "2025-05-17T21:30:08.783629"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.6418923139572144,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.6277148723602295,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6229695677757263,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.621153712272644,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.5746484994888306,
            "answer": "gears",
            "hit": false
          },
          {
            "score": 0.5701915621757507,
            "answer": "transit",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 238,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5379375703632832
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.6738998889923096,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6428590416908264,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6324461698532104,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6108195781707764,
            "answer": "char",
            "hit": false
          },
          {
            "score": 0.6085513830184937,
            "answer": "tooth",
            "hit": false
          },
          {
            "score": 0.5886767506599426,
            "answer": "bytes",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5580848157405853
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.6466057300567627,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.643842339515686,
            "answer": "combining",
            "hit": false
          },
          {
            "score": 0.6384396553039551,
            "answer": "combination",
            "hit": false
          },
          {
            "score": 0.6259201765060425,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6237051486968994,
            "answer": "combined",
            "hit": false
          },
          {
            "score": 0.6235185265541077,
            "answer": "combines",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 856,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5220930427312851
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.6466392278671265,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6462249755859375,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6439383029937744,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6388989686965942,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6120886206626892,
            "answer": "tooth",
            "hit": false
          },
          {
            "score": 0.5926922559738159,
            "answer": "seat",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 890,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5340496264398098
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ced22f1c-2701-46a2-b01a-d148b78c9057",
      "timestamp": "2025-05-17T21:30:08.924347"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.7116199731826782,
            "answer": "exciting",
            "hit": false
          },
          {
            "score": 0.7098447680473328,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.674475908279419,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.655182957649231,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.6320584416389465,
            "answer": "pleased",
            "hit": false
          },
          {
            "score": 0.6271489858627319,
            "answer": "exhausted",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6119736731052399
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.7085448503494263,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6290883421897888,
            "answer": "cottage",
            "hit": false
          },
          {
            "score": 0.6161001920700073,
            "answer": "palace",
            "hit": true
          },
          {
            "score": 0.6146937608718872,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.6047805547714233,
            "answer": "castle",
            "hit": true
          },
          {
            "score": 0.6042600274085999,
            "answer": "warehouse",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6161001995205879
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.6128216981887817,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6097032427787781,
            "answer": "river",
            "hit": false
          },
          {
            "score": 0.5911825895309448,
            "answer": "acre",
            "hit": false
          },
          {
            "score": 0.5881069898605347,
            "answer": "torment",
            "hit": false
          },
          {
            "score": 0.5861111879348755,
            "answer": "bay",
            "hit": false
          },
          {
            "score": 0.5855565071105957,
            "answer": "agitated",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5204055421054363
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.6509934663772583,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.6451658606529236,
            "answer": "pains",
            "hit": false
          },
          {
            "score": 0.6260854601860046,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.6206733584403992,
            "answer": "headache",
            "hit": false
          },
          {
            "score": 0.6129794120788574,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.6122669577598572,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5681212991476059
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.6367942094802856,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.6142218708992004,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.6111558079719543,
            "answer": "mare",
            "hit": false
          },
          {
            "score": 0.6037063002586365,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6028488874435425,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.5983964800834656,
            "answer": "palace",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6367941945791245
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.6361720561981201,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6157368421554565,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6148773431777954,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6000432372093201,
            "answer": "chelsea",
            "hit": false
          },
          {
            "score": 0.5986278653144836,
            "answer": "marine",
            "hit": false
          },
          {
            "score": 0.5907032489776611,
            "answer": "sail",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6148773431777954
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.777485191822052,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.6352306604385376,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.6294099688529968,
            "answer": "lunch",
            "hit": false
          },
          {
            "score": 0.6172149777412415,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.6105872392654419,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.6063209176063538,
            "answer": "sandwiches",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.603202797472477
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.7222700119018555,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.6707360744476318,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.6219480633735657,
            "answer": "sick",
            "hit": false
          },
          {
            "score": 0.6212087273597717,
            "answer": "sleepy",
            "hit": false
          },
          {
            "score": 0.6163983941078186,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.6138979196548462,
            "answer": "agitated",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6707360446453094
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 8,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "dcee81d3-8b83-4aa1-a27e-1da7c02f9df8",
      "timestamp": "2025-05-17T21:30:08.940696"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.817987322807312,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.77348792552948,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.700553297996521,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.6967519521713257,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.6790180206298828,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.642828643321991,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.817987322807312
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.6172791719436646,
            "answer": "towels",
            "hit": false
          },
          {
            "score": 0.6059563159942627,
            "answer": "towel",
            "hit": false
          },
          {
            "score": 0.6009942293167114,
            "answer": "gown",
            "hit": false
          },
          {
            "score": 0.5969920754432678,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.5957379341125488,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.5949875116348267,
            "answer": "clothing",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5833756700158119
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.6875951886177063,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.6799824833869934,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.6579490303993225,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.6531082987785339,
            "answer": "euros",
            "hit": false
          },
          {
            "score": 0.624122679233551,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.6241132020950317,
            "answer": "pounds",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 61,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5686410665512085
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.7318296432495117,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7258578538894653,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.6900853514671326,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.6816075444221497,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.654568612575531,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.6531572341918945,
            "answer": "dad",
            "hit": true
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6531572043895721
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.6872068643569946,
            "answer": "helps",
            "hit": false
          },
          {
            "score": 0.6778712868690491,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.6757569313049316,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.6226977109909058,
            "answer": "assist",
            "hit": true
          },
          {
            "score": 0.6150705814361572,
            "answer": "assisting",
            "hit": false
          },
          {
            "score": 0.607931911945343,
            "answer": "helpful",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5970470979809761
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.6607675552368164,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.6471704840660095,
            "answer": "intelligence",
            "hit": false
          },
          {
            "score": 0.6326569318771362,
            "answer": "clever",
            "hit": true
          },
          {
            "score": 0.6279138326644897,
            "answer": "smart",
            "hit": true
          },
          {
            "score": 0.6262668967247009,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.6189440488815308,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6326569020748138
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7380550503730774,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.6289678812026978,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.6059303879737854,
            "answer": "gem",
            "hit": true
          },
          {
            "score": 0.6041183471679688,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.5986575484275818,
            "answer": "treasures",
            "hit": false
          },
          {
            "score": 0.5923501253128052,
            "answer": "velvet",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6059303879737854
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.7981202006340027,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.6439796686172485,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.6412200927734375,
            "answer": "statues",
            "hit": false
          },
          {
            "score": 0.6222602725028992,
            "answer": "tomb",
            "hit": false
          },
          {
            "score": 0.6187885999679565,
            "answer": "museum",
            "hit": false
          },
          {
            "score": 0.6101217865943909,
            "answer": "sculpture",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6093042120337486
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.6452468633651733,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.6330894231796265,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.6307617425918579,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.6183075904846191,
            "answer": "fresh",
            "hit": false
          },
          {
            "score": 0.6018754839897156,
            "answer": "novel",
            "hit": false
          },
          {
            "score": 0.5911282896995544,
            "answer": "nova",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 51,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.547841913998127
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.6067640781402588,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.5903311967849731,
            "answer": "packaged",
            "hit": false
          },
          {
            "score": 0.5819100141525269,
            "answer": "import",
            "hit": false
          },
          {
            "score": 0.5798555612564087,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.5747068524360657,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.5642499923706055,
            "answer": "interface",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5284064244478941
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.7007666826248169,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.6627023816108704,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.6536914110183716,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.6460394859313965,
            "answer": "subway",
            "hit": false
          },
          {
            "score": 0.6161107420921326,
            "answer": "tram",
            "hit": false
          },
          {
            "score": 0.6131568551063538,
            "answer": "airline",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7007666677236557
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.7108136415481567,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.6242227554321289,
            "answer": "reasonable",
            "hit": true
          },
          {
            "score": 0.6240074634552002,
            "answer": "reasoned",
            "hit": false
          },
          {
            "score": 0.6191129684448242,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.6097402572631836,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.602912187576294,
            "answer": "logical",
            "hit": true
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6029122099280357
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.7769125699996948,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7473894357681274,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.6321077942848206,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.6274793148040771,
            "answer": "rational",
            "hit": false
          },
          {
            "score": 0.6271873712539673,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.6200495958328247,
            "answer": "satisfactory",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6100237518548965
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.6542693376541138,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.6229280233383179,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6061592698097229,
            "answer": "brock",
            "hit": false
          },
          {
            "score": 0.5940687656402588,
            "answer": "pop",
            "hit": false
          },
          {
            "score": 0.5881277322769165,
            "answer": "stone",
            "hit": true
          },
          {
            "score": 0.5868672728538513,
            "answer": "rap",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5881277471780777
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.7282079458236694,
            "answer": "couch",
            "hit": true
          },
          {
            "score": 0.6594799757003784,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.6381642818450928,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.6320680379867554,
            "answer": "desk",
            "hit": false
          },
          {
            "score": 0.627389132976532,
            "answer": "carpet",
            "hit": false
          },
          {
            "score": 0.6272206902503967,
            "answer": "fireplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7282079458236694
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.6732774972915649,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.6317658424377441,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.597168505191803,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.583621621131897,
            "answer": "layout",
            "hit": false
          },
          {
            "score": 0.5815811157226562,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.5813379287719727,
            "answer": "aesthetics",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5202462375164032
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c285c585-e8f4-4867-9040-d49a8aaf909a",
      "timestamp": "2025-05-17T21:30:08.970315"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.6287667751312256,
            "answer": "before",
            "hit": true
          },
          {
            "score": 0.6175951957702637,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6173255443572998,
            "answer": "afterward",
            "hit": false
          },
          {
            "score": 0.6160954833030701,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.6062844395637512,
            "answer": "last",
            "hit": false
          },
          {
            "score": 0.6048121452331543,
            "answer": "upon",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6287667751312256
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.5786998867988586,
            "answer": "away",
            "hit": false
          },
          {
            "score": 0.5770614743232727,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.5748227834701538,
            "answer": "atop",
            "hit": false
          },
          {
            "score": 0.5744896531105042,
            "answer": "vance",
            "hit": false
          },
          {
            "score": 0.5729998350143433,
            "answer": "output",
            "hit": false
          },
          {
            "score": 0.5703137516975403,
            "answer": "backing",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5770614743232727
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.7579258680343628,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.6640464067459106,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.6438737511634827,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.6205797791481018,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.6160998940467834,
            "answer": "anatomical",
            "hit": false
          },
          {
            "score": 0.6141523718833923,
            "answer": "inferior",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7579258382320404
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.6442307233810425,
            "answer": "after",
            "hit": true
          },
          {
            "score": 0.6280564665794373,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.6142721176147461,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.6132209300994873,
            "answer": "until",
            "hit": false
          },
          {
            "score": 0.6083498597145081,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.6027110815048218,
            "answer": "preceded",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6442306935787201
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.727841854095459,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.7107303738594055,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.6965617537498474,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.6860994100570679,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.6792010068893433,
            "answer": "starts",
            "hit": false
          },
          {
            "score": 0.6768019795417786,
            "answer": "starting",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6209751814603806
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.6708860397338867,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6708712577819824,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.6667145490646362,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.6604629755020142,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.6599246263504028,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.6450651288032532,
            "answer": "deaths",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6074757054448128
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.7939799427986145,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.648261547088623,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.6082819104194641,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.6079606413841248,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.6018297076225281,
            "answer": "diver",
            "hit": false
          },
          {
            "score": 0.6003190875053406,
            "answer": "jump",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 1216,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.530891191214323
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.6946501135826111,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.6758065223693848,
            "answer": "fell",
            "hit": false
          },
          {
            "score": 0.6725301146507263,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.6482315063476562,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.6256066560745239,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.6224559545516968,
            "answer": "spring",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.565156601369381
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7008923292160034,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.6850290298461914,
            "answer": "second",
            "hit": false
          },
          {
            "score": 0.6315212249755859,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.6270719766616821,
            "answer": "fourth",
            "hit": false
          },
          {
            "score": 0.61660236120224,
            "answer": "third",
            "hit": false
          },
          {
            "score": 0.6100560426712036,
            "answer": "last",
            "hit": true
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6100560501217842
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.7460335493087769,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.6575344800949097,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.6107202768325806,
            "answer": "select",
            "hit": false
          },
          {
            "score": 0.587958812713623,
            "answer": "form",
            "hit": false
          },
          {
            "score": 0.5828988552093506,
            "answer": "stimulus",
            "hit": false
          },
          {
            "score": 0.5814098119735718,
            "answer": "outputs",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6575344800949097
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.6961456537246704,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.6719566583633423,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.6339986324310303,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.6171422600746155,
            "answer": "behind",
            "hit": false
          },
          {
            "score": 0.6066268086433411,
            "answer": "indoors",
            "hit": false
          },
          {
            "score": 0.604576826095581,
            "answer": "atop",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.696145623922348
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.6811457276344299,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.6226418614387512,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.6106668710708618,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.6021744012832642,
            "answer": "inner",
            "hit": false
          },
          {
            "score": 0.6007127165794373,
            "answer": "interior",
            "hit": false
          },
          {
            "score": 0.5839775800704956,
            "answer": "generic",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6226418688893318
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.6165964603424072,
            "answer": "mort",
            "hit": false
          },
          {
            "score": 0.6061608195304871,
            "answer": "deadly",
            "hit": false
          },
          {
            "score": 0.5967645645141602,
            "answer": "human",
            "hit": false
          },
          {
            "score": 0.5958204865455627,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.5941900014877319,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.5938513278961182,
            "answer": "assassin",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5941899791359901
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.801712155342102,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.7877735495567322,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7719051837921143,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.713111400604248,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.666494607925415,
            "answer": "occupations",
            "hit": false
          },
          {
            "score": 0.6474530100822449,
            "answer": "inhabited",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6272625923156738
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.6573066711425781,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.616120457649231,
            "answer": "back",
            "hit": false
          },
          {
            "score": 0.606242299079895,
            "answer": "out",
            "hit": false
          },
          {
            "score": 0.6041996479034424,
            "answer": "across",
            "hit": false
          },
          {
            "score": 0.5970669984817505,
            "answer": "behind",
            "hit": false
          },
          {
            "score": 0.5891609787940979,
            "answer": "about",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.56125108897686
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.7258127927780151,
            "answer": "previous",
            "hit": false
          },
          {
            "score": 0.7121467590332031,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.6656098961830139,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.6436119675636292,
            "answer": "initially",
            "hit": false
          },
          {
            "score": 0.6408653259277344,
            "answer": "otherwise",
            "hit": false
          },
          {
            "score": 0.6270662546157837,
            "answer": "beforehand",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6656098961830139
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.81429123878479,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7440966367721558,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7322075963020325,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.6269397139549255,
            "answer": "progressing",
            "hit": false
          },
          {
            "score": 0.6238136887550354,
            "answer": "progressed",
            "hit": false
          },
          {
            "score": 0.6193766593933105,
            "answer": "progresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 254,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5524710565805435
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.8310618996620178,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7653113603591919,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7021041512489319,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.6617441773414612,
            "answer": "decline",
            "hit": false
          },
          {
            "score": 0.6402183175086975,
            "answer": "surge",
            "hit": false
          },
          {
            "score": 0.6399879455566406,
            "answer": "arise",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 55,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5458454787731171
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.7734091281890869,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.7638677358627319,
            "answer": "west",
            "hit": false
          },
          {
            "score": 0.7291518449783325,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.6385339498519897,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.6366708278656006,
            "answer": "southern",
            "hit": false
          },
          {
            "score": 0.6315457820892334,
            "answer": "southwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7291518300771713
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.7063325047492981,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.676810085773468,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.6686249375343323,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.6305898427963257,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.629044771194458,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.6192006468772888,
            "answer": "eastern",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6686249375343323
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.8583446741104126,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.6362786889076233,
            "answer": "against",
            "hit": false
          },
          {
            "score": 0.6333227157592773,
            "answer": "approaching",
            "hit": false
          },
          {
            "score": 0.6138519048690796,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6095027923583984,
            "answer": "favors",
            "hit": false
          },
          {
            "score": 0.6064296960830688,
            "answer": "recognizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 240,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5403120070695877
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.6148394346237183,
            "answer": "none",
            "hit": false
          },
          {
            "score": 0.6075279712677002,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.5925593376159668,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.5907383561134338,
            "answer": "sure",
            "hit": false
          },
          {
            "score": 0.5847495794296265,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.5761802196502686,
            "answer": "open",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6075279414653778
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.8390332460403442,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.7601153254508972,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.6911830902099609,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.6696398854255676,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.6252611875534058,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.6213127970695496,
            "answer": "northwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8390332460403442
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 23,
      "accuracy": 0.2608695652173913
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6e876ac2-71c8-4aac-9a71-09fe585627e4",
      "timestamp": "2025-05-17T21:30:09.031913"
    }
  }
]